{
  "example_idx": 21,
  "reference": "Under review as a conference paper at ICLR 2023\n\nSOCIAL NETWORK STRUCTURE SHAPES INNOVATION: EXPERIENCE SHARING IN RL WITH SAPIENS\n\nAnonymous authors Paper under double-blind review\n\nABSTRACT\n\nHuman culture relies on innovation: our ability to continuously explore how existing elements can be combined to create new ones. Innovation is not solitary, it relies on collective search and accumulation. Reinforcement learning (RL) approaches commonly assume that fully-connected groups are best suited for innovation. However, human laboratory and field studies have shown that hierarchical innovation is more robustly achieved by dynamic social network structures. In dynamic settings, humans oscillate between innovating individually or in small clusters, and then sharing outcomes with others. To our knowledge, the role of social network structure on innovation has not been systematically studied in RL. Here, we use a multi-level problem setting (WordCraft), with three different innovation tasks to test the hypothesis that the social network structure affects the performance of distributed RL algorithms. We systematically design networks of DQNs sharing experiences from their replay buffers in varying structures (fullyconnected, small world, dynamic, ring) and introduce a set of behavioral and mnemonic metrics that extend the classical reward-focused evaluation framework of RL. Comparing the level of innovation achieved by different social network structures across different tasks shows that, first, consistent with human findings, experience sharing within a dynamic structure achieves the highest level of innovation in tasks with a deceptive nature and large search spaces. Second, experience sharing is not as helpful when there is a single clear path to innovation. Third, the metrics we propose, can help understand the success of different social network structures on different tasks, with the diversity of experiences on an individual and group level lending crucial insights.\n\n1\n\nINTRODUCTION\n\nUnlike herds or swarms, human social networks solve different tasks with different topologies (Momennejad, 2022). Human and computational studies show that properties of both the social network structure and task affect the abilities of groups to search collectively: social network structures with high connectivity are better suited for quick convergence in problems with clear global optima (Coman et al., 2016; Momennejad et al., 2019), while partially-connected structures perform best in deceptive tasks, where acting greedily in the short-term leads to missing the optimal solution (Derex & Boyd, 2016; Lazer & Friedman, 2007; Cantor et al., 2021; Du et al., 2021; Adjodah et al., 2019). Despite this evidence, works in distributed reinforcement learning (RL) have focused on fully-connected architectures (Mnih et al., 2016; Horgan et al., 2018; Espeholt et al., 2018; Nair et al., 2015; Christianos et al., 2020; Schmitt et al., 2019; Jaderberg et al., 2018). Here, we test the performance of different social network structures in groups of RL agents that share their experiences in a distributed RL learning paradigm. We refer to such groups as multi-agent topologies, introduce SAPIENS, a learning framework for Structuring multi-Agent toPologies for Innovation through ExperieNce Sharing1, and evaluate it on a deceptive task that models collective innovation.\n\nInnovations represent the expansion of an agent’s behavioral repertoire with new problem-solving abilities and are, therefore, a necessary ingredient of continuous learning (Leibo et al., 2019). They arise from tinkering, recombination and adoption of existing innovations (Sol ́e et al., 2013; Derex & Boyd, 2016) and have been characterized as a type of combinatorial search constrained by semantics\n\n1We provide an implementation of SAPIENS and code to reproduce the simulations we report.\n\n1\n\nUnder review as a conference paper at ICLR 2023\n\ndictating the feasible combinations of innovations (Sol ́e et al., 2013; Derex & Boyd, 2016). We adopt this definition: innovations are a type of collective search task with : a) a multi-level search space, where innovations arise out of recombination of existing ones (Hafner, 2021) b) rewards that increase monotonically with the level of innovation, in order to capture the human intrinsic motivation for progress (Sol ́e et al., 2013).\n\nLaboratory and field studies of human groups have shown that collective innovation is highly contingent on the social network structure (Momennejad, 2022; Migliano & Vinicius, 2022; Derex & Boyd, 2016). The reason for this lies in the exploration versus exploitation dynamics of social networks. High clustering and long shortest path in partially-connected structures help maintain diversity in the collective at the benefit of exploration, while high connectivity quickly leads to conformity, which benefits exploitation (Lazer & Friedman, 2007). Of particular interest are structures that achieve a balance in this trade-off: small-worlds are static graphs that, due a modular structure with long-range connections, achieve both high clustering and small shortest path (Watts & Strogatz, 1998). Another example are dynamic structures, where agents are able to periodically change neighbors (Volz & Meyers, 2007). These two families of graphs have the attractive property that they both locally protect innovations and quickly disseminate good solutions (Derex & Boyd, 2016).\n\nDespite progress on multiple fronts, many open questions remain before we get a clear understanding of how social network structure shapes innovation. On the cognitive science side, computational and human laboratory studies of collective innovation are few and have studied a single task where two innovations are combined to create a new one (Derex & Boyd, 2016; Cantor et al., 2021), while most works study other types of collective search that do not resemble innovation (Mason & Watts, 2012; Mason et al., 2008; Lazer & Friedman, 2007; Fang et al., 2010). Furthermore, laboratory studies have collected purely behavioral data (Mason et al., 2008; Derex & Boyd, 2016), while studies of collective memory have shown significant influence of social interactions on individual memory (Coman et al., 2016), indicating that mnemonic data may be another good source of information. In distributed RL, studies are hypothesizing that the reason why groups outperform single agents not just in terms of speed, but also in terms of performance, is the increased diversity of experiences collected by heterogeneous agents but not explicitly measure it (Nair et al., 2015; Horgan et al., 2018). In this case two steps seem natural: introducing appropriate metrics of diversity, and increasing it, not only through heterogeneity, but also through the social network topology.\n\nTo achieve this we propose SAPIENS, a distributed RL learning framework for modeling a group of agents exchanging experiences according to a social network topology. We study instantiations of SAPIENS where multiple DQN learners (Mnih et al., 2013) share experience tuples from their replay buffers with their neighbors in different static and dynamic social network structures and compare them to other distributed RL algorithms (Mnih et al., 2016; Nair et al., 2015). We employ Wordcraft (Jiang et al., 2020b) as a test-bed and design three custom tasks (Figures 1 and 2) covering innovation challenges of different complexity: (i) a task with a single innovation path to an easy-to-find global optimum. This type of task can be used to model a linear innovation structure, such as the evolution of the fork from knife to having, two-, three- and, eventually four tines. (Sol ́e et al., 2013) and is not a deceptive task. (ii) a task with two paths that individually lead to local optima, but when combined, can merge toward the global optimum. Ispired from previous studies in cognitive science (Derex & Boyd, 2016; Cantor et al., 2021) this task we can capture innovations that were repurposed after their invention, such as Gutenberg’s screw press leading to the print press (Sol ́e et al., 2013). (iii) a task with ten paths, only one of which leads to the global optimum, which captures search in vast spaces. In addition to the two deceptive tasks in Wordcraft, we also evaluate SAPIENS algorithms on a deceptive task implemented in a grid world. We empirically show that the performance of SAPIENS depends on the inter-play between social network structure and task demands. Dynamic structures perform most robustly, converging quickly in the easy task, avoiding local optima in the second task, and exploring efficiently in the third task. To interpret these findings, we propose and compute novel behavioral and mnemonic metrics that quantify, among others, the diversity of experiences.\n\nContributions Our contributions are two-fold. From a cognitive science perspective, SAPIENS is, to our knowledge, the first computational study of hypotheses in human studies relating social network structure to collective innovation, that employs deep RL as the individual learning mechanism. Compared to the simple agent-based models employed by previous computational studies (Lazer & Friedman, 2007; Cantor et al., 2021; Mason & Watts, 2012), deep RL offers three main advantages : i) it enables empirical experiments with more complex test-beds and larger search spaces\n\n2\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 1: (Left) Illustration of an innovation task, consisting of an initial set of elements (Earth, Water) and a recipe book indicating which combinations create new elements. Upon creating a new element the player moves up an innovation level and receives a reward that increases monotonically with levels. (Right) Dynamic social network structures oscillate between phases of low connectivity, where experience sharing takes place within clusters, and high connectivity, where experiences spread between clusters.\n\nii) agents can share their experience by simply exchanging transitions from their respective replay buffers, without requiring ad-hoc mechanisms for copying the behaviors of other agents, such as the majority rule (Lazer & Friedman, 2007; Cantor et al., 2021) iii) by using the replay buffer as a proxy of the memories of agents, we can directly measure properties such as the diversity of experiences that are challenging to estimate with humans. Aside these methodological contributions, as we will see later, our empirical study leads to clear hypotheses for future experiments with humans. From an RL perspective, our work extends upon the distributed RL paradigm by systematically analyzing the effect of static and dynamic social network structures on different types of innovation tasks both in terms of performance and novel behavioral and mnemonic metrics.\n\n2 METHODS\n\n2.1 WORDCRAFT: A TEST-BED FOR INNOVATION\n\nWe perform experiments on Wordcraft (Jiang et al., 2020b), an RL environment inspired from the game Little Alchemy 2 2. As we illustrate on the left of Figure 1, tasks start with an initial set of elements and the player explores combinations of two elements in order to create new ones.\n\nIn Wordcraft one can create different types of tasks using a recipe book (Xvalid), which is a dictionary containing the valid element combinations of two elements and the newly crafted one. In addition to the recipe book, a task requires a reward function Rvalid that returns a scalar reward associated with crafting element z. A valid combination returns a new element and reward only the first time it is chosen. When queried with a non-valid combination, Rvalid returns a reward of zero. Thus, a task can be be described by a tuple (X0, Xvalid, Rvalid, T ), where X0 denotes the initial set of elements and T is the number of time steps available to an agent before the environment resets, and can be modelled as a fully-observable Markov Decision process (see Appendix A).\n\n2.2\n\nINNOVATION TASKS\n\nWe introduce the following concepts to characterize the structure of innovation tasks. An innovation task can contain one or more paths, which can potentially be connected to each other (as in the In our proposed tasks, an innovation path X is defined as a sequence of merging paths task). elements [X1, ..., Xn], where crafting an element Xi (i > 1) requires to combine the previously crafted element Xi−1 and a base element from the initial set. The first element X1 in the sequence requires combining elements from the initial set or from other paths. The innovation level of an element corresponds to the length of the path it belongs to, plus the sum of the path lengths required to craft its first item (0 if the first item is crafted from base elements). For example, the innovation level of A3 in the single path task is 3, while the innovation level of element C1 in the merging paths task is 5 (1 on C + 2 on A + 2 on B). Within an innovation task, the trajectory of an agent is defined\n\n2https://littlealchemy2.com/.\n\n3\n\nEarthWaterMud++==MudFireBricks+=BricksCementHouseLevel 1Level 2Level 3Reward 2Reward 5Reward 7Sparse connectivityHigh connectivitySparse connectivityHigh connectivityTimeUnder review as a conference paper at ICLR 2023\n\nFigure 2: We introduce three innovation tasks called single path, merging paths and best-of-ten paths, described in Section 2.2. Each task contains one or more paths, labeled by an uppercase letter (A to J). Each path X has its own initial set of three base elements {x1, x2, x3}, which are represented in dashed circles. Crafted elements in path X are represented in upper case (Xi) in solid circles. Optimal trajectories for each tasks are represented by solid red arrows, with their corresponding reward in bold red.\n\nas the sequence of crafted elements it produces. Finally, the optimal trajectory of an innovation task is the trajectory that returns the highest cumulative reward within the problem horizon T . We design three innovation tasks, shown in Figure 2, that pose different challenges:\n\nSingle innovation path The initial set contains three elements (Xvalid = {a1, a2, a3}) and . An agent needs to first combine two of them to create the first element and then progresses further by combining the most recently created element with an appropriate one from the initial set. This optimization problem contains a single global optimum.\n\nMerging paths There are two paths, A and B, and at level 2 there is a cross-road that presents the player with three options: moving forward to the end path A, moving forward to the end of path B, or combining elements from path A and B to progress on path C. The latter is more rewarding and is, thus, the optimal choice. This task is particularly challenging because the player needs to avoid two local optima before finding the global optimum.\n\nBest-of-ten paths Here, one of the ten paths is the most rewarding, but, to find it, the player must first explore and reject the other nine paths. This optimization task is characterized by a single global optimum and 9 local one and its challenge lies in its large search space.\n\n2.3 LEARNING FRAMEWORK\n\nSAPIENS considers a group of K DQN agents, where each agent interacts with its own copy of the environment and can share experiences with others. An undirected graph G, with nodes indicating agents and edges indicating that two agents share experiences with each other, determines who shares information with whom . We define the neighborhood of agent k, Nk, as the set of nodes connected to it. At the end of each episode the agent shares experiences with each of its neighbors with probability ps: sharing consists of sampling a subset of experiences of length Ls from its own buffer Bk and inserting it in the buffers of all neighbors Bn, n ∈ Nk. Thus, an agent communicates distinct experiences with each of its neighbors. We present a schematic of two DQN agents sharing\n\n4\n\nCombinationInnovation level 1238ResultReward......1238Single pathMerging pathsBest-of-ten paths...1238...58............814++==...1238......1238...281020...1238Path AMerged path CPath APath BPath BPath APath J......++++====a1A1A2A2A8A3A7A1...a2a3a1a3......++++====a1A1A2A2A8A3A7A1...a2a3a1a3......++++====a1A1A2B2C3C1C4A2A2A8A3A7A1...a2c3a3a1a3......++++====b1B1B2B2B8B3B7B1...b2b3b1b3......++++====b1B1B2B2B8B3B7B1...b2b3b1b3......++++====j1J1J2J2J8J3J7J1...j2j3j1j3xiith base element in path Xxiith crafted element in path XReuse of a crafted element in a non-optimal trajectoryReuse of a crafted element in an optimal trajectoryUnder review as a conference paper at ICLR 2023\n\nFigure 3: (Left) Social network structures (a) fully-connected (b) small-world (c) ring (d) dynamic. (Right) Schematic of two neighboring DQNs sharing experiences: agent 1 shares experiences from its own replay buffer to that of agent 2 (red arrow) and vice versa (blue arrow) while both agents are independently collecting experiences by interacting with their own copy of the environment.\n\nexperiences on the right of Figure 3 and the pseudocode of SAPIENS in Appendix C. We also provide more implementation details about the DQN in Appendix A.\n\nThus, SAPIENS is a distributed RL learning paradigm where all agents are both actors and learners, a setting distinct from multi-agent RL (Garnelo et al., 2021; Christianos et al., 2020; Jiang et al., 2020a), where agents co-exist in the same environment and from parallelised RL (Steinkraus et al., 2005), where there need to be multiple agents. It should also be distinguished from distributed RL paradigms with a single learner and multiple actors (Horgan et al., 2018; Espeholt et al., 2018; Nair et al., 2015; Garnelo et al., 2021), as multiple policies are learned simultaneously.\n\nWe visualize the social network structures studied in our work on the left of Figure 3: fullyconnected, small-world, ring and dynamic. We construct the latter by grouping the agents in pairs and then allowing agents to visit other groups for a pre-determined duration, Tv with probability pv. This is a common type of dynamic topology that has been used in human laboratory and field studies (Derex & Boyd, 2016; Migliano & Vinicius, 2022) and thoeretically studied (Volz & Meyers, 2007). We provide more information about it in Appendix D, where we study how its behavior changes with different values of its hyper-parameters Tv, pv. We also present and analyze an alternative type of dynamic topology where the group oscillates between phases of full and no connectivity.\n\n2.4 EVALUATION FRAMEWORK\n\nDuring evaluation trials with experience sharing deactivated, we measure the quality of the final solution and the convergence speed. In addition, we define metrics that are not directly related to performance but can help us analyze the effect of social network structure. These are behavioral metrics, characterizing the policies followed by the agents, and mnemonic metrics, characterizing the replay buffers of agents, either at an individual or group level.\n\nPerformance-based metrics: (i) S, group success, a binary variable denoting whether at least one agent in a group found the optimal solution (ii) R+ t : the maximum reward of the group at training step t; (iii) R∗ t : the average reward of the group at training step t; (iv) T +, Time to first success: the first training step at which at least one of the agents found the optimal solution; (v) T ∗, Time to all successes: the first training step at which all of the agents found the optimal solution (vi) T >, Spread time: number of training steps required for the optimal solution to spread to the whole group, once at least one member discovered it (equals T ∗ − T +).\n\nBehavioral metrics: (i) conformity Ct denotes the percentage of agents in a group that end up with the same element at the end of a given evaluation trial. Thus, agents conform to each other even if they follow alternative trajectories.; (ii) volatility Vt is an agent-level metric that denotes the cumulative number of changes in the trajectory followed by an agent across episodes.\n\nMnemonic metrics: (i) diversity Dk experiences in an agent’s replay buffer; (ii) DG the aggregated group buffer..\n\nt is an agent-level metric that denotes the number of unique t is a group-level metric that captures the diversity of\n\n5\n\n(a)(b)(c)(d)Visit startVisit endIndependentgroupsAgent 1Buffer 1Q1Agent 2Q2Env 1Buffer 2Env 2Under review as a conference paper at ICLR 2023\n\n3 RESULTS\n\nWe now evaluate the social network structures presented in Figure 3 on the innovation tasks described in Section 2.2 and visualized in Figure 2. Specifically, methods ring, small-world, dynamic and fully-connected are instantiations of SAPIENS for different social network structures with 10 DQNs where shared experiences are sampled randomly from the replay buffers. We benchmark SAPIENS against: a) no-sharing, a setting with 10 DQN agents without experience sharing b) single, a single DQN agent c) A2C, a distributed policy-gradient algorithm where 10 workers share gradients with a single (Mnih et al., 2016) and d) Ape-X, a distributed RL algorithm with 10 workers that share experience samples with a single DQN learner (Horgan et al., 2018). To test for statistical significance we perform ANOVA for multiple and Tukey range tests for pairwise comparisons. We refer readers to Appendix E for more information about our experimental setup, including tables 2, 2 and 2 that contain the means and standard deviations for evaluation metrics in the three tasks.\n\n3.1 OVERALL COMPARISON\n\nIn Figure 4 we compare methods across tasks in terms of group success S and Time to first success T +, where we also indicate statistically significant pairwise comparisons with asterisks (more asterisks denote higher significance).\n\nWe observe that performance varies across tasks and topologies. The single path task is optimally solved by all methods, except for single and Ape-X, which failed in 20% and 15% of the trials respectively due to slow convergence. ANOVA showed no significant difference in terms of group success S (p = 0.43) but methods differed significantly in terms of T + (p = 0.2e−13). In particular, single is significantly slower than all other methods (T + = 648e3 for single) and A2C is significantly quicker than other methods (T + = 36200 for A2C), with the Tukey’s range test indicating significance with p = 0.001 for all pairwise comparisons with these two methods. This is in agreement with the expectation that a single agent learns slower due to having less data and that the policy-gradient algorithm A2C is more sample efficient than value function algorithms like DQNs. In the merging paths task there were significant differences among methods both for group success S ( p = 0.4e−4) and convergence speed T + (p = 0.0095). The group success of dynamic (S = 0.65) is significantly higher compared to Ape-X (S = 0.05, p = 0.001), A2C (S = 0.0, p = 0.00101), fully-connected (S = 0.0, p = 0.00101) and ring (S = 0.2, p = 0.0105). The single, no-sharing and small-world structures performed comparably well, but did not show statistically significant differences with other methods. In terms of T +, we see that dynamic is quicker than other methods with positive S, which leads to it being the only method with statistically significant differences with Ape-X (p = 0.0292), fully-connected (p = 0.0421) and A2C (p = 0.0421), the methods that failed in almost all trials and hence have T + equal to the budget of the experiment. Thus, our main conclusion in the merging-paths task is that methods with fully-connected topologies (fully-connected, A2C, Ape-X) fail dramatically and that the dynamic structure succeeds with higher probability. Finally, in the best-of-ten paths task, differences are also significant both for T + (p = 0.9e−7) and S (p = 0.15e−6). Here, dynamic outperforms all methods in terms of S with all Tukey range tests indicating significance with p = 0.001, which leads to it also having significantly higher convergence rate (T + = 14e6 for dynamic) compared to the other methods that exhausted their time budget.\n\nIn additional experiments we have also: a) observed that these conclusions are consistent across group sizes, with increasing sizes leading to better performance in partially-connected and worse in fully-connected structures (see Appendix E.5) b) observed a drop in performance under prioritized experience sharing (Souza et al., 2019; Horgan et al., 2018), where the DQNs employ prioritized replay buffers (Schaul et al., 2016) and experiences with higher priority are shared more often (see Appendix E.6). In agreement with previous works (Souza et al., 2019), we observe that performance degrades in all methods that share experiences. This does not happen for no-sharing, which indicates that prioritized experiences are detrimental only when they are shared. To address this, agents can recompute priorities upon receiving them from other agents to ensure they agree with their own experience (Horgan et al., 2018). c) analyzed how the performance of dynamic varies with its hyperparameters and derived suggestions for tuning it (see Appendix D) d) monitored the robustness of social network structures to different learning hyper-parameters and observed that dynamic is more robust than fully-connected and no-sharing (see Appendix E.4) e) measured alignment of experiences within and across groups that further support our hypothesis that the content of replay buffers\n\n6\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 4: Overall performance comparison for the single path (first column), merging paths (second column) and best-of-ten paths (third column) task in terms of group success (S) (top row) and Time to first success (T +) (bottom row).\n\nis highly contingent on the social network structure (see Appendix E.3) f) performed simulations in another deceptive test-bed and derived similar conclusions to what we observed in Wordcraft, namely that partially-connected structures are better at avoiding local optima (See Appendix E.7) g) tested for the robustness of SAPIENS methods to the amount of sharing (hyper-parameters Ls and ps introduced in Section 2.3) in Appendix E.8, where we observe sub-optimal performance for low amounts of sharing in dynamic and for large shared batches in fully-connected structures. To explain the differences for SAPIENS under different structures we now study each task in isolation for nosharing, fully-connected, ring, small-world and dynamic, focusing on the behavioral and mnemonic metrics described in Section 2.4.\n\n3.2 TASK: SINGLE PATH\n\nPrevious human (Mason et al., 2008) and computational (Lazer & Friedman, 2007) studies have indicated that, when it comes to problems with a single global optimum, fully-connected topologies perform best. Our analysis here, however, indicates no statistically significant difference between methods: the fully-connected topology was actually the slowest (T + = 311e3). To shed light into this behavior, we turn towards diversity and volatility. We compare average individual diversity ( ̄Dt) and group diversity DG t , where for each method we create two samples by looking at these two metrics at the timestep at which diversity starts decreasing. ANOVA tests indicate that differences are significant both for ̄DT + (p = 0.16e−8), where all pairwise comparisons are significant based on the Tukey range test, and DG t (p = 0.0005), where the significantly different pairs are (no-sharing, dynamic, p = 0.02), (dynamic, fully-connected, p = 0.001), (dynamic, small-world, p = 0.0087), (fully-connected, ring, p = 0.008476). Intuitively, fully-connected exhibits the highest average individual diversity ̄Dt (left in Figure 5) and the lowest group diversity DG t (left in Figure 5): sharing experiences with others diversifies an individual’s experiences but also homogenizes the group.\n\nThis task does not require group diversity, but we expect that high individual diversity should be indicative of quicker exploration. So why does the higher ̄Dt of fully-connected not act to its benefit? To answer this we turn to volatility Vt (top left of Figure 5) and observe that it is highest for the fully-connected topology. We tested for statistically significant differences among methods in terms of volatility at convergence (VTtrain ) and found that these pairs differ significantly: (small-world, ring, p = 0.002387), (small-world, dynamic, p = 0.001), (small-world, no-sharing,p = 0.001), (small-world, fully-connected, p = 0.001), (ring, fully-connected, p = 0.001), (dynamic, fullyconnected, p = 0.001) and (no-sharing, fully-connected, p = 0.001). We hypothesize that the higher individual diversity and volatility of the fully-connected structure are linked and indicate that, although experience sharing helps speed up exploration, it also destabilizes agents, so that no\n\n7\n\n0.00.51.01.52.0, Group successSingle path0.00.51.01.52.0*********Merging paths0.00.51.01.52.0*********************Best-of-ten paths0.00.51.01.52.02.53.0T+, Time to first success1e6********************************0.00.51.01.52.02.53.01e7***singleno-sharingdynamicfully-connectedringsmall-worldA2CApe-X01231e7*********************Under review as a conference paper at ICLR 2023\n\nFigure 5: Analyzing group behavior: (Left) Average Diversity ̄Dt in the single path task (Right) Average volatility (Vt) (top row) and Group Diversity DG t (bottom row) in the single path task (first column), merging paths task (second column) and best-of-10 paths task (third column) in term sof\n\nnet gain is observed in terms of convergence rate. Notably the fact that experience sharing degrades performance in RL has been observed but not understood (Souza et al., 2019; Schmitt et al., 2019), while as we see here, this becomes possible by analyzing diversity and volatility.\n\n3.3 TASK: MERGING PATHS\n\nThe hypothesis that motivated this task was that partially connected groups will perform better than fully-connected structures due to their ability to explore diverse trajectories and avoid the two local optima (Derex & Boyd, 2016). This was indeed the case as we saw in our discussion of Figure 4 in Section 3.1. If we also look at the diversities in this task, then we see that the group diversity DG of fully connected (illustrated in the middle bottom plot in Figure 5) differs significantly to the one of (no-sharing, p = 0.001), (ring, p = 0.0067) and dynamic (p = 0.0177). The group diversity in small-world, which was relatively successful (S = 0.3), follows that of the other partially connected structures but peaks at a lower level (DG ≈ 1700). We believe that this is due to the dual ability of this topology to both protect and spread information and that its diversity and performance will improve as we increase the size of the group, enabling higher clustering (we illustrate this behavior in Figure 15 in Appendix E.5 where we increase the size of groups to 50 agents).\n\n3.4 TASK: BEST-OF-TEN PATH\n\nWhich social network topology works best in large search spaces? Our analysis in Figure 4 clearly indicates that dynamic achieves the highest performance. Differently from the two previous tasks where fully-connected exhibited the highest volatility, dynamic and ring, the topologies with the lowest number of connections, are the most volatile here (top row of Figure 5), as agents in them are exploring quickly and, hence, performing better. In terms of group diversity, we found that no-sharing scored significantly lower than all other methods with p = 0.001, the small-world surpassed all methods, with its difference from dynamic being marginally statistically significant and fully-connected did not score last. Thus, differently from the other two tasks with small search spaces, quick spreading of information increases group diversity here. However, to solve the task quickly, group diversity needs to be combined with quick, local exploitation of the optimal path, which is possible under structures with large shortest path, such as dynamic and ring. Another interesting observation here and in the single-path task is that dynamic is the only structure that exhibits significantly higher group diversity than no-sharing, indicating that it fosters group exploration.\n\n4 RELATED WORK\n\nIn distributed RL, shared information has the form of experience tuples or gradients, with the former being preferred due to instabilities and latency concerns in the latter (Horgan et al., 2018; Mnih et al., 2016; Schmitt et al., 2019; Nair et al., 2015; Garnelo et al., 2021). A common social network struc-\n\n8\n\n0246Training step, t1e50100200300400Average Diversity, Dtno-sharingdynamicfully-connectedringsmall-world0.00.51.0Training step, t1e6246Average Volatility, Vt0.51.0Training step, t1e601230.51.0Training step, t1e6123no-sharingdynamicfully-connectedringsmall-world0.00.51.0Training step, t1e60.00.51.0Group divesrity, Dt1e30.00.51.0Training step, t1e60121e30.00.51.0Training step, t1e60.02.55.01e3Under review as a conference paper at ICLR 2023\n\nture is that of multiple actors and a single learner (Mnih et al., 2016; Horgan et al., 2018; Schmitt et al., 2019; Garnelo et al., 2021), while the Gorila framework (Nair et al., 2015) is a more general multi-learner architecture, that differs from ours as agents are sharing parameters. Networked Evolutionary Strategies (NetES) consider the effect of network structure on evolutionary strategies (Adjodah et al., 2019), where multiple actors share gradients with a single learner. NetES was applied on continuous control tasks that differ from our deceptive and discrete innovation tasks. In MARL, social network structure determines who co-exists with whom in the environment (Garnelo et al., 2021) or which agents in its neighborhood an agent attends to (Jiang et al., 2020a; Du et al., 2021). Here, dynamic topologies that are adapted to maximize a group’s reward have been shown to maximize strategic diversity (Garnelo et al., 2021) and help the agents coordinate on demand (Du et al., 2021). In contrast, our dynamic topologies vary periodically independently of the group’s performance, which is important for avoiding local optima. In population-based training, policies are compared against the whole population, thus only considering a fully-connected social network structure (Jaderberg et al., 2018). Admittedly, the literature on the effect of social network structure on collective search is diverse, with different fields making different design choices; to illustrate this we provide a non-exhaustive summary of our literature review in Table 1 of Appendix B.\n\n5 DISCUSSION AND FUTURE WORK\n\nWe tested the hypothesis that the social network structure of experience sharing can shape the performance of a group of RL agents using our proposed learning framework, SAPIENS, and showed that, in line with human studies, both social network topology and task structure affect performance. Based on our experimental results, we can provide general recommendations on which topology to use for which task class. In the single-path task, an instance of a class of tasks with no strong local optima (similarly to long-horizon tasks (Gupta et al., 2019)), our results show no benefit of experience sharing. In the merging-path task which exhibits strong local optima that have to be explored up to a certain point in order to discover the global optimum (in the spirit of hard exploration tasks (Baker et al., 2022; Ecoffet et al., 2021)), our results show that topologies with low initial connectivity (such as no-sharing, small world and dynamic) perform best. The dynamic topology shows the highest performance, allowing different groups to explore non-optimal paths before sharing their experience during visits to other groups to find the optimal one. Finally, in the case of large search space with many local optimas (in the spirit of combinatorial optimization tasks (Mazyavkina et al., 2021)), our results show that the dynamic topology performs best, allowing different groups to first explore different paths, then spread the optimal solution to other groups once discovered.\n\nWhen adopting RL algorithms as computational models for replicating experiments with humans, one needs to acknowledge that their communication and decision-making mechanisms may not faithfully replicate the ones used by humans. One notable difference is that humans may exhibit normative behavior, adopting information not for its utility in the task but for social approval (Mason et al., 2008). From an RL perspective, our study is limited in including experiments only in a few symbolic tasks and a simple navigation task; in the future we plan to study more complex environments like Crafter (Hafner, 2021).\n\nWe hope that our work will contribute to the fields of cognitive science and DRL in multiple ways. First, our empirical observations in the single path and best-of-ten-path tasks provide concrete hypotheses for future experiments studying human innovation, which has so far been studied only in a task that inspired our merging-paths task (Derex & Boyd, 2016). By continuing the dialogue that has been initiated between human and computational studies (Fang et al., 2010; Lazer & Friedman, 2007; Cantor et al., 2021) to include DRL methods, we believe that cognitive science will benefit from tools that, as we show here, can learn in realistic problem set-ups and can be analyzed not just in terms of their behavior, but also in terms of their memories. Second, we hope that studies in distributed RL will extend their evaluation methodology by analyzing not just rewards, but also behavioral and mnemonic metrics such as diversity, conformity and volatility that, as we show here, correlate with success. Aside this, the effect of social network structure in distributed RL can be extended beyond evolutionary strategies (Adjodah et al., 2019) and beyond our current instantiation of SAPIENS, by considering other off-policy algorithms than DQNs and other types of information sharing. Finally, considering the effectiveness of the dynamic topologies observed in this study, we envision future works that investigate more types of them, as well as meta-learning or onlineadaptation algorithms where the social network structure is optimized for a desired objective.\n\n9\n\nUnder review as a conference paper at ICLR 2023\n\nREFERENCES\n\nDhaval Adjodah, Dan Calacci, Abhimanyu Dubey, Anirudh Goyal, Peter M. Krafft, Esteban Moro, and Alex Pentland. Communication topologies between learning agents in deep reinforcement learning. CoRR, abs/1902.06740, 2019. URL http://arxiv.org/abs/1902.06740.\n\nBowen Baker, Ilge Akkaya, Peter Zhokhov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon Houghton, Raul Sampedro, and Jeff Clune. Video pretraining (vpt): Learning to act by watching unlabeled online videos. arXiv preprint arXiv: Arxiv-2206.11795, 2022.\n\nPhilip Bontrager, Ahmed Khalifa, Damien Anderson, Matthew Stephenson, Christoph Salge, and Julian Togelius. Superstition in the network: Deep reinforcement learning plays deceptive games. CoRR, abs/1908.04436, 2019. URL http://arxiv.org/abs/1908.04436.\n\nMauricio Cantor, Michael Chimento, Simeon Q. Smeele, Peng He, Danai Papageorgiou, Lucy M. Aplin, and Damien R. Farine. Social network architecture and the tempo of cumulative cultural evolution. Proceedings of the Royal Society B: Biological Sciences, 288(1946):20203107, March 2021. doi: 10.1098/rspb.2020.3107. URL https://royalsocietypublishing.org/ doi/10.1098/rspb.2020.3107. Publisher: Royal Society.\n\nFilippos Christianos, Lukas Sch ̈afer, and Stefano Albrecht. Shared experience actor-critic for multiagent reinforcement learning. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 10707–10717. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/ file/7967cc8e3ab559e68cc944c44b1cf3e8-Paper.pdf.\n\nAlin Coman, Ida Momennejad, Rae D Drach, and Andra Geana. Mnemonic convergence in social networks: The emergent properties of cognition at a collective level. Proc. Natl. Acad. Sci. U. S. A., 113(29):8171–8176, July 2016.\n\nMaxime Derex and Robert Boyd. Partial connectivity increases cultural accumulation within groups. Proceedings of the National Academy of Sciences, 113(11):2982–2987, March 2016. ISSN 00278424, 1091-6490. doi: 10.1073/pnas.1518798113. URL http://www.pnas.org/lookup/ doi/10.1073/pnas.1518798113.\n\nYali Du, Bo Liu, Vincent Moens, Ziqi Liu, Zhicheng Ren, Jun Wang, Xu Chen, and Haifeng Zhang. Learning Correlated Communication Topology in Multi-Agent Reinforcement learning. In Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems, AAMAS ’21, pp. 456–464, Richland, SC, May 2021. International Foundation for Autonomous Agents and Multiagent Systems. ISBN 978-1-4503-8307-3.\n\nMarina Dubova, Arseny Moskvichev, and Robert Goldstone. Reinforcement Communication Learning in Different Social Network Structures. arXiv:2007.09820 [cs], July 2020. URL http://arxiv.org/abs/2007.09820. arXiv: 2007.09820.\n\nRobin I. M. Dunbar. How conversations around campfires came to be. Proceedings of the National Academy of Sciences, 111(39):14013, September 2014. doi: 10.1073/pnas.1416382111. URL http://www.pnas.org/content/111/39/14013.abstract.\n\nAdrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O Stanley, and Jeff Clune. First return, then\n\nexplore. Nature, 590(7847):580–586, 2021.\n\nLasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymir Mnih, Tom Ward, Yotam Doron, Vlad Firoiu, Tim Harley, Iain Dunning, Shane Legg, and Koray Kavukcuoglu. IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures. Technical Report arXiv:1802.01561, arXiv, June 2018. URL http://arxiv.org/abs/1802. 01561. arXiv:1802.01561 [cs].\n\nChristina Fang, Jeho Lee, and Melissa Schilling. Balancing Exploration and Exploitation Through Structural Design: The Isolation of Subgroups and Organizational Learning. Organization Science, 21:625–642, June 2010. doi: 10.1287/orsc.1090.0468.\n\n10\n\nUnder review as a conference paper at ICLR 2023\n\nMarta Garnelo, Wojciech Marian Czarnecki, Siqi Liu, Dhruva Tirumala, Junhyuk Oh, Gauthier Gidel, Hado van Hasselt, and David Balduzzi. Pick your battles: Interaction graphs as populationlevel objectives for strategic diversity. CoRR, abs/2110.04041, 2021. URL https://arxiv. org/abs/2110.04041.\n\nAbhishek Gupta, Vikash Kumar, Corey Lynch, Sergey Levine, and Karol Hausman. Relay policy learning: Solving long-horizon tasks via imitation and reinforcement learning. In Leslie Pack Kaelbling, Danica Kragic, and Komei Sugiura (eds.), 3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 - November 1, 2019, Proceedings, volume 100 of Proceedings of Machine Learning Research, pp. 1025–1037. PMLR, 2019. URL http: //proceedings.mlr.press/v100/gupta20a.html.\n\nDanijar Hafner. Benchmarking the spectrum of agent capabilities. arXiv preprint arXiv:2109.06780,\n\n2021.\n\nDan Horgan, John Quan, David Budden, Gabriel Barth-Maron, Matteo Hessel, Hado van Hasselt, and David Silver. Distributed Prioritized Experience Replay. arXiv:1803.00933 [cs], March 2018. URL http://arxiv.org/abs/1803.00933. arXiv: 1803.00933.\n\nMax Jaderberg, Wojciech M. Czarnecki, Iain Dunning, Luke Marris, Guy Lever, Antonio Garc ́ıa Casta ̃neda, Charles Beattie, Neil C. Rabinowitz, Ari S. Morcos, Avraham Ruderman, Nicolas Sonnerat, Tim Green, Louise Deason, Joel Z. Leibo, David Silver, Demis Hassabis, Koray Kavukcuoglu, and Thore Graepel. Human-level performance in first-person multiplayer games with population-based deep reinforcement learning. CoRR, abs/1807.01281, 2018. URL http://arxiv.org/abs/1807.01281.\n\nJiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu. Graph Convolutional Reinforcement Learning. Technical Report arXiv:1810.09202, arXiv, February 2020a. URL http://arxiv. org/abs/1810.09202. arXiv:1810.09202 [cs, stat].\n\nMinqi Jiang, Jelena Luketina, Nantas Nardelli, Pasquale Minervini, Philip H. S. Torr, Shimon Whiteson, and Tim Rockt ̈aschel. WordCraft: An Environment for Benchmarking Commonsense Agents. arXiv:2007.09185 [cs], July 2020b. URL http://arxiv.org/abs/2007.09185. arXiv: 2007.09185.\n\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2014. URL http://arxiv.org/abs/1412.6980. cite arxiv:1412.6980Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015.\n\nMichelle A. Kline and Robert Boyd. Population size predicts technological complexity in Oceania. Proceedings of the Royal Society B: Biological Sciences, 277(1693):2559–2564, Audoi: 10.1098/rspb.2010.0452. URL https: gust 2010. //royalsocietypublishing.org/doi/10.1098/rspb.2010.0452.\n\nISSN 0962-8452, 1471-2954.\n\nDavid Lazer and Allan Friedman. The Network Structure of Exploration and Exploitation. Administrative Science Quarterly, 52(4):667–694, December 2007. ISSN 0001-8392, 1930-3815. doi: 10.2189/asqu.52.4.667. URL http://journals.sagepub.com/doi/10.2189/ asqu.52.4.667.\n\nJoel Z Leibo, Edward Hughes, Marc Lanctot, and Thore Graepel. Autocurricula and the emergence of innovation from social interaction: A manifesto for multi-agent intelligence research. arXiv preprint arXiv:1903.00742, 2019.\n\nRyan Lowe, Yi Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, and Igor Mordatch. Multi-agent actorcritic for mixed cooperative-competitive environments, 2017. URL https://arxiv.org/ abs/1706.02275.\n\nW. Mason and D. J. Watts. Collaborative learning in networks. Proceedings of the National Academy of Sciences, 109(3):764–769, January 2012. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas. 1110069108. URL http://www.pnas.org/cgi/doi/10.1073/pnas.1110069108.\n\n11\n\nUnder review as a conference paper at ICLR 2023\n\nWinter A. Mason, Andy Jones, and Robert L. Goldstone. Propagation of innovations in networked groups. Journal of Experimental Psychology: General, 137(3):422–433, 2008. ISSN 1939-2222, 0096-3445. doi: 10.1037/a0012798. URL http://doi.apa.org/getdoi.cfm?doi= 10.1037/a0012798.\n\nNina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Burnaev. Reinforcement learning for combinatorial optimization: A survey. Computers & Operations Research, 134:105400, 2021.\n\nAndrea Bamberg Migliano and Lucio Vinicius.\n\nThe origins of human cumulative culture: from the foraging niche to collective intelligence. Philosophical Transactions of the Royal Society B: Biological Sciences, 377(1843):20200317, January 2022. 10.1098/rstb. 2020.0317. URL https://royalsocietypublishing.org/doi/10.1098/rstb. 2020.0317. Publisher: Royal Society.\n\ndoi:\n\nVolodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin A. Riedmiller. Playing atari with deep reinforcement learning. CoRR, abs/1312.5602, 2013. URL http://arxiv.org/abs/1312.5602.\n\nVolodymyr Mnih, Adri`a Puigdom`enech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous Methods for Deep Reinforcement Learning. arXiv:1602.01783 [cs], June 2016. URL http://arxiv.org/abs/1602. 01783. arXiv: 1602.01783.\n\nIda Momennejad. Collective minds: social network topology shapes collective cognition. Philosophical Transactions of the Royal Society B: Biological Sciences, 377(1843):20200315, January 2022. doi: 10.1098/rstb.2020.0315. URL https://royalsocietypublishing.org/ doi/10.1098/rstb.2020.0315. Publisher: Royal Society.\n\nIda Momennejad, Ajua Duker, and Alin Coman. Bridge ties bind collective memories. Nat. Com-\n\nmun., 10(1):1578, April 2019.\n\nArun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas Alcicek, Rory Fearon, Alessandro De Maria, Vedavyas Panneershelvam, Mustafa Suleyman, Charles Beattie, Stig Petersen, Shane Legg, Volodymyr Mnih, Koray Kavukcuoglu, and David Silver. Massively Parallel Methods for Deep Reinforcement Learning. Technical Report arXiv:1507.04296, arXiv, July 2015. URL http://arxiv.org/abs/1507.04296. arXiv:1507.04296 [cs].\n\nTom Schaul, John Quan, Ioannis Antonoglou, and David Silver. Prioritized Experience Replay. Technical Report arXiv:1511.05952, arXiv, February 2016. URL http://arxiv.org/abs/ 1511.05952. arXiv:1511.05952 [cs].\n\nSimon Schmitt, Matteo Hessel, and Karen Simonyan. Off-Policy Actor-Critic with Shared Experience Replay. Technical Report arXiv:1909.11583, arXiv, November 2019. URL http: //arxiv.org/abs/1909.11583. arXiv:1909.11583 [cs, stat].\n\nRicard V. Sol ́e, Sergi Valverde, Marti Rosas Casals, Stuart A. Kauffman, Doyne Farmer, and Niles Eldredge. The evolutionary ecology of technological innovations. Complexity, 18(4):15–27, March 2013. ISSN 10762787. doi: 10.1002/cplx.21436. URL http://doi.wiley.com/ 10.1002/cplx.21436.\n\nLucas Oliveira Souza, Gabriel de Oliveira Ramos, and Celia Ghedini Ralha. Experience Sharing Between Cooperative Reinforcement Learning Agents. arXiv:1911.02191 [cs], November 2019. URL http://arxiv.org/abs/1911.02191. arXiv: 1911.02191.\n\nD. Steinkraus, I. Buck, and P.Y. Simard. Using gpus for machine learning algorithms. In Eighth International Conference on Document Analysis and Recognition (ICDAR’05), pp. 1115–1120 Vol. 2, 2005. doi: 10.1109/ICDAR.2005.251.\n\nEmanuel Todorov, Tom Erez, and Yuval Tassa. Mujoco: A physics engine for model-based control. In 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 5026–5033, 2012. doi: 10.1109/IROS.2012.6386109.\n\n12\n\nUnder review as a conference paper at ICLR 2023\n\nOriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich K ̈uttler, John Agapiou, Julian Schrittwieser, John Quan, Stephen Gaffney, Stig Petersen, Karen Simonyan, Tom Schaul, Hado van Hasselt, David Silver, Timothy Lillicrap, Kevin Calderone, Paul Keet, Anthony Brunasso, David Lawrence, Anders Ekermo, Jacob Repp, and Rodney Tsing. Starcraft ii: A new challenge for reinforcement learning, 2017. URL https://arxiv.org/abs/1708.04782.\n\nErik Volz and Lauren Ancel Meyers. Susceptible–infected–recovered epidemics in dynamic contact networks. Proceedings of the Royal Society B: Biological Sciences, 274(1628):2925– ISSN 0962-8452, 1471-2954. doi: 10.1098/rspb.2007.1159. URL 2934, December 2007. https://royalsocietypublishing.org/doi/10.1098/rspb.2007.1159.\n\nDuncan J Watts and Steven H Strogatz. Collective dynamics of ‘small-world’ networks. 393:3,\n\n1998.\n\nPolly W. Wiessner. Embers of society: Firelight talk among the Ju/’hoansi Bushmen. Proceedings of the National Academy of Sciences, 111(39):14027, September 2014. doi: 10.1073/pnas. 1404212111. URL http://www.pnas.org/content/111/39/14027.abstract.\n\n13\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 6: Visualizing actions and states in Wordcraft: we present the first 3 time steps of an episode corresponding to playing the example in Figure 1. This task contains 7 elements, so the action space is a integer with maximum value 7. In the components current c and inventory i, each digit in the vector corresponds to the element with the corresponding index. The initial set includes Water and Earth (their indexes at τ = 0 in the inventory are non-zero). The agent first picks Earth (second index in the action vector). At t = 1, Earth becomes active in the Current vector of the state, the the agent selects Water and receives a positive reward. At t = 2, Mud is created and inserted in the inventory and c is cleared.\n\nThis supplementary material provides additional methods, results and discussion, as well as implementation details.\n\n• Section A describes in detail the MDP formulation of Wordcraft;\n\n• Section C contains the pseudocde of SAPIENS;\n\n• Section D explains how we model dynamic social network structures and how their perfor-\n\nmance varies with their hyper-paramaters;\n\n• Section E provides more information about our experimental setup and results (effect of group size, intra-group and inter-group alignment, robustness to learning hyper-parameters and effect of prioritized experience sharing). We also provide tables and figures for all metrics presented in Section 2.4 and reward plots.\n\n• Section E.7 contains simulations with another testbed, the Deceptive Coins game.\n\nA DETAILS OF WORDCRAFT AS A MARKOV DECISION PROCESS\n\nWe consider the episodic setting, where the environment resets at the end of each episode and an agent is trained for Etrain episodes. At each time step t, the agent observes the state st and selects an action at from a set of possible actions A according to its policy πθ, where πθ is a mapping from states to actions, parameterized by a neural network with weights θ. In return, the agent receives the next state st+1 and a scalar reward rt. Each DQN agent collects experience tuples of the form [st, at, st+1, rt] in its replay buffer.\n\nFigure 6 offers a visualization of the states and actions encountered during an episode in Wordcraft, where the chosen actions and elements are chosen so as to reproduce the example of Figure 1. In order to solve the innovation task described in Section 2.1 we compute the maximum number of elements a player can craft within horizon T for recipe book Xvalid and initial set X0, which we denote as |X|. We, then, encode each element as an integer in [0, |X|). Thus, the action space is\n\n14\n\nReward, Action, Inventory, Current, State, 000000000000111200000100110000000000000110000421Episode step,210Idx = 0Idx = 1Idx = 2Idx = 3Idx = 4Idx = 5Idx = 6EpisodictimeUnder review as a conference paper at ICLR 2023\n\nWork (Garnelo et al., 2021) MARL\n\nField\n\nAgent Model DRL\n\nInformation type interaction 3\n\nDynamic structure? Yes\n\nTask microstrategic management (StarCraft(Vinyals et al., 2017))\n\n(Adjodah 2019)\n\net\n\nal.,\n\nDec-RL\n\n(Du et al., 2021)\n\nMARL\n\nDRL\n\nDRL\n\nrewards, NN weights\n\nobservations\n\ncontrol (Todorov\n\ncontinuous (Mujoco et al., 2012)) cooperative navigation (Particle World (Lowe et al., 2017))\n\nNo\n\nYes\n\n(Dubova et al., 2020) MARLC 4\n\nDRL\n\ninteraction 1\n\ncoordination game\n\nNo\n\n(Fang et al., 2010)\n\ncomputational cognitive science\n\n(Lazer & Friedman, 2007)\n\ncomputational cognitive science\n\n(Cantor et al., 2021)\n\ncomputational cognitive science\n\nbelief-majority rule 5\n\nbelief, reward\n\nNK problem 6\n\nbelief-majority rule 3\n\nbelief, reward\n\nNK type 74\n\nbelief-majority rule 3\n\nbelief, reward\n\ninnovation\n\n(Mason & Watts, 2012)\n\ncognitive science\n\nhuman\n\naction,reward\n\nNK problem 3\n\n(Mason et al., 2008)\n\ncognitive science\n\nhuman\n\naction, reward\n\nline search\n\nNo\n\nNo\n\nNo\n\nNo\n\nNo\n\nchoose\n\nMain conclusion with Topologies encourage cycles strategic diversity and dynamic ones perform robustly across tasks Random topologies fullyoutperforms connected ones Agents to communicate when they need to coordinate. Global connectivity leads to shared and symmetric protocols, partiallywhile connected groups learn local dialects. Partial maximizes mance Partial maximizes mance Performance depends on both task and group structure, no topology is robustly optimal across tasks. Full connectivity maximizes diversity and works best even in complex tasks. Partial connectivity works best in complex problems\n\nconnectivity perfor-\n\nconnectivity perfor-\n\n(Derex & Boyd, 2016) (this work)\n\ncognitive science\n\naction,reward\n\ninnovation\n\nYes\n\ndistributed RL and computational cognitive science\n\nDRL\n\ntransition tuples\n\ninnovation\n\nconnectivity\n\npartial works best yes\n\nPartially-connected structures, especially dynamics ones, perform robustly in different of types innovation tasks\n\nTable 1: A non-comprehensive summary of the literature on the topic of the effect of social network topology on collective search\n\nA = [0, |X|), with action at indicating the index of the currently chosen element. The state st contains two sets of information: a binary vector of length |X| with non-zero entries for elements already crafted by the agent within the current episode (we refer to this as inventory i) and another binary vector of length |X| where an index is non-zero if it is currently selected by the agent (we refer to this as current c). An agent begins with an inventory having non-zero element only for the initial set X0 and an all-zero selection. With the first action a0, the selected item becomes non-zero in the selection. With the second action, a1, we check if the combination (a1, c0) is valid under the recipe book and, if so, return the newly crafted element (corresponding entry in i becomes non-zero) and the reward. This two-step procedure continues until the end of the episode.\n\nB SUMMARY OF RELATED WORKS\n\nIn this appendix we provide a non-comprehensive summary of the literature on the topic of the effect of social network topology on collective search in Table 1, where our objective is to highlight similarities and differences within and across the fields of cognitive science and DRL.\n\nC PSEUDOCODE OF SAPIENS\n\nWe present the pseudocode of our proposed algorithm SAPIENS in Algorithm 1. SAPIENS works similarly to an off-policy reinforcement learning algorithm, with the difference that, after each episode, an experience sharing phase takes place between agents that belong in the same group.\n\n15\n\nUnder review as a conference paper at ICLR 2023\n\nAlgorithm 1 SAPIENS (Structuring multi-Agent toPology for Innovation through ExperieNce Sharing)\n\nI.neighbors= I.formNeighborhood(G) ▷ Inform agent about its neighbors I.env = initEnv(R) ▷ Create agent’s own copy of the environment based on the recipe book\n\n▷ Initialize agents\n\nfor i ∈ I do\n\n1: Input: G, connectivity, R, ps, LS 2: G.initializeGraph(connecticity) 3: I.initializeAgent() 4: for i ∈ I do 5: 6: 7: end for 8: while training not done do 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: 19: 20:\n\na = i.policy() r, snew = env.step(a) i.B.insert([s, r, a, snew])\n\nend while ε =random() if ε < ps then\n\nwhile episode not done do\n\nfor j ∈ i.neighbors do\n\nend for\n\nend if i.train()\n\nj.B.add(i.B.sample(L))\n\n▷ Loop through each agent\n\n▷ Choose action\n\n▷ Share with probability ps\n\n▷ Sample random set of experiences of length L\n\n▷ Train agent\n\nend for\n\n21: 22: end while\n\nD ANALYSIS OF DYNAMIC NETWORK TOPOLOGIES\n\nIn the main paper we presented results for a single type of dynamic topolgoy. Here we present another type and analyze how they both behave for different values of their hyper-parameters. The two dynamic topologies are:\n\n• Inspired by graphs employed in human laboratory studies (Derex & Boyd, 2016), we designed graphs where the macro structure of the graph is constant but agents can randomly change their position. In particular, we divide a group of agents into sub-groups of two agents and, at the end of each episode, move an agent to another group with a probability pv for a duration of Tv episodes (for a visualization see Figure 3). To reduce the complexity of the implementation, we assume that only one visit can take place at a time. In the main paper we employ pv = 0.01 and Tv = 10 across conditions and present results with different values in Appendix D, where we refer to this topology as dynamic-Boyd.\n\n• Human behavioral ecology emphasize the importance of periodic variation in human social networks encountered throughout our evolutionary trajectory Wiessner (2014); Dunbar (2014). Due to ecological constraints human groups oscillate between phases of high and low connectivity: low-connectivity phases arise when individuals need to individually collected resources (e.g. day-time hunting) while high-connectivity phases arise when humans are idle and “forced” to be in proximity with others (e.g. fireside chats). Although these high-connectivity phases do not bare a direct evolutionary advantage, they may have played an important role by creating the conditions for the evolution of human language and culture. Inspired by this hypothesis, we have designed dynamic graphs that oscillate between a fully-connected topology that lasts for Th episodes and a topology without sharing that lasts for Tl episodes. We present results for various values of Th and Td of this topology in Appendix D, where we refer to this topology as dynamic-periodic.\n\nIn Figure 8, we observe the % of group success (SG) with the dynamic-Boyd topology for different probabilities of visit (pv) and visit duration Tv (the sub-group size is 2 in all cases). We note that, due to our implementation choice that a visit can take place only if no other agent is currently on a visit, the visit duration also affects the mixing of the group: longer visits mean that fewer visits will\n\n16\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 7: Two types of dynamic topologies: (Left) in the dynamic-Boyd topology the group is divided into sub-groups of two agents and a visit takes place with probability pv and lasts Tv episodes (Right) In the dynamic-periodic topology the graph oscillates between a phase with a fullyconnected topology that lasts for Th episodes to a phase without sharing that lasts for Tl episodes.\n\nFigure 8: Examining the sensitivity of the dynamic-Boyd topology to its hyper-parameters: % of group success (SG) for the merging-paths task (left) and the best-of-ten paths task (right).\n\ntake place in total. In the merging paths task (left), two hyper-parameter settings have a clear effect: (i) short visits with of high probability lead to bad performance. As such settings lead to a quick mixing of the population, they lead to convergence to the local optimum (ii) long visits with high probability work well. Due to the high visit probability, this setting effectively leads to topology where exactly one agent is always on a long visit. Thus, it ensures that sub-groups stay isolated for at least 1000 episodes, after which inter sub-group sharing needs to takes place to ensure that the sub-groups can progress quickly. In the best-of-ten paths task (right), this structure has a clear optimal hyper-parameterization: short visits with high probability are preferred, which maximizes the mixing of the group and makes early exploration more effective.\n\nIn Figure 9, we observe the % of group success (SG) of the dynamic-periodic topology for various values of Th and Tl. In the merging paths task (left of Figure 9) medium values for the period of both phases works best, while there is some success when the low connectivity phase lasts long (Tl = 1000). In the best-of-ten paths task (rightof Figure 9), we observe the same medium values for the period of both phases work best: thus both the absolute value and their ratio is important to ensure that exploration is efficient. The optimal configuration is the same between the two tasks (Tl = 100, Th = 10), which is a good indication of the robustness of this structure.\n\nE EMPIRICAL RESULTS\n\nTo ensure that all methods have the same number of samples, we assume that, for trials where a method did not find the optimal solution, and, hence, T + is undefined, T + is equal to the total number of timesteps the method was trained for, Ttrain. For each task, all methods have been trained for an equal duration of time: Ttrain = 1e6 for the single path , Ttrain = 7e6 for the merging paths task and Ttrain = 2e7 for the best-of-ten paths task.\n\n17\n\nDivide into sub-groups of twoVisit with probability Return afterepisodes Fully-connected phase that lasts forepisodes No-sharing phase that lasts forepisodes 0.0050.010.10.5pv, Visit probability101001000Tv, Visit duration S,% of group success0.00.10.20.30.40.50.0050.010.10.5pv, Visit probability101001000Tv, Visit duration S,% of group success0.00.10.20.30.4Under review as a conference paper at ICLR 2023\n\nFigure 9: Examining the sensitivity of the dynamic-periodic topology to its hyper-parameters: % of group success (SG) for the merging-paths task (left) and the best-of-ten paths task (right).\n\nWe perform 20 independent trials for each task and method and visualize our proposed metrics with barplots and line plots of averages across trials with error bars indicating 95% confidence intervals. We test for statistical significance of our evaluation metrics separately for each task by applying ANOVA tests 8 to detect whether at least one method differs from the rest and, subsequently, employing the Tukey’s range test 9 to detect which pairs of methods that differ significantly. We report the exact p values of theses tests in the text and, when applicable, illustrate them in figures using a set of asterisks whose number indicates the significance level (p <= 0.05: *, p <= 0.01: **, p <= 0.001: ***, p <= 0.0001: **** ) 10.\n\nWe presented the major results of our evaluation of SAPIENS in Section 3. We now present additional information regarding the implementation of the different components (Appendix E.1), the values of all performance metrics and additional plots for experiments discussed in 3 (Appendix E.2), results on intra-group and inter-group alignment (AppendixE.3), results for groups of varying sizes (Appendix E.5) and results on various dynamic topologies (Appendix D)\n\nE.1\n\nIMPLEMENTATION DETAILS\n\nImplementation of DQN We employ the same hyper-parameter for each DQN across all studied tasks and topologies: discount factor γ = 0.9, the Adam optimizer with learning rate α = 0.001 (Kingma & Ba, 2014; Dunbar, 2014), ε-greedy exploration with ε = 0.01. We employ a feedforward network with two layers with 64 neurons each. We implemented SAPIENS by extending the DQN implementation in the stable-baselines3 framework.\n\nImplementation of A2C We used the stable-baselines3 implementation of A2C 11 and tuned the hyper-parameters: learning rate, number of steps, discount factor, the entropy coefficient and the value function coefficient. This gave us the best-performing values 0.001, 5, 0.99, 0.1 and 0.25, respectively, that we also employed in the other tasks.\n\nImplementation of Ape-X We used the ray implementation of Ape-X DQN 12 and tuned the hyper-parameters: learning rate, discount factor, replay buffer capacity and ε-greedy exploration. This gave us the best-performing values in the single path task 0.001, 0.9, 5000 and 0.02, respectively.\n\n8https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f oneway.html 9https://pypi.org/project/bioinfokit/0.3/ 10https://www.graphpad.com/support/faq/what-is-the-meaning-of–or–or–in-reports-of-statistical-\n\nsignificance-from-prism-or-instat/\n\n11https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html 12https://docs.ray.io/en/latest/rllib/rllib-algorithms.html\n\n18\n\n101001000Th, High-connectivity period101001000Tl, Low-connectivity periodS,% of group success0.00.2101001000Th, High-connectivity period101001000Tl, Low-connectivity periodS,% of group success0.00.5Under review as a conference paper at ICLR 2023\n\nTopology no-sharing dynamic fully-connected ring small-world single A2C Ape-X\n\nR+ ∞\n(0.92, 0.0.036) (1,0) (1,0) (1,0) (1,0) (0.92, 0.163) (1,0) (0.93, 0.18)\n\nR∗ ∞\n(1,0) (1,0) (1,0) (1,0) (1,0) (0.927, 0.163) (1,0) (0.93, 0.18)\n\nT + (236250, 33441) (237222, 53885) (310666, 89240) (235333, 70190) (253333, 63320) (64750, 266145) (36200, 16450) (270941, 102445)\n\nT ∗ (830000,0) (346666,122041) (362000, 98503) (305333, 78818) (302666, 74110) (64750, 266145) (36200, 16450) (270941, 102445)\n\nT > (600000, 0) (109444, 98067) (51333, 20655) (70000, 22038) (49333, 31274) (0,0) (0,0) (0,0)\n\nS (1,0) (1,0) (1,0) (1,0) (1,0) (0.2, 0.41) (1,0) (0.15, 0.366)\n\n ̄Vavg (0.038,0.002) (0.027,0.01) (0.052, 0.027) (0.038,0.0026 (0.029, 0.013) (0.015, 0.013) a non-co (0,0) (0.015, 0.022)\n\nCavg (0.697, 0.0354) (0.885, 0.026) (0.891,0.034) (0.697, 0.0354) (0.912, 0.0267) (1,0) (1,0) (1,0)\n\nTable 2: Evaluation metrics for the single-path task in the form (mean of metrics, standard deviation of metric)\n\nTopology no-sharing dynamic fully-connected ring small-world single A2C Ape-X\n\nR+ ∞\n(0.657, 0.037) (0.7,0.04) (0.5349,0.085) (0.661,0.135) (0.639,0.091) (0.758, 0.187) (0.269,0).2 (0.573, 0.31)\n\nR∗ ∞\n(0.838,0).14 (0.9,0.13) (0.58, 0.04) (0.72, 0.15) (0.774, 0.173) (0.758, 0.187) (0.269, 0.2) (0.573, 0.31)\n\nT + (5334000, 2311945) (4716500,222965) (7000000,0) (5892000, 2288393) (5998000, 1699076) (5235000, 2385948) (7000000, 0) (6656900, 1534389 )\n\nT ∗ (7000000,2311945 (7000000, 0) (7000000, 0) (7000000, 0) (7000000, 0) (5235000, 2385948) (7000000, 0) (26656900, 1534389 )\n\nT > (7000000, 0) (7000000, 0) (7000000, 0) (7000000, 0) (7000000,0) (0,0) (0,0) (0,0)\n\nS (0.4,0.51) (0.75,0.48) (0,0) (0.2,0.41) (0.3, 0.483) (0.3, 0.47) (0,0) (0.05, 0.223)\n\nCavg (0.597, 0.06) (0.597, 0.0059) (0.597,0.0051) (0.595, 0.0051) (0.596,0.0065) (1,0) (1,0) (1,0)\n\n ̄Vavg (0.0089,0.0021) (0.005, 0.0016) (0.0764, 0.0044) (0.0149,0.021) (0.06775,0.0328) (0.0063, 0.0063) (0.013, 0.038) (0.054,0.157)\n\nTable 3: Evaluation metrics for the merging-paths task in the form (mean of metrics, standard deviation of metric)\n\nImplementation of graphs used as social network structures We construct small-worlds using the Watts–Strogatz model (watts strogatz graph method of the networkx package 13). This model first builds a ring lattice where each node has n neighbors and then rewires an edge with probability β. Compared to other techniques used in previous works studying the effect of topology Mason et al. (2008), this way of constructing small-worlds ensures that the average path lengths is short and clustering is high. These two properties are what differentiates small-worlds from random (short average path length and small clustering) and regular (long average path length and high clustering) graphs. We employ n = 4 and β = 0.2 in our experiments, which we empirically found to lead to good values of average path length and clustering.\n\nWe have described the generation process of dynamic topologies in Appendix D. In the main paper we employ the dynamic-Boyd topology with Tv = 10 and pv = 0.001 across tasks. These parameters have been tuned for the merging-paths task.\n\nE.2 OVERALL COMPARISON\n\nTables 2, 3 and 4 contain the values of all metrics discussed in Section 2.4 for the single path, merging paths and best-of-ten paths, respectively. We denote values computed after convergence of the group with underscore ∞ and values averaged over all training steps with underscore avg (note that we use ̄over variables to denote averaging over agents in a single training step). Cells with a dash (-) indicate that we could not compute the corresponding metrics because a group failed to find a solution in all trials. We also provide the plots of volatility and average diversity for the merging paths and best-of-10 paths task (that were not included in Figure 5) due to page limit constraints).\n\nFigure 10 presents the reward curves for all methods in the single path, merging paths and best-often paths tasks respectively. Specifically, we plot the maximum reward of the group at training step t (R+\n\nt ).\n\n13https://networkx.org/\n\nTopology no-sharing dynamic fully-connected ring small-world single A2C Ape-X\n\nR+ ∞\n(0.2124,0.036) (0.5141,0.323) (0.1615,0.09) (0.2319,0.3045) (0.198,0.281) (0.178, 0.067) (0.1285,0.19) (0.481, 0.213)\n\nR∗ ∞\n(0.446, 0.131) (0775, 0.32) (0.1819, 0.1013) (0.275,0.332) (0.216,0.275) (0.1785,0.0676) (0.1285,0.19) (0.482, 0.213)\n\nT + (20000000, 0) (13616000, 5441395) (20000000, 0) (18781000, 3854816) (18706000, 4091987) (20000000, 0) (20000000, 0) (20000000, 0)\n\nT ∗ (20000000,0) (20000000,0) (20000000, 0) (18826000, 3712513) (18746000, 3965496) (20000000,0) (20000000,0) (20000000,0)\n\nT > (20000000, 0) (20000000, 0) (20000000,0) (18045000, 6182252) (18040000, 6198064) (0,0) (0,0) (0,0)\n\nS (0,0) (0.6,0.51) (0,0) (0.1,0.31) (0.1,0.316) (0, 01) (1,0) (0.9, 0.316)\n\nCavg (0.239, 0.005) (0.242,0.0078) (0.238,0.0053) (0.237,0.004) (0.234,0.007) (1,0) (1,0) (1,0)\n\n ̄Vavg (0.007, 0.0021) (0.04,0.0223) (0.007,0.003) (0.047,0.019) (0.018,0.0049) (0.006,0.0031) (0.3244,0.35) (0.018,0.009)\n\nTable 4: Evaluation metrics for the best-of-ten paths task in the form (mean of metrics, standard deviation of metric)\n\n19\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 10: Maximum reward of the group at training step t (R+ (middle) merging paths task (right) best-of-ten paths task\n\nt ) in the (left) single path task\n\nE.3 MEASURING INTER-GROUP AND INTRA-GROUP ALIGNMENT\n\nWe have so far captures the agreement between agents in a group through the behavioral metric of conformity. Here, we present a mnemonic metric for agreement, which we term alignment. Alignment is a complementary metric to the diversity (Dk t ) metrics, that aims at capturing the effect of experience sharing on the replay buffers in a group. We propose a definition of alignment within a single group (intra-group alignmentAG t ) and a definition of alignment between two different groups (AGj ,Gj ). Such metrics of mnemonic convergence have been linked to social network topology (Coman et al., 2016) and, as we show here, they can prove useful in analyzing groups of reinforcement learning agents.\n\nt ) and group diversity (DG\n\nt\n\nt\n\nSpecifically: (i) AG is the intra-group alignment. This metric captures the similarity in terms of content between the replay buffers of agents belonging to the same group. To compute this we compute the size of the common subset of experiences for each pair of agents and, then, average over all these pairs, normalizing in [0,1]. (ii) inter-group alignment AGj ,Gj is a similar notion of alignment but employed between different groups (e.g. how different is a group of fully-connected and a dynamic group of agents in terms of the content of their group replay buffers). To compute it we concatenate all replay buffers of a group into a single one and then compute the size of the common subset of the two replay buffers.\n\nt\n\nFigure 12 presents intra-group alignment in the three tasks. We observe that, in all tasks, intragroup alignment increases with connectivity and that it reduces when the agents enter the exploitation phase. Thus, intra-group alignment can prove useful in characterizing the exploration behavior of a group. In Figure 13, we present the inter-group alignment in the single path, merging paths and best-of-ten paths tasks. We observe that the topologies do not differ significantly in the single path task. In the merging task, we observe that inter-group alignment is lower during the exploration phase, compared to other tasks, and that the small-world is the slowest to align with all other structures. Perhaps this explains why this topology finds the optimal solution with the least probability: by propagating information quickly, the group early on\n\n20\n\n0.000.250.500.751.00Training step, t1e60.00.51.0Maximum reward, RmaxAPEX-DQNsingleno-sharingdynamicfully-connectedringsmall-worldA2C024Training step, t1e60.00.51.0Maximum reward, RmaxAPEX-DQNsingleno-sharingdynamicfully-connectedringsmall-worldA2C0123Training step, t1e70.00.51.0Maximum reward, RmaxAPEX-DQNsingleno-sharingdynamicfully-connectedringsmall-worldA2CUnder review as a conference paper at ICLR 2023\n\nFigure 11: Analyzing group behavior in the merging paths task (top row) and best-of-10 paths task (bottom row). (left) Conformity Ct is a behavioral metric that denotes the percentage of agents in a group that followed the same trajectory in a given evaluation trial (right) Average Diversity ̄Dt is a mnemonic metric that denotes the number of unique experiences in the replay buffer of an agent, averaged over all agents.\n\n21\n\n0.000.250.500.751.00Training step, t1e60.20.40.60.81.0Conformity, Ct0123Training step, t1e60200400Average Diversity, Dtno-sharingdynamicfully-connectedringsmall-world02468Training step, t1e50.20.40.6Conformity, Ct0246Training step, t1e505001000Average Diversity, DtUnder review as a conference paper at ICLR 2023\n\nFigure 12: Intra-group alignment AG best-of-ten paths task (right)\n\nt in the single path task (left), merging paths task (middle) and\n\nconverges to the local optimum in this task. In the best-of-ten task, the no-sharing setting has the smallest alignment with all other structures. This reinforces our main conclusion in this work: experience sharing affects individuals and different topologies do so in different ways.\n\nE.4 ROBUSTNESS TO LEARNING HYPER-PARAMETERS\n\nIn Figure 14 we present how the performance of SAPIENS varies for different values of the learning hyperparameters learning rate and disocunt factor in the single path task under a fully-connected and a dynamic topolgoy, as well as the no-sharing condition. We observe that, although convergence to the optimal solution is not always achieved, the dynamic topology is at least as effective as the others either in terms of convergence rate and/or final performance in all conditions.\n\nE.5 EFFECT OF GROUP SIZE\n\nWe here examine the effect of the group size for all social network structures in the merging-paths and best-of-ten paths task. To visualize the progression of a group on the paths of the different tasks, we focus on specific elements in the tasks: (i) ([A8, B8, C2] in the merging-paths task. The first two correspond to reaching the end of the paths corresponding to the two local optima. To reduce the computational complexity of experiments, we do not study the last element of the optimal path (C4), but focus on C2 instead. This is sufficient to detect whether a group has discovered the optimum path. Here, we observe that the fully-connected topology fails to find the optimal path regardless of its size (with a small success probability for N = 10). We observe that the ability of the ring , small-world and dynamict topologies to avoid the local optima improves with the group size (ii) [B4, A2, E2] in the best-of-ten tasks. B4 is the fourth element on the optimal path (again we do not study the last element to reduce complexity). To avoid cluttering the visualization we only present two of the nine sub-optimal paths. In this task, we again observe that the fully-connected network fails to discover the optimal task. Among all structures and group sizes, the large dynamic network performs best, while the performance of ring and small-world is also best for N = 50. We observe that small networks sizes (N = 2, N = 6) are slower at exploring (we can see that as they rarely find the second element of the sub-optimal paths, which is required to conclude that path B is the optimal choice).\n\nOverall, this scaling analysis indicates that increasing the group size in a fully-connected topology will not improve performance, while benefits are expected for low-connectivity structures, particularly for the dynamic topology. We believe that this observation is crucial. In studies of groups of both human and artificial agents, we often encounter the conviction that, larger groups perform better and that size is a more important determinant than connectivity, the latter justifying why connectivity is often ignored Kline & Boyd (2010); Horgan et al. (2018); Mnih et al. (2016); Schmitt et al. (2019); Nair et al. (2015). Our results here point to the contrary.\n\nE.6 PRIORITIZED EXPERIENCE SHARING\n\nWe now examine how sharing prioritized experiences instead of randomly sampled ones affects the performance of SAPIENS. In Figure 16 we repeat the same experiment with Figure 4, with the difference that all methods compute priorities, which they employ both for implementing a prioritized\n\n22\n\n0123Training step, t1e60.60.70.80.91.0Intra-group alignment, At0123Training step, t1e60.40.60.81.0Intra-group alignment, At0.00.51.01.52.0Training step, t1e60.40.60.81.0Intra-group alignment, AtUnder review as a conference paper at ICLR 2023\n\nFigure 13: Inter-group alignment AGj ,Gj and best-of-ten paths task (right). In each row we compare one topology with all the rest.\n\nin the single path task (left), merging paths task (middle)\n\nt\n\n23\n\n0.00.51.0Inter-group alignment, Aj,jtdynamicfully-connectedringsmall-worldno-sharing0.00.51.0Inter-group alignment, Aj,jtindependentfully-connectedringsmall-worlddynamic0.00.51.0Inter-group alignment, Aj,jtindependentdynamicringsmall-worldfully-connected0.00.51.0Inter-group alignment, Aj,jtindependentdynamicfully-connectedsmall-worldring0123Training step, t1e60.00.51.0Inter-group alignment, Aj,jtindependentdynamicfully-connectedring0123Training step, t1e6small-world012Training step, t1e6Under review as a conference paper at ICLR 2023\n\nFigure 14: Varying the learning hyper-parameters learning rate (λ) and discount factor (γ) in different social network topologies in the single path task. )\n\nFigure 15: Scaling of different social network structures in the merging paths (top row) and best-often paths tasks (bottom row). We highlight the element belonging to the optimal path in red.\n\n24\n\n0.00.20.40.60.81.0Maximum reward, Rmax=0.01 , =0.1no-sharingdynamicfully-connected=0.01 , =0.5=0.01 , =0.90.00.20.40.60.81.0=0.001 , =0.1=0.001 , =0.5=0.001 , =0.90.00.20.40.60.81.0Training step, t1e60.00.20.40.60.81.0=0.0001 , =0.10.00.20.40.60.81.01e6=0.0001 , =0.50.00.20.40.60.81.01e6=0.0001 , =0.9A_8B_8C_20.000.250.500.751.00Selement,% of trials with elementringA_8B_8C_2fully-connectedN=2N=6N=10N=20N=50A_8B_8C_2small-worldA_8B_8C_2dynamicB_4A_2E_2element0.000.250.500.751.00Selement,% of trials with elementB_4A_2E_2elementB_4A_2E_2elementB_4A_2E_2elementUnder review as a conference paper at ICLR 2023\n\nFigure 16: Examining the effect of prioritization in experience sharing. For more details about the setup, we refer the reader to Figure 4\n\nreplay buffer and sharing experiences by sampling them in proportion to their priorities. As we see, using priorities negatively impacts experience sharing, while it helps speed up the performance of the single agent in the single path task. This behavior has been observed in previous works Souza et al. (2019) and can be attributed to the fact that the priorities of the sender do not necessarily agree with the priorities of the receiver and, therefore, destabilize learning.\n\nE.7 ADDITIONAL TEST-BED: THE DECEPTIVE COINS GAME\n\nDeceptive games are grid-world tasks introduced to test the ability of deep RL agents to avoid local optima. (Bontrager et al., 2019). Here, we perform preliminary experiments with our own JAXbased implementation of one of the games: the first difficulty level of the deceptive coins game (see Figure 17 for an illustration). Here, the agent can navigate in the grid-world during an episode and collect diamonds, which give a unit of reward. The game finishes once the agent reaches the fire, which offers an additional reward, or when a timeout of 14 time steps is reached. There are two possible paths the agent can follow: moving left and reaching the fire will give a reward of two while moving right and reaching the fire will give a reward of five. The second path is more rewarding but is harder to complete because, once an agent discovers the easier-to-find diamond on the left, it is deceived into following the left path. Once an agent commits on a path (reaches the edge of the grid-world) a barrier is raised so that the agent cannot go back within that episode.\n\nWe now examine the performance of SAPIENS under different social network structures (fullyconnected, small-world, ring, dynamic), as well as the no-sharing, A2C and Ape-X baselines for three group sizes: 6 , 10 and 20 agents. We present the reward plots for the 3 sizes in Figures 18, 19 and 20, respectively, and present an overall comparison in Figure 21 (equivalent to Figure 4 for the Wordcraft tasks).\n\nWe observe that all conditions found either the local or the global optimum and that : a) A2C fails for all network sizes. This behavior has been observed in previous works (Bontrager et al., 2019) and can be attributed to the fact that policy-gradient methods are more susceptible to local minima b) no-sharing gets stuck in the local optimum in half of the trials when the group size is small. Increasing the group size increases the probability that at least one agent in the group will escape the local minima by ε-greedy exploration c) partially connected structures find the global minima across network sizes d) fully-connected converges to the local optimum for the large group size, although the global optimum was discovered at the early exploration phase (see Figure 20). Thus, too much experience sharing is harmful e) Ape-X fails with high probability for all network sizes.\n\n25\n\n0.00.20.40.60.81.01.2, Group successSingle pathMerging pathsBest-of-ten paths0246T+, Time to first success1e6singleno-sharingdynamicfully-connectedringsmall-worldUnder review as a conference paper at ICLR 2023\n\nFigure 17: A screenshot of our implementation of the Deceptive Coins task. Collecting diamonds gives a positive reward and touching the fire terminates the game.\n\nFigure 18: Performance for a group with 6 agents\n\nFigure 19: Performance for a group with 10 agents\n\nFigure 20: Performance for a group with 20 agents\n\n26\n\n0100000200000300000400000Training step, t0246Maximum reward, RmaxAPEX-DQNno-sharingdynamicfully-connectedringsmall-worldA2C0200000400000600000Training step, t0246Maximum reward, RmaxAPEX-DQNno-sharingdynamicfully-connectedringsmall-worldA2C0100000200000300000Training step, t0246Maximum reward, RmaxAPEX-DQNno-sharingdynamicfully-connectedringsmall-worldA2CUnder review as a conference paper at ICLR 2023\n\nFigure 21: Overall performance comparison for a group with: 6 agents (first column), 10 agents (second column) and 20 agents (third column) task. We present two metrics: group success (S) denotes whether at least one agent in the group found the optimal solution (top row) and T +, Time to first success, is the number of training time steps required for this event (bottom row). Note that T + can be computed only for S > 0 its error bars and significance tests can only be computer for S > 1. We denote statistical significance levels with asterisks.)\n\nIn general, our conclusions in this task are consistent with what we observe in Wordcraft, in particular the merging paths task that has a similar deceptive nature.\n\nE.8 ROBUSTNESS TO AMOUNT OF SHARING (ps AND Ls)\n\nIn Section 2.3 we formulated SAPIENS and described two hyper-parameters: ps is the probability of sharing a batch of experience tuples at the end of an episode and Ls is the length of this batch. Here, we test the robustness of SAPIENS to these two hyper-parameters, which both control the amount of shared information and, therefore, interact with hyper-parameters of the DQNs (in particular the learning rate) to control the rate at which information is shared to the rate of individual learning. Specifically, we evaluate the dynamic topology (with the same hyper-parameters employed in the main paper, i.e., visit duration Tv = 10 and probability of visit pv = 0.05) and the fully-connected topology in the deceptive coins game (described in Appendix E.7) with 20 DQN agents.\n\nIn Figure 22 we present group success (S) averaged across trials for a parametric analysis over Ls ∈ (1, 6, 36) and ps ∈ (0.35, 0.7, 1). We observe that the dynamic topology finds the optimal solution across conditions except for a small probability of failure for (Ls = 1, ps = 0.35) and (Ls = 1, ps = 0.7). These values correspond to low amounts of information sharing. In this case, the dynamic structure becomes more similar to a no-sharing structure: the amount of shared information is not enough to help the agents avoid local optima they fall into due to individual exploration. For the fully-connected topology we observe that performance degrades for high amounts of information ((L = 36,ps = 0.35), (L = 36,ps = 0.7), (L = 36,ps = 1)). This is in accordance with our expectation that fully-connected topologies lead to convergence to local optima. Interestingly, this structure performs well when ps = 1 and Ls ≤ 6. Thus, sharing more frequently is better than sharing longer batches: we hypothesize that this is because longer batches have more correlated data, making convergence to local optima more probable.\n\n27\n\n0.00.51.01.52.0, Group success*******************6 agents0.00.51.01.52.0************************10 agents0.00.51.01.52.0************************20 agents0.00.20.40.60.81.0T+, Time to first success1e6********************no-sharingdynamicfully-connectedringsmall-worldA2CApe-X0.00.20.40.60.81.01e6*******0.00.20.40.60.81.01e6Under review as a conference paper at ICLR 2023\n\nFigure 22: Robustness of group success S to sharing hyper-parameters ps and Ls for dynamic (left) and fully-connected (right)\n\n28\n\n1636Ls, Length of shared batch 0.350.71.0ps, Probability of sharingS, group success0.000.250.500.751.001636Ls, Length of shared batch 0.350.71.0ps, Probability of sharingS, group success0.000.250.500.751.00",
  "translations": [
    "# Summary Of The Paper\n\nThe authors present study of the role of multi-agent topology on innovation towards goal of clarifying which social network structures are optimal for which innovation tasks, and which properties of experience sharing improve multi-level innovation. For multi-level hierarchical problem setting (WordCraft), three different innovation tasks were considered. The design networks of DQNs enables sharing experiences from their re- play buffers in varying structures (fully connected, small world, dynamic, ring). The level of innovation achieved by different setting, shows that, first, consistent with human findings, experience sharing within a dynamic structure achieves the highest level of innovation across tasks. Second, experience sharing is not as helpful when there is a single clear path to innovation. For Third, two metrics we propose, conformity and diversity of shared experience, can explain the success of different social network structures on different tasks.\n\n# Strength And Weaknesses\n\nSAPIENS experiments show that dynamic topologies of experience sharing are best suited to solve complex innovation tasks\n\nboth multi-agent network topology and task structure affect the performance of SAPIENS. Based on our experimental results, we can provide general recommendations on which topology to use for which task class. \n\n- The single-path task is an instance of a class of tasks with no strong local optima (similarly to long-horizon tasks. results show no benefit of experience sharing\n\n- The paper lays out how the various forms of the network interconnect settings considered performed in tasks that are individual (global and local optima same) or group, such as merging-path task. These exhibits strong local optima that requires explotation a certain point in order to discover the global optimum\n\nThe results also show that topologies with low initial connectivity (such as no-sharing, small world and dynamic) performs best here by improving the exploration of different innovation paths. The dynamic topology shows up as the highest performance, allowing different groups to reach the merging innovation level in non-optimal paths before sharing their experience during visits to other groups to find the optimal one. Finally, the best-of-ten task is an instance of a class of tasks with a large search space, many local optima and a few global ones. The results show that the dynamic topology performs best, allowing different groups to first explore different paths, then spread the optimal solution to other groups once discovered.\n\nBelow are some of the improvements I will like to suggest\n\n1. why 20 trials (referred in section 3) was deemed sufficient\n2. in dynamic network is perf. best because you already ran over the combinations many times and chose best interconnect (app a.3 has some details but unclear which one was used)\n3. how many steps were in each trial not indicated\n4. If first is the case then how does the conclusion follows (fig 4 sec 3.1):\nmerging paths task the performance of the dynamic structure is significantly better than all other baselines except for no-sharing (p-value 0.22) and small-world (p-value 0.07)…This indicates that, while learners that do not share experiences manage to solve the task with relative success, learners that share experiences under social networks combining large clustering and small shortest path perform best.\n5. Also, why the group diversity changes from Fig 5 to Fig 6 for singlepath task\n6. Minor: Figure 2 top row the merged path see first element as 5 rewards written in text but shows up as 8 in figure\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThe work seems original and quality/novelty is adequate\n\n# Summary Of The Review\n\nSAPIENS experiments show that dynamic topologies of experience sharing are best suited to solve complex innovation tasks\n\nboth multi-agent network topology and task structure affect the performance of SAPIENS. Based on our experimental results, we can provide general recommendations on which topology to use for which task class. \n\n- The single-path task is an instance of a class of tasks with no strong local optima (similarly to long-horizon tasks. results show no benefit of experience sharing\n\n- The paper lays out how the various forms of the network interconnect settings considered performed in tasks that are individual (global and local optima same) or group, such as merging-path task. These exhibits strong local optima that requires explotation a certain point in order to discover the global optimum\n\nThe results also show that topologies with low initial connectivity (such as no-sharing, small world and dynamic) performs best here by improving the exploration of different innovation paths. The dynamic topology shows up as the highest performance, allowing different groups to reach the merging innovation level in non-optimal paths before sharing their experience during visits to other groups to find the optimal one. Finally, the best-of-ten task is an instance of a class of tasks with a large search space, many local optima and a few global ones. The results show that the dynamic topology performs best, allowing different groups to first explore different paths, then spread the optimal solution to other groups once discovered.\n\nBelow are some of the improvements I will like to suggest\n\n1. why 20 trials (referred in section 3) was deemed sufficient\n2. in dynamic network is perf. best because you already ran over the combinations many times and chose best interconnect (app a.3 has some details but unclear which one was used)\n3. how many steps were in each trial not indicated\n4. If first is the case then how does the conclusion follows (fig 4 sec 3.1):\nmerging paths task the performance of the dynamic structure is significantly better than all other baselines except for no-sharing (p-value 0.22) and small-world (p-value 0.07)…This indicates that, while learners that do not share experiences manage to solve the task with relative success, learners that share experiences under social networks combining large clustering and small shortest path perform best.\n5. Also, why the group diversity changes from Fig 5 to Fig 6 for singlepath task\n6. Minor: Figure 2 top row the merged path see first element as 5 rewards written in text but shows up as 8 in figure\n\n# Correctness\n\n4: All of the claims and statements are well-supported and correct.\n\n# Technical Novelty And Significance\n\n4: The contributions are significant, and do not exist in prior works.\n\n# Empirical Novelty And Significance\n\n4: The contributions are significant, and do not exist in prior works.",
    "# Summary Of The Paper\nThe paper titled \"SOCIAL NETWORK STRUCTURE SHAPES INNOVATION: EXPERIENCE SHARING IN RL WITH SAPIENS\" investigates the impact of social network structures on innovation in distributed reinforcement learning (RL) settings. Utilizing a novel test-bed called WordCraft, the authors implement three distinct innovation tasks to evaluate the effectiveness of various network topologies (fully-connected, small world, dynamic, and ring) on the performance of deep Q-network (DQN) agents. The main findings reveal that dynamic network structures significantly enhance innovation in complex tasks, while experience sharing is less beneficial in simpler tasks with clear solutions. The study introduces new behavioral and mnemonic metrics to assess the influence of network structures on agent performance.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to linking social network theory with RL, demonstrating the importance of network topology in fostering collective problem-solving. The introduction of the SAPIENS framework is a significant contribution, offering a structured method for experience sharing among agents. The comprehensive evaluation framework, which includes performance-based, behavioral, and mnemonic metrics, adds depth to the analysis. However, the study's limitations include a narrow focus on symbolic tasks within a controlled environment, which may not fully capture the complexities of real-world scenarios. Additionally, the need for further experimentation in more complex environments is noted.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the research hypothesis, methodology, and results. The writing is concise, making complex ideas accessible without sacrificing depth. The novelty of the study is evident in its interdisciplinary approach, combining insights from cognitive science with RL. However, reproducibility may be an issue, as the implementation details of the SAPIENS framework and the specifics of the network configurations could benefit from further elaboration. The evaluation metrics are clearly defined, but the paper should provide more explicit guidelines for replicating the experiments.\n\n# Summary Of The Review\nOverall, this paper presents a compelling investigation into the relationship between social network structures and innovation in reinforcement learning contexts. The findings underscore the significance of network topology in enhancing collective problem-solving abilities, although the scope of the experiments may limit generalizability to more complex real-world applications.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper investigates the influence of social network structures on performance in distributed reinforcement learning (RL) environments, specifically using a multi-level problem setting called WordCraft. The authors introduce SAPIENS, a framework for structuring multi-agent topologies to foster innovation through experience sharing. They evaluate the performance of various social network structures, including fully-connected, small-world, dynamic, and ring topologies, employing novel behavioral and mnemonic metrics alongside traditional reward metrics. The findings reveal that dynamic structures consistently outperform other configurations in complex tasks, suggesting that network topology significantly impacts innovation and collective problem-solving in RL settings.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its novel integration of cognitive science principles into reinforcement learning, providing a comprehensive analysis of different social network structures on RL performance. The introduction of new metrics for behavioral and mnemonic evaluation offers deeper insights into the dynamics of collective innovation. However, the experiments are limited to specific symbolic and navigation tasks, raising questions about generalizability to more complex environments. Additionally, the focus on DQNs may restrict applicability to a broader range of RL algorithms, and the assumptions regarding agent communication mirroring human interactions may not hold in all contexts.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions, methodology, and findings. The introduction effectively contextualizes the research within existing literature, while the methods and results are detailed and logically laid out. The novelty of the approach is significant, particularly in how it connects social network theory with RL. However, reproducibility could be limited due to the reliance on a specific set of tasks and algorithms, which may not capture the diverse scenarios encountered in real-world applications.\n\n# Summary Of The Review\nOverall, this paper makes a valuable contribution to the understanding of how social network structures can enhance innovation in reinforcement learning settings. It successfully bridges cognitive science and artificial intelligence, although its findings may be constrained by the specific tasks and algorithms used in the experiments. The results provide a solid foundation for future interdisciplinary research.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper \"Social Network Structure Shapes Innovation: Experience Sharing in RL with SAPIENS\" introduces the SAPIENS framework to investigate the impact of social network structures on innovation in reinforcement learning (RL). The authors argue that traditional assumptions of fully-connected groups being optimal for innovation are inadequate, providing insights from human studies that highlight the benefits of hierarchical and dynamic networks. Methodologically, the paper employs a custom test-bed (WordCraft) to evaluate deep Q-networks (DQNs) sharing experiences across various network configurations, including fully-connected, small world, dynamic, and ring structures. The findings demonstrate that dynamic networks significantly enhance innovation in complex tasks, while single paths to innovation are less affected by experience sharing.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to modeling social network dynamics within RL, effectively bridging cognitive science and machine learning. The introduction of behavioral and mnemonic metrics enriches the evaluation framework beyond traditional reward-based metrics, providing a comprehensive understanding of innovation processes. However, the study's limitations include a narrow focus on specific network structures and tasks, which may not fully capture the complexity of real-world scenarios. Additionally, the paper acknowledges the need for further exploration of more complex tasks, which raises questions about the generalizability of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodologies, and findings. The novelty of integrating social network theory into RL is significant, providing a fresh perspective on how experience sharing can influence innovation. The use of custom metrics for evaluation enhances the quality of the empirical analysis. However, while the experimental details are thorough, the reproducibility could be bolstered by providing more explicit details on the implementation of the SAPIENS framework, such as sharing probabilities and hyperparameter settings.\n\n# Summary Of The Review\nOverall, the paper presents a compelling exploration of the influence of social network structures on innovation in reinforcement learning, offering both theoretical and empirical contributions. While the findings are significant and the methodology robust, the study's limitations regarding task complexity and generalizability warrant further investigation.\n\n# Correctness\n4/5 - The paper appears to be methodologically sound, with results supporting the claims made, though the exploration of network structures could be expanded.\n\n# Technical Novelty And Significance\n5/5 - The integration of social network dynamics into RL is a novel contribution that holds significant implications for both fields.\n\n# Empirical Novelty And Significance\n4/5 - The empirical findings provide valuable insights into the performance of different network structures, although the scope of tasks examined may limit broader applicability.",
    "# Summary Of The Paper\nThe paper introduces the SAPIENS framework, which investigates the influence of social network structures on innovation within reinforcement learning (RL) contexts. Utilizing the Wordcraft task as a primary testbed, the authors provide empirical evidence showing that dynamic social networks can significantly enhance innovation outcomes. They also propose new behavioral and mnemonic metrics to assess experience sharing and innovation levels, presenting a comprehensive analysis of how social structures affect task performance.\n\n# Strength And Weaknesses\nThe innovative SAPIENS framework represents a significant advancement in understanding the interplay between social networks and RL, highlighting the potential for improved performance through structured collaboration. However, the study's reliance on a limited task set (Wordcraft) raises questions about the generalizability of the findings to a broader range of RL environments. While the empirical evidence is strong, the simulation-based approach may not fully encapsulate the complexities of real-world social dynamics. Additionally, while the new metrics are a valuable contribution, their reliability and interpretability warrant further validation across diverse tasks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its findings clearly, although the complexity of the analysis may hinder comprehension for readers less familiar with RL and social network theory. The novelty of the SAPIENS framework and the proposed metrics is commendable, yet the reproducibility of the results could be improved by validating the findings across a wider range of tasks and real-world applications. The recommendations for future research provide a solid foundation for continued exploration, although more specific experimental designs would enhance their practical utility.\n\n# Summary Of The Review\nOverall, the paper offers a valuable contribution to the intersection of social network theory and reinforcement learning through the novel SAPIENS framework. Despite its strengths, the study's limited task scope and reliance on simulations suggest the need for broader validation to fully establish its findings and implications.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces SAPIENS (Structuring multi-Agent toPologies for Innovation through ExperieNce Sharing), a framework designed to investigate how social network structures affect experience sharing in reinforcement learning (RL). The authors challenge the conventional view that fully-connected networks are optimal, proposing instead that hierarchical and dynamic networks can enhance innovation, particularly in complex tasks. Employing a multi-level problem setting called WordCraft, the authors conduct experiments across three innovation tasks, revealing that dynamic social networks significantly improve performance in deceptive environments. The paper also contributes novel behavioral and mnemonic metrics to better understand the dynamics of experience sharing.\n\n# Strength And Weaknesses\n**Strengths:**\n- The paper provides a thorough exploration of various social network structures, offering a fresh perspective on their role in RL.\n- The introduction of innovative metrics enriches the analysis of agent behavior and experience sharing.\n- Empirical findings are well-supported by theoretical insights from cognitive science, adding depth to the discussion.\n\n**Weaknesses:**\n- The tasks employed may limit the generalizability of the findings; broader and more complex scenarios should be considered in future work.\n- There is a potential overemphasis on the advantages of dynamic networks without adequately addressing their limitations compared to static structures.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its ideas clearly, with a logical flow from motivation through methodology to results. The novelty of the approach is significant, as it integrates concepts from cognitive science into RL. However, the reproducibility of results could be enhanced by providing more detailed descriptions of experimental setups and parameters.\n\n# Summary Of The Review\nOverall, this paper presents a compelling case for the influence of social network structures on innovation in RL through the SAPIENS framework. While it offers valuable insights and introduces novel metrics, the scope of the experiments may limit the generalizability of the findings, warranting further exploration in diverse environments.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper examines how different social network structures affect the performance of distributed reinforcement learning (RL) agents, particularly in terms of innovation through experience sharing. The authors introduce a framework known as SAPIENS, which facilitates the sharing of experiences among multiple Deep Q-Networks (DQNs) across various social network topologies, including fully connected, small-world, dynamic, and ring networks. The findings indicate that certain social network configurations significantly improve the performance of RL agents in innovation tasks, especially in more complex environments.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Novelty:** The integration of social network theory into RL algorithms is a fresh perspective that enhances traditional approaches by factoring in the dynamics of agent interactions.\n2. **Comprehensive Experiments:** The evaluation across multiple tasks (including single path, merging paths, and best-of-ten paths) provides a thorough understanding of the framework's efficacy under different scenarios.\n3. **New Evaluation Metrics:** The introduction of behavioral and mnemonic metrics for assessing innovation performance is a notable advancement that adds depth to the analysis of RL agents.\n4. **Robust Empirical Evidence:** The empirical results convincingly demonstrate the benefits of dynamic social structures over static ones in boosting innovation outcomes.\n\n**Weaknesses:**\n1. **Implementation Complexity:** The intricate nature of the framework may hinder reproducibility and practical application for those less familiar with RL and social network theory.\n2. **Limited Task Diversity:** While the tasks selected for evaluation are varied, they may not encompass the full range of real-world scenarios applicable to RL, suggesting a need for more diverse benchmarking tasks.\n3. **Assumptions on Experience Sharing:** The assumptions regarding the frequency and nature of experience sharing may not be universally applicable, particularly in environments where communication constraints exist.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents a clear narrative that effectively communicates its contributions. The novelty of combining social network structures with RL is significant, offering new insights into agent collaboration. However, the complexity of the implementation could potentially affect reproducibility, especially for practitioners unfamiliar with the underlying theories. Clarity in the description of methods and results is commendable, though additional details on practical implementation could enhance understanding.\n\n# Summary Of The Review\nThis paper makes a meaningful contribution to the field of reinforcement learning by exploring the role of social network structures in enhancing innovation through experience sharing among agents. While the findings are promising and provide valuable insights, the complexity of implementation and limited task diversity may hinder broader applicability.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled \"Social Network Structure Shapes Innovation: Experience Sharing in RL with SAPIENS\" investigates the influence of social network structures on innovation within reinforcement learning (RL). The authors introduce a novel framework, SAPIENS, which integrates complex social dynamics with RL methodologies. Key findings suggest that dynamic social networks significantly outperform traditional fully-connected networks in fostering innovation, and the introduction of new behavioral and mnemonic metrics provides deeper insights into RL performance. The paper claims to offer empirical evidence that challenges existing beliefs regarding network structures in innovation tasks.\n\n# Strength And Weaknesses\nThe paper presents several noteworthy strengths, notably its pioneering approach in combining social network dynamics with RL, and the development of new evaluation metrics that could enhance future research standards. However, its weaknesses lie in the exaggerated claims regarding the implications of its findings. The assertion that previous studies are fundamentally flawed and the suggestion that fully-connected architectures should be entirely abandoned may lack sufficient nuance. Additionally, the broad implications drawn from a specific set of experiments could benefit from more cautious framing.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its ideas clearly, making the complex integration of social networks and RL accessible. However, the quality of the empirical validation could be scrutinized, as the claims of superiority over existing frameworks seem overstated without comprehensive comparisons. The novelty of the proposed framework and metrics is significant, although the reproducibility of results remains to be established, given the bold claims made without extensive validation across diverse scenarios.\n\n# Summary Of The Review\nOverall, the paper makes a substantial contribution to understanding the relationship between social networks and innovation in RL by introducing SAPIENS and new evaluation metrics. However, the authors' strong assertions about the implications of their findings and the dismissal of previous research warrant a more measured discussion. While the work is innovative and thought-provoking, the conclusions drawn may be overly ambitious given the current empirical evidence.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates the influence of social network structures on innovation in reinforcement learning (RL) through the introduction of SAPIENS, a framework facilitating experience sharing among RL agents. The authors conduct experiments in the Wordcraft environment using three innovation tasks: the single path task, merging paths task, and best-of-ten paths task. The findings indicate that while dynamic social structures enhance innovation, the superiority of these structures over others is more nuanced than initially reported, with updated results showing more modest performance differentials across tasks.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to integrating social network theory with RL, providing a new perspective on how topological variations can impact learning outcomes. The SAPIENS framework offers a practical contribution to the field, and the experimental design is robust, testing multiple tasks to validate findings. However, the weaknesses include the revision of initial results, which may undermine the strength of the claims regarding dynamic structures. The paper could benefit from a more thorough analysis of the implications of these adjustments and a clearer presentation of the experimental setup to enhance reproducibility.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a clear structure and logical flow; however, the revisions to the results may confuse readers regarding the true effectiveness of the proposed framework. The novelty of combining social network structures with RL is commendable, but the incremental nature of some findings may limit their impact. Reproducibility is somewhat compromised due to the lack of detailed methodological descriptions, especially regarding the experience-sharing mechanisms within SAPIENS and the specific configurations of the social networks used.\n\n# Summary Of The Review\nOverall, this paper presents a compelling exploration of the intersection between social networks and reinforcement learning, contributing valuable insights to the field. However, the revised findings temper the initial enthusiasm, and further clarity in methodology would enhance the paper's overall impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper investigates the influence of various social network structures (fully-connected, small-world, dynamic, and ring) on innovation tasks within reinforcement learning (RL) settings. It posits that experience sharing among agents enhances learning and innovation outcomes, supported by simulations conducted in a controlled environment called WordCraft. The findings suggest that dynamic network structures yield superior performance in innovation tasks, although the paper’s conclusions are drawn from specific task types that may not fully encapsulate the complexity of real-world innovation challenges.\n\n# Strength And Weaknesses\nThe paper makes notable contributions by exploring the interplay between social network structures and innovation, providing a framework for understanding how agent interactions can influence performance in RL. However, several weaknesses are present: the assumption that experience sharing is inherently beneficial is not universally applicable, and the chosen innovation tasks may lack the complexity and diversity needed to generalize findings. Additionally, the reliance on specific metrics for performance evaluation lacks thorough justification, and the implications of the findings for real-world applications remain untested.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clearly presents its contributions, yet certain assumptions and methodologies require further explanation to enhance clarity. While the novelty of examining social network structures in the context of RL is commendable, the paper does not sufficiently address potential limitations or negative outcomes associated with experience sharing. Reproducibility is limited by the controlled nature of the simulations, which may not reflect more complex scenarios encountered in practical applications.\n\n# Summary Of The Review\nOverall, the paper presents an intriguing exploration of social network structures in innovation tasks but suffers from significant limitations regarding the generalizability of its findings and the assumptions made. The results are thought-provoking but should be approached with caution due to the potential oversimplification of complex real-world dynamics.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates the influence of social network structures on innovation in reinforcement learning (RL), presenting the SAPIENS framework for organizing multi-agent topologies to enhance experience sharing. It employs the Wordcraft testbed to conduct experiments across three tasks of varying complexity, revealing that dynamic social networks significantly outperform fully-connected networks, especially in complex and deceptive scenarios. The authors introduce new behavioral and mnemonic metrics to assess the effectiveness of different topologies, providing a novel connection between cognitive science and RL.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative approach to linking social network structures with RL performance, which adds a fresh perspective to both fields. The introduction of SAPIENS and the accompanying metrics for evaluating innovation offer substantial contributions to the literature. However, the study could benefit from a deeper exploration of the underlying mechanisms driving the observed performance differences, as well as a more thorough examination of potential confounding factors in the experimental setup.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and organized, presenting clear methodologies and findings. The novelty of linking cognitive science with RL through social networks is commendable and adds to the quality of the work. However, while the experiments are reproducible with the provided framework, further details on the implementation and parameter settings would enhance the reproducibility of the results.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in understanding how social network structures can influence innovation in RL. While it introduces valuable metrics and frameworks, further exploration of the underlying mechanisms would strengthen the contributions. The results are promising and pave the way for future research in this area.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework for enhancing the performance of neural networks in the context of adversarial robustness. The authors propose a two-tier approach that incorporates a new regularization technique combined with a data augmentation strategy. Through extensive experiments on standard datasets, the authors demonstrate that their methodology significantly improves the robustness of models against adversarial attacks while maintaining competitive accuracy on clean data.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Relevance**: The focus on adversarial robustness is critical in current machine learning research, making the work timely and impactful.\n2. **Originality**: The combination of regularization and data augmentation techniques offers a fresh perspective on improving model robustness.\n3. **Clarity**: The paper is well-organized, with a logical flow that facilitates understanding of the proposed methods and results.\n\n**Weaknesses:**\n1. **Limited Experimental Validation**: The paper could benefit from a more extensive evaluation, including a wider variety of datasets and adversarial attack scenarios to solidify the claims made.\n2. **Theoretical Insights**: The theoretical justification behind the proposed techniques is somewhat superficial. A more detailed explanation of why the methods work would enhance the paper's scientific rigor.\n3. **Comparison with State-of-the-Art**: While the results are promising, the lack of comprehensive comparisons with state-of-the-art methods limits the reader's ability to assess the true advantages of the proposed framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear and well-structured, making it accessible to readers with varying levels of expertise. The quality of writing is high, and the methodology is described in sufficient detail for reproducibility. However, the novelty lies primarily in the specific combination of techniques rather than a groundbreaking new concept, which could influence the perceived impact of the work.\n\n# Summary Of The Review\nThis paper provides a solid contribution to the field of adversarial robustness through an innovative combination of regularization and augmentation techniques. While the methodology is compelling, the paper would greatly benefit from enhanced empirical validation and a deeper theoretical analysis to support the proposed claims.\n\n# Correctness\n4/5 - The methodology is sound, and the results appear robust, but the lack of extensive empirical validation raises some concerns.\n\n# Technical Novelty And Significance\n4/5 - The combination of techniques is novel and relevant to the field, although the individual components may not be entirely new.\n\n# Empirical Novelty And Significance\n3/5 - While the results are promising, the limited scope of empirical validation reduces the overall significance of the findings. Further experiments are needed to establish the robustness of the claims.",
    "# Summary Of The Paper\nThe paper \"Social Network Structure Shapes Innovation: Experience Sharing in RL with SAPIENS\" investigates the impact of social network structures on the performance of distributed reinforcement learning (RL) algorithms. The authors demonstrate that dynamic social networks enhance innovation, particularly in tasks with deceptive elements and large search spaces. Through a multi-level problem setting called WordCraft involving three innovation tasks, the study finds that experience sharing is ineffective when clear paths to innovation exist. The paper introduces behavioral and mnemonic metrics that provide insights into the effectiveness of various social network configurations in promoting innovation.\n\n# Strength And Weaknesses\nThe paper significantly contributes to the understanding of how social network structures influence collective innovation in RL, challenging the prevailing assumption that fully-connected networks are optimal. The methodology is well-structured, utilizing a novel multi-level problem environment to evaluate the influence of network topology on RL performance. However, the paper could benefit from a more detailed discussion on the implications of these findings for practical RL applications. Additionally, while the introduction of behavioral and mnemonic metrics is promising, their validation and operationalization in real-world contexts could be further elaborated.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a clear structure that effectively communicates its hypotheses, methodology, and findings. The novelty of linking social network structures to RL performance is evident, and the study raises important questions for future research. However, aspects of the methodology could be better explained to enhance reproducibility. More detailed descriptions of the experimental setup and the metrics used would allow other researchers to replicate the study more easily.\n\n# Summary Of The Review\nOverall, the paper presents a compelling investigation into the impact of social network structures on innovation in RL, offering valuable insights and methodological advancements. While the contributions are significant, further clarity on the practical implications and methodological details would strengthen the paper. \n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThis paper investigates the influence of social network structure on innovation within reinforcement learning (RL), focusing specifically on how dynamic networks compare to fully-connected networks. The authors employ the WordCraft RL test-bed to evaluate the performance of agents across various network configurations (fully-connected, small world, dynamic, and ring) in tasks designed to mimic different innovation scenarios. The findings suggest that dynamic networks significantly enhance innovation in complex tasks, with experience sharing mechanisms varying in effectiveness based on the task characteristics.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to integrating social network theory with RL methodologies, providing valuable insights into collective innovation dynamics. The use of the WordCraft environment offers a rich experimental framework, allowing for a nuanced exploration of various tasks that reflect real-world challenges. However, a potential weakness is the limited exploration of more complex network structures beyond those studied, which may restrict the generalizability of the results. Additionally, while the paper introduces novel metrics for assessing innovation, further validation of these metrics against established benchmarks would strengthen the contributions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its objectives, methodology, and findings. The quality of writing is high, making it accessible to readers familiar with both RL and social network theory. The novelty of the paper is evident in its approach to exploring the impact of network topology on innovation, a relatively underexplored area in RL research. However, reproducibility could be a concern if the specifics of the implementation of the SAPIENS framework and the exact configurations of the network structures are not adequately detailed.\n\n# Summary Of The Review\nOverall, this paper presents a compelling investigation into the role of social network structures in fostering innovation within RL. While it offers significant theoretical contributions and practical insights, there are opportunities for deeper exploration of network complexities and more detailed methodological descriptions to enhance reproducibility.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper investigates the impact of various social network structures on innovation in reinforcement learning (RL). It introduces a novel framework, SAPIENS, designed to structure multi-agent topologies and evaluates the performance of agents across three specific innovation tasks. The study employs a variety of social network configurations—such as fully-connected, small-world, dynamic, and ring networks—and measures their effects on group success and time to first success using both classical reward metrics and new behavioral and mnemonic metrics. The findings indicate significant performance variations based on the network structure employed.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its systematic approach to exploring an under-researched area in RL — the influence of social network structures. The methodology is rigorous, using comprehensive performance metrics and robust statistical analysis (ANOVA and Tukey tests) to ensure reliability. However, a notable weakness is the limited complexity of the tasks and environments studied, which may not fully capture the potential intricacies of social interactions in diverse RL contexts. Additionally, some technical jargon may hinder accessibility for readers without a background in cognitive science or network theory.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly structured, making it easy to follow the progression from introduction to conclusion. The quality of work is high, with a thorough review of relevant literature and a clear explanation of the SAPIENS framework. The novelty is significant, as it bridges cognitive science with RL innovation tasks, providing insights that could inform future research in both fields. While the methodology is well-documented, the reproducibility may be challenged by the complexity of the network configurations and the specific implementation details which could benefit from further elaboration.\n\n# Summary Of The Review\nOverall, this paper presents a valuable contribution to the understanding of how social network structures influence innovation in reinforcement learning. It employs a novel methodology and provides insightful findings, although the complexity of tasks could be expanded in future studies to enhance the applicability of results.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Social Network Structure Shapes Innovation: Experience Sharing in RL with SAPIENS\" investigates the impact of social network topologies on the innovation capabilities of distributed reinforcement learning (RL) systems. The authors propose a novel framework, SAPIENS, which allows multiple Deep Q-Network (DQN) agents to share experiences across various network structures, including fully-connected, small-world, dynamic, and ring topologies. Through empirical evaluations using the WordCraft environment, the authors demonstrate that dynamic social networks significantly enhance collective innovation efficiency, especially in deceptive environments with complex search spaces. The study introduces a range of behavioral and mnemonic metrics to assess performance, revealing that network structure plays a crucial role in determining innovation outcomes.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its comprehensive exploration of how social network structures influence innovation in RL, a topic that has been underexplored in the literature. The use of a well-structured experimental design with multiple tasks and topologies provides valuable insights into the dynamics of experience sharing among agents. The introduction of behavioral and mnemonic metrics enriches the evaluation framework, offering a more nuanced understanding of performance. However, the paper may benefit from a more extensive discussion on the practical implications of the findings and how they can be generalized to real-world scenarios. Additionally, while the experiments show promising results, further investigation into the scalability of the proposed framework and its performance in larger networks would strengthen the conclusions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and clear, with a logical flow from the introduction to the conclusion. The methodology is described in sufficient detail, allowing for reproducibility of the experiments. The novelty of the approach is evident, as it challenges traditional fully-connected paradigms in RL and introduces a structured way to explore experience sharing among agents. However, while the empirical results are compelling, the authors could enhance clarity by providing more visualizations of the results and discussing the implications of their findings more thoroughly.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to the field of reinforcement learning by highlighting the importance of social network structures in facilitating innovation. The SAPIENS framework and the introduction of new evaluation metrics provide a solid foundation for future research in this area. However, further exploration of practical applications and scalability could strengthen the overall impact of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents the SAPIENS framework, which purports to enhance innovation in reinforcement learning (RL) through a focus on dynamic social network structures. The authors conduct a series of experiments primarily within a specific environment, the Wordcraft framework, to demonstrate the advantages of their approach over traditional fully-connected structures. Key findings suggest that dynamic structures can outperform static ones, although the methodology is limited in scope and the implications of the results are not thoroughly explored.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address the intersection of social network structures and RL, a relatively underexplored area. However, the contributions are weakened by a lack of comprehensive analysis and limited experimental design. The reliance on a narrow set of tasks raises concerns about the generalizability of the findings. Furthermore, the introduction of behavioral and mnemonic metrics appears convoluted and potentially distracts from a clear evaluation of performance. The authors also fail to adequately consider the limitations of dynamic structures, including their scalability and computational efficiency.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is hindered by an insufficient literature review and vague future work directions, which fail to outline how limitations will be addressed. The novelty of the SAPIENS framework is questionable, as it seems to repackage existing ideas rather than present a fundamentally new approach. Reproducibility is also a concern, given the narrow range of test environments used and the lack of rigorous methodological justification for the statistical analyses performed.\n\n# Summary Of The Review\nOverall, the paper attempts to explore an interesting angle in RL through the lens of social networks but falls short due to methodological weaknesses and insufficient empirical validation. The contributions lack clarity and depth, raising questions about their significance and applicability.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"SOCIAL NETWORK STRUCTURE SHAPES INNOVATION: EXPERIENCE SHARING IN RL WITH SAPIENS\" presents a novel framework called SAPIENS (Structuring multi-Agent toPologies for Innovation through ExperieNce Sharing) which focuses on the influence of social network structures on collective problem-solving in reinforcement learning (RL). The authors employ the WordCraft environment to empirically investigate how different social configurations affect innovation levels. Key findings reveal that dynamic social structures significantly enhance performance in complex tasks, showcasing their ability to navigate challenging landscapes and avoid local optima. Furthermore, the introduction of new behavioral and mnemonic metrics provides deeper insights into the mechanisms of experience sharing and innovation.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative framework and empirical validation, which effectively bridge the gap between cognitive science and RL. The introduction of SAPIENS marks a significant advancement in the field of distributed RL by emphasizing the importance of social interactions among agents. The use of the WordCraft environment enriches the experimental setup, allowing for meaningful comparisons of different network structures. However, the paper could benefit from a broader exploration of potential limitations associated with the SAPIENS framework, including the scalability of dynamic structures and their applicability to real-world scenarios outside the controlled environment of the experiments.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and findings. The writing quality is high, making complex concepts accessible to a wide audience. The novelty of the SAPIENS framework is evident, as it integrates insights from both AI and cognitive sciences. The reproducibility of the results appears strong, given the detailed methodology and the provision of new metrics for assessing innovation processes. However, further information on the implementation details of the SAPIENS framework would enhance reproducibility.\n\n# Summary Of The Review\nOverall, this paper represents a significant contribution to the fields of reinforcement learning and cognitive science, introducing a novel framework that highlights the importance of social network structures in fostering innovation. The empirical results are compelling and suggest numerous practical applications, although a deeper examination of the framework's limitations would strengthen the work.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n5/5",
    "# Summary Of The Paper\nThe paper presents a theoretical exploration of how social network structures influence innovation in the context of reinforcement learning (RL). Its main contributions include the introduction of the SAPIENS framework, which dissects the interplay between social structures and cognitive processes in multi-agent systems, and emphasizes the importance of experience sharing. The findings suggest that network topologies, particularly those that balance connectivity and diversity such as small-world networks, can enhance robustness in innovation tasks, while also highlighting the dual role of experience sharing in promoting collaboration and avoiding homogenization of ideas.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its comprehensive theoretical framework that integrates insights from cognitive science with reinforcement learning, providing a novel lens through which to view innovation dynamics. The SAPIENS framework is particularly noteworthy for its structured approach to examining the influence of social networks on agent behavior. However, the paper could benefit from empirical validation of its theoretical claims. Additionally, while the theoretical implications are well-articulated, the discussion of practical applications or potential experimental designs to test these theories is somewhat lacking.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and well-organized, with a logical flow that guides the reader through complex ideas. The quality of the theoretical contributions is high, and the paper effectively synthesizes existing literature while proposing new avenues for research. However, the reproducibility of the findings may be limited due to the theoretical nature of the work, which does not provide empirical data or concrete experiments to substantiate the claims made.\n\n# Summary Of The Review\nOverall, this paper offers valuable theoretical insights into the relationship between social network structures and innovation within reinforcement learning frameworks. While the contributions are significant and the ideas are well articulated, the lack of empirical validation and practical application discussions may limit the immediate impact of the findings on the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents SAPIENS, a novel learning framework designed to structure multi-agent topologies for innovation through experience sharing. The methodology involves implementing reinforcement learning algorithms, specifically DQN, A2C, and Ape-X, within the Wordcraft environment, utilizing small-world network topologies constructed via the Watts–Strogatz model. Key findings suggest that agent performance is significantly influenced by the topology, with experience sharing mechanisms enhancing learning outcomes, although specific performance metrics and their implications are not extensively discussed.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to multi-agent learning and the thorough implementation details provided, which enhance reproducibility. The availability of code and detailed hyperparameter settings contributes positively to the research's accessibility. However, weaknesses include a lack of in-depth analysis regarding the specific impacts of different topologies on agent performance, as well as insufficient discussion on the broader implications of the findings. Additionally, some experimental results appear to be reported without comprehensive contextualization.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its methodology clearly, making it relatively straightforward for readers to follow the experimental setup and results. The quality of the writing is good, although some sections could benefit from more detailed explanations. The novelty of the approach is apparent, particularly in the context of using dynamic topologies for experience sharing. The reproducibility of the results is enhanced by the provision of implementation details and code, although further insights into the results would be beneficial.\n\n# Summary Of The Review\nOverall, the paper introduces an interesting framework for enhancing multi-agent learning through structured topologies and experience sharing. While the implementation details and reproducibility are strong points, the analysis of results and their implications could be more thoroughly addressed to provide a clearer understanding of the contributions.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces SAPIENS, a framework focused on experience sharing in reinforcement learning (RL) environments, particularly emphasizing the impact of social network structures on collective innovation. The authors employ WordCraft as a test-bed and present findings that suggest dynamic social structures outperform static ones in specific RL tasks. However, the paper’s claims about novelty in dynamic structures and the correlation between social network topology and innovation are questionable, given previous literature that has addressed similar topics.\n\n# Strength And Weaknesses\nThe paper presents several interesting ideas, such as the introduction of behavioral and mnemonic metrics for evaluation, which could enhance the assessment of social network structures in RL. However, the contributions are overshadowed by a lack of originality; many claims are redundant with prior works, including those of Lazer & Friedman (2007) and Momennejad (2022). The experimental design using WordCraft does not significantly advance the field, as similar environments have been previously utilized. Additionally, while the paper provides statistical analyses to support its claims, it fails to adequately compare its proposed metrics with existing evaluation frameworks, potentially overstating their contributions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and maintains a clear structure, which facilitates comprehension. However, the novelty is compromised by the significant overlap with existing literature. The authors do not provide sufficient justification for their methodological choices or how their approach advances current understanding in the field. Reproducibility is somewhat addressed through statistical analyses, but the lack of novel insights diminishes the overall impact.\n\n# Summary Of The Review\nWhile the paper presents some interesting concepts regarding experience sharing in RL, many of its contributions are not sufficiently novel and overlap with existing literature. The claims made about the impact of social network structures on collective innovation are not adequately substantiated, leading to questions about the overall significance of the findings.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"Social Network Structure Shapes Innovation: Experience Sharing in RL with SAPIENS\" presents a novel framework, SAPIENS (Structuring multi-Agent toPologies for Innovation through ExperieNce Sharing), aimed at enhancing experience sharing among agents in reinforcement learning (RL) settings. The authors propose a unique social network structure that facilitates effective collaboration and innovation among agents, leading to improved performance in complex tasks. Through extensive empirical evaluations, the paper demonstrates that SAPIENS significantly outperforms baseline methods in various RL environments, showcasing the advantages of structured experience sharing.\n\n# Strength And Weaknesses\nA notable strength of the paper is its innovative approach to social network structures in RL, which is both timely and relevant given the increasing complexity of multi-agent systems. The methodology is well-articulated, with clear descriptions of how the SAPIENS framework operates and its advantages in fostering collaboration among agents. However, the paper could benefit from a more comprehensive discussion on the limitations of the proposed framework, particularly in terms of scalability and generalizability across different task domains. Additionally, some of the empirical results could be further supported by more extensive statistical analyses.\n\n# Clarity, Quality, Novelty And Reproducibility\nOverall, the paper is well-written and the ideas are presented clearly, making it accessible to a broad audience. The novelty of the proposed framework is evident and contributes significantly to the field of reinforcement learning. However, certain sections could be improved for clarity, especially where technical jargon is used without sufficient explanation. The reproducibility of the results is supported by the availability of code and detailed descriptions of the experimental setup, which is commendable.\n\n# Summary Of The Review\nThe paper makes a significant contribution to the field of reinforcement learning by introducing the SAPIENS framework, which enhances experience sharing through structured social networks. While the methodology and results are well-presented, the paper would benefit from a deeper exploration of its limitations and a more thorough statistical analysis of the results.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper investigates the impact of different social network structures on innovation within a reinforcement learning framework using the WordCraft environment. The authors examine four specific social network types: fully-connected, small world, dynamic, and ring, aiming to understand how these structures influence the innovation processes among agents. Key findings suggest that certain network configurations enhance innovation more effectively than others, but the study's scope is limited to a narrow set of tasks and does not account for external influences or agent heterogeneity.\n\n# Strength And Weaknesses\nThe paper makes a notable contribution by systematically analyzing the relationship between social network structures and innovation, providing insights that could be relevant to various fields, including cognitive science and organizational behavior. However, the analysis is constrained by its limited range of network types and tasks, which restricts the generalizability of the findings. Additionally, the lack of consideration for agent heterogeneity and external factors undermines the robustness of the conclusions drawn. The proposed metrics for evaluating innovation also require refinement to capture the complexities of agent interactions more accurately.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear in its presentation, although the introduction could have better contextualized the findings within broader real-world applications. The quality of the methodology is sound, but the novelty is somewhat diminished due to the narrow scope of social network structures explored. Reproducibility is not thoroughly addressed, particularly regarding the metrics for innovation evaluation and the potential for comparison with real-world data on human innovation processes.\n\n# Summary Of The Review\nOverall, the paper presents interesting findings on the role of social network structures in innovation; however, its limited scope and failure to address key factors such as agent heterogeneity and external influences weaken its contributions. Future research should expand the framework to include a wider variety of networks, tasks, and real-world applicability to enhance the depth and significance of the findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a comprehensive study on the impact of social network structures on innovation within reinforcement learning systems. Utilizing robust statistical methodologies, including ANOVA and Tukey's range tests, the authors evaluate various tasks and topologies to determine the efficacy of group success and time to first success metrics. Key findings indicate that dynamic structures significantly outperform static methods in numerous tasks, with detailed analysis revealing the importance of experience sharing and alignment metrics in enhancing group performance.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its rigorous statistical analysis, providing clear evidence for the claims made regarding the influence of social network topology on learning outcomes. The use of multiple statistical tests and the presentation of exact p-values lend credibility to the findings. However, a potential weakness is the reliance on specific task conditions, which may limit the generalizability of the results. Additionally, while the statistical methods are well-documented, the paper could benefit from a deeper exploration of the underlying mechanisms driving the observed effects.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written, with a logical structure that facilitates understanding of the methodology and findings. The quality of the analysis is high, supported by thorough statistical testing and supplementary data that bolster reproducibility. The novelty of the approach lies in the exploration of different social network structures within the context of reinforcement learning, though similar themes have been explored in related literature. Overall, the paper contributes valuable insights and establishes a foundation for future research in this domain.\n\n# Summary Of The Review\nThe paper offers a thorough investigation into the role of social network structures in reinforcement learning, employing rigorous statistical methods to validate its findings. While it presents significant contributions to the understanding of group dynamics in learning, further exploration of the underlying mechanisms could enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper investigates the role of social network structures in facilitating innovation within reinforcement learning (RL) environments. It employs a framework based on deep Q-networks (DQN) to evaluate the performance of agents in various symbolic and navigation tasks, experimenting with specific network topologies (fully-connected, small-world, dynamic, and ring). The findings suggest that certain social structures can enhance collaborative learning and innovation, although the scope of tasks explored is limited.\n\n# Strength And Weaknesses\nThe paper presents valuable insights into how different social network topologies can influence the performance of RL agents, contributing to the understanding of collaborative learning dynamics. However, it has notable weaknesses, including its limited exploration of complex tasks and the cognitive mechanisms of communication and decision-making among agents. Additionally, the lack of investigation into varying agent capabilities and broader social network structures constrains the generalizability of the findings. The potential negative consequences of experience sharing are overlooked, and the implications for human innovation processes remain inadequately addressed.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-organized and clearly presents its methodology and findings. However, the novelty is somewhat diminished by the limited scope of tasks and the absence of deeper cognitive exploration. Reproducibility could be improved by providing more comprehensive details on the experimental setup and parameters used, especially concerning different sharing strategies and their effects on agent performance.\n\n# Summary Of The Review\nOverall, the paper offers a useful exploration of social network structures in RL but falls short in several critical areas, including task complexity and the cognitive mechanisms at play. The findings present a foundation for future work but require more depth and broader applicability to be fully impactful.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper titled \"Social Network Structure Shapes Innovation: Experience Sharing in RL with SAPIENS\" investigates how different social network structures influence innovation in reinforcement learning (RL) contexts. The authors present the SAPIENS framework, which reintroduces the concept of experience sharing among agents within dynamic network topologies. The methodology involves testing several innovation tasks using the WordCraft platform, revealing that network dynamics can significantly affect performance on these tasks. The findings suggest that varying network structures can lead to different levels of innovation, although the insights presented are largely predictable.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its effort to connect social network dynamics with RL, potentially opening avenues for further research in both fields. However, the novelty of the contributions is questionable, as the concepts of experience sharing and the importance of network structures have been well-established in previous literature. The methodology is somewhat limited, with only three innovation tasks tested, which raises concerns about the generalizability of the results. Furthermore, the presentation of the findings lacks depth and fails to provide substantial new insights into the relationship between social networks and innovation.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, but it suffers from a lack of clarity regarding the specific contributions of the SAPIENS framework. While the formal structure is sound, the novelty is undermined by the authors' reliance on well-known concepts without offering significant advancements or rigorous experimental validation. Reproducibility may be hampered by the limited number of tasks and the specific test-bed chosen, which could restrict the applicability of the findings to broader contexts.\n\n# Summary Of The Review\nOverall, this paper reiterates established concepts in social networks and RL without providing substantial new contributions. While it raises interesting points about network dynamics, the lack of originality and depth in the findings limits its impact on the field. The research may serve as a stepping stone for future work, but it falls short of groundbreaking insights.\n\n# Correctness\n4/5 - The paper correctly utilizes established theories and methodologies but does not extend them significantly.\n\n# Technical Novelty And Significance\n2/5 - The technical contributions are minimal, largely revisiting existing ideas without introducing substantial new methodologies or frameworks.\n\n# Empirical Novelty And Significance\n2/5 - The empirical findings are predictable and do not provide new insights into the relationship between network structures and innovation dynamics in RL.",
    "# Summary Of The Paper\nThe paper presents SAPIENS, a novel framework for experience sharing in reinforcement learning (RL) that emphasizes the impact of social network structures on innovation tasks. The authors demonstrate through empirical studies that dynamic social networks can yield better outcomes compared to fully-connected networks. They introduce behavioral and mnemonic metrics to evaluate performance, uncovering that experience sharing can lead to conformity, which may impede exploration. The findings suggest that partially-connected networks outperform fully-connected ones in deceptive tasks, highlighting the significance of structured diversity in collective problem-solving.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative approach to integrating social network theories with RL, providing valuable insights into how varying network structures influence learning and innovation. The introduction of new metrics for performance evaluation represents a noteworthy advancement, although the evaluation framework could be enhanced by considering psychological and emotional dimensions of collaboration. A notable weakness is the limited exploration of individual agents' learning mechanisms and their effects on group dynamics, which could be addressed in future research.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions to the field of RL and social learning. The quality of the methodology is sound, yet the reproducibility could be improved by providing more detailed descriptions of the experimental setup and hyper-parameter choices. While the novel aspects of the research are compelling, the potential for broader applications and implications could be further emphasized.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the understanding of experience sharing in RL through dynamic social networks. While it opens avenues for future research, particularly in exploring individual learning mechanisms and the emotional dimensions of collaboration, it would benefit from a more comprehensive evaluation framework.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper evaluates the performance of SAPIENS, a distributed reinforcement learning (RL) framework, across three innovation tasks: single path, merging paths, and best-of-ten paths. It employs various social network structures, including fully-connected, small-world, dynamic, and ring networks. The findings indicate that while most methods achieved high group success in the single path task, the dynamic social structure significantly outperformed others in both the merging paths and best-of-ten paths tasks, demonstrating enhanced exploration and exploitation capabilities. The results suggest that experience sharing through dynamic social structures leads to improved performance in deceptive tasks, confirming the hypothesis that social structure plays a crucial role in innovation within RL settings.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its comprehensive evaluation of SAPIENS across diverse social network structures and tasks, providing valuable insights into how these factors influence RL performance. The empirical results highlight the superiority of dynamic structures in various scenarios, which is a notable contribution to the field. However, a potential weakness is the lack of detailed exploration of the mechanisms underlying the observed performance differences, which may leave readers wanting for deeper theoretical insights.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, with a logical flow that guides the reader through the methodology and findings. The quality of the experiments is high, with rigorous evaluations and appropriate statistical analyses. In terms of novelty, the exploration of different social network structures in the context of RL is a fresh perspective. However, the reproducibility of the results may be an issue if the implementation details of the SAPIENS framework and the specific configurations used in experiments are not adequately provided.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in understanding the impact of social network structures on reinforcement learning performance. While it offers valuable empirical contributions, it could benefit from deeper theoretical explanations and clearer reproducibility guidelines.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThis paper presents a novel approach to experience sharing in reinforcement learning, focusing on the effective use of experience tuples to enhance agent learning efficiency. The authors propose a methodology that incorporates structured experience sharing mechanisms and evaluate its performance through a series of experiments across various environments. The findings demonstrate significant improvements in learning speed and policy performance, suggesting that the proposed framework can effectively accelerate agent training.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to experience sharing, which addresses a critical challenge in reinforcement learning. The methodology is well-structured, and the experimental results are compelling, indicating a clear advancement in the field. However, the paper suffers from clarity issues, particularly in the abstract and introduction, where complex sentences and disjointed ideas may hinder reader comprehension. Additionally, while the contributions are noteworthy, they could be presented more clearly to emphasize their significance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe overall clarity of the paper is undermined by several factors, including excessive use of parentheses and jargon, which may alienate readers not deeply familiar with the subject. The quality of the figures is adequate, but many lack detailed captions that would enhance understanding. In terms of novelty, the proposed framework introduces fresh ideas to experience sharing in reinforcement learning; however, the reproducibility of the results could be improved by providing clearer metric definitions and context for statistical significance.\n\n# Summary Of The Review\nWhile the paper introduces a novel and significant contribution to reinforcement learning through experience sharing, issues with clarity and presentation detract from its overall impact. Addressing these concerns would greatly enhance the paper's readability and the accessibility of its contributions.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -1.8592322954003708,
    -1.8537254139036399,
    -1.9350339768456002,
    -1.8831381578534514,
    -1.8580904949927186,
    -1.8595779561368033,
    -1.7003067933671407,
    -2.0772361125726024,
    -1.9093108199934141,
    -1.8808482082270117,
    -1.893361175325597,
    -1.3172854669645429,
    -1.9188641798621715,
    -1.6818092238265498,
    -1.9134795761607215,
    -1.5876484783971194,
    -2.0471798478571106,
    -1.788587757207257,
    -1.6746731909647734,
    -1.7551391557083926,
    -2.092132714636942,
    -1.462442915785548,
    -1.7828839210012644,
    -1.7541759534197683,
    -1.9125138401566315,
    -1.8034694467398158,
    -1.9744129117815283,
    -1.701160661802325,
    -1.7663194524232109
  ],
  "logp_cond": [
    [
      0.0,
      -1.7036150516834307,
      -1.694773127758848,
      -1.6897150116094144,
      -1.7395849529865406,
      -1.6952191103126013,
      -1.68121837121181,
      -1.7389881189833367,
      -1.6967622544030065,
      -1.7270691925742003,
      -1.720602632484582,
      -1.7846128374010604,
      -1.6896300792430148,
      -1.7176640539595203,
      -1.7318141682712325,
      -1.7101090962933678,
      -1.740421331205705,
      -1.7214442601380922,
      -1.7503826389967971,
      -1.7363664776205974,
      -1.7416411063228332,
      -1.7472832982702762,
      -1.7349786118128514,
      -1.748301094154271,
      -1.7434230791564993,
      -1.7251494224002895,
      -1.7255989183841547,
      -1.6808291075406205,
      -1.7760421885615807
    ],
    [
      -1.3745838155973686,
      0.0,
      -1.1896149357830903,
      -1.1356077597028786,
      -1.3789454832037875,
      -1.3054806092942635,
      -1.3196565708176224,
      -1.3133098818509479,
      -1.3806939467344042,
      -1.3615591365180841,
      -1.3324818505303706,
      -1.6356666808236435,
      -1.1930929386225075,
      -1.2878663290383392,
      -1.3282835257022052,
      -1.2127714067154787,
      -1.3785728146307255,
      -1.2449221896317169,
      -1.4605364912584013,
      -1.4927978856746256,
      -1.3367307170772726,
      -1.4136103572045315,
      -1.4189919137744291,
      -1.4901539293677313,
      -1.4217438386676227,
      -1.3468968312238594,
      -1.3759143092350847,
      -1.384428657265653,
      -1.5703774612509607
    ],
    [
      -1.485625236224678,
      -1.3085659542829762,
      0.0,
      -1.381489254278487,
      -1.4982599574706286,
      -1.3297188858717917,
      -1.405482892610374,
      -1.472883919124592,
      -1.4764816178017193,
      -1.4765676128360836,
      -1.4187980916013554,
      -1.6940281717569834,
      -1.3909882733714634,
      -1.4362427761738876,
      -1.3815731358552383,
      -1.41551863678258,
      -1.4851321512603666,
      -1.3703703130661005,
      -1.5742313351964057,
      -1.536868470385533,
      -1.4701190735450627,
      -1.5487326187009542,
      -1.5333506513680688,
      -1.5861846728989761,
      -1.4647777385409264,
      -1.489533267510481,
      -1.482893394980186,
      -1.4994261300457676,
      -1.6884086883159344
    ],
    [
      -1.4319497057605273,
      -1.2320532215781765,
      -1.374616338707009,
      0.0,
      -1.465235770857735,
      -1.350680970017377,
      -1.3991694722092836,
      -1.393381650052915,
      -1.416301616254781,
      -1.4750464356188187,
      -1.3936404112417407,
      -1.6310013150185845,
      -1.2843071199551208,
      -1.361830312980543,
      -1.403644977031481,
      -1.3186263827401972,
      -1.4727177411489798,
      -1.3234434918921798,
      -1.5134869711991397,
      -1.5495439453437247,
      -1.44581878909122,
      -1.4719689052692313,
      -1.4806641475567142,
      -1.5372037693161409,
      -1.4410920862026948,
      -1.417869692854262,
      -1.4319344496164417,
      -1.4944399062737155,
      -1.6036032147455368
    ],
    [
      -1.4279545025847034,
      -1.311341125920998,
      -1.3425632552548599,
      -1.3315507843548384,
      0.0,
      -1.2920423581094582,
      -1.3402589720944493,
      -1.2893457478830532,
      -1.3589495136781196,
      -1.3522984381674492,
      -1.2926891818298185,
      -1.574015129827194,
      -1.3081817516023664,
      -1.3910944619779702,
      -1.3385178300739968,
      -1.3310175094025427,
      -1.268883969198485,
      -1.3130006426261611,
      -1.3740768895438302,
      -1.4401922041950026,
      -1.298534031643331,
      -1.39163398904344,
      -1.4138780221143752,
      -1.4206579139522217,
      -1.4294050592607708,
      -1.3897737942649397,
      -1.3113494585396834,
      -1.4015141130547866,
      -1.4896304560974218
    ],
    [
      -1.3779653635237141,
      -1.2321865256058662,
      -1.1675205384294398,
      -1.211511390324225,
      -1.347782550902343,
      0.0,
      -1.3236930709861046,
      -1.3549851307755327,
      -1.3336465892870701,
      -1.4093005328291728,
      -1.2307490375659194,
      -1.5750306574558095,
      -1.2016558479968233,
      -1.3477256624746536,
      -1.2833640934614954,
      -1.2901690451109629,
      -1.384604143193218,
      -1.1732635649646497,
      -1.4420091034828326,
      -1.421054009999363,
      -1.338782262540817,
      -1.3708577722699191,
      -1.473584836037251,
      -1.5134548491007254,
      -1.4264423985178,
      -1.374743952931015,
      -1.3147139062093658,
      -1.3983752908597404,
      -1.5216479522515187
    ],
    [
      -1.2781977665974746,
      -1.2260934506664902,
      -1.2584518677554917,
      -1.246214637015506,
      -1.3248334773506416,
      -1.2691645505170097,
      0.0,
      -1.328917774657838,
      -1.2487185523035615,
      -1.3357162393477182,
      -1.3263744213919393,
      -1.4825795545345677,
      -1.2920922398045767,
      -1.2998752194739713,
      -1.306384353080374,
      -1.2335114620058538,
      -1.3579376136817873,
      -1.2886344201560846,
      -1.4064946670176077,
      -1.409148465719577,
      -1.3175374261819983,
      -1.395542121110715,
      -1.4058855356068145,
      -1.4052653511584212,
      -1.3294807310530241,
      -1.3708779007186724,
      -1.3024583543430157,
      -1.2382038985280748,
      -1.4560466675620185
    ],
    [
      -1.695236972226657,
      -1.4662262468302443,
      -1.57349546535888,
      -1.5033357140859356,
      -1.5638649069319501,
      -1.5311899245271867,
      -1.5749529241347024,
      0.0,
      -1.6294388471856867,
      -1.6160602044097698,
      -1.5421284221684564,
      -1.819970028575728,
      -1.490846703140398,
      -1.5896011895237017,
      -1.564859874969759,
      -1.4726981756678088,
      -1.5519001740697853,
      -1.5094451000432567,
      -1.6273251708207699,
      -1.6975452613076656,
      -1.5734623423668812,
      -1.5990642530209773,
      -1.6612702842385556,
      -1.6791441932269586,
      -1.7059318028045987,
      -1.616892019553677,
      -1.5252798713994442,
      -1.6546892690675854,
      -1.7454825130250997
    ],
    [
      -1.3704738002560577,
      -1.3678510729666709,
      -1.361204132095826,
      -1.4312266252954269,
      -1.4845450656194024,
      -1.3760847326585974,
      -1.3085981595508573,
      -1.5050415623263487,
      0.0,
      -1.4656258741982857,
      -1.4157939561299084,
      -1.6576827179429665,
      -1.353948960688322,
      -1.3496546040647674,
      -1.4968931841644044,
      -1.4399071502645586,
      -1.483529073814867,
      -1.411054977542749,
      -1.505547776570639,
      -1.5014803628273186,
      -1.48734923276604,
      -1.510169388860963,
      -1.543392241816238,
      -1.5202899774561451,
      -1.446893926895833,
      -1.412609380879483,
      -1.5007611003544639,
      -1.3545162128938695,
      -1.5960177325457099
    ],
    [
      -1.4197979269449068,
      -1.3619784093910092,
      -1.4387619492525936,
      -1.4605207814271939,
      -1.4413023001525,
      -1.477772306626317,
      -1.5263971020289477,
      -1.4509638916259626,
      -1.5051495197376334,
      0.0,
      -1.4534358426314113,
      -1.6739472301891563,
      -1.4908028578110208,
      -1.4724666119522307,
      -1.4775655872554738,
      -1.4330488861632233,
      -1.4707419426437085,
      -1.4976500079045791,
      -1.4897692861533312,
      -1.5154602277130602,
      -1.461816598538936,
      -1.4924876915236134,
      -1.4438632557036917,
      -1.541040028721783,
      -1.4602678519479806,
      -1.4698923051774961,
      -1.473036088718386,
      -1.4764499159137114,
      -1.574297821535154
    ],
    [
      -1.3508666332699113,
      -1.1949058288510093,
      -1.2454456412281076,
      -1.2903314554811427,
      -1.269388652423039,
      -1.169141924585526,
      -1.3588094412486171,
      -1.3013773370435269,
      -1.3193950025067047,
      -1.330413890290385,
      0.0,
      -1.6469546229515974,
      -1.2013988559400248,
      -1.2886874966513093,
      -1.2751053692661083,
      -1.2642632831816496,
      -1.2925307678609232,
      -1.2679739348436279,
      -1.4246079368368945,
      -1.4099197565972423,
      -1.3174489761634385,
      -1.3665453058367414,
      -1.401644485670809,
      -1.4590818146778104,
      -1.429383759636987,
      -1.3862661297694345,
      -1.2850603935875318,
      -1.3486984325798124,
      -1.5281390169343156
    ],
    [
      -1.1366889525815063,
      -1.0998742626557427,
      -1.0951397913055103,
      -1.0749974748418094,
      -1.1012808232094038,
      -1.0659114702726407,
      -1.074493481685461,
      -1.0912735750164153,
      -1.0909962740931833,
      -1.0928315996540863,
      -1.110707580878925,
      0.0,
      -1.086497894362724,
      -1.0878757025011354,
      -1.1032334589719173,
      -1.1053477705471024,
      -1.08993108850419,
      -1.080544283962386,
      -1.0991930397781873,
      -1.0989457457920575,
      -1.1017658994069106,
      -1.093506407127899,
      -1.1055351631808759,
      -1.1075538064142185,
      -1.0814586731038034,
      -1.0689631008091844,
      -1.1083053228730488,
      -1.1183082307203347,
      -1.0852464331285203
    ],
    [
      -1.4176026183028483,
      -1.2552232371374303,
      -1.3456268582195554,
      -1.2658770535601502,
      -1.4331754827029541,
      -1.2623861149897926,
      -1.4299158208886047,
      -1.3687806746697662,
      -1.4426447535980742,
      -1.471763638859216,
      -1.3952366213746012,
      -1.6547214624932234,
      0.0,
      -1.3840600805565528,
      -1.4762534145667683,
      -1.3078431127574484,
      -1.463795423972232,
      -1.3170782333299558,
      -1.5308999788813595,
      -1.5892079243395123,
      -1.434767999548322,
      -1.4739509899639285,
      -1.5259607057573779,
      -1.6026248435734325,
      -1.5487867237290263,
      -1.404820490521783,
      -1.4048195816286144,
      -1.4953992554149114,
      -1.6121894076762517
    ],
    [
      -1.223507215507321,
      -1.098007536778021,
      -1.1765690086821583,
      -1.1034983078537732,
      -1.295525478871366,
      -1.1825222661401327,
      -1.2011911357673104,
      -1.2321117275336368,
      -1.1967103684834406,
      -1.2619335126028617,
      -1.2158409021483378,
      -1.4447617010979406,
      -1.135956620836303,
      0.0,
      -1.2419376646998825,
      -1.158582390526069,
      -1.2481741456245503,
      -1.1879437296709259,
      -1.2968627621923408,
      -1.3235423206375097,
      -1.2632100703820535,
      -1.3191610614062754,
      -1.2967167778390074,
      -1.3567927466904488,
      -1.2670182328390527,
      -1.2341559320135724,
      -1.3089491465607757,
      -1.2555035129123557,
      -1.4653298152699157
    ],
    [
      -1.5200959842112132,
      -1.3626982270259698,
      -1.3858691928129474,
      -1.4336068906781818,
      -1.5056495035551956,
      -1.3934896988797696,
      -1.4480605775751023,
      -1.4434194986187754,
      -1.5093283285319412,
      -1.4761386483479728,
      -1.4067644964512944,
      -1.689709569778053,
      -1.4486023117375064,
      -1.44708329486171,
      0.0,
      -1.4550404595436401,
      -1.4687148454205097,
      -1.4499468402506241,
      -1.5062010212882697,
      -1.5383664629765375,
      -1.4877178503201578,
      -1.531095762099175,
      -1.490876964143569,
      -1.473002577103205,
      -1.5149755783718548,
      -1.5665293807319642,
      -1.4676859056570253,
      -1.4424257987962212,
      -1.6100424841044059
    ],
    [
      -1.1775586775759999,
      -1.00389805674021,
      -1.0777157883655786,
      -1.05633237342738,
      -1.1722912338164102,
      -1.082308704270245,
      -1.0889212567498958,
      -1.083569265377111,
      -1.1945648233462847,
      -1.1676149381491772,
      -1.0719748093405794,
      -1.393122180101204,
      -1.0150335623040538,
      -1.1238319022117946,
      -1.1324329960670865,
      0.0,
      -1.1358895221196392,
      -1.0916242169380166,
      -1.2736819211994257,
      -1.2087107619560422,
      -1.1191367523503657,
      -1.177822622971078,
      -1.2112076773184894,
      -1.2514457970620356,
      -1.2414284203172377,
      -1.1806603365273936,
      -1.1070108523086937,
      -1.1803050818062566,
      -1.3174213556997127
    ],
    [
      -1.6370457681835733,
      -1.5139389011888618,
      -1.5230688213454104,
      -1.5439460829638831,
      -1.4938363174027782,
      -1.5142913620687055,
      -1.587000704893425,
      -1.5004947885130033,
      -1.6259858700170857,
      -1.5726075336239849,
      -1.4647346033551958,
      -1.793582586467685,
      -1.5727714001712951,
      -1.586738720519096,
      -1.5488088742002908,
      -1.4796504098345007,
      0.0,
      -1.5267423598519503,
      -1.6248316227750421,
      -1.6139361878217373,
      -1.4964908271477013,
      -1.6120080069710667,
      -1.6102848712636568,
      -1.6386248283716922,
      -1.6489659280925073,
      -1.6083096134162491,
      -1.5329855147622042,
      -1.6115315825971646,
      -1.6918613582803155
    ],
    [
      -1.430704977682195,
      -1.1936131051666659,
      -1.2191912892284142,
      -1.2313788286287517,
      -1.3368478383049176,
      -1.168888255156175,
      -1.3506907469672136,
      -1.2884077048749922,
      -1.3530685819998274,
      -1.432150391439649,
      -1.2775913702614121,
      -1.5414146013744214,
      -1.226887247526266,
      -1.3301022001360465,
      -1.3253710960010388,
      -1.2639542285058494,
      -1.334007560842183,
      0.0,
      -1.4025220344085978,
      -1.4141516252101014,
      -1.3118195122314085,
      -1.2892702543706012,
      -1.442482030789013,
      -1.4700796790173873,
      -1.4466202749690027,
      -1.3140052093643904,
      -1.3446834355636708,
      -1.3870141693264155,
      -1.5252031088042841
    ],
    [
      -1.292892574756058,
      -1.1891330469686727,
      -1.268619714087969,
      -1.2637817718612665,
      -1.252829364943848,
      -1.2400942277780458,
      -1.266094399496971,
      -1.2437719347820815,
      -1.2831248212086406,
      -1.2396913823386768,
      -1.2374572750140684,
      -1.4118747278182155,
      -1.2456858260128651,
      -1.2322454882260336,
      -1.206192379452913,
      -1.2543138284625692,
      -1.3011193398029695,
      -1.2785149310569857,
      0.0,
      -1.2875694515829457,
      -1.2674501003066625,
      -1.2839578065831385,
      -1.2904546677554745,
      -1.2862354009043453,
      -1.2902520968593814,
      -1.2783116039776,
      -1.2495320449812466,
      -1.2713143096333106,
      -1.3463217463969812
    ],
    [
      -1.3092801475676077,
      -1.3199334782475938,
      -1.2975906036136562,
      -1.377245682710662,
      -1.3350761520867283,
      -1.265684881930537,
      -1.3845488440955467,
      -1.3295728252396688,
      -1.3026368703411888,
      -1.3369778550997653,
      -1.2699754658021065,
      -1.4868179681183447,
      -1.362062889754482,
      -1.3284719882367866,
      -1.3338013541417286,
      -1.317609094893491,
      -1.305317197786615,
      -1.305234388515949,
      -1.3669817466517864,
      0.0,
      -1.2826540308816048,
      -1.3218908252660113,
      -1.3449927950224854,
      -1.3436930553148596,
      -1.4269707385244939,
      -1.3565847083205043,
      -1.3477442616087891,
      -1.3359305010249363,
      -1.409706931234856
    ],
    [
      -1.6166227817080496,
      -1.504474123017464,
      -1.5923978909755918,
      -1.6174525382546032,
      -1.5896053322757613,
      -1.61078025496878,
      -1.6504935394483988,
      -1.64321295405814,
      -1.6962366906472621,
      -1.6473226562263714,
      -1.5994256698663165,
      -1.8676690520270036,
      -1.5971816694514822,
      -1.6447474430213471,
      -1.6207391932600255,
      -1.544575063753911,
      -1.6493360107246093,
      -1.578193559032554,
      -1.6799922456867917,
      -1.6706257962000441,
      0.0,
      -1.6626890984328584,
      -1.6898178605720537,
      -1.6460485904187443,
      -1.7407199337255455,
      -1.709169481983103,
      -1.5728591149842865,
      -1.6725519421722699,
      -1.786156425638229
    ],
    [
      -1.101752174715139,
      -0.9731857196646739,
      -1.0398499893187643,
      -1.0453828280367796,
      -1.0789874908542019,
      -0.9727881179987797,
      -1.1047557185606438,
      -1.003157846650847,
      -1.1014423565297173,
      -1.1019833284970355,
      -1.033220786593492,
      -1.2233106659522806,
      -1.005123281017088,
      -1.0885634965797732,
      -1.0620181019974257,
      -0.987904067375707,
      -1.0764695096226458,
      -0.9259373811943754,
      -1.1135843776507812,
      -1.0258513512692455,
      -1.0346245706611636,
      0.0,
      -1.139919383061149,
      -1.1223752848929658,
      -1.131335011576093,
      -1.0690234047689848,
      -1.046353924052643,
      -1.0895222875792365,
      -1.1039804803348174
    ],
    [
      -1.3766260259584029,
      -1.3244628870709136,
      -1.3662633392244654,
      -1.356450404380071,
      -1.37393651086269,
      -1.3728817379538873,
      -1.3999725027626946,
      -1.3879445436923639,
      -1.410336258724364,
      -1.331095096481915,
      -1.3675430250659322,
      -1.532420609356639,
      -1.3993466551360787,
      -1.3743528450921378,
      -1.3668061391656954,
      -1.3482584659636587,
      -1.3356474461431629,
      -1.3806152819847046,
      -1.4239508401569894,
      -1.447310932233806,
      -1.361737471639338,
      -1.4244038833463544,
      0.0,
      -1.4338113152111294,
      -1.2976736869293266,
      -1.3975758342029831,
      -1.3914304307258256,
      -1.3992873591597037,
      -1.471036496152271
    ],
    [
      -1.398707788971594,
      -1.3143152016919624,
      -1.34049316612997,
      -1.33965633717413,
      -1.3161600061613994,
      -1.3302682863758697,
      -1.3470135707207624,
      -1.3248504633016218,
      -1.2829891383288392,
      -1.3083114072207969,
      -1.2937517586237886,
      -1.4602401345571911,
      -1.3255539162334422,
      -1.323294532778216,
      -1.2746788502623545,
      -1.306132484980213,
      -1.3308827784991,
      -1.3382606615056671,
      -1.273474019719796,
      -1.3009797305235815,
      -1.2856400814140267,
      -1.3427182230163104,
      -1.3459809147644701,
      0.0,
      -1.3288391778556354,
      -1.3456387844732058,
      -1.3121851533393487,
      -1.2419699134837194,
      -1.3641634316868523
    ],
    [
      -1.4805564786429302,
      -1.4703991650200445,
      -1.4476625728865897,
      -1.4364934240540692,
      -1.5625166776752153,
      -1.5260468438431845,
      -1.4767903351209002,
      -1.5510280468592246,
      -1.5036607011742509,
      -1.4286873294127804,
      -1.543784176640262,
      -1.6640361531121035,
      -1.5079537933938656,
      -1.5121095363883308,
      -1.5498595918959797,
      -1.490501402741104,
      -1.564438641445997,
      -1.5442036616872092,
      -1.536308159371873,
      -1.5849668162995807,
      -1.5708416194931243,
      -1.6000952046902026,
      -1.4874482616493703,
      -1.572005278598354,
      0.0,
      -1.5069670138114253,
      -1.5608011730002034,
      -1.5017702907380674,
      -1.6839621888069942
    ],
    [
      -1.4224662083915782,
      -1.2947509192924929,
      -1.376081423141247,
      -1.302679876911858,
      -1.4318851241275818,
      -1.3629184855826015,
      -1.445009770596573,
      -1.3611502584345878,
      -1.4058134915797933,
      -1.431858067027811,
      -1.4039101862652328,
      -1.550030156903811,
      -1.3324742305117738,
      -1.363665967685317,
      -1.4407321083423357,
      -1.3530440420222611,
      -1.4378449691689006,
      -1.306357171309153,
      -1.4171021326453512,
      -1.4693765128851068,
      -1.3609400163359682,
      -1.385464519514787,
      -1.4919160859353926,
      -1.4955073063351203,
      -1.4795974486681633,
      0.0,
      -1.4281671066639696,
      -1.480332344764866,
      -1.5313139355686798
    ],
    [
      -1.514383891888836,
      -1.415305166759971,
      -1.4870657392209827,
      -1.4644319300790956,
      -1.4197494715088919,
      -1.399376176553566,
      -1.4589650466411337,
      -1.3679961670818874,
      -1.5290717730259427,
      -1.4882585906298893,
      -1.3985679549036647,
      -1.6872251648850354,
      -1.4044485268847513,
      -1.5329256942579308,
      -1.4539463746151644,
      -1.3997623841118614,
      -1.4595214978754905,
      -1.456094348534171,
      -1.4881762908097858,
      -1.5468419622771108,
      -1.3985969886837286,
      -1.5275750301840387,
      -1.544309422225338,
      -1.5427828492623308,
      -1.5554196396687827,
      -1.5182885037518323,
      0.0,
      -1.487365350301482,
      -1.5971262457940352
    ],
    [
      -1.2305311135757842,
      -1.1634536465721688,
      -1.2566680176194167,
      -1.2461641729928008,
      -1.2918867671054977,
      -1.234996430961465,
      -1.1326769685763525,
      -1.264523435814618,
      -1.1656354488751577,
      -1.2459300306176975,
      -1.2606430274100486,
      -1.4931476152540997,
      -1.237213988888425,
      -1.1909384226755966,
      -1.1891191308791786,
      -1.1921389067802843,
      -1.272996464679671,
      -1.2732448144297563,
      -1.2655600857898475,
      -1.3359265068693928,
      -1.2701431792356672,
      -1.2724751908583383,
      -1.2872879363317793,
      -1.2648343076604989,
      -1.312517336569682,
      -1.33898991662576,
      -1.218900721948786,
      0.0,
      -1.357247299386492
    ],
    [
      -1.4373213678792354,
      -1.3892393548177884,
      -1.4193831258613936,
      -1.425402212575209,
      -1.3779850975982035,
      -1.3904676159606788,
      -1.4107653638438387,
      -1.3784813979598491,
      -1.425929008472448,
      -1.413507354993908,
      -1.3814309772951876,
      -1.4105616630114524,
      -1.3949365484142866,
      -1.4083642862668295,
      -1.4258796335957675,
      -1.3644860932125016,
      -1.3675999812428958,
      -1.4040897288946308,
      -1.404051577429686,
      -1.385665491696047,
      -1.3595805650327228,
      -1.354740923982543,
      -1.3896976226141269,
      -1.3654638065848135,
      -1.416848550295783,
      -1.4555997502867544,
      -1.3575559732677511,
      -1.3559183594298811,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.15561724371694008,
      0.1644591676415228,
      0.16951728379095643,
      0.11964734241383024,
      0.16401318508776952,
      0.17801392418856077,
      0.12024417641703411,
      0.16247004099736428,
      0.1321631028261705,
      0.13862966291578882,
      0.07461945799931047,
      0.16960221615735604,
      0.14156824144085056,
      0.12741812712913836,
      0.149123199107003,
      0.11881096419466575,
      0.13778803526227867,
      0.10884965640357369,
      0.12286581777977346,
      0.11759118907753763,
      0.11194899713009465,
      0.12425368358751943,
      0.1109312012460999,
      0.11580921624387153,
      0.13408287300008137,
      0.13363337701621614,
      0.1784031878597503,
      0.08319010683879013
    ],
    [
      0.47914159830627123,
      0.0,
      0.6641104781205496,
      0.7181176542007612,
      0.47477993069985236,
      0.5482448046093764,
      0.5340688430860174,
      0.540415532052692,
      0.4730314671692357,
      0.49216627738555574,
      0.5212435633732693,
      0.21805873307999635,
      0.6606324752811323,
      0.5658590848653007,
      0.5254418882014347,
      0.6409540071881612,
      0.4751525992729144,
      0.608803224271923,
      0.3931889226452385,
      0.3609275282290143,
      0.5169946968263672,
      0.44011505669910833,
      0.43473350012921075,
      0.3635714845359086,
      0.4319815752360172,
      0.5068285826797805,
      0.47781110466855514,
      0.46929675663798687,
      0.2833479526526792
    ],
    [
      0.4494087406209222,
      0.626468022562624,
      0.0,
      0.5535447225671133,
      0.4367740193749716,
      0.6053150909738085,
      0.5295510842352262,
      0.46215005772100826,
      0.4585523590438809,
      0.45846636400951657,
      0.5162358852442448,
      0.2410058050886168,
      0.5440457034741368,
      0.49879120067171256,
      0.5534608409903619,
      0.5195153400630201,
      0.4499018255852336,
      0.5646636637794997,
      0.3608026416491945,
      0.3981655064600671,
      0.46491490330053753,
      0.38630135814464595,
      0.4016833254775314,
      0.34884930394662406,
      0.4702562383046738,
      0.4455007093351191,
      0.4521405818654143,
      0.43560784679983255,
      0.2466252885296658
    ],
    [
      0.45118845209292413,
      0.6510849362752749,
      0.5085218191464425,
      0.0,
      0.41790238699571636,
      0.5324571878360744,
      0.48396868564416784,
      0.48975650780053637,
      0.4668365415986704,
      0.40809172223463275,
      0.48949774661171075,
      0.2521368428348669,
      0.5988310378983306,
      0.5213078448729085,
      0.47949318082197045,
      0.5645117751132542,
      0.4104204167044716,
      0.5596946659612716,
      0.36965118665431174,
      0.33359421250972665,
      0.43731936876223143,
      0.4111692525842201,
      0.40247401029673724,
      0.3459343885373105,
      0.4420460716507566,
      0.4652684649991894,
      0.4512037082370097,
      0.3886982515797359,
      0.2795349431079146
    ],
    [
      0.43013599240801526,
      0.5467493690717207,
      0.5155272397378587,
      0.5265397106378802,
      0.0,
      0.5660481368832604,
      0.5178315228982693,
      0.5687447471096654,
      0.49914098131459905,
      0.5057920568252694,
      0.5654013131629001,
      0.28407536516552456,
      0.5499087433903522,
      0.46699603301474846,
      0.5195726649187218,
      0.5270729855901759,
      0.5892065257942336,
      0.5450898523665575,
      0.4840136054488884,
      0.417898290797716,
      0.5595564633493877,
      0.4664565059492787,
      0.4442124728783434,
      0.43743258104049687,
      0.42868543573194784,
      0.46831670072777887,
      0.5467410364530352,
      0.45657638193793204,
      0.36846003889529677
    ],
    [
      0.4816125926130892,
      0.6273914305309372,
      0.6920574177073635,
      0.6480665658125784,
      0.5117954052344604,
      0.0,
      0.5358848851506988,
      0.5045928253612706,
      0.5259313668497332,
      0.45027742330763054,
      0.628828918570884,
      0.2845472986809938,
      0.65792210813998,
      0.5118522936621497,
      0.5762138626753079,
      0.5694089110258405,
      0.4749738129435854,
      0.6863143911721536,
      0.4175688526539707,
      0.4385239461374404,
      0.5207956935959863,
      0.4887201838668842,
      0.38599312009955233,
      0.34612310703607796,
      0.43313555761900324,
      0.4848340032057883,
      0.5448640499274375,
      0.4612026652770629,
      0.3379300038852846
    ],
    [
      0.4221090267696661,
      0.4742133427006505,
      0.4418549256116491,
      0.4540921563516347,
      0.37547331601649914,
      0.43114224285013103,
      0.0,
      0.37138901870930274,
      0.4515882410635792,
      0.36459055401942253,
      0.37393237197520146,
      0.21772723883257306,
      0.4082145535625641,
      0.4004315738931694,
      0.3939224402867667,
      0.4667953313612869,
      0.3423691796853534,
      0.4116723732110561,
      0.293812126349533,
      0.2911583276475638,
      0.38276936718514243,
      0.3047646722564257,
      0.29442125776032624,
      0.29504144220871953,
      0.37082606231411663,
      0.3294288926484683,
      0.39784843902412503,
      0.46210289483906597,
      0.24426012580512224
    ],
    [
      0.3819991403459455,
      0.6110098657423582,
      0.5037406472137225,
      0.5739003984866669,
      0.5133712056406523,
      0.5460461880454157,
      0.5022831884379,
      0.0,
      0.4477972653869158,
      0.4611759081628326,
      0.5351076904041461,
      0.25726608399687434,
      0.5863894094322044,
      0.48763492304890077,
      0.5123762376028433,
      0.6045379369047936,
      0.5253359385028171,
      0.5677910125293457,
      0.44991094175183255,
      0.37969085126493685,
      0.5037737702057212,
      0.4781718595516251,
      0.4159658283340468,
      0.3980919193456438,
      0.37130430976800377,
      0.46034409301892554,
      0.5519562411731582,
      0.42254684350501703,
      0.3317535995475027
    ],
    [
      0.5388370197373564,
      0.5414597470267433,
      0.5481066878975882,
      0.47808419469798724,
      0.42476575437401176,
      0.5332260873348167,
      0.6007126604425568,
      0.40426925766706545,
      0.0,
      0.4436849457951284,
      0.4935168638635057,
      0.2516281020504476,
      0.5553618593050922,
      0.5596562159286467,
      0.4124176358290097,
      0.4694036697288555,
      0.42578174617854714,
      0.4982558424506651,
      0.403763043422775,
      0.40783045716609556,
      0.4219615872273741,
      0.39914143113245104,
      0.3659185781771761,
      0.389020842537269,
      0.46241689309758116,
      0.49670143911393105,
      0.40854971963895026,
      0.5547946070995446,
      0.31329308744770423
    ],
    [
      0.4610502812821049,
      0.5188697988360025,
      0.4420862589744181,
      0.4203274267998178,
      0.43954590807451166,
      0.4030759016006946,
      0.35445110619806397,
      0.4298843166010491,
      0.37569868848937826,
      0.0,
      0.42741236559560036,
      0.20690097803785545,
      0.39004535041599087,
      0.408381596274781,
      0.4032826209715379,
      0.44779932206378836,
      0.4101062655833032,
      0.38319820032243257,
      0.39107892207368056,
      0.3653879805139515,
      0.41903160968807573,
      0.38836051670339833,
      0.43698495252332004,
      0.3398081795052288,
      0.4205803562790311,
      0.41095590304951557,
      0.4078121195086257,
      0.40439829231330027,
      0.30655038669185775
    ],
    [
      0.5424945420556857,
      0.6984553464745877,
      0.6479155340974894,
      0.6030297198444543,
      0.6239725229025579,
      0.7242192507400711,
      0.5345517340769799,
      0.5919838382820701,
      0.5739661728188923,
      0.562947285035212,
      0.0,
      0.24640655237399955,
      0.6919623193855722,
      0.6046736786742877,
      0.6182558060594887,
      0.6290978921439474,
      0.6008304074646738,
      0.6253872404819691,
      0.46875323848870254,
      0.48344141872835467,
      0.5759121991621585,
      0.5268158694888556,
      0.491716689654788,
      0.4342793606477866,
      0.46397741568861006,
      0.5070950455561625,
      0.6083007817380652,
      0.5446627427457846,
      0.36522215839128136
    ],
    [
      0.1805965143830366,
      0.21741120430880012,
      0.22214567565903254,
      0.24228799212273344,
      0.21600464375513906,
      0.2513739966919022,
      0.24279198527908186,
      0.22601189194812754,
      0.2262891928713595,
      0.22445386731045658,
      0.20657788608561778,
      0.0,
      0.23078757260181892,
      0.22940976446340744,
      0.21405200799262558,
      0.21193769641744042,
      0.2273543784603529,
      0.23674118300215685,
      0.21809242718635558,
      0.21833972117248535,
      0.21551956755763224,
      0.2237790598366438,
      0.211750303783667,
      0.20973166055032433,
      0.23582679386073946,
      0.2483223661553584,
      0.208980144091494,
      0.19897723624420816,
      0.23203903383602253
    ],
    [
      0.5012615615593232,
      0.6636409427247412,
      0.5732373216426161,
      0.6529871263020213,
      0.48568869715921736,
      0.6564780648723789,
      0.4889483589735668,
      0.5500835051924053,
      0.4762194262640973,
      0.4471005410029556,
      0.5236275584875703,
      0.2641427173689481,
      0.0,
      0.5348040993056187,
      0.4426107652954032,
      0.6110210671047231,
      0.45506875588993956,
      0.6017859465322157,
      0.38796420098081197,
      0.3296562555226592,
      0.4840961803138495,
      0.444913189898243,
      0.39290347410479365,
      0.316239336288739,
      0.37007745613314524,
      0.5140436893403886,
      0.5140445982335571,
      0.42346492444726014,
      0.30667477218591976
    ],
    [
      0.45830200831922885,
      0.5838016870485288,
      0.5052402151443915,
      0.5783109159727766,
      0.3862837449551839,
      0.4992869576864172,
      0.48061808805923945,
      0.449697496292913,
      0.48509885534310926,
      0.41987571122368816,
      0.465968321678212,
      0.2370475227286093,
      0.5458526029902468,
      0.0,
      0.4398715591266673,
      0.5232268333004808,
      0.43363507820199954,
      0.493865494155624,
      0.3849464616342091,
      0.3582669031890402,
      0.4185991534444964,
      0.3626481624202744,
      0.38509244598754244,
      0.32501647713610105,
      0.41479099098749717,
      0.4476532918129774,
      0.3728600772657742,
      0.4263057109141941,
      0.21647940855663417
    ],
    [
      0.39338359194950834,
      0.5507813491347517,
      0.5276103833477741,
      0.4798726854825397,
      0.40783007260552595,
      0.5199898772809519,
      0.4654189985856192,
      0.4700600775419461,
      0.4041512476287803,
      0.4373409278127487,
      0.5067150797094271,
      0.22377000638266842,
      0.4648772644232151,
      0.46639628129901145,
      0.0,
      0.45843911661708137,
      0.44476473074021183,
      0.46353273591009736,
      0.4072785548724518,
      0.37511311318418405,
      0.4257617258405637,
      0.38238381406154653,
      0.42260261201715243,
      0.4404769990575166,
      0.3985039977888667,
      0.34695019542875727,
      0.4457936705036962,
      0.47105377736450027,
      0.30343709205631564
    ],
    [
      0.41008980082111957,
      0.5837504216569094,
      0.5099326900315408,
      0.5313161049697395,
      0.4153572445807092,
      0.5053397741268744,
      0.4987272216472236,
      0.5040792130200085,
      0.39308365505083476,
      0.42003354024794226,
      0.51567366905654,
      0.1945262982959155,
      0.5726149160930656,
      0.4638165761853248,
      0.45521548233003295,
      0.0,
      0.4517589562774802,
      0.49602426145910283,
      0.31396655719769373,
      0.3789377164410772,
      0.46851172604675373,
      0.40982585542604144,
      0.37644080107863,
      0.3362026813350838,
      0.34622005807988177,
      0.4069881418697259,
      0.48063762608842575,
      0.4073433965908628,
      0.2702271226974067
    ],
    [
      0.4101340796735373,
      0.5332409466682488,
      0.5241110265117002,
      0.5032337648932275,
      0.5533435304543324,
      0.5328884857884051,
      0.4601791429636857,
      0.5466850593441073,
      0.4211939778400249,
      0.47457231423312574,
      0.5824452445019148,
      0.2535972613894255,
      0.47440844768581547,
      0.4604411273380147,
      0.4983709736568198,
      0.5675294380226099,
      0.0,
      0.5204374880051603,
      0.4223482250820685,
      0.4332436600353733,
      0.5506890207094093,
      0.4351718408860439,
      0.4368949765934538,
      0.4085550194854184,
      0.3982139197646033,
      0.4388702344408615,
      0.5141943330949064,
      0.43564826525994604,
      0.3553184895767951
    ],
    [
      0.3578827795250621,
      0.5949746520405912,
      0.5693964679788428,
      0.5572089285785053,
      0.45173991890233944,
      0.619699502051082,
      0.43789701024004346,
      0.5001800523322648,
      0.43551917520742967,
      0.3564373657676081,
      0.5109963869458449,
      0.2471731558328356,
      0.5617005096809911,
      0.4584855570712105,
      0.4632166612062183,
      0.5246335287014077,
      0.45458019636507396,
      0.0,
      0.38606572279865925,
      0.37443613199715564,
      0.4767682449758486,
      0.4993175028366559,
      0.3461057264182441,
      0.3185080781898697,
      0.34196748223825435,
      0.4745825478428667,
      0.4439043216435863,
      0.4015735878808415,
      0.26338464840297293
    ],
    [
      0.3817806162087154,
      0.4855401439961007,
      0.4060534768768045,
      0.4108914191035069,
      0.4218438260209254,
      0.4345789631867276,
      0.4085787914678025,
      0.4309012561826919,
      0.39154836975613283,
      0.4349818086260966,
      0.43721591595070497,
      0.26279846314655786,
      0.42898736495190826,
      0.44242770273873977,
      0.4684808115118604,
      0.4203593625022042,
      0.37355385116180395,
      0.39615825990778775,
      0.0,
      0.38710373938182774,
      0.4072230906581109,
      0.3907153843816349,
      0.38421852320929895,
      0.3884377900604281,
      0.38442109410539205,
      0.3963615869871735,
      0.4251411459835268,
      0.4033588813314628,
      0.3283514445677922
    ],
    [
      0.44585900814078494,
      0.43520567746079886,
      0.45754855209473644,
      0.3778934729977306,
      0.4200630036216644,
      0.48945427377785555,
      0.37059031161284595,
      0.42556633046872383,
      0.4525022853672038,
      0.41816130060862733,
      0.4851636899062861,
      0.26832118759004797,
      0.39307626595391065,
      0.42666716747160605,
      0.421337801566664,
      0.43753006081490153,
      0.4498219579217777,
      0.44990476719244366,
      0.38815740905660623,
      0.0,
      0.47248512482678784,
      0.4332483304423813,
      0.41014636068590726,
      0.411446100393533,
      0.3281684171838988,
      0.39855444738788837,
      0.4073948940996035,
      0.41920865468345636,
      0.3454322244735366
    ],
    [
      0.4755099329288923,
      0.5876585916194779,
      0.49973482366135014,
      0.4746801763823387,
      0.5025273823611807,
      0.481352459668162,
      0.4416391751885431,
      0.448919760578802,
      0.3958960239896798,
      0.44481005841057053,
      0.49270704477062544,
      0.22446366260993833,
      0.49495104518545974,
      0.4473852716155948,
      0.4713935213769165,
      0.5475576508830309,
      0.4427967039123326,
      0.513939155604388,
      0.4121404689501502,
      0.4215069184368978,
      0.0,
      0.42944361620408356,
      0.4023148540648882,
      0.44608412421819765,
      0.3514127809113965,
      0.382963232653839,
      0.5192735996526554,
      0.41958077246467207,
      0.305976288998713
    ],
    [
      0.360690741070409,
      0.48925719612087415,
      0.4225929264667838,
      0.41706008774876846,
      0.3834554249313462,
      0.48965479778676835,
      0.3576871972249043,
      0.459285069134701,
      0.36100055925583074,
      0.3604595872885126,
      0.42922212919205616,
      0.23913224983326753,
      0.45731963476846005,
      0.37387941920577483,
      0.40042481378812234,
      0.47453884840984106,
      0.3859734061629023,
      0.5365055345911727,
      0.34885853813476686,
      0.43659156451630254,
      0.42781834512438444,
      0.0,
      0.32252353272439915,
      0.3400676308925823,
      0.33110790420945513,
      0.39341951101656325,
      0.41608899173290514,
      0.37292062820631156,
      0.35846243545073064
    ],
    [
      0.40625789504286147,
      0.4584210339303507,
      0.41662058177679895,
      0.42643351662119344,
      0.4089474101385744,
      0.410002183047377,
      0.3829114182385698,
      0.3949393773089005,
      0.3725476622769004,
      0.4517888245193493,
      0.4153408959353322,
      0.2504633116446253,
      0.38353726586518566,
      0.4085310759091265,
      0.416077781835569,
      0.43462545503760563,
      0.4472364748581015,
      0.40226863901655974,
      0.358933080844275,
      0.33557298876745834,
      0.42114644936192636,
      0.35848003765491,
      0.0,
      0.349072605790135,
      0.48521023407193775,
      0.3853080867982812,
      0.39145349027543874,
      0.38359656184156066,
      0.3118474248489933
    ],
    [
      0.3554681644481743,
      0.4398607517278059,
      0.41368278728979835,
      0.4145196162456384,
      0.4380159472583689,
      0.4239076670438986,
      0.40716238269900584,
      0.42932549011814647,
      0.4711868150909291,
      0.4458645461989714,
      0.46042419479597974,
      0.29393581886257714,
      0.4286220371863261,
      0.4308814206415523,
      0.4794971031574138,
      0.44804346843955534,
      0.4232931749206683,
      0.41591529191410115,
      0.4807019336999723,
      0.4531962228961868,
      0.46853587200574154,
      0.4114577304034579,
      0.40819503865529816,
      0.0,
      0.42533677556413285,
      0.40853716894656245,
      0.4419908000804196,
      0.5122060399360489,
      0.390012521732916
    ],
    [
      0.43195736151370134,
      0.442114675136587,
      0.4648512672700418,
      0.4760204161025623,
      0.3499971624814162,
      0.38646699631344705,
      0.4357235050357313,
      0.36148579329740693,
      0.4088531389823806,
      0.4838265107438511,
      0.3687296635163695,
      0.248477687044528,
      0.4045600467627659,
      0.4004043037683007,
      0.36265424826065185,
      0.4220124374155274,
      0.3480751987106345,
      0.36831017846942227,
      0.37620568078475847,
      0.3275470238570508,
      0.3416722206635072,
      0.3124186354664289,
      0.42506557850726123,
      0.34050856155827747,
      0.0,
      0.4055468263452062,
      0.3517126671564281,
      0.41074354941856406,
      0.22855165134963729
    ],
    [
      0.38100323834823757,
      0.5087185274473229,
      0.42738802359856876,
      0.5007895698279579,
      0.37158432261223395,
      0.44055096115721426,
      0.3584596761432428,
      0.442319188305228,
      0.3976559551600225,
      0.37161137971200486,
      0.399559260474583,
      0.2534392898360047,
      0.47099521622804197,
      0.4398034790544989,
      0.3627373383974801,
      0.45042540471755466,
      0.3656244775709152,
      0.4971122754306627,
      0.38636731409446456,
      0.33409293385470895,
      0.4425294304038476,
      0.4180049272250288,
      0.3115533608044232,
      0.3079621404046955,
      0.32387199807165246,
      0.0,
      0.3753023400758462,
      0.3231371019749498,
      0.272155511171136
    ],
    [
      0.4600290198926924,
      0.5591077450215574,
      0.4873471725605456,
      0.5099809817024328,
      0.5546634402726365,
      0.5750367352279624,
      0.5154478651403946,
      0.6064167446996409,
      0.4453411387555857,
      0.48615432115163904,
      0.5758449568778636,
      0.28718774689649296,
      0.569964384896777,
      0.44148721752359754,
      0.5204665371663639,
      0.574650527669667,
      0.5148914139060379,
      0.5183185632473573,
      0.4862366209717426,
      0.42757094950441754,
      0.5758159230977997,
      0.4468378815974896,
      0.4301034895561904,
      0.43163006251919755,
      0.4189932721127456,
      0.456124408029696,
      0.0,
      0.48704756148004624,
      0.37728666598749316
    ],
    [
      0.4706295482265408,
      0.5377070152301562,
      0.44449264418290824,
      0.45499648880952415,
      0.4092738946968273,
      0.46616423084086,
      0.5684836932259725,
      0.43663722598770693,
      0.5355252129271673,
      0.4552306311846275,
      0.4405176343922763,
      0.20801304654822528,
      0.4639466729138999,
      0.5102222391267284,
      0.5120415309231463,
      0.5090217550220406,
      0.42816419712265397,
      0.4279158473725686,
      0.4356005760124775,
      0.3652341549329321,
      0.43101748256665773,
      0.4286854709439867,
      0.41387272547054565,
      0.4363263541418261,
      0.3886433252326429,
      0.362170745176565,
      0.482259939853539,
      0.0,
      0.34391336241583303
    ],
    [
      0.3289980845439755,
      0.3770800976054225,
      0.3469363265618173,
      0.3409172398480018,
      0.38833435482500733,
      0.37585183646253206,
      0.3555540885793722,
      0.3878380544633617,
      0.3403904439507628,
      0.352812097429303,
      0.38488847512802327,
      0.3557577894117585,
      0.37138290400892426,
      0.35795516615638134,
      0.34043981882744334,
      0.4018333592107093,
      0.39871947118031503,
      0.36222972352858007,
      0.36226787499352486,
      0.38065396072716395,
      0.406738887390488,
      0.4115785284406679,
      0.376621829809084,
      0.4008556458383974,
      0.3494709021274278,
      0.3107197021364565,
      0.40876347915545974,
      0.4104010929933297,
      0.0
    ]
  ],
  "row_avgs": [
    0.134473738481066,
    0.4935364043608682,
    0.4599535153506859,
    0.45044984319151327,
    0.49293509833928045,
    0.508120096169398,
    0.3738554105335398,
    0.47790261776252674,
    0.457234284870317,
    0.4004666287489756,
    0.5567973844000889,
    0.2224137774152864,
    0.4790280190402538,
    0.4320943634134306,
    0.4322960706652646,
    0.43273719673935523,
    0.4694985819249656,
    0.4438691372732966,
    0.40471475299870435,
    0.41567532420722175,
    0.44566496776081344,
    0.398071382321032,
    0.39527042011635344,
    0.4292777422128446,
    0.3815890352118731,
    0.3905269515036617,
    0.4907136909809308,
    0.4416681301957442,
    0.37092825840477456
  ],
  "col_avgs": [
    0.4231361190295636,
    0.5178425629220309,
    0.47668937638588055,
    0.4819507263178946,
    0.4251064933342747,
    0.48613806567757983,
    0.44457630516654595,
    0.44835220942638493,
    0.4231791521589457,
    0.42017396332405177,
    0.46040801389723135,
    0.24452213119869587,
    0.4832321403085545,
    0.4450053769722123,
    0.44252657363949927,
    0.4859145135920181,
    0.4238643609026071,
    0.4746294231124484,
    0.38205445660131027,
    0.36916243913041297,
    0.44126961762029726,
    0.4000312739868752,
    0.3805272518710475,
    0.3577216099445532,
    0.3822591619420458,
    0.4102311746322824,
    0.4350234742227806,
    0.4173163647724011,
    0.298918492503641
  ],
  "combined_avgs": [
    0.2788049287553148,
    0.5056894836414496,
    0.4683214458682832,
    0.46620028475470393,
    0.4590207958367776,
    0.49712908092348895,
    0.4092158578500429,
    0.46312741359445586,
    0.44020671851463133,
    0.41032029603651365,
    0.5086026991486601,
    0.23346795430699113,
    0.48113007967440413,
    0.43854987019282143,
    0.43741132215238193,
    0.4593258551656867,
    0.44668147141378634,
    0.4592492801928725,
    0.3933846048000073,
    0.39241888166881733,
    0.44346729269055535,
    0.3990513281539536,
    0.38789883599370045,
    0.3934996760786989,
    0.3819240985769594,
    0.40037906306797205,
    0.4628685826018557,
    0.42949224748407266,
    0.3349233754542078
  ],
  "gppm": [
    599.4132007305969,
    610.0048531190718,
    627.9055767523917,
    621.3111033502406,
    656.3897184566829,
    626.3502726203158,
    640.2323048619093,
    641.4073690689331,
    653.1696027461531,
    658.2947318722499,
    641.3254155692821,
    737.6766126180165,
    626.6388620575693,
    647.5174667015855,
    645.6621611133479,
    628.0006384678746,
    654.7771455660987,
    630.4435847198947,
    678.2384273787354,
    682.1251162184011,
    645.4185588171841,
    671.5216952625224,
    676.4773070906833,
    687.9379585923823,
    674.9020536352302,
    657.6198765591773,
    650.9760132702002,
    659.112391567799,
    715.3025461921595
  ],
  "gppm_normalized": [
    1.3906070168244953,
    1.2960972472711971,
    1.3343465565594201,
    1.3309386287342684,
    1.388677421105772,
    1.3275927251501785,
    1.374842741474414,
    1.35760507581438,
    1.3887754649596473,
    1.3927971756433417,
    1.3521162333880696,
    1.588576248528071,
    1.3283812853861543,
    1.3750742971523402,
    1.3692791593302616,
    1.3375280442978712,
    1.3831663623637114,
    1.3416367319627935,
    1.438280075839734,
    1.4482983088555024,
    1.3641556461181696,
    1.4278829111391416,
    1.4359426116401226,
    1.4597735381230987,
    1.4295810615992897,
    1.405503491531082,
    1.3746060681890941,
    1.4020721865673023,
    1.5181429591710311
  ],
  "token_counts": [
    1329,
    483,
    449,
    539,
    405,
    428,
    556,
    422,
    421,
    395,
    365,
    540,
    411,
    423,
    433,
    505,
    392,
    477,
    403,
    400,
    409,
    433,
    408,
    393,
    377,
    493,
    377,
    420,
    364
  ],
  "response_lengths": [
    6656,
    2750,
    2665,
    3157,
    2349,
    2394,
    3167,
    2523,
    2378,
    2365,
    2135,
    2991,
    2438,
    2467,
    2457,
    2954,
    2199,
    2715,
    2375,
    2347,
    2354,
    2456,
    2394,
    2321,
    2161,
    2841,
    2270,
    2419,
    2181
  ]
}