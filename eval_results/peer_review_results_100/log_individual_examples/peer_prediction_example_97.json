{
  "example_idx": 97,
  "reference": "Under review as a conference paper at ICLR 2023\n\nSPLIT AND MERGE PROXY: PRE-TRAINING PROTEINPROTEIN CONTACT PREDICTION BY MINING RICH INFORMATION FROM MONOMER DATA\n\nAnonymous authors Paper under double-blind review\n\nABSTRACT\n\nProtein-protein contact prediction is a key intelligent biology computation technology for complex multimer protein function analysis but still sufferers from low accuracy. An important problem is that the number of training data cannot meet the requirements of deep-learning-based methods due to the expensive cost of capturing structure information of multimer data. In this paper, we solve this data volume bottleneck in a cheap way, borrowing rich information from monomer data. To utilize monomer (single chain) data in this multimer (multiple chains) problem, we propose a simple but effective pre-training method called Split and Merger Proxy (SMP), which utilizes monomer data to construct a proxy task for model pre-training. This proxy task cuts monomer data into two sub-parts, called pseudo multimer, and pre-trains the model to merge them back together by predicting their pseudo contacts. The pre-trained model is then used to initialize for our target – protein-protein contact prediction. Because of the consistency between this proxy task and the final target, the whole method brings a stronger pre-trained model for subsequent fine-tuning, leading to significant performance gains. Extensive experiments validate the effectiveness of our method and show the model performs better than the state of the art by 11.40% and 2.97% on the P@ L/10 metric for bounded benchmarks DIPS-Plus and CASP-CAPRI, respectively. Further, the model also achieves almost 1.5 times performance superiority to the state of the art on the harder unbounded benchmark DB5. The code, model, and pre-training data will be released after this paper is accepted.\n\n1\n\nINTRODUCTION\n\nProteins are large molecules consisting of amino acids (also called residues) sequences. Proteinprotein contact prediction aims to compute the constraints between given protein sequences (specifically whether residue (can be understood as an individual amino acid) on one protein are in contact with residue on the other protein), which is important for the structural or functional analysis of protein complexes. The predicted constraints reveal the relationships between each residue pair of the two protein sequences, which can not only benefit complex protein structure prediction but also be useful for many kinds of protein function analysis scenarios, e. g. developing new drugs and designing new proteins. The success of RaptorX Wang et al. (2017); Xu et al. (2021) and AlphaFold2 Jumper et al. (2021) demonstrates the application potential of deep learning in the computational biology field and inspired a series of new biological computation methods. However, when extending the deep model to protein-protein (inter-chain) contact prediction, recent works have not achieved satisfying performance as the aforementioned successful works do. An important bottleneck is data quantity limitation.\n\nMany well-known successful deep learning systems are almost trained under large-scale datasets. For example, in computer vision (CV), ConvNet Krizhevsky et al. (2012); Simonyan & Zisserman (2014); He et al. (2016)) and ViT Dosovitskiy et al. (2020); Liu et al. (2021); Yuan et al. (2021) are trained on ImageNet Deng et al. (2009) which has 14 million labeled data who provides enough vision category information of real word. For natural language processing (NLP), the most popular language model BERT Devlin et al. (2018) is trained on document-level data BooksCorpus Zhu et al. (2015) and English Wikipedia in an unsupervised manner. And in computational biology, the\n\n1\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 1: The main idea of Split and Merger Proxy (best viewed in color). In the pre-training stage, a monomer (single chain) is firstly split into two sub-parts that are treated as pseudo multimers (a pair of chains). And then the deep model is pre-trained by learning to merge the pseudo multimers back by predicting their protein-protein contacts.\n\nrecent most popular protein structure prediction model AlphaFold2 Jumper et al. (2021) is trained on about 400k monomer data, 60k with 3D structure labels of Protein Data Bank (PDB) wwp (2019) and 350k protein sequence, and achieves electron microscope accuracy. Obviously, existing humanlevel accurate and successful artificial intelligence models also need big data to train. However, the number of the current largest open-sourced multimer training data Morehead et al. (2022) is much lower than the aforementioned topics, which is only 15k and limits the performance of the deep model. The main reason is the expensive cost of capturing the multimer protein structural information by high-accurate devices. So to tackle the problem of the scarcity of training data, we focus on finding a cheap way to obtain additional data and avoid the extra cost.\n\nOur main idea is to expand the training data by introducing the monomer data into the training step for protein-protein contact prediction. The existing monomer data is free and also can provide useful biological prior. ComplexContact Zeng et al. (2018) is the first work introducing the monomer data It proves the potential value of the monomer data to into the multimer contact prediction task. the multimer task. But obviously, there is an unneglectable task gap between the monomer and the multimer. Specifically, the monomer can only provide information about one chain while the multimer task requires more. So ComplexContact Zeng et al. (2018) suffers from that task gap and existing contact prediction methods often neglect these data. In this paper, we design a novel and effective pre-training method called Split and Merger Proxy (SMP) to introduce monomer data into the protein-protein contact prediction task more effectively, which reduces the aforementioned task gap and leads to better results.\n\nThe proposed SMP is a proxy task for contact prediction pre-training. As shown in Figure 1, SMP generates pseudo multimer data from monomers and utilizes that data to pre-train the contact prediction model. In particular, a single protein is split into two sub-parts that are treated as a pseudo multimer. That pseudo data are used to train the contact prediction model, equal to guide the model to merge these split data back. Although the pseudo multimer data contain biological noise, they can provide additional richer information that complements the existing multimer data. The training targets of SMP and the final task are both contact prediction, so there is no task gap in the fine-tuning stage. The pre-trained model can be fine-tuned on the real multimer data without any modification, leading to a better final model and more accurate contact results.\n\nOur main contributions are as follows:\n\n• We design a novel proxy task, Split and Merger Proxy (SMP), to pre-train contact prediction models on the monomer data more effectively. From the best of our knowledge, this is the first work to leverage the monomer protein data to pre-train the multimer protein contact prediction task.\n\n• Experiments show that we achieve a new state-of-the-art and improve the P@ L/10 metric by a large margin – 11.40% and 2.97% respectively on DIPS-Plus and CASP-CAPRI benchmarks when compared with the latest state-of-the-art DeepInteract Morehead et al.\n\n2\n\nMergeSplitmonomerpseudo multimerUnder review as a conference paper at ICLR 2023\n\n(2022). Moreover, we almost achieve 1.5 times more performance than GeoTrans on the harder unbounded benchmark DB5.\n\n2 RELATED WORKS\n\n2.1 PROTEIN-PROTEIN CONTACT PREDICTION\n\nIntra-protein contact prediction has been well treated Jumper et al. (2021); Baek et al. (2021), but protein-protein contact prediction has not been extensively studied. Some early works Weigt et al. (2009); Morcos et al. (2011); Ekeberg et al. (2014) used direct-coupling analysis (DCA) to disentangle direct and indirect correlations to infer potential relationships between amino acids at different positions. With the great success of Convolutional Neural Network (CNN) LeCun et al. (1998) in CV area, Zeng et al. (2018); Yan & Huang (2021); Roy et al. (2022) applied CNN to multimer contact prediction. Zeng et al. (2018) used two CNNs, one with 1D convolution processed sequence information and the other with 2D convolution encoded MSA information. Yan & Huang (2021) utilized more biological features (e.g., inter-protein docking pattern, physico-chemical information and sequence conservation) as inputs to the neural network to enrich the information carried by multimer data. Because He et al. (2016) demonstrated that deeper networks could learn more discriminative features from the dataset, Roy et al. (2022) used a deeper dilated residual network Yu et al. (2017) to capture relationships between residues. Due to each protein has 3D structure, Fout et al. (2017); Liu et al. (2020); Morehead et al. (2022); Xie & Xu (2022) designed graph neural network (GNN) Scarselli et al. (2008) to predict contacts between proteins. They first built a graph for each protein, the residue on each protein is regarded as a node, and whether the residues in the protein are connected is regarded as an edge. Fout et al. (2017) used graph convolution Kipf & Welling (2016) to get the graph representation of the underlying protein structure and a fully convolutional network (FCN) was utilized to determine contacts between two proteins. Liu et al. (2020) employed weights sharing GNNs to obtain the residue features of each protein, then they devised multilayer CNNs as the interaction module to perform contact prediction. Based on this, Morehead et al. (2022) designed graph transformers to encode the geometric information in multimers, e.g., the distance and direction between residues and the amide angle. Xie & Xu (2022) believed that simply building the residue graph was not enough, so they built two more graphs, e.g., atom graph and surface graph, then they did message passing in each graph. Since AlphaFold2 Jumper et al. (2021) has achieved surprising results in monomer structure prediction, Evans et al. (2021); Bryant et al. (2022); Gao et al. (2022) extended it to multimer contact prediction. Evans et al. (2021) took into account permutation symmetry, position encoding of different chains in multimer, and multimer multiple sequence alignment (MSA) construction for contact prediction. Bryant et al. (2022); Gao et al. (2022) directly spliced multimer as monomer and fed it into AlphaFold2 to get contact prediction. But due to the small level of existing multimer data, current models are less accurate in protein-protein contact prediction.\n\n2.2 PRE-TRAINING IN PROTEIN MODELING\n\nPre-training from a lot of data can provide a good prior knowledge for the model, so it achieves great success in data science community, such as computer vision and natural language processing areas. Some recent works introduced pre-training paradigm to protein modeling area. Rao et al. (2021); Rives et al. (2021); Elnaggar et al. (2021); Chowdhury et al. (2021); Fang et al. (2022); Lin et al. (2022) used Masked Language Model (MLM) proxy task Devlin et al. (2018) to learn residue embedding from massive protein sequences. Rives et al. (2021); Elnaggar et al. (2021); Chowdhury et al. (2021) directly utilized transformer Vaswani et al. (2017) as pre-training network to capture potential biological patterns of amino acids. Since MSAs can provide a certain biological prior for the model, Fang et al. (2022); Lin et al. (2022) devised the same Evoformer network as AlphaFold2 Jumper et al. (2021) and Rao et al. (2021) designed MSA transformer to fully integrate the MSA information into the transformer architecture in pre-training stage, which can make the network directly learn evolutionary information. Because each atom of the protein in PDB Database wwp (2019) has 3D coordinates, Gligorijevi ́c et al. (2021); Chen et al. (2022) designed distance prediction and the dihedral angle prediction proxy tasks, then they got the underlying structural representations for monomers and achieved excellent performance in protein classification tasks. Due to the lack of multimer data and the cost of collecting multimer data is expensive, it is difficult\n\n3\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 2: The Framework of the proposed Split and Merge Proxy (SMP) pre-training method (best viewed in color). The split stage cuts a monomer (the sequence “APFLDLRL” in the figure) into a pseudo multimer consisting of two sub-parts (the two sub-parts “APFLD” and “LRL” in the figure) and computes the contact ground truth. The merge step is the pre-training process, which trains the model to predict the contact relationships on the split data, essentially equal to merging the split sequences back. Note that the sequence here is just an example, not the real chain. And in the finetuning stage, the whole contact predictor, including the graph feature extractor and the interleave module, is directly fine-tuned without any modification on the real multimer data.\n\nto build effective pre-training on existing multimer data. So in this paper, we design a novel proxy task to adapt the monomer into multimer contact prediction, which can pre-train the model getting stronger performance.\n\n3 METHOD\n\n3.1 TASK DEFINITION\n\nThe protein-protein contact prediction, also called residue-residue interface interaction prediction, aims to compute the contact relationship map A ∈ (0, 1)L1×L2 between the two given protein chains. The element Ai,j is 0 or 1, indicating whether the i-th residue in one sequence interacts with the j-th residue in another sequence or not. The contact prediction models take multiple kinds of biological features as inputs, such as amino acid sequences s ∈ PL (P is the set of the amino acid, including 20 kinds of amino acids) and residue 3D coordinates c ∈ RL×3 which is essentially the location of the non-hydrogen atoms. The computation pipeline can be defined as:\n\nApred = f (x1, x2), where xi = {si, ci} ,\n\ni ∈ {1, 2}\n\n(1)\n\nTo achieve this, whatever details of the function f , proteins are often regarded as a graph so the residues are treated as graph nodes and processed by graphic models to extract features. After that, an interleave module fuses these node features and measures the similarities between each residue pair to calculate the contact scores. The whole process is the same as the Fine-tuning block in Figure 2.\n\n3.2 SPLIT AND MERGER PROXY\n\nThe Split and Merger Proxy (SMP) is an effective proxy task proposed to pre-train the contact prediction model. The main pipeline includes a split step and a merge step, shown in Figure 2. Each monomer sequence is cut into two sub-parts to generate the pseudo multimer data. In the merge step, the model learns the contact prediction task directly on the aforementioned split data without any modification. After that, the model would be fine-tuned on real multimer data.\n\n4\n\nInterleaveAPFLDLRL0.10.00.10.30.10.10.10.00.10.90.10.10.00.80.2pseudoground truthAPFLDLRL000000000100010Merge stageFine-tuningCa5Ca3Ca6Ca8Ca2Ca1Ca4Ca7Ca5Ca3Ca2Ca1Ca4Ca1Ca3Ca2LRLAPFLDLRLAPFLDSplit stageCa4Ca3Ca2Ca1GraphFeatureExtractionGraphFeatureExtractionrealground truthAPALInterleaveCa8Ca5Ca6Ca7Ca4Ca1Ca2Ca3LALDRLRDAPALDLAL0RLRD0001000000100000000010000100000APALDLAL0RLRD0001000000100000000010000100000APALDLALRLRD0.20.00.10.10.00.30.80.10.10.20.70.10.20.10.60.60.00.00.10.20.00.30.10.00.00.40.10.00.10.10.10.6monomermultimerpseudo multimerUnder review as a conference paper at ICLR 2023\n\nSplit stage: We use the monomers from the Protein Data Bank (PDB) wwp (2019) dataset because its monomer data including both amino acid sequences s ∈ PL and corresponding 3D coordinates c ∈ RL×3. The target of the split stage is to generate the pseudo multimer that has the same data structure as the real one, including two sub-sequences (s1 and s2) with structural information (c1 and c2) and their corresponding contact ground truth A. We first cut the amino acid sequence into two sub-sequences at a random location:\n\ns1 = s[: l], s2 = s[l :],\n\n(2)\n\nwhere l means the random split index uniformly sampled from the range R, keeping each cut sequence informative and avoiding too short split results that contain only small amounts of residues. In other words, this split location is around the center of the given sequence.\n\nAnd for the 3D structure, we do a similar split operation:\n\nc1 = c[: l], c2 = c[l :].\n\n(3)\n\nWe do not operate any kind of normalization on these 3D coordinates, keeping their values still in the monomer coordinate system so ground-truth A could be computed by the following formula directly:\n\nAi,j =\n\n(cid:26)1 Di,j ≤ λ 0 Di,j > λ\n\n, Di,j = ||c1[i] − c2[j]||2,\n\n(4)\n\nwhere λ is the threshold to determine whether the i-th and j-th residue pair contact or not. ||·|| means the Euclidean distance. This process could be interpreted that the ground-truth contact of pseudo multimer is equal to the intra-contact of the original monomer. Based on the steps mentioned above, monomer data is converted to the pseudo multimer in the form of {s1, s2, c1, c2, A}.\n\nMerge stage: The merge stage is essentially the mimicking learning of the standard contact prediction training. The model learns to predict the A based on the given pseudo multimer inputs {s1, s2, c1, c2}.\n\nWe first extract and calculate co-evolution, conservation and geometric information for each cut subsequence by Multiple Sequence Alignments (MSA) and Protein Structure and Interaction Analyzer (PSAIA), respectively. And then, these pieces of information combined with the protein sequence and 3D structural information are sent to a weights-sharing graph feature extractor to extract residue features F1 ∈ RL1×C and F2 ∈ RL2×C like Figure 2 shows. Note that the coordinate values in c1, c2 all belong in the same monomer coordinate system. So they are all treated to the relative distances of residue pairs in each protein sequence to avoid information leakage. After that, an interleave module computes the interaction features FI ∈ RL1×L2×C′ , which stores the high-level relationship patterns for each residue pair. Finally, a contact prediction head, often a fully convolutional neural network (FCN), predicts a contact map based on that features. For the prediction, we train it as a binary classification task by utilizing the cross-entropy loss function.\n\nFine-tuning stage: The SMP task is the same as the final contact prediction task, both predicting the protein-protein contact maps. So there is not any task gap between this proxy task and fine-tuning. Every module and parameter of the pre-trained model could be re-used in the final model. So, We feed the real multimer data into the pre-trained model and fine-tune the whole model directly.\n\n4 EXPERIMENTS 4.1 DATASET AND EVALUATION PROTOCOL\n\nIn this section, we conduct several experiments on three popular benchmarks DIPS-Plus Morehead et al. (2021), CASP-CAPRI Lensink et al. (2019; 2021) and DB5 Vreven et al. (2015) datasets.\n\nDIPS-Plus is latest open-sourced dataset for protein-protein contact prediction. It provides amino acid sequences and residue coordinates for each multimer data. Except for these pieces of basic information, DIPS-Plus also offers additional different types of biological features such as protrusion index and amide plane normal vector, composing much richer information. After filtering extreme data, such as too long, too short sequences and high relative data with other datasets, the DIPS-Plus dataset still has 15,618 and 3,548 protein complexes for training and validation, respectively, which is the recent known largest open-sourced benchmark. For testing, it provides 32 protein complexes consisting of 16 homodimers and 16 heterodimers to evaluate the model’s ability to handle samples of different difficulties.\n\n5\n\nUnder review as a conference paper at ICLR 2023\n\nTable 1: The average top-k precision (P@k) and recall (R@k) on DIPS-Plus test dataset (%).\n\n16 (Homo)\n\nMethod BIPSPI Sanchez-Garcia et al. (2018) DeepHomo Yan & Huang (2021) ComplexContact Zeng et al. (2018) GCN Morehead et al. (2022) GeoTrans Morehead et al. (2022) GeoTrans + SMP\n\nMethod BIPSPI Sanchez-Garcia et al. (2018) GCN Morehead et al. (2022) GeoTrans Morehead et al. (2022) GeoTrans + SMP\n\nP@ L/10 0\n12.00 -\n20.00 25.00 39.81\n\nP@ L/10 1.00 16.00 19.00 30.40\n\nP@ L/5 0\n9.00 -\n18.00 23.00 33.33 32 (All Proteins) P@ L/5 1.00 12.00 17.00 26.70\n\nP@ L/2 -\n- -\n- -\n26.02\n\nP@ L/2 -\n- -\n20.51\n\nP@ L/10 2.00 -\n16.00 8.00 14.00 20.99\n\nR@ L 1.00 10.00 15.00 24.00\n\n16 (Hetero) P@ L/5 2.00 -\n15.00 7.00 11.00 20.07\n\nR@ L/2 0.40 6.00 9.00 16.02\n\nP@ L/2 -\n- -\n- -\n15.00\n\nR@ L/5 0.30 3.00 4.00 8.56\n\nTable 2: The average top-k precision and recall on CASP-CAPRI 13 & 14 dataset.\n\n14 (Homo)\n\nMethod BIPSPI Sanchez-Garcia et al. (2018) DeepHomo Yan & Huang (2021) ComplexContact Zeng et al. (2018) GCN Morehead et al. (2022) GeoTrans Morehead et al. (2022) GeoTrans + SMP\n\nMethod BIPSPI Sanchez-Garcia et al. (2018) GCN Morehead et al. (2022) GeoTrans Morehead et al. (2022) GeoTrans + SMP\n\nP@ L/10 0\n2.00 -\n11.00 13.00 18.63\n\nP@ L/10 0\n10.00 19.00 21.97\n\nP@ L/5 0\n2.00 -\n13.00 11.00 14.37 19 (All Proteins) P@ L/5 1.00 9.00 14.00 16.77\n\nP@ L/2 -\n- -\n- -\n11.57\n\nP@ L/2 -\n- -\n13.36\n\nP@ L/10 0\n- 8.00 11.00 31.00 32.00\n\nR@ L 2.00 11.00 13.00 14.33\n\n5 (Hetero) P@ L/5 3.00 -\n5.00 9.00 24.00 23.49\n\nR@ L/2 1.00 6.00 8.00 8.34\n\nP@ L/2 -\n- -\n- -\n18.35\n\nR@ L/5 0.1 2.00 4.00 3.91\n\nCASP-CAPRI has been well known as a biologically joint challenge since 2014, aiming to assess the computational methods of modeling protein structures. Morehead et al. (2022) re-organized the data of the 13th and 14th CASP-CAPRI challenge sessions Lensink et al. (2019; 2021), filtering the overlap between the original CASP-CAPRI data and the DIPS-Plus. These filtered data include 14 homodimers and 5 heterodimers and are used to evaluate the ability of real-world applications and cross-set generalization of models trained on the DIPS-Plus training set.\n\nDB5 (Docking Benchmarks version 5 Vreven et al. (2015)) is a traditional benchmark dataset for protein-protein contact prediction, including 140 training, 35 evaluation and 55 testing samples. DB5 consists of unbounded protein complexes that have varying contact types. In contrast, complexes in DIPS-Plus and CASP-CAPRI are bounded and their multiple chains are already conformed with each other. So it can indicate the performance and effectiveness of our model on different types of complexes.\n\nEvaluation All the experiments follow the standard evaluation protocol in existing multimer contact prediction benchmarks. To assess the accuracy of the prediction, the top-k precision and recall are adopted as the evaluation metrics, where k ∈ {L/30, L/20, L/10, L/5, L/2, L} with L being the length of the shortest chain.\n\n4.2\n\nIMPLEMENTATION DETAILS\n\nWe generate the pseudo multimer data from all monomers before 2018-4-30 from Protein Data Bank (PDB) wwp (2019). There are 60, 206 pdb files in total. Each file contains sequence and structural information for the protein. Monomers that cannot be parsed by Biopython Cock et al. (2009) (containing unknown atoms; missing atoms; chain numbers are not in order and so on) are filtered out. Except that each protein file contains several conformations, we only keep the first one and abandon the other. We set the split range R = {1/3 ∼ 2/3} so that the cut position is close to the middle of the given sequence to get pseudo multimers. Too short split proteins whose length of any chain is less than 20 are dropped. The threshold λ used to calculate the contact ground truth is set as 6 ̊A following the same procedure that real multimer utilizes Morehead et al. (2021). Finally, there are 22, 589 pseudo multimers, about 1.5 times of the existing real multimer dataset. Whatever for the pseudo or real multimer data, we also use HHBlits Remmert et al. (2012) with Uniclust30 Mirdita et al. (2017) database for MSA, and PSAIA Mihel et al. (2008) to calculate geometric features.\n\nOur SMP is a pre-training method that is not tightly bound to a specific model. So we combine SMP with the Geometric Transformer (GeoTrans Morehead et al. (2022)) to evaluate the effectiveness of\n\n6\n\nUnder review as a conference paper at ICLR 2023\n\nTable 3: The average top-k precision and recall on DB5 test dataset. 55 (Hetero) P@ L/5 0.10 0.30 0.70 1.10 1.88\n\nR@ L/5 0.04 0.10 0.30 0.34 0.69 Table 4: SMP vs self-supervised pre-training (SSL) on DIPS-Plus test dataset.\n\nMethod BIPSPI Sanchez-Garcia et al. (2018) ComplexContact Zeng et al. (2018) GCN Morehead et al. (2022) GeoTrans Morehead et al. (2022) GeoTrans + SMP\n\nP@ L/10 0.20 0.30 0.60 0.90 1.78\n\nR@ L/2 0.10 0.30 0.80 1.00 1.45\n\nP@ L/2 -\n- -\n- 1.55\n\nR@ L 0.30 0.70 1.30 1.80 2.53\n\nRow 1\n2 3\n4 5\n\nModel GCN GCN GeoTrans GeoTrans GeoTrans\n\nPreTrain -\nSMP -\nSSL SMP\n\nP@ L/10 16.00 18.96 19.00 20.87 30.40\n\nP@ L/5 12.00 15.64 17.00 18.19 26.70\n\nP@ L/2 -\n11.61 -\n14.62 20.51\n\nP@ L -\n8.24 -\n12.40 15.87\n\nR@ L 10.00 13.58 15.00 17.46 24.00\n\nR@ L/2 6.00 10.04 9.00 9.88 16.02\n\nR@ L/5 3.00 5.36 4.00 4.87 8.56\n\nR@ L/10 -\n3.14 -\n2.83 4.79\n\nSMP in the following experiments. The batch size of pre-training and fine-tuning are all set as 48 (except the fine-tuning one of CASP-CAPRI is set as 32 because of the cross-domain evaluation setting of CASP-CAPRI). Other experimental settings, including loss function, optimizer, learning rate and so on, are all kept the same to the latest open-sourced state-of-the-art GeoTrans.\n\n4.3 COMPARISON WITH STATE-OF-THE-ART METHODS We compare several state-of-the-art multimer contact prediction methods including BIPSPI Sanchez-Garcia et al. (2018), ComplexContact Zeng et al. (2018), DeepHomo Yan & Huang (2021), GCN Morehead et al. (2022) and GeoTrans Morehead et al. (2022). Except that the input of ComplexContact is the amino acid sequence, the other methods take both amino acid sequence and 3D structural information as inputs, which are the same as our model.\n\nTable 1 shows the comparison results between SMP and other methods on the DIPS-Plus dataset, demonstrating that SMP outperforms existing state-of-the-art method GeoTrans Morehead et al. (2022) by a large margin. For homologous complexes, SMP outperforms GeoTrans by 7.43% on the harder metric P@ L/2 and even 18.36% on P@ L/20, demonstrating that SMP can learn more useful residue representation and contact prediction knowledge from additional pseudo multimer data. For more difficult heterologous complexes, SMP also surpasses GeoTrans 4.49% on harder P@ L/2. These heterologous performances benefit from the potential consistency with the pseudo multimer and heterologous proteins. Specifically, the cut chains usually have low sequence identities, sharing certain similar properties and distributions of the real heterologous data, making SMP an obvious improvement on heterologous multimers. From an overall perspective, the proposed SMP brings significant gains compared with GeoTrans by 11.4% at P@ L/10 and 8.00% at R @L, proving that our SMP brings more discriminative expression for multimer contact prediction whatever homologous or heterologous complexes.\n\nTables 2 presents the average top-k metrics of SMP on the CASP-CAPRI dataset, specifically, 19 challenging protein complexes (14 homodimers and 5 heterodimers). SMP also surpasses the stateof-the-art method GeoTrans on P@ L/10 by 5.63% on 14 homologous when keeping comparable performances for 5 heterologous. SMP achieves improvements for several different settings, demonstrating that the pre-training of SMP learns many valuable patterns of contact prediction from pseudo multimers to help learn real multimer prediction effectively.\n\nOn the DB5 dataset in Table 3, SMP also exceeds the precision of GeoTrans for all metrics. All methods perform poorly due to testing hard and unseen unbound complexes with varying contact types that are not necessarily conformal. However, SMP still shows more than 1.5 times better performance than GeoTrans in almost all metrics. It indicates that SMP has good cross-domain capabilities and has the potential to be used in real-world applications of complex contact prediction.\n\nOverall, this pre-training paradigm plays a considerable role in various types of downstream proteinprotein contact prediction tasks (cross set and unbound set), showing good robustness with SMP.\n\n4.4 ABLATION STUDIES\n\n4.4.1 COMPARISON WITH DIFFERENT PRE-TRAINING PARADIGM AND CONTACT PREDICTOR\n\nPrevious comparisons show the effectiveness of the combination of our SMP with the latest stateof-the-art model GeoTrans Morehead et al. (2022). In this ablation study, we further investigate the\n\n7\n\nUnder review as a conference paper at ICLR 2023\n\nTable 5: Partial pre-training results on DIPS-Plus test dataset.\n\nP@ L/10 19.00 18.22 18.61 24.64 26.20 30.40\n\nP@ L/5 17.00 15.58 19.02 21.36 21.29 26.70\n\nP@ L/2 -\n13.35 15.10 16.59 15.85 20.51\n\nP@ L -\n11.06 11.76 11.92 12.77 15.87\n\nR@ L 15.00 16.80 17.08 16.93 18.09 24.00\n\nR@ L/2 9.00 10.48 11.14 12.08 11.50 16.02\n\nR@ L/5 4.00 4.84 5.68 6.14 6.40 8.56\n\nTable 6: Partial fine-tuning results on DIPS-Plus test dataset.\n\nP@ L/10 5.98 15.42 19.83 19.84 23.99 30.40\n\nP@ L/5 3.70 15.40 16.12 17.11 19.55 26.70\n\nP@ L/2 2.08 12.25 12.53 12.96 15.49 20.51\n\nP@ L 1.98 9.63 10.80 10.62 11.92 15.87\n\nR@ L 1.78 14.02 15.87 14.29 16.97 24.00\n\nR@ L/2 0.82 8.59 9.71 8.70 11.11 16.02\n\nR@ L/5 0.62 4.20 4.91 4.56 5.53 8.56\n\nRow 1\n2 3\n4 5\n6\n\nRow 1\n2 3\n4 5\n6\n\nRatio 0\n1/5 1/4 1/3 1/2 1\n\nRatio 0\n1/5 1/4 1/3 1/2 1\n\nR@ L/10 -\n2.76 2.90 3.35 3.84 4.79\n\nR@ L/10 0.56 1.96 3.10 2.50 3.22 4.79\n\nsuperiority of our SMP. We combine SMP with different contact predictor to prove its generalization and also compare the SMP with other pre-training method to show the advantage of the SMP design. All related results are shown in Table 4.\n\nTo investigate the influence of the combined contact predictor with SMP, we change the graph feature transfer module from Transformer into the Graph Convolutional Network (GCN) Kipf & Welling (2016). This GCN only has a total of 33k parameters, which is quite much lower than the 1.4m parameters of the Transformer one. So this setting can show the generalization of the SMP on a small-scale model. From the 1st and 2nd lines of Table 4, it can be seen that our SMP still brings a 3.64% performance increase under the P@ L/5. It indicates that the SMP paradigm keeps strong generalization on the small-scale model, showing the potential for extensions of future different types and levels of contact predictors.\n\nTo show the superiority of the SMP design, we construct another pre-training method by adapting a popular self-supervised learning (SSL) paradigm Proteinbert Brandes et al. (2022) to train on the monomer data with 3D structural cues. This method pre-trains the model by a self-supervised proxy task that guides the model to reconstruct the inputs by partial observation, providing different pretraining mechanisms compared with our SMP. As shown in the 3rd ∼ 4th lines of Table 4, this SSL method provides average 1% gains on all metrics, proving the fact that monomers bring much useful information for this multimer task from a different view. But when compared with the SMP (5th line), SMP still shows stronger performance and outperforms the SSL by 5.89% on the harder metric P@ L/2, indicating the superiority of the SMP design that can utilize information in 3D structures more effectively and further eliminate the task gap between the pre-training and fine-tuning.\n\n4.4.2 PARTIAL PRE-TRAINING RESULTS\n\nWe study the effectiveness of pre-training data volume for SMP and conduct partial pre-training experiments with different degrees of monomer data. We set five partial pre-training ratios {1/5, 1/4, 1/3, 1/2, 1}. When comparing the 2nd line of Table 5 with the 1st line (without pretraining), we find that the performance has some fluctuation when the number of introduced pseudo multimers is small. This is caused by the biological noise introduced by the small-scale pseudo data, which is eliminated when the scale increases and clearly indicated in Table 5 3rd∼6th lines. Obviously, when the amount of pre-trained data reaches 1/4 (in the 3rd line), SMP has introduced certain precision and recall gains except on P@ L/10 metric than GeoTrans (in the 1st line), with an average improvement of 2%. Moreover, as the amount of pre-trained data increases, the performance gradually improves, proving that SMP guides the model to learn rich contact prediction to provide beneficial initialization parameters for contact prediction models.\n\n4.4.3 PARTIAL FINE-TUNING RESULTS\n\nThe pre-trained model has the potential to achieve satisfying performances only trained with smallscale training data. So we aim to explore the effect of SMP for fine-tuning with different scale data. We use six partial fine-tuning ratios, which belong to the set {0, 1/5, 1/4, 1/3, 1/2, 1}. The 1st line of Table 6 shows that SMP surpasses the traditional method BIPSPI (Table 3) without any fine-tuning, which indicates that pseudo multimer can provide prior knowledge that is relevant to the real multimers contact prediction. Moreover, the 3rd line of Table 6 shows that our model achieves\n\n8\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 3: Contact visualization results of the 2 multimer 4LIW (first row) and 4DR5 (second row). The GeoTrans’s predictions, SMP’s predictions and ground truths are corresponding to the left, middle and right columns, respectively.\n\nTable 7: Different split ranges results on DIPS-Plus test dataset.\n\nRow 1\n2 3\n4\n\nRange 2/5 ∼ 3/5 1/3 ∼ 2/3 1/4 ∼ 3/4 1/5 ∼ 4/5\n\nP@ L/10 21.94 30.40 23.11 23.90\n\nP@ L/5 19.47 26.70 20.00 20.75\n\nP@ L/2 14.37 20.51 17.22 14.17\n\nP@ L 11.66 15.87 14.35 11.36\n\nR@ L 17.63 24.00 20.80 16.84\n\nR@ L/2 11.43 16.02 12.80 10.71\n\nR@ L/5 6.39 8.56 5.85 6.16\n\nR@ L/10 3.65 4.79 3.35 3.40\n\ncomparable results to our combined predictor GeoTrans Morehead et al. (2022) only with 1/4 training data demonstrating that the SMP pre-training can provide knowledge that can be effectively re-used and transferred to the real multimer scenario. With further increasing the data volume in the 4th ∼ 6th line of Table 6, it can finally achieve 30.4% on metric P@ L/10, surpassing the previous state-of-the-art method GeoTrans. These experiments prove that our pre-training paradigm can effectively reduce the dependence on real data and make the model adapt to different volume-level training data situations, having the potential to save the extra cost of collecting multimer data.\n\n4.4.4 DIFFERENT SPLIT RANGE RESULTS\n\nWe study the influence of different split ranges on the split stage for SMP to find the optimal one. We set four split intervals settings {2/5 ∼ 3/5, 1/3 ∼ 2/3, 1/4 ∼ 3/4, 1/5 ∼ 4/5}. As shown in the 2nd line of Table 7, we find the performance is best when the split interval is 1/3 ∼ 2/3. This appropriate range makes the random interval relatively close to the middle of the protein chain and avoids yielding one of the monomers with a too short length simultaneously.\n\n4.5 VISUALIZATION\n\nWe also visualize some prediction results of GeoTrans in Figure 3. We exhibit a homologous multimer (i.e., PDB ID: 4LIW) and a heterologous multimer (i.e., 4DR5) from the DIPS-Plus test set. The blue box in Figure 3 indicates that SMP successfully can predict several positive contacts that GeoTrans neglects. And the green box in Figure 3 shows that our SMP can eliminate some false positives provided by GeoTrans. All these bounded areas demonstrate that SMP is more accurate in multimer contact prediction than the state-of-the-art method GeoTrans, demonstrating that the model pre-trained by SMP can carry several types of new advantages over the original one.\n\n5 CONCLUSION\n\nThis paper introduces the Split and Merger Proxy (SMP), a simple yet effective pre-training framework for protein-protein contact prediction to solve the limited number of multimers by using rich monomer information. SMP splits monomer data into pseudo multimers and trains the model to merge them back together by predicting its pseudo contact interaction, which reduces the task gap between this proxy task and the final target, leading to significant performance gain. It demonstrates that splitting monomers benefit multimer contact prediction tasks and also implies that monomers data may have the potential for other downstream computational multimer protein tasks.\n\n9\n\nGeoTransSMPGroundTruthUnder review as a conference paper at ICLR 2023\n\nREFERENCES\n\nProtein data bank: the single global archive for 3d macromolecular structure data. Nucleic acids\n\nresearch, 47(D1):D520–D528, 2019.\n\nMinkyung Baek, Frank DiMaio, Ivan Anishchenko, Justas Dauparas, Sergey Ovchinnikov, Gyu Rie Lee, Jue Wang, Qian Cong, Lisa N Kinch, R Dustin Schaeffer, et al. Accurate prediction of protein structures and interactions using a three-track neural network. Science, 373(6557):871– 876, 2021.\n\nNadav Brandes, Dan Ofer, Yam Peleg, Nadav Rappoport, and Michal Linial. Proteinbert: a universal deep-learning model of protein sequence and function. Bioinform., 38(8):2102– 2110, 2022. doi: 10.1093/bioinformatics/btac020. URL https://doi.org/10.1093/ bioinformatics/btac020.\n\nPatrick Bryant, Gabriele Pozzati, and Arne Elofsson. Improved prediction of protein-protein inter-\n\nactions using alphafold2. Nature communications, 13(1):1–11, 2022.\n\nCan Chen, Jingbo Zhou, Fan Wang, Xue Liu, and Dejing Dou. Structure-aware protein self-\n\nsupervised learning. arXiv preprint arXiv:2204.04213, 2022.\n\nRatul Chowdhury, Nazim Bouatta, Surojit Biswas, Charlotte Rochereau, George M Church, Peter K Sorger, and Mohammed AlQuraishi. Single-sequence protein structure prediction using language models from deep learning. bioRxiv, 2021.\n\nPeter JA Cock, Tiago Antao, Jeffrey T Chang, Brad A Chapman, Cymon J Cox, Andrew Dalke, Iddo Friedberg, Thomas Hamelryck, Frank Kauff, Bartek Wilczynski, et al. Biopython: freely available python tools for computational molecular biology and bioinformatics. Bioinformatics, 25(11):1422–1423, 2009.\n\nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pp. 248–255. Ieee, 2009.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\n\nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020.\n\nVijay Prakash Dwivedi and Xavier Bresson. A generalization of transformer networks to graphs.\n\narXiv preprint arXiv:2012.09699, 2020.\n\nMagnus Ekeberg, Tuomo Hartonen, and Erik Aurell. Fast pseudolikelihood maximization for directcoupling analysis of protein structure from many homologous amino-acid sequences. Journal of Computational Physics, 276:341–356, 2014.\n\nAhmed Elnaggar, Michael Heinzinger, Christian Dallago, Ghalia Rehawi, Yu Wang, Llion Jones, Tom Gibbs, Tamas Feher, Christoph Angerer, Martin Steinegger, et al. Prottrans: Towards cracking the language of lifes code through self-supervised deep learning and high performance computing. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2021.\n\nRichard Evans, Michael O’Neill, Alexander Pritzel, Natasha Antropova, Andrew W Senior, Timothy Green, Augustin ˇZ ́ıdek, Russell Bates, Sam Blackwell, Jason Yim, et al. Protein complex prediction with alphafold-multimer. BioRxiv, 2021.\n\nXiaomin Fang, Fan Wang, Lihang Liu, Jingzhou He, Dayong Lin, Yingfei Xiang, Xiaonan Zhang, Hua Wu, Hui Li, and Le Song. Helixfold-single: Msa-free protein structure prediction by using protein language model as an alternative. arXiv preprint arXiv:2207.13921, 2022.\n\n10\n\nUnder review as a conference paper at ICLR 2023\n\nAlex Fout, Jonathon Byrd, Basir Shariat, and Asa Ben-Hur. Protein interface prediction using graph convolutional networks. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30, pp. 6530–6539. Curran Associates, Inc., 2017. URL https://proceedings.neurips. cc/paper/2017/file/f507783927f2ec2737ba40afbd17efb5-Paper.pdf.\n\nMu Gao, Davi Nakajima An, Jerry M Parks, and Jeffrey Skolnick. Af2complex predicts direct physical interactions in multimeric proteins with deep learning. Nature communications, 13(1): 1–13, 2022.\n\nVladimir Gligorijevi ́c, P Douglas Renfrew, Tomasz Kosciolek, Julia Koehler Leman, Daniel Berenberg, Tommi Vatanen, Chris Chandler, Bryn C Taylor, Ian M Fisk, Hera Vlamakis, et al. Structurebased protein function prediction using graph convolutional networks. Nature communications, 12(1):1–14, 2021.\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016.\n\nJie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks.\n\nIn Proceedings of the IEEE\n\nconference on computer vision and pattern recognition, pp. 7132–7141, 2018.\n\nZiniu Hu, Yuxiao Dong, Kuansan Wang, Kai-Wei Chang, and Yizhou Sun. Gpt-gnn: Generative pre-training of graph neural networks. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp. 1857–1867, 2020.\n\nSergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pp. 448–456. PMLR, 2015.\n\nJohn Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin ˇZ ́ıdek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583–589, 2021.\n\nDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\n\narXiv:1412.6980, 2014.\n\nThomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional net-\n\nworks. arXiv preprint arXiv:1609.02907, 2016.\n\nAlex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.\n\nImagenet classification with deep convolutional neural networks. In F. Pereira, C.J. Burges, L. Bottou, and K.Q. Weinberger (eds.), Advances in Neural Information Processing Systems, volume 25. Curran Associates, Inc., 2012. URL https://proceedings.neurips.cc/paper/2012/file/ c399862d3b9d6b76c8436e924a68c45b-Paper.pdf.\n\nYann LeCun, L ́eon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to\n\ndocument recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.\n\nMarc F Lensink, Guillaume Brysbaert, Nurul Nadzirin, Sameer Velankar, Rapha ̈el AG Chaleil, Tereza Gerguri, Paul A Bates, Elodie Laine, Alessandra Carbone, Sergei Grudinin, et al. Blind prediction of homo-and hetero-protein complexes: The casp13-capri experiment. Proteins: Structure, Function, and Bioinformatics, 87(12):1200–1221, 2019.\n\nMarc F Lensink, Guillaume Brysbaert, Th ́eo Mauri, Nurul Nadzirin, Sameer Velankar, Raphael AG Chaleil, Tereza Clarence, Paul A Bates, Ren Kong, Bin Liu, et al. Prediction of protein assemblies, the next frontier: The casp14-capri experiment. Proteins: Structure, Function, and Bioinformatics, 2021.\n\nPengyong Li, Jun Wang, Ziliang Li, Yixuan Qiao, Xianggen Liu, Fei Ma, Peng Gao, Seng Song, and Guotong Xie. Pairwise half-graph discrimination: A simple graph-level self-supervised strategy for pre-training graph neural networks. arXiv preprint arXiv:2110.13567, 2021.\n\n11\n\nUnder review as a conference paper at ICLR 2023\n\nZeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Allan dos Santos Costa, Maryam Fazel-Zarandi, Tom Sercu, Sal Candido, et al. Language models of protein sequences at the scale of evolution enable accurate structure prediction. bioRxiv, 2022.\n\nYi Liu, Hao Yuan, Lei Cai, and Shuiwang Ji. Deep learning of high-order interactions for protein interface prediction. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pp. 679–687, 2020.\n\nZe Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 10012–10022, 2021.\n\nJosip Mihel, Mile ˇSiki ́c, Sanja Tomi ́c, Branko Jeren, and Kristian Vlahoviˇcek. Psaia–protein struc-\n\nture and interaction analyzer. BMC structural biology, 8(1):1–11, 2008.\n\nMilot Mirdita, Lars Von Den Driesch, Clovis Galiez, Maria J Martin, Johannes S ̈oding, and Martin Steinegger. Uniclust databases of clustered and deeply annotated protein sequences and alignments. Nucleic acids research, 45(D1):D170–D176, 2017.\n\nFaruck Morcos, Andrea Pagnani, Bryan Lunt, Arianna Bertolino, Debora S Marks, Chris Sander, Riccardo Zecchina, Jos ́e N Onuchic, Terence Hwa, and Martin Weigt. Direct-coupling analysis of residue coevolution captures native contacts across many protein families. Proceedings of the National Academy of Sciences, 108(49):E1293–E1301, 2011.\n\nAlex Morehead, Chen Chen, Ada Sedova, and Jianlin Cheng. Dips-plus: The enhanced database of interacting protein structures for interface prediction. CoRR, abs/2106.04362, 2021. URL https://arxiv.org/abs/2106.04362.\n\nAlex Morehead, Chen Chen, and Jianlin Cheng. Geometric transformers for protein interface contact In The Tenth International Conference on Learning Representations, ICLR 2022, prediction. Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL https://openreview.net/ forum?id=CS4463zx6Hi.\n\nFranco P Preparata and Michael I Shamos. Computational geometry: an introduction. Springer\n\nScience & Business Media, 2012.\n\nRoshan M Rao, Jason Liu, Robert Verkuil, Joshua Meier, John Canny, Pieter Abbeel, Tom Sercu, and Alexander Rives. Msa transformer. In International Conference on Machine Learning, pp. 8844–8856. PMLR, 2021.\n\nMichael Remmert, Andreas Biegert, Andreas Hauser, and Johannes S ̈oding. Hhblits: lightning-fast iterative protein sequence searching by hmm-hmm alignment. Nature methods, 9(2):173–175, 2012.\n\nAlexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Jason Liu, Demi Guo, Myle Ott, C Lawrence Zitnick, Jerry Ma, et al. Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences. Proceedings of the National Academy of Sciences, 118(15):e2016239118, 2021.\n\nRaj S Roy, Farhan Quadir, Elham Soltanikazemi, and Jianlin Cheng. A deep dilated convolutional residual network for predicting interchain contacts of protein homodimers. Bioinformatics, 38(7): 1904–1910, 2022.\n\nRuben Sanchez-Garcia, C O S Sorzano, J M Carazo, and Joan Segura. BIPSPI: a method for the prediction of partner-specific protein–protein interfaces. Bioinformatics, 35(3):470–477, 07 2018. ISSN 1367-4803. doi: 10.1093/bioinformatics/bty647. URL https://doi.org/10.1093/ bioinformatics/bty647.\n\nFranco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE transactions on neural networks, 20(1):61–80, 2008.\n\nKaren Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image\n\nrecognition. arXiv preprint arXiv:1409.1556, 2014.\n\n12\n\nUnder review as a conference paper at ICLR 2023\n\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):1929–1958, 2014.\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\n\nThom Vreven, Iain H Moal, Anna Vangone, Brian G Pierce, Panagiotis L Kastritis, Mieczyslaw Torchala, Raphael Chaleil, Brian Jim ́enez-Garc ́ıa, Paul A Bates, Juan Fernandez-Recio, et al. Updates to the integrated protein–protein interaction benchmarks: docking benchmark version 5 and affinity benchmark version 2. Journal of molecular biology, 427(19):3031–3041, 2015.\n\nSheng Wang, Siqi Sun, Zhen Li, Renyu Zhang, and Jinbo Xu. Accurate de novo prediction of protein contact map by ultra-deep learning model. PLoS computational biology, 13(1):e1005324, 2017.\n\nMartin Weigt, Robert A White, Hendrik Szurmant, James A Hoch, and Terence Hwa. Identification of direct residue contacts in protein–protein interaction by message passing. Proceedings of the National Academy of Sciences, 106(1):67–72, 2009.\n\nZiwei Xie and Jinbo Xu. Deep graph learning of inter-protein contacts. Bioinformatics, 38(4):\n\n947–953, 2022.\n\nJinbo Xu, Matthew Mcpartlon, and Jin Li. Improved protein structure prediction by deep learning\n\nirrespective of co-evolution information. Nature Machine Intelligence, 3(7):601–609, 2021.\n\nYumeng Yan and Sheng-You Huang. Accurate prediction of inter-protein residue–residue contacts\n\nfor homo-oligomeric protein complexes. Briefings in bioinformatics, 22(5):bbab038, 2021.\n\nFisher Yu, Vladlen Koltun, and Thomas Funkhouser. Dilated residual networks. In Proceedings of\n\nthe IEEE conference on computer vision and pattern recognition, pp. 472–480, 2017.\n\nLi Yuan, Yunpeng Chen, Tao Wang, Weihao Yu, Yujun Shi, Zi-Hang Jiang, Francis EH Tay, Jiashi Feng, and Shuicheng Yan. Tokens-to-token vit: Training vision transformers from scratch on imagenet. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 558–567, 2021.\n\nHong Zeng, Sheng Wang, Tianming Zhou, Feifeng Zhao, Xiufeng Li, Qing Wu, and Jinbo Xu. Complexcontact: a web server for inter-protein contact prediction using deep learning. Nucleic acids research, 46(W1):W432–W437, 2018.\n\nYukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by watching In Proceedings of the IEEE international conference on computer movies and reading books. vision, pp. 19–27, 2015.\n\n13\n\nUnder review as a conference paper at ICLR 2023\n\nTable 8: Different batch size results on three benchmarks. DS: dataset, BZ: batch size.\n\nDS\n\nDIPS-Plus\n\nCASP-CAPRI\n\nDB5\n\nBZ bs=32 bs=48 bs=72 bs=32 bs=48 bs=72 bs=32 bs=48 bs=72\n\nP@ L/10 30.28 30.40 28.29 23.52 23.36 16.28 1.59 1.78 1.42\n\nP@ L/5 26.63 26.70 24.34 18.94 18.84 14.91 1.69 1.88 1.84\n\nP@ L/2 19.64 20.51 19.93 13.78 13.92 12.90 2.24 1.55 1.60\n\nP@ L 15.09 15.87 15.32 11.17 11.14 10.02 2.05 1.33 1.65\n\nR@ L 20.85 24.00 21.02 12.58 13.88 14.34 3.96 2.53 2.96\n\nR@ L/2 14.19 16.02 13.84 7.96 8.64 9.15 2.04 1.45 1.46\n\nR@ L/5 7.31 8.56 6.59 4.35 4.33 4.83 0.56 0.69 0.69\n\nR@ L/10 4.01 4.79 3.70 2.52 2.57 2.68 0.22 0.33 0.24\n\nA APPENDIX\n\nA.1 DETAILED NETWORK DESIGN\n\nWe use the same network architecture as GenoTrans Morehead et al. (2022), the details are as follows, a k-nearest neighbor graph Preparata & Shamos (2012) is applied to construct a graph of each chain, the residue on each chain is regarded as a node, and the first k residues with the smallest distance from other residues are considered for connecting with the current residue, the k is 20. For network architecture, we use the 2 layers of graph transformer Dwivedi & Bresson (2020) with batch normalization Ioffe & Szegedy (2015), each transformer has 4 attention head and 128 hidden size to get rich node and edge representations. We also use a 14 layers of dilated residual network Yu et al. (2017) for interleave module. It contains a 4 residual block, and each block is composed of 2D convolution with kernel size 3 × 3 and instance normalization. A squeeze-and-excitation (SE) attention Hu et al. (2018) is added after each block to capture channel-wise information. In addition, we use Adam optimizer Kingma & Ba (2014) with the learning rate of 1e−3, the weight decay rate of 1e−2 and the batch size of 48 to train the network. The dropout Srivastava et al. (2014) of 0.2 and an early-stopping patience period of 5 epochs are applied to avoid network over-fitting. Since there are more non-contact sites than contacts in the protein-protein contact prediction task, there is a huge class imbalance, and we use weighted cross entropy with a positive class weight of 5 to overcome this imbalance. To experiment on unbounded dataset DB5, we fine-tune models on 140 training and 35 validation complexes of DB5 with the learning rate of 1e−5.\n\nA.2 BATCH SIZE TUNING\n\nThe benchmarks that we utilize for fine-tunning and evaluating our model cover several contact prediction scenarios, including bounded Morehead et al. (2021), cross-set Lensink et al. (2019; 2021) and unbounded situations Vreven et al. (2015). So the hyper-parameters in fine-tuning may affect the final results. In this sub-section, we aim to find the optimal batch size on these downstream datasets respectively. We set different batch size settings of 32, 48 and 72 on all utilized benchmarks as shown in Table 8. We find that when pre-training with batch size of 48 achieving the best result of 30.40 % on P@ L/10 metric on the bounded benchmark DIPS-Plus. On the cross-set benckmark CASP-CAPRI, fine-tuning with batch size of 32 is optimal and can obtain 23.52 % on P@ L/10. For the unbounded DB5 dataset, it achieves the best result of 1.78 % on P@ L/10 metric with batch size 48.\n\nA.3 COMPARISON WITH DIFFERENT GRAPH PRE-TRAINING METHODS\n\nSince GeoTrans is a graph-based model, we use different graph pre-training methods to compare with SMP to show the superiority of the SMP design. We compare several simple graph pre-training methods including Mask node Hu et al. (2020), Mask edge Hu et al. (2020), and PHD Li et al. (2021). Table 9 shows the contrast results between SMP and other graph pre-training methods. We find that all these graph pre-training methods have improved to the baseline method GeoTrans, and SMP outperforms other methods by a large margin in all metrics. This experiment indicates that SMP has no task gap between the pre-training stage and the fine-tuning stage in the protein-protein contact prediction task, but other graph pre-training methods have.\n\n14\n\nUnder review as a conference paper at ICLR 2023\n\nTable 9: Comparison with different graph pre-training methods on DIPS-Plus test dataset.\n\nRow 1\n2 3\n4 5\n\nModel GeoTrans Morehead et al. (2022) GeoTrans + Mask Node Hu et al. (2020) GeoTrans + Mask Edge Hu et al. (2020) GeoTrans + PHD Li et al. (2021) GeoTrans + SMP\n\nP@ L/10 19.00 20.87 20.26 20.33 30.40\n\nP@ L/5 17.00 18.19 17.67 17.32 26.70\n\nP@ L/2 -\n14.62 14.31 14.50 20.51\n\nR@ L 15.00 17.46 16.37 16.51 24.00\n\nR@ L/2 9.00 9.88 10.47 10.75 16.02\n\nR@ L/5 4.00 4.87 5.16 5.34 8.56\n\nTable 10: Comparison with different protein language methods on DIPS-Plus test dataset.\n\nRow 1\n2 3\n4\n\nModel GeoTrans Morehead et al. (2022) ESM-1b Rives et al. (2021) ESM-MSA-1b Rao et al. (2021) GeoTrans + SMP\n\nP@ L/10 19.00 18.96 23.49 30.40\n\nP@ L/5 17.00 16.97 20.68 26.70\n\nP@ L/2 -\n14.26 16.86 20.51\n\nR@ L 15.00 12.85 14.73 24.00\n\nR@ L/2 9.00 8.44 9.71 16.02\n\nR@ L/5 4.00 3.98 4.89 8.56\n\nA.4 COMPARISON WITH DIFFERENT PROTEIN LANGUAGE MODELS\n\nThe large protein language model has the potential to learn prior biological knowledge from massive monomer sequences. We investigate large-scale protein language models ESM-1b Rives et al. (2021) and ESM-MSA-1b Rao et al. (2021) on DIPS-Plus test dataset as shown in Table 10. It demonstrates that SMP has higher accuracy than other pretrained protein language models for all metrics. Both ESM-1b (650M parameters) and ESM-MSA-1b (100M parameters) have much more parameters than our SMP (4.5M parameters), reflecting the effectiveness and light weight of our SMP. Since ESM-1b does not use any MSA and geometric information, its accuracy is lower than the baseline method GeoTrans. ESM-MSA-1b acquires a strong biological prior knowledge to get higher accuracy. The above experiments demonstrate that SMP splits the monomer into the pseudo multimer and pre-training the pseudo multimer could be more beneficial than using monomer pretraining directly.\n\n15",
  "translations": [
    "# Summary Of The Paper\n\nThe paper describes simple pre-training strategy for multi-mer contact prediction.  The strategy is shown to provide empirical benefit across several benchmark tasks.  However the paper does not compare to some of the most widely used methods for predicting contacts (AlphaFold and RosettaFold).\n\n# Strength And Weaknesses\n\nStrengths:\n* The chief benefit of the suggested approach is it's simplicity.\n* The comparison of the performance of GeoTrans with and without SMP is good ablation for checking the extent to which the method improves performance.\n\nWeaknesses:\n* Discussion of prior work.  RoseTTAFold2 is explicitly geared towards interaction prediction, as is AF2 Multimer.  While these methods are primarily built for structure prediction (rather than phrased as for contact prediction) they may easily used for contact prediction.  For example using the predicted alignment error (PAE) output by AF2.\n*  Predicted alignment error as been shown to be effective in predicting existence and strength of contacts in the context of binder design (Bennet et al. 2022).   For RosettaFold a simple option could be pLDDT at the interacting residues.\n* How does pre-training compare to relying on generalization from structure prediction with large (e.g. 384 residue crops), as in AlphaFold?\n* An empirical comparison to AF2 or RosettaFold is crucial.  I will not consider changing my score if a comparison is not to be added.\n\nIn some cases, it seems that the pre-training strategy does not help (in particular, in table 2 in some comparisons to GeoTrans).  Could the authors comment on the situations in which they expect the pre-training will have the largest / smallest improvements?\n\nNit:\n* Check for typos: e.g. suppresses —> surpasses?\n* What do you mean by “rich” information in the title?  Would be helpful to clarify this vague language in the main text or choose alternative phrasing.\n\nReferences:\nBennett, Nathaniel, et al. \"Improving de novo protein binder design with deep learning.\" bioRxiv (2022).\nBaek, Minkyung, et al. \"Accurate prediction of protein structures and interactions using a three-track neural network.\" Science 373.6557 (2021): 871-876.\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThe simple idea of the paper is clearly articulated.  Given the success of AlphaFold at predicting multimers it is not surprising that it works.\nHowever, I would not describe the idea as particularly novel, since AlphaFold is trained on monomers as well.\n\n# Summary Of The Review\n\nA clear explanation and empirical demonstration of simple idea, but with insufficient demonstration of the novelty and comparison + discussion of existing work (namely AlphaFold and RosettaFold).\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.\n\n# Empirical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
    "# Summary Of The Paper\nThe paper presents a novel pre-training method named Split and Merge Proxy (SMP) aimed at improving protein-protein contact prediction by exploiting abundant monomer data. The methodology involves splitting monomer sequences into two pseudo multimers and training a model to predict contact maps based on these splits. The experimental results demonstrate that SMP significantly outperforms existing state-of-the-art methods, achieving improvements of 11.40% and 2.97% on the P@ L/10 metric for the DIPS-Plus and CASP-CAPRI benchmarks, respectively, and exhibiting a 1.5 times performance enhancement on the more challenging DB5 benchmark.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to leveraging monomer data to address the data scarcity problem in multimer predictions, which is a significant issue in the field. The methodology is clearly delineated, with appropriate experimental validation demonstrating the effectiveness of SMP. However, a potential weakness is the lack of extensive comparison with a wider range of contemporary methods, which could strengthen the claims of superiority. Additionally, while the empirical results are promising, the paper does not fully address potential limitations or scenarios where SMP might underperform.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, making it easy to follow the proposed methodology and results. The quality of the experiments is high, and the results are presented with sufficient detail to allow for reproducibility. The novelty of the approach, particularly in the way monomer data is utilized for multimer prediction tasks, is a significant contribution to the field of protein structure prediction. However, further details on the implementation specifics could enhance reproducibility.\n\n# Summary Of The Review\nOverall, this paper presents a compelling approach to protein-protein contact prediction by effectively utilizing monomer data through the Split and Merge Proxy method. The results are robust and demonstrate significant improvements over existing methods, making a valuable contribution to the field. However, a broader comparative analysis could enhance the claims of the study's effectiveness.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to protein-protein contact prediction through the Split and Merge Proxy (SMP) methodology, which innovatively utilizes monomer data to generate pseudo multimers. This addresses the challenge of data scarcity in training deep learning models for accurate contact prediction. The SMP is structured in two stages: a split stage that divides monomer data into sub-parts to form pseudo multimers, and a merge stage that trains the model to predict contact maps based on these multimers. The authors report substantial performance improvements over the state-of-the-art model, GeoTrans, across multiple benchmark datasets, highlighting the robustness and potential generalizability of their approach.\n\n# Strength And Weaknesses\nThe SMP method stands out due to its innovative use of readily available monomer data, effectively bridging the gap to multimer data, which is often limited. The significant performance enhancements observed in various benchmarks underscore the robustness of the approach. However, the method's reliance on existing monomer datasets could hinder its applicability if such resources are not comprehensive. Additionally, the introduction of pseudo multimers might introduce biological noise, potentially affecting performance at smaller data scales. Furthermore, while the architecture shows promise, its complexity may pose challenges in terms of computational resources and broader accessibility.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology and findings, making it accessible to readers. The extensive evaluation across multiple datasets and metrics enhances its quality and supports reproducibility. The novelty of the SMP in leveraging monomer data for contact prediction is evident, but the potential limitations regarding biological noise and reliance on monomer datasets could affect its general applicability in diverse biological contexts.\n\n# Summary Of The Review\nOverall, the paper presents a compelling advancement in protein-protein contact prediction through the innovative SMP approach. Its significant performance improvements across benchmarks suggest strong implications for computational biology, although the reliance on monomer data and model complexity warrant further consideration.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to protein-protein contact prediction through a method called Split and Merge Proxy (SMP). This method leverages abundant monomer data to create pseudo multimers, which are then used to pre-train a model to predict residue contacts. The authors demonstrate that SMP significantly improves prediction accuracy on established benchmarks, achieving 11.40% and 2.97% performance gains on DIPS-Plus and CASP-CAPRI datasets, respectively, and 1.5 times better results on the DB5 unbounded benchmark. This work highlights the potential of utilizing monomer data for enhancing multimer prediction tasks in computational biology.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to addressing the well-known issue of limited multimer data in protein contact prediction, as well as its clear demonstration of performance improvements across multiple benchmarks. The methodology is well-documented, with thorough experiments validating the effectiveness of the proposed SMP method. However, a notable weakness is the lack of comprehensive comparison with other state-of-the-art methods beyond GeoTrans, which might limit the generalizability of the findings. Additionally, while the ablation studies provide insights into the pre-training process, further exploration of the impacts of different hyperparameters could enhance understanding.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodology, making it accessible to readers with varying levels of expertise in computational biology. The quality of the writing is high, with appropriate use of technical terminology and detailed explanations of the methods and results. The novelty of the approach is significant, as it introduces a new way to leverage monomer data for multimer tasks. Reproducibility is supported by the detailed description of the experimental setup, datasets, and hyperparameters, although providing access to code or models would further enhance reproducibility.\n\n# Summary Of The Review\nOverall, this paper presents a compelling and innovative approach to protein-protein contact prediction that effectively utilizes monomer data to enhance model performance on multimer tasks. While the contributions are significant and well-supported by empirical results, a broader comparison with existing methods could strengthen the findings.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces the Split and Merger Proxy (SMP), a novel pre-training method designed to enhance protein-protein contact prediction by leveraging monomer data. The authors present a comprehensive methodology detailing how SMP integrates into existing contact prediction frameworks. Through extensive experiments across benchmarks such as DIPS-Plus, CASP-CAPRI, and DB5, the method demonstrates significant performance improvements, achieving state-of-the-art results, including an 11.40% enhancement in the P@L/10 metric.\n\n# Strength And Weaknesses\nThe paper contributes a novel approach to protein contact prediction, showcasing significant performance gains over existing models, which is a valuable advancement in computational biology. The extensive validation across multiple benchmarks adds credibility to the findings. However, the reliance on pseudo multimers derived from monomer data raises concerns about the method’s ability to fully capture the complexity of multimer interactions, limiting its applicability in real-world scenarios. Additionally, while the methodology is clearly articulated, some critical aspects, such as the handling of biological noise and the potential variability in model performance across different contexts, warrant further exploration.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clear, providing detailed explanations of the SMP methodology. However, the discussion around certain limitations, particularly regarding biological noise and the representativeness of the training data, could be enhanced. The novelty of the SMP method is notable, but the reproducibility of results across diverse datasets remains uncertain, which could affect the overall impact of the work.\n\n# Summary Of The Review\nOverall, this paper presents a significant advancement in protein-protein contact prediction through the innovative SMP approach. While the methodology and results are promising, concerns regarding data representativeness and the generalization of findings highlight areas for further investigation.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces the \"Split and Merge Proxy\" (SMP) method for protein-protein contact prediction, addressing the issue of limited multimer data in computational biology. The main contributions include an innovative pre-training strategy that creates pseudo multimers from monomer data, enhancing model initialization for contact prediction tasks. The methodology demonstrates significant performance improvements on established benchmarks, achieving state-of-the-art results, particularly on the DIPS-Plus and CASP-CAPRI datasets.\n\n# Strength And Weaknesses\nStrengths of the paper include its novel approach to leveraging abundant monomer data and the effective design of the proxy task that bridges the gap between monomer and multimer data. The performance gains reported are compelling and suggest that the method is both robust and practical for real-world applications. However, the paper could benefit from a more in-depth discussion of potential limitations, such as the generalizability of the SMP method to other domains within computational biology or the computational costs associated with the proposed pre-training phase.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its methodology, contributions, and findings. The experiments are rigorously designed, with detailed comparisons to state-of-the-art methods. The reproducibility of the results could be enhanced through the inclusion of code and datasets used in the experiments. While the novelty of the SMP approach is evident, further exploration of its applicability to other contexts would strengthen the overall impact of the work.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in protein-protein contact prediction through its innovative use of monomer data and the introduction of the SMP methodology. The empirical results are impressive and establish a new benchmark, although there is room for improvement in discussing limitations and enhancing reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper introduces the Split and Merge Proxy (SMP) method, aimed at enhancing adversarial training for deep learning models by leveraging simpler datasets. The methodology involves generating pseudo adversarial examples from easily accessible data, creating a proxy task for model pre-training, and subsequently fine-tuning the model on actual adversarial examples. The empirical results demonstrate substantial performance improvements—up to 11.40% higher accuracy—compared to traditional adversarial training techniques, validating the effectiveness and robustness of the proposed approach across various adversarial scenarios.\n\n# Strength And Weaknesses\nStrengths of the paper include the innovative use of simpler datasets to address the challenges of adversarial training, which typically requires extensive labeled datasets. The proposed SMP method effectively bridges the gap between simpler and complex data, providing a novel pre-training strategy. However, the paper could strengthen its empirical foundation by including more diverse datasets and adversarial attack scenarios to further validate the generalizability of the findings. Additionally, while the results are promising, the practical implications of the method in real-world applications could be elaborated upon.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its methodology and findings. The quality of the presentation is high, with a logical flow that guides the reader through the proposed method and its validation. The novelty of the SMP method is significant, especially in the context of adversarial training in deep learning. However, reproducibility could be enhanced by providing more detailed descriptions of experimental setups, including hyperparameters and specific datasets used.\n\n# Summary Of The Review\nOverall, this paper presents a compelling and innovative approach to adversarial training through the Split and Merge Proxy method. The significant performance improvements shown in the experiments indicate strong potential for practical applications, although further exploration of the method's adaptability is warranted.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper introduces the Split and Merge Proxy (SMP), a novel approach aimed at enhancing protein-protein contact prediction by utilizing existing monomer data to tackle the prevalent issue of data scarcity in multimer contexts. The methodology involves a pre-training technique that generates pseudo multimers from monomer data, which is claimed to significantly improve performance metrics over existing state-of-the-art methods. The authors assert that their approach not only addresses critical limitations in the field but also sets a new standard for protein contact prediction, implying a transformative impact on related areas such as drug development and protein design.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its attempt to innovate within a challenging domain, addressing the critical issue of data scarcity for protein-protein interactions. The proposed SMP method is an interesting approach to leverage monomer data, potentially offering a more accessible means for researchers in the field. However, the paper suffers from several weaknesses, including an overstatement of the method's novelty and effectiveness. The authors claim that SMP is a revolutionary advance that renders previous methods obsolete, which is not convincingly substantiated by the results presented. Additionally, the framing of the findings suggests an exclusivity that may deter future exploration and improvements in the area.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper communicates its main ideas clearly, the claims made about the SMP method's novelty and impact are exaggerated. The quality of the work appears solid, yet the implications drawn from the results could mislead the research community regarding the definitive nature of the proposed method. Reproducibility is not adequately addressed, as the experimental setup and datasets used lack sufficient detail, making it challenging for others to replicate the findings.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to protein-protein contact prediction through the SMP method; however, it significantly overstates its contributions and implications. While the methodology may provide valuable insights, the exaggerated claims detract from the credibility of the work and its potential impact on the field.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents the Split and Merge Proxy (SMP), a novel approach for protein-protein contact prediction that utilizes monomer data to address the data scarcity typically associated with training deep learning models for this task. The methodology involves generating pseudo multimers from monomer sequences and training models to predict contact relationships between residues. The findings demonstrate significant performance improvements over existing state-of-the-art methods, with notable gains of 8.30% and 1.97% on the DIPS-Plus and CASP-CAPRI benchmarks, respectively, as well as a marked performance increase on the unbounded DB5 benchmark.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to bridging the gap between monomer and multimer prediction tasks, effectively leveraging existing monomer data to enhance performance in contact prediction. The experimental results are compelling, showcasing clear advantages over previous methods, particularly in scenarios where multimer data is limited. However, the paper could benefit from a more detailed discussion of the limitations of the SMP approach and potential areas for future work, such as the scalability of the method to larger datasets or its application to different protein classes.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and results, making it accessible to readers. The quality of the experiments is high, with thorough evaluations and ablation studies that validate the proposed method's effectiveness. The novelty of the SMP approach is significant, as it introduces a new way to predict protein-protein contacts using available monomer data. Reproducibility is supported by detailed descriptions of datasets and methodologies, although the inclusion of code or models for direct replication would further enhance this aspect.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to protein-protein contact prediction by introducing the SMP method, which effectively utilizes monomer data to achieve substantial performance improvements. The clarity and quality of the work are commendable, though further exploration of limitations and scalability could strengthen the paper.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces a method for predicting protein-protein contacts using monomer data to generate pseudo multimers. The authors claim that their approach effectively reduces the task gap between proxy tasks and target tasks in contact prediction. They leverage existing monomer datasets to address the scarcity of multimer data, asserting that the additional biological noise present in pseudo multimers can enhance model learning. The findings suggest significant performance improvements over state-of-the-art methods, although the implications of these results warrant further scrutiny.\n\n# Strength And Weaknesses\nThe paper presents several strengths, including a novel approach to utilizing monomer data in the context of multimer interactions and the achievement of notable performance metrics. However, it also has substantial weaknesses. For instance, it relies heavily on the assumption that monomer-derived pseudo multimers are representative of true biological interactions, which is not validated experimentally. Furthermore, the lack of a thorough analysis regarding biological noise, generalization across datasets, and the limitations of performance metrics raises concerns about the robustness and applicability of the proposed method. The failure to critically engage with baseline comparisons and the assumption of model simplicity pose additional weaknesses.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is generally acceptable, although some concepts could benefit from deeper elaboration, particularly regarding the task gap and the implications of biological noise. The quality of the methodology is variable, as it lacks empirical validation for several key assumptions. In terms of novelty, the approach contributes a new perspective to the protein contact prediction field; however, the reliance on monomer data without addressing its limitations diminishes its impact. Reproducibility is also called into question due to the absence of a detailed exploration of how increased data volume affects model performance and the lack of a rigorous discussion regarding model transferability.\n\n# Summary Of The Review\nOverall, the paper presents an interesting approach to protein-protein contact prediction by leveraging monomer data, but it is marred by significant assumptions that are not thoroughly validated. While the reported performance improvements are notable, the lack of critical engagement with limitations and comparative baselines raises concerns about the robustness of the findings.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel approach to protein-protein contact prediction by introducing the Split and Merger Proxy (SMP) pre-training method, aimed at overcoming the limitations posed by scarce training data. The methodology involves a two-step process where pseudo multimers are generated from monomer data, followed by a training phase that aligns the proxy task with the final prediction task. The findings demonstrate that SMP significantly improves performance on multiple benchmarks (DIPS-Plus, CASP-CAPRI, DB5) compared to existing state-of-the-art methods, particularly in challenging prediction scenarios.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its innovative approach to leveraging monomer data for enhancing multimer predictions, effectively addressing the data scarcity issue in protein-protein interactions. The rigorous experimental validation across multiple benchmarks showcases the robustness and effectiveness of the proposed method. However, a potential weakness lies in the limited exploration of the underlying mechanisms of the SMP method, which could be further elaborated to provide deeper insights into why this approach yields superior results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its content with clarity, making it accessible to both specialists and generalists in computational biology. The quality of the writing is high, with clear explanations of methodologies and results. The novelty of the SMP method is notable, as it fills a critical gap in the application of pre-training techniques for protein-protein contact prediction. As for reproducibility, the paper provides sufficient details regarding experimental setups and metrics, although it would benefit from sharing code or datasets to facilitate further validation by the community.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of protein-protein contact prediction by introducing the SMP pre-training method, which effectively utilizes monomer data to enhance prediction accuracy. The experimental results validate the approach, although further exploration of the underlying mechanisms could strengthen the findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel framework designed to enhance model performance by effectively utilizing underutilized data sources in machine learning. The authors propose a unique methodology that improves the pre-training process, addressing critical limitations of existing approaches. Through comprehensive experiments, the findings indicate that their method yields superior performance on various downstream tasks, showcasing its potential to bridge gaps in the current literature.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its well-articulated motivation, which tackles a significant challenge within the field of machine learning. The proposed method presents a conceptually sound approach with a clear rationale for its techniques, appealing to a broad audience. However, the paper exhibits weaknesses in empirical validation, as the experimental scope appears limited, and the results could benefit from more rigorous statistical analysis. Additionally, the discussion of related work could be more robust to better contextualize the contributions within the existing body of literature.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear in its presentation, with a logical flow of ideas. The quality of the writing is solid, though some technical details could be elaborated further to enhance understanding. The novelty of the approach is noteworthy, as it offers a fresh perspective on leveraging data. However, reproducibility could be improved by providing more detailed descriptions of the experimental setup and the datasets used.\n\n# Summary Of The Review\nOverall, the paper presents a promising contribution to machine learning, with an innovative approach that could influence future research. While the methodology shows great potential, enhancing empirical validation and situating the work more thoroughly within the existing literature would strengthen its impact. With revisions addressing these areas, the paper could make a significant addition to the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces the Split and Merge Proxy (SMP) method, which aims to enhance protein-protein contact prediction by utilizing monomer data to create a proxy task for model pre-training. SMP addresses the challenge of limited training data for multimer protein structures by splitting monomer datasets into pseudo multimers and training a model to predict their contacts. The findings indicate that models pre-trained with this method achieve significant performance improvements, surpassing state-of-the-art techniques across various benchmarks.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to leveraging monomer data to improve multimer predictions, which is a critical challenge in the field of computational biology. The methodology is well-conceived, effectively addressing the data scarcity issue, and the experimental results demonstrate a clear advancement in predictive performance. However, the paper could strengthen its contribution by providing more extensive comparisons with existing methods beyond state-of-the-art benchmarks and discussing potential limitations of the SMP approach, particularly regarding its generalizability to diverse protein types and structures.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written, with a logical flow from the introduction of the problem to the presentation of the methodology and results. The quality of the writing is high, making complex ideas accessible. The novelty of the SMP approach is significant, as it introduces a new pre-training strategy that could have implications beyond protein contact prediction. However, reproducibility could be enhanced by providing additional details on the experimental setup, including the datasets used and specific hyperparameters for the models.\n\n# Summary Of The Review\nOverall, the paper presents a novel and effective method for improving protein-protein contact prediction by utilizing monomer data. While the contributions are significant and the methodology is sound, further elaboration on experimental details and comparisons with existing models would bolster the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents the Split and Merge Proxy (SMP) methodology for pre-training models in the task of protein-protein contact prediction, aiming to mitigate the challenges posed by the scarcity of multimer training data. The SMP approach utilizes monomer data to create pseudo multimers, facilitating enhanced training and ultimately leading to improved prediction performance. The authors demonstrate that their method significantly outperforms existing state-of-the-art techniques across several benchmark datasets, including DIPS-Plus, CASP-CAPRI, and DB5, indicating its robustness and effectiveness in various protein contact prediction tasks.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative use of monomer data to enhance prediction capabilities for protein contacts, addressing a critical gap in the current methodologies that rely heavily on limited multimer datasets. The SMP methodology is well-defined and demonstrates clear and significant improvements in model performance across different benchmarks. However, a potential weakness is that while the results are promising, the paper could benefit from a more detailed analysis of the limitations of the SMP approach and its applicability to other types of protein interactions beyond the studied benchmarks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and experimental results. The quality of the writing is high, making complex ideas accessible to the audience. The novelty of the SMP approach is notable, as it introduces a new way to leverage monomer data for protein-protein contact prediction. However, reproducibility could be a concern if the specifics of the implementation details and data processing steps are not sufficiently elaborated for other researchers to replicate the experiments.\n\n# Summary Of The Review\nOverall, this paper presents a significant advancement in protein-protein contact prediction by introducing the SMP methodology, which effectively utilizes monomer data to improve training outcomes. The empirical results strongly support the proposed method's efficacy, although further exploration of its limitations and broader applicability would enhance the paper's impact.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper proposes a novel method for protein-protein contact prediction called Split and Merge Proxy (SMP). This method addresses the challenge of limited training data by leveraging existing monomer data to create pseudo multimers, thereby enhancing the training process. The experimental results indicate that SMP significantly improves performance metrics compared to state-of-the-art methods on several benchmark datasets, including DIPS-Plus, CASP-CAPRI, and DB5. The authors provide detailed ablation studies and visualizations to support their claims.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to utilizing monomer data, which is a common limitation in the field of protein-protein contact prediction. The methodology is well-structured, with clear definitions of the split and merge stages of the SMP framework. The experimental validation demonstrates meaningful performance enhancements, suggesting that the proposed method can fill a critical gap in the current research landscape. However, the paper could benefit from additional discussions on the limitations of the SMP approach, as well as a more thorough exploration of potential biases in the datasets used.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and logically organized, making it easy to follow the authors' arguments and methodology. The quality of the figures and tables is good, providing a clear representation of the results. The novelty of the method is apparent, as it introduces a unique approach to harnessing monomer data for improving contact predictions. However, the reproducibility could be enhanced by including more detailed information regarding the implementation, hyperparameter choices, and specific data preprocessing steps.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and novel method for protein-protein contact prediction that effectively addresses data limitations in the field. While the results are promising, further discussion of potential limitations and enhanced details on reproducibility would strengthen the contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel methodology termed Split and Merge Proxy (SMP) for pre-training protein-protein contact prediction (PPCP) by leveraging monomer data. The SMP framework bifurcates monomeric sequences into pseudo multimers and trains a predictive model to reconstruct contact prediction matrices. Empirical results indicate significant performance improvements, with the SMP approach outperforming existing state-of-the-art models by 11.40% and 2.97% on the DIPS-Plus and CASP-CAPRI benchmarks, respectively, while achieving a multiplicative performance factor of 1.5 on the unbounded benchmark DB5.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to address the limitations of current PPCP methodologies, primarily the scarcity of multimer datasets. By effectively utilizing monomer data, the authors provide a compelling solution that bridges a critical gap in the field. The methodology is well-defined, and the results are robust, demonstrating significant advancements in predictive accuracy. However, a potential weakness is the reliance on monomer data, which may not capture all aspects of protein interactions present in actual multimers. Additionally, while the empirical results are promising, the paper could benefit from a more in-depth exploration of the underlying reasons for the observed performance gains.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions, methodology, and results. The clarity of the explanation regarding the SMP process and empirical validation enhances its accessibility to readers. The novelty of the SMP approach is evident, particularly in its application of monomer data for multimer prediction tasks. The reproducibility of the results is supported by detailed descriptions of the experimental protocols and datasets used, although additional implementation details could further enhance reproducibility.\n\n# Summary Of The Review\nOverall, the paper introduces a novel and effective approach to protein-protein contact prediction through the innovative use of monomer data. The empirical results demonstrate significant improvements over existing methods, although further exploration of the implications and limitations of the approach would strengthen the contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper proposes a novel method called Split and Merger Proxy (SMP) aimed at improving protein-protein contact prediction. The methodology involves training models using monomer data to supplement multimer data and incorporates a split-and-merge strategy. The authors claim that their approach achieves performance gains over existing state-of-the-art methods, specifically citing benchmarks such as DIPS-Plus, CASP-CAPRI, and DB5. However, the approach faces criticism regarding its innovative depth and the validity of its assumptions.\n\n# Strength And Weaknesses\nThe main contribution of the paper lies in its attempt to address protein-protein contact prediction, an important problem in computational biology. However, the lack of innovative depth is a significant weakness, as the SMP method appears to adapt existing concepts rather than introduce truly novel techniques. The reliance on monomer data raises concerns regarding the validity of the pseudo multimer approach, potentially reducing the method's applicability. The performance improvements reported may not hold under broader scrutiny, as they rely on benchmarks with inherent limitations. Additionally, the methodology's simplicity and the potential for noise introduction, alongside the lack of engagement with existing critiques, further undermine the contributions of this work.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is compromised by vague implementation details and arbitrary hyperparameter choices, which raises questions about the reproducibility of the results. While the method is presented clearly, the lack of thorough explanation regarding the implications of using pseudo multimers and the absence of an extensive ablation study detract from the overall quality. The novelty of the approach is limited, as it does not sufficiently differentiate itself from existing methods, and the empirical findings are not robustly supported by quantitative analysis.\n\n# Summary Of The Review\nOverall, the paper presents a method that lacks true innovation and fails to rigorously address fundamental issues in protein-protein contact prediction. While it attempts to report performance improvements over state-of-the-art methods, the findings are overstated and lack sufficient validation. Additional research and validation are necessary before the proposed method can be considered a significant advancement in the field.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper introduces the Split and Merge Proxy (SMP), a novel methodology for protein-protein contact prediction that innovatively utilizes existing monomer data to enhance training efficiency. By transforming monomer data into pseudo multimers, SMP significantly increases the available training data while mitigating the costs typically associated with capturing multimer structural information. The model achieves state-of-the-art performance, surpassing previous benchmarks by notable margins on the P@L/10 metric for the DIPS-Plus and CASP-CAPRI datasets, and showcases remarkable accuracy on the unbounded DB5 benchmark. The paper emphasizes the transformative impact of SMP on drug development and computational biology, alongside its potential for broader applications.\n\n# Strength And Weaknesses\nStrengths of the paper include its groundbreaking approach to data utilization, leading to substantial performance improvements and the promise of enhancing drug development processes. The seamless integration of pre-training and fine-tuning without a task gap is another significant advantage, ensuring that the model is effectively trained for its intended tasks. However, the paper could benefit from a more detailed discussion on the limitations of the SMP approach, as well as potential challenges when applying it to diverse biological contexts. Additionally, a thorough comparison with more existing methodologies could strengthen the claims made regarding performance improvements.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology and results, with detailed explanations of the SMP approach and its implications for protein-protein contact prediction. The quality of the experiments and the clarity of the presented results contribute to a comprehensive understanding of the work. The novelty of the SMP method is evident, particularly in its innovative use of monomer data. The authors’ promise to release the code, model, and pre-training data post-acceptance enhances reproducibility and encourages further research in this domain.\n\n# Summary Of The Review\nThe Split and Merge Proxy method presents a significant advancement in protein-protein contact prediction, demonstrating impressive performance gains while effectively utilizing existing monomer data. Its innovative approach, combined with the potential for broad applicability in computational biology, positions it as a transformative contribution to the field.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper introduces the Split and Merge Proxy (SMP) method for protein-protein contact prediction, addressing the challenge of data scarcity in multimer training datasets. The authors propose a novel approach that utilizes existing monomer data by creating pseudo multimers, thereby generating a relevant training task that enhances model performance. The findings suggest that this method effectively bridges the gap between pre-training on synthetic data and fine-tuning on actual contact prediction tasks, leading to improved predictions in complex protein interactions.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to leveraging monomer data to create pseudo multimers, which theoretically enhances the representational capacity of training datasets. The empirical results demonstrate a solid performance improvement in contact prediction tasks, validating the proposed methodology. However, a potential weakness lies in the limited exploration of the practical implementation and computational demands of the SMP framework, which may affect its applicability in real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and provides a clear explanation of the SMP methodology, making the theoretical concepts accessible. The quality of writing is high, with appropriate use of diagrams and examples to illustrate key points. In terms of novelty, the approach presents a significant advancement in the field, although further details on reproducibility, such as specific datasets and hyperparameter settings used during experiments, would strengthen the paper.\n\n# Summary Of The Review\nOverall, the SMP framework shows promise in addressing data limitations in protein-protein contact prediction by introducing an innovative method for utilizing monomer data. While the theoretical contributions are significant and the empirical results are encouraging, further exploration of the practical aspects of implementation is needed. \n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel pre-training method called Split and Merge Proxy (SMP) for predicting protein-protein contact interactions using monomer data. The methodology involves creating pseudo multimers from monomer data, where a graph-based model is trained to predict contact interactions based on 3D residue coordinates. The authors demonstrate that SMP generates a significantly larger dataset of pseudo multimers (22,589) compared to existing multimer datasets, leading to improved performance over state-of-the-art methods in various benchmarks such as DIPS-Plus, CASP-CAPRI, and DB5. The results show strong generalization capabilities, particularly with increased pre-training data.\n\n# Strength And Weaknesses\nStrengths of the paper include the innovative approach of utilizing monomer data to create pseudo multimers, which enhances the available training data for contact prediction. The graph-based architecture and the use of advanced techniques such as batch normalization and squeeze-and-excitation mechanisms add robustness to the model. Furthermore, comprehensive evaluations, including ablation studies and visualization of predictions, provide strong evidence of the method's effectiveness. A potential weakness is the reliance on the quality of the initial monomer dataset, as filtering and selection criteria could impact the diversity and representativeness of the training examples.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology, implementation details, and findings. The use of standard evaluation metrics aids in understanding the comparative performance of SMP against existing methods. The authors commit to releasing the code, model, and pre-training data post-acceptance, which supports reproducibility. However, the paper could benefit from more detailed discussions on the implications of the hyperparameter choices and their impact on model performance.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of protein-protein contact prediction through the innovative SMP method, demonstrating substantial improvements over existing techniques. The approach is well-supported by empirical evidence and thorough evaluations, though some aspects related to data quality and hyperparameter choices could be further elaborated.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper introduces the Split and Merge Proxy (SMP) as a pre-training method for protein-protein contact prediction. The authors claim that SMP effectively bridges the gap between monomer and multimer data, resulting in significant performance improvements over state-of-the-art methods such as GeoTrans. However, the paper does not provide adequate justification for these claims, as it lacks a thorough comparison with existing methodologies and does not acknowledge the context of the benchmark results.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its proposed method, SMP, which aims to enhance protein-protein contact prediction by leveraging monomer data. Nonetheless, the paper's weaknesses are pronounced; it fails to recognize prior contributions in the field, particularly those from models like ComplexContact and DeepInteract, which also address similar challenges. Furthermore, the comparisons drawn between SMP and models such as AlphaFold2 are misleading due to their differing purposes and training datasets. The paper's claims of performance improvements are overstated and do not sufficiently account for alternative explanations, diminishing the credibility of the results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is undermined by a lack of transparency in the methodology and results. The authors do not adequately discuss the experimental setup or provide sufficient comparisons with other methods under equivalent conditions, raising questions about reproducibility. The novelty of SMP is questionable, as the paper overlooks previous works that have also integrated monomer data into multimer tasks, thus failing to convincingly establish its significance within the broader research landscape.\n\n# Summary Of The Review\nWhile the SMP method presents certain enhancements for protein-protein contact prediction, the paper does not convincingly demonstrate that these advancements are fundamentally superior to existing methodologies. The lack of thorough comparisons and acknowledgment of prior work diminishes the overall impact of the contributions made.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper titled \"SPLIT AND MERGE PROXY: PRE-TRAINING PROTEIN PROTEIN CONTACT PREDICTION BY MINING RICH INFORMATION FROM MONOMER DATA\" proposes a novel method called Split and Merge Proxy (SMP) for protein-protein contact prediction. The methodology leverages both monomer and multimer data to enhance prediction accuracy, addressing a gap in existing models that primarily utilize monomer data. The findings indicate significant performance improvements, with reported enhancements of 11.40% and 2.97% on the P@L/10 metric, although clarification on whether these metrics pertain to the same or different datasets is needed.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to utilizing monomer data in conjunction with multimer data, which could potentially lead to advancements in protein contact prediction accuracy. However, there are weaknesses in clarity and consistency throughout the document, including terminological inconsistencies and grammatical issues that could hinder comprehension. Additionally, the methodology could benefit from a more detailed explanation of certain terms, such as \"pseudo multimer,\" which lacks clear definition in the context of the study.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a novel approach, several clarity issues detract from its overall quality. Inconsistencies in terminology (e.g., \"monomer data\" vs. \"multimer data\") and formatting errors (such as citation inconsistencies) may confuse readers. The reproducibility of the findings could be improved by providing clearer definitions, consistent formatting, and adequately detailed methodological descriptions, particularly regarding the datasets used in the experiments.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to protein contact prediction through the innovative use of monomer and multimer data. However, significant clarity and consistency issues need to be addressed to enhance the understanding and reproducibility of the proposed method. Improvements in the paper's presentation and detailed explanations of key concepts would strengthen its contributions to the field.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper addresses the challenge of predicting protein-protein contacts in multimeric proteins, particularly focusing on the limitations posed by the availability of training data. The authors propose a novel method called Split and Merger Proxy (SMP), which leverages monomer data to enhance prediction capabilities. Their findings demonstrate that SMP significantly improves contact prediction performance on established benchmarks such as DIPS-Plus, CASP-CAPRI, and DB5. However, the paper does not explore broader implications or potential applications of the proposed method beyond contact prediction.\n\n# Strength And Weaknesses\nThe SMP method presents a valuable contribution to the field of protein-protein interaction prediction by addressing a significant gap in training data. The experimental validation of the method shows promising results, indicating its potential effectiveness. However, the paper has notable weaknesses, including a lack of exploration of alternative data augmentation strategies, insufficient discussion on the impact of biological prior knowledge, and a narrow focus on binary classification for contact prediction. Additionally, the paper could benefit from a more comprehensive evaluation of the method's performance across diverse datasets and potential noise in monomer data.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, though some sections could benefit from more detailed discussions, particularly regarding noise in monomer data and the implications of using pseudo multimers. The novelty of the proposed method is significant; however, the reproducibility could be enhanced by providing further insight into the methodologies for filtering and preprocessing data. The potential for future work and integration with other machine learning paradigms is mentioned, but not sufficiently elaborated upon.\n\n# Summary Of The Review\nOverall, the paper presents a promising method for protein-protein contact prediction with notable empirical improvements. However, it lacks depth in discussing the broader applicability of the method, potential noise in training data, and the implications of its use. Addressing these weaknesses could strengthen the paper's impact on the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents the Split and Merge Proxy (SMP) methodology aimed at enhancing protein-protein contact prediction. The authors define contact prediction as a binary classification problem, employing precision and recall metrics to evaluate performance. They demonstrate significant improvements on established benchmarks, achieving a 11.40% increase on the P@L/10 metric for the DIPS-Plus dataset and a 2.97% increase for CASP-CAPRI. Additionally, SMP shows over 1.5 times performance superiority on the unbounded DB5 benchmark when compared to state-of-the-art methods. The methodology is validated through extensive experimentation, ablation studies, and visualizations of the predictive performance.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its rigorous statistical analysis and comprehensive benchmarking against existing methods, showcasing the effectiveness of SMP. The use of multiple datasets (DIPS-Plus, CASP-CAPRI, and DB5) strengthens the validation of the proposed model. However, the paper could improve by providing more explicit statistical significance testing results rather than relying on implicit evaluations. Furthermore, while the findings are promising, the implications of the results in practical applications are not discussed in depth, which could enhance the paper's impact.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodology and results with clarity. The use of tables and figures aids in the comprehension of numerical results and comparisons. The methodology is described sufficiently to allow for reproducibility, although more detail on the implementation of the SMP approach could enhance this aspect. The novelty of the SMP method is apparent, although it is vital to contextualize its contributions within the broader landscape of protein contact prediction methods.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in protein-protein contact prediction through the Split and Merge Proxy methodology, demonstrating substantial performance improvements on benchmark datasets. While the statistical analysis is strong, providing clearer significance testing and discussing practical implications could enhance the paper's contributions.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel approach to protein-protein contact prediction, introducing a method termed SMP (Structured Monomer Prediction). The authors claim that this method leverages existing monomer data to enhance the accuracy of contact predictions. The findings indicate that SMP outperforms some baseline methods in specific datasets, suggesting its potential utility in biological applications.\n\n# Strength And Weaknesses\nWhile the paper contributes to the field of protein contact prediction and introduces a potentially effective approach, several weaknesses are evident. Notably, the paper fails to address the inherent biological noise present in pseudo multimer data, which could significantly impact the reliability of contact predictions. Furthermore, there is no exploration of data quality's influence on model performance, raising concerns about the robustness of SMP across varying quality levels of monomer data. The method's applicability is also limited, as it is explicitly focused on protein-protein interactions without consideration for generalizability to other biological tasks. The lack of discussion regarding computational efficiency and model interpretability presents additional limitations, as these aspects are crucial for practical implementation. Lastly, the paper does not propose systematic hyperparameter tuning strategies or address scalability issues with larger datasets.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and written, providing clarity in its methodology and findings. However, the novelty of the proposed method is somewhat constrained by its limited applicability and the lack of comprehensive exploration of its implications. Reproducibility may be hindered due to the absence of detailed guidance on hyperparameter tuning and the reliance on specific monomer data, which may not be universally available.\n\n# Summary Of The Review\nThe paper introduces the SMP method for protein-protein contact prediction, offering some promising results, but it is hampered by significant limitations in addressing biological noise, data quality, and model interpretability. Future research will be essential to validate SMP's effectiveness across diverse datasets and improve its applicability in real-world scenarios.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper presents a method called \"Split and Merge Proxy\" (SMP) for enhancing protein-protein contact prediction by utilizing monomer data to address the limitations of multimer prediction. The authors propose a methodology that involves splitting monomer data into two segments to create a \"pseudo multimer,\" predicting contacts, and subsequently merging these back together. They report improvements over state-of-the-art models, claiming enhancements of 11.40% and 2.97% in accuracy.\n\n# Strength And Weaknesses\nWhile the paper aims to address a key issue in protein contact prediction, its contributions appear to lack originality, as the methodology largely rehashes established ideas in the field. The proposed method of utilizing monomer data is not novel, and the authors fail to provide sufficient justification for the significance of their experimental results. Although the reported improvements in metrics may catch attention, they do not convincingly demonstrate a substantial advancement over existing methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written, with well-structured sections and understandable diagrams. However, the novelty of the approach is questionable, as it does not introduce significant new ideas or methods. The reproducibility of their results may be hampered by the small dataset used for testing, which raises concerns regarding the generalizability of the findings. \n\n# Summary Of The Review\nIn summary, while the paper presents a clear methodology for protein contact prediction, it lacks significant novelty and fails to convincingly demonstrate its contributions to the field. The results, though presented positively, do not substantiate a meaningful advancement over existing approaches.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper introduces a novel method, referred to as SMP, that enhances multimer contact prediction by integrating additional monomer data. The authors develop a proxy task to facilitate pre-training and emphasize the importance of bridging task gaps between pre-training and fine-tuning stages. Through extensive experiments, they demonstrate that their approach leads to improved performance in contact prediction across various protein complexes, highlighting the potential for cross-domain applicability and the importance of data volume in model training.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative integration of supplementary biological data, which addresses the common challenge of data scarcity in computational biology. The introduction of a proxy task is a compelling aspect that could foster further research into similar strategies across different biological domains. However, the paper lacks a comprehensive evaluation of performance metrics, as it primarily focuses on top-k precision and recall, which may not capture the full spectrum of model performance. Additionally, while the results suggest promising generalizability, the exploration of alternative model architectures could have been more thoroughly discussed.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible to readers. The methodology is described in sufficient detail to allow for reproducibility, although more rigorous benchmarking against established methods would enhance its credibility. The novelty of the approach, particularly the proxy task concept, is significant; however, the paper could benefit from a deeper exploration of the implications of its findings for broader biological applications.\n\n# Summary Of The Review\nOverall, the paper presents a compelling approach to improving multimer contact prediction through innovative data integration and task mitigation strategies. While it offers valuable insights and potential avenues for future research, the evaluation metrics employed and the discussion on alternative methodologies could be expanded to strengthen the paper's overall impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel methodology for protein-protein contact prediction, specifically through the integration of GeoTrans and a new framework termed SMP (pseudo multimers). The authors present compelling results, demonstrating significant improvements over the existing state-of-the-art model, GeoTrans, across various benchmarks, including DIPS-Plus and CASP-CAPRI. The proposed method achieves up to 11.40% improvement on the P@ L/10 metric in DIPS-Plus and shows robust performance with a P@ L/10 score of 32.00% in CASP-CAPRI, underscoring its effectiveness in predicting contacts for both homologous and heterologous protein complexes.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its empirical results, which consistently show the proposed model outperforming existing benchmarks across various datasets and metrics, thus highlighting its practical applicability in predicting protein interactions. The inclusion of ablation studies further strengthens the findings by providing insights into the contributions of the SMP method. However, a potential weakness is the lack of detailed explanations of the underlying principles of SMP, which could hinder the reproducibility of the results for practitioners.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with clear presentation of methodologies and results. The quality of the data and experiments is high, contributing to the strength of the findings. The technical novelty of the proposed method is notable, particularly in its approach to leveraging monomer data through pseudo multimers. Nonetheless, the lack of detailed methodological transparency may affect the reproducibility of the findings, which is a crucial aspect in computational biology research.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in protein-protein contact prediction through a novel methodology that shows impressive empirical results across multiple benchmarks. While the findings are robust and the methodology promising, the paper could benefit from greater clarity regarding the implementation to enhance reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThis paper presents a novel approach to protein-protein contact prediction by leveraging monomer data for pre-training, with a focus on enhancing the accuracy of contact predictions in protein structures. The authors introduce a new proxy task, referred to as the SMP (Structure-Motivated Prediction), which aims to improve the model's understanding of protein interactions. The findings demonstrate that their method outperforms existing techniques, showing promise in addressing challenges associated with protein contact predictions.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative use of monomer data, which has been underexplored in this context, providing a fresh perspective on protein contact prediction. The proposed SMP task effectively bridges a gap in existing methodologies and demonstrates measurable improvements in predictive performance. However, the paper suffers from several weaknesses, including a lack of clarity in terminology and an overly complex writing style that could alienate readers outside the immediate field. Additionally, the repetitive nature of some arguments detracts from the overall impact of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper introduces a novel concept, the clarity of its presentation is hindered by technical jargon and complex sentence structures. The methodology is well-defined, but terms like \"proxy task\" and \"pseudo multimer\" could benefit from clearer definitions. The reproducibility of the results is plausible, as the authors provide details on their experimental setup, but improved clarity and organization would enhance the paper's overall quality.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to the field of protein contact prediction through an innovative approach utilizing monomer data. However, improvements in clarity, organization, and the simplification of technical terms are necessary to make the findings more accessible to a broader audience.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.5020480047005105,
    -1.69731749206459,
    -1.956404831182533,
    -1.6711387615912725,
    -1.9572844987248055,
    -1.655344640510405,
    -1.6613055954218618,
    -1.9028234169112168,
    -1.6578491368788542,
    -1.9244440953033433,
    -1.6749746988037753,
    -1.6239797089333925,
    -1.569772208227091,
    -1.560355845883142,
    -1.572459345798976,
    -1.7189312447696805,
    -1.962199973060347,
    -1.9188894603409175,
    -1.8325596580325703,
    -1.804858982323887,
    -1.9355906497766688,
    -1.7409260328315295,
    -1.856084668853489,
    -1.8811563547817307,
    -1.762750859689278,
    -1.9888320461211784,
    -1.8552275775977574,
    -1.822928720263391,
    -1.696289604003783
  ],
  "logp_cond": [
    [
      0.0,
      -2.2898027160929293,
      -2.285700496492718,
      -2.253829584353041,
      -2.290277509262721,
      -2.2890421113872774,
      -2.3666424942859634,
      -2.2983723142078563,
      -2.301122271627822,
      -2.3183755498333745,
      -2.3034546596843373,
      -2.3746914385501516,
      -2.2906483636999617,
      -2.2864276407645607,
      -2.3158484530991417,
      -2.304170458427824,
      -2.311789845495919,
      -2.2968256399188514,
      -2.315237508039065,
      -2.287299177067498,
      -2.2613437158996783,
      -2.296463297112014,
      -2.3124782430762014,
      -2.3364912491687995,
      -2.328127815725983,
      -2.3236313304156346,
      -2.2939492968340756,
      -2.2928974204280053,
      -2.3136774328705214
    ],
    [
      -1.337534112754144,
      0.0,
      -1.2617681452961553,
      -1.0508061127305948,
      -1.1634432001716013,
      -1.2045834932121664,
      -1.3241217468979312,
      -1.2383456922177174,
      -1.1318485588149287,
      -1.2879288244745284,
      -1.1512390745714827,
      -1.3870704671703995,
      -1.270694507371691,
      -1.1244407407450492,
      -1.1938871151365449,
      -1.0692254912454568,
      -1.1778405925068494,
      -1.1593408516214194,
      -1.276244839133385,
      -1.1969085891558875,
      -1.2571489294288924,
      -1.150490906546928,
      -1.1951941101416959,
      -1.1169069298962833,
      -1.3307391608932664,
      -1.1648993874439162,
      -1.3104437971319318,
      -1.2000791301280274,
      -1.3061776240587766
    ],
    [
      -1.5895426731859452,
      -1.5102372284419687,
      0.0,
      -1.4170688479374178,
      -1.4483086651600063,
      -1.4769859674497523,
      -1.6061703433914043,
      -1.4864316882329818,
      -1.4525828549590303,
      -1.493617002289585,
      -1.481598326101103,
      -1.683008152570763,
      -1.5017297665535554,
      -1.4685411867386902,
      -1.5024299573516617,
      -1.4814380811326358,
      -1.5006943718700947,
      -1.4805387791042766,
      -1.5187655546843712,
      -1.4792348371494224,
      -1.493530447558254,
      -1.5118627425185804,
      -1.5174742185763892,
      -1.5379952588974026,
      -1.5461476094468185,
      -1.485407738572667,
      -1.5311016697212787,
      -1.5048121987288015,
      -1.5757809371011533
    ],
    [
      -1.2789424088917458,
      -1.0801070046464778,
      -1.2001065466636929,
      0.0,
      -1.1580694934332667,
      -1.1583513860099897,
      -1.2853189389178294,
      -1.219057765511803,
      -1.0953071331394786,
      -1.2722521042428772,
      -1.1555711157985533,
      -1.3666112357357556,
      -1.2340662273430694,
      -1.1517619720778682,
      -1.179431568159416,
      -1.046808829045854,
      -1.169825630809622,
      -1.1674000929792747,
      -1.2502359993548546,
      -1.1873254133817515,
      -1.212502396500935,
      -1.210615401414046,
      -1.206507248943283,
      -1.1110209482381035,
      -1.3324608281646975,
      -1.2102598855901792,
      -1.2857933947387288,
      -1.1533270464585978,
      -1.284893945368209
    ],
    [
      -1.5506204248112503,
      -1.335806141721545,
      -1.406848946141186,
      -1.3340468362424696,
      0.0,
      -1.415803730928298,
      -1.5757383563132878,
      -1.412341886522902,
      -1.4007092088256043,
      -1.4067637378669102,
      -1.383918561995689,
      -1.6694759489135658,
      -1.4597249743922474,
      -1.3903694089888943,
      -1.4239129250256384,
      -1.3390331579005164,
      -1.30750242576386,
      -1.3620083858507621,
      -1.487762795115811,
      -1.3854475947075524,
      -1.5060682207919238,
      -1.418971346971313,
      -1.326346911948915,
      -1.447943058514076,
      -1.4916800656563471,
      -1.4042470460085275,
      -1.505541147258514,
      -1.4475682993357402,
      -1.5503076649066572
    ],
    [
      -1.278212226097968,
      -1.0869350593271396,
      -1.11529724387947,
      -1.0562688512323262,
      -1.1220360330459567,
      0.0,
      -1.231687523812535,
      -1.1263194035232367,
      -1.0757070654897787,
      -1.1756538053697225,
      -1.078172872408943,
      -1.309153223091968,
      -1.1253392493233525,
      -1.0915417643651175,
      -1.0902741272891532,
      -1.09397301306019,
      -1.0815631851039962,
      -1.0904413515475626,
      -1.140975239642661,
      -1.1180544253040037,
      -1.1740642494230307,
      -1.1683867854962289,
      -1.1129384294301892,
      -1.1457878923860951,
      -1.2610951418895393,
      -1.1268303742031631,
      -1.166407481240497,
      -1.16104456635715,
      -1.2028731455701132
    ],
    [
      -1.3979762672394795,
      -1.2682169653044195,
      -1.2670381731161566,
      -1.2308976686183282,
      -1.2597923529385087,
      -1.2400011150272576,
      0.0,
      -1.2667626421603737,
      -1.2775532444726354,
      -1.3422520685254162,
      -1.2372436951218782,
      -1.3447545000712195,
      -1.2625673246030036,
      -1.2586461046036408,
      -1.3212748205650553,
      -1.2683473520397348,
      -1.3253189155588612,
      -1.291919067508709,
      -1.271023028177368,
      -1.2894172712104257,
      -1.2928950609001204,
      -1.2403465975517551,
      -1.3151876441234966,
      -1.2976323575385704,
      -1.3461705250865426,
      -1.2846133053806401,
      -1.300430488255801,
      -1.3304128781894853,
      -1.2876985411071056
    ],
    [
      -1.5385993288627273,
      -1.421386251804501,
      -1.4122588501770201,
      -1.4167440076479239,
      -1.3947275257910388,
      -1.415921401180902,
      -1.5217895911769088,
      0.0,
      -1.3977111500755275,
      -1.4702095515130733,
      -1.4023253296600904,
      -1.573395419758991,
      -1.4572361979012707,
      -1.4197041866935258,
      -1.4411998049319088,
      -1.4546237713924026,
      -1.4363389606777723,
      -1.4031324982619582,
      -1.4398719635894257,
      -1.441972946154148,
      -1.433326607890432,
      -1.454848966876151,
      -1.4570363481604585,
      -1.4933910364278546,
      -1.5188119031472829,
      -1.4081542368653528,
      -1.4722336079395522,
      -1.4818742429227052,
      -1.5372085621678022
    ],
    [
      -1.3248465516036863,
      -1.0827693094970614,
      -1.166225954063828,
      -0.9907351854131351,
      -1.124624347970896,
      -1.1208372783983196,
      -1.3054668017718833,
      -1.1955384427210407,
      0.0,
      -1.2170670194825166,
      -1.1048544635096076,
      -1.3762380381593542,
      -1.2184371274108725,
      -1.1257149638495114,
      -1.1170350576060104,
      -1.03052646564672,
      -1.1328802167348493,
      -1.1238286319698254,
      -1.2330442585494503,
      -1.1558918304741606,
      -1.230602744428065,
      -1.1774466557685928,
      -1.1405247384804695,
      -1.0994764412531566,
      -1.2757227967241749,
      -1.1644898589717356,
      -1.2607671732160863,
      -1.183436983655303,
      -1.2613242341371025
    ],
    [
      -1.620236402391279,
      -1.5570870616348493,
      -1.49125474156285,
      -1.5619100894172315,
      -1.5103009187383767,
      -1.554132084682377,
      -1.7106743982151842,
      -1.552820772413604,
      -1.5294504523772774,
      0.0,
      -1.5409694648733476,
      -1.6929699909916334,
      -1.5581357281124746,
      -1.5582297802901888,
      -1.5664881238474633,
      -1.5616059460043918,
      -1.5182871350079206,
      -1.5394056745869846,
      -1.5317518010109843,
      -1.5690958702529294,
      -1.5894442461923777,
      -1.6021829990107381,
      -1.5424173669435752,
      -1.6412928726810154,
      -1.5448214789121988,
      -1.5616014315166424,
      -1.555112194266438,
      -1.5972833388812964,
      -1.5944487361105313
    ],
    [
      -1.318951012727113,
      -1.079729944602421,
      -1.209913914598802,
      -1.0699790768169595,
      -1.058908987517877,
      -1.0882770672254483,
      -1.244028756313053,
      -1.1525565857951907,
      -1.0908153126001907,
      -1.2382870399375756,
      0.0,
      -1.3349648728663115,
      -1.1586145437800623,
      -1.0880272818291248,
      -1.1350197512363898,
      -1.1095791309179106,
      -1.084896959718375,
      -1.1203374952343348,
      -1.181152523683155,
      -1.1364705831786686,
      -1.221178548571191,
      -1.2126052577081539,
      -1.1193381021134676,
      -1.1730127497438607,
      -1.2801654004662055,
      -1.1929808505217214,
      -1.2213155454926372,
      -1.223558815454885,
      -1.2579631908394557
    ],
    [
      -1.3490787680222969,
      -1.3193779191071502,
      -1.304287694694144,
      -1.3018077248830358,
      -1.3203650851518212,
      -1.3040242547993504,
      -1.360544267838861,
      -1.230718887965204,
      -1.305537437333193,
      -1.2588462003917027,
      -1.3195541194608855,
      0.0,
      -1.3076091396752758,
      -1.3045300491941103,
      -1.331479637299876,
      -1.3307817494097962,
      -1.2369212134448393,
      -1.329447292089874,
      -1.2672373370914032,
      -1.3020860874064453,
      -1.2905530174062838,
      -1.3184778705744744,
      -1.2653458731752927,
      -1.319919683599957,
      -1.3151856037627292,
      -1.2739825562394245,
      -1.267079643522253,
      -1.3167858010807254,
      -1.315318972393246
    ],
    [
      -1.2018013662912534,
      -1.0687895408074177,
      -1.0720466917899307,
      -1.0307613382470702,
      -1.0472099697637112,
      -1.017134783856475,
      -1.1484258032571437,
      -1.0118110648306204,
      -1.0589562679738522,
      -1.096776430353589,
      -1.0197204921641327,
      -1.1896326839491878,
      0.0,
      -1.0391167147346838,
      -1.0720212465025722,
      -1.061411537285951,
      -1.0818878743609277,
      -1.0467811834147696,
      -1.0302893222908356,
      -1.0894453362021668,
      -1.0401201122095376,
      -1.0770016054844795,
      -1.0886193881228035,
      -1.125702637877259,
      -1.1851454402521044,
      -1.0650834024877844,
      -1.0454221510829214,
      -1.1388579886444774,
      -1.1098128664927325
    ],
    [
      -1.227972022704099,
      -1.044842159852694,
      -1.1127014624690628,
      -1.022168762165388,
      -1.0442402459489386,
      -1.0540845526201523,
      -1.1926123484211513,
      -1.0862186992462708,
      -1.032964574220791,
      -1.1683526455621047,
      -1.030651680848651,
      -1.2392360635775743,
      -1.1010893319778725,
      0.0,
      -1.033475363288897,
      -1.0208131306815729,
      -1.0536157156504895,
      -1.0789593398201032,
      -1.132563721389794,
      -1.0693247936444619,
      -1.1035950223166344,
      -1.131942588408301,
      -1.0654967217786238,
      -1.1062519936556,
      -1.1845903196374283,
      -1.0708575965945504,
      -1.159285006121649,
      -1.110533841329378,
      -1.1721539569146768
    ],
    [
      -1.2424413403941423,
      -1.0161119791944662,
      -1.0964856328739652,
      -1.003493544420715,
      -1.0699184100673274,
      -1.0506601691316526,
      -1.2447748959473222,
      -1.079589543223552,
      -1.0016679552150731,
      -1.1326860895072801,
      -1.0465496369975202,
      -1.2813291159532865,
      -1.110087348137261,
      -0.9938814088082751,
      0.0,
      -1.0140656568843587,
      -1.04759619610648,
      -1.0306572793255815,
      -1.0592501814813096,
      -1.0428479164440767,
      -1.1811217058131365,
      -1.1318984200588478,
      -1.0584918787063884,
      -1.0858853459426054,
      -1.2026788587515227,
      -1.1086091350914744,
      -1.1858672266985835,
      -1.116033913523997,
      -1.2023942286060558
    ],
    [
      -1.4108812027567115,
      -1.0870479986595103,
      -1.2577653419837878,
      -1.0625323946228278,
      -1.171544043473893,
      -1.2324117667425603,
      -1.3491739144823072,
      -1.2523974190198266,
      -1.1314886483942772,
      -1.3065288757893425,
      -1.2061702607588718,
      -1.4119580614794516,
      -1.264303819978902,
      -1.1311269008042657,
      -1.2044089131987639,
      0.0,
      -1.2197681592453158,
      -1.2166364540353891,
      -1.2800922593263098,
      -1.2549662725223882,
      -1.3020690194147686,
      -1.2310064123766067,
      -1.2170336341486525,
      -1.1359148312036036,
      -1.3573823723229188,
      -1.2250523172392047,
      -1.3060932770056581,
      -1.2553326157772433,
      -1.3042567583787346
    ],
    [
      -1.6289727614219995,
      -1.4409152736136732,
      -1.480967345936638,
      -1.4176823883282237,
      -1.3996340428055964,
      -1.4839045152899017,
      -1.6716083282315162,
      -1.4893180192146227,
      -1.4324542749852824,
      -1.5372958300981605,
      -1.4297722203168888,
      -1.6965261509750529,
      -1.5257663472910674,
      -1.4171587022930994,
      -1.420694671814716,
      -1.4423797948670256,
      0.0,
      -1.4629862080225178,
      -1.555994649982327,
      -1.4537076612162607,
      -1.540735403844086,
      -1.5845235520758127,
      -1.427376606734395,
      -1.514906057740562,
      -1.6037515096290158,
      -1.501043686012609,
      -1.6017839060288186,
      -1.5301250385565837,
      -1.6231036891707797
    ],
    [
      -1.643987883686021,
      -1.3998596240122947,
      -1.4608370813590323,
      -1.4075436611485588,
      -1.4663045421872336,
      -1.4573528375194669,
      -1.6143857902985355,
      -1.4756325291258707,
      -1.4218296682106917,
      -1.545026054680799,
      -1.4928905235943657,
      -1.6798663195976788,
      -1.5348364454821246,
      -1.4731416915834221,
      -1.480948783391659,
      -1.4492353532717075,
      -1.4809278515949127,
      0.0,
      -1.5225540391050638,
      -1.4465946365305355,
      -1.5126911313416243,
      -1.4851665859343868,
      -1.5224352485777906,
      -1.4612493417382943,
      -1.6008090357090052,
      -1.540877463106851,
      -1.524122181528844,
      -1.5220498550251247,
      -1.5764563039160504
    ],
    [
      -1.4745475095436742,
      -1.3239889516528325,
      -1.3136507041786092,
      -1.3228377877779693,
      -1.362022181436965,
      -1.2434475605667283,
      -1.3847250396907858,
      -1.320784297265727,
      -1.3362419685886713,
      -1.3504001083315755,
      -1.306746986456816,
      -1.4647486505814742,
      -1.2708112196604187,
      -1.3025447002934252,
      -1.2767362880220807,
      -1.3405193124048365,
      -1.3632681688079957,
      -1.3213859415177185,
      0.0,
      -1.3152404567243465,
      -1.4064667842484515,
      -1.356288660027415,
      -1.3327995108526864,
      -1.407773534464224,
      -1.4520618405306043,
      -1.3265917718745217,
      -1.322267653996179,
      -1.4010293765700912,
      -1.389274889221196
    ],
    [
      -1.4960182330322547,
      -1.3044908847998855,
      -1.3595939685011924,
      -1.2905279499261992,
      -1.2885676853301533,
      -1.30512772311916,
      -1.4668750541184006,
      -1.3393586317890733,
      -1.2787900005517647,
      -1.4095555092565706,
      -1.304763932829477,
      -1.5405217721302384,
      -1.3543309824674286,
      -1.2703959090145611,
      -1.2841865958702736,
      -1.3008844701598878,
      -1.330784046298844,
      -1.244173059200833,
      -1.3556686809339322,
      0.0,
      -1.3871694320692611,
      -1.3828076226174928,
      -1.330296577662604,
      -1.3768110402330596,
      -1.4370591132739259,
      -1.3901868586916,
      -1.421147240453525,
      -1.3808141553972701,
      -1.4213177989602654
    ],
    [
      -1.5081855863091504,
      -1.4812986577454892,
      -1.4306893031928452,
      -1.4141357082288466,
      -1.4529214218572863,
      -1.4771870577800001,
      -1.5135724242673,
      -1.4099440430059171,
      -1.4519768904297883,
      -1.5232737410905675,
      -1.4865025759457047,
      -1.6352050000801404,
      -1.5145367380385018,
      -1.4781510725716123,
      -1.5003734547094458,
      -1.4590391282792257,
      -1.44646770148025,
      -1.4245173431641796,
      -1.4853946980315333,
      -1.4827955608831667,
      0.0,
      -1.4452683153939831,
      -1.5183753281372834,
      -1.5138272241384256,
      -1.4965473098420583,
      -1.4568863803263434,
      -1.4942551841871032,
      -1.4762349115868258,
      -1.4794914915354918
    ],
    [
      -1.4447490316302174,
      -1.1970335223848265,
      -1.2795479716629037,
      -1.2347318693788794,
      -1.2133112008284808,
      -1.2700971074730514,
      -1.3291323649838107,
      -1.2889414588155608,
      -1.270845082512353,
      -1.3707836407991372,
      -1.3093401553589212,
      -1.492194539258531,
      -1.3161945100760024,
      -1.2828046056318003,
      -1.2950443919309949,
      -1.256883036892552,
      -1.2928556155406632,
      -1.2547686401887261,
      -1.2936310139063503,
      -1.29576189307359,
      -1.2810134261541868,
      0.0,
      -1.3011871006520412,
      -1.2758499958389415,
      -1.349168608872698,
      -1.204794694097059,
      -1.4039696657307912,
      -1.304903148950937,
      -1.3090974860115334
    ],
    [
      -1.4843666209644912,
      -1.3821617369349366,
      -1.4137845799697364,
      -1.3341840646374699,
      -1.265566480187047,
      -1.375020249188074,
      -1.57850154684423,
      -1.3998462453838532,
      -1.3397209625116009,
      -1.4051586324979484,
      -1.336927678873501,
      -1.5884096030970747,
      -1.4438254083493696,
      -1.346750010696907,
      -1.338590418488342,
      -1.3798614790495045,
      -1.288208005317842,
      -1.3704463990709363,
      -1.42257332009793,
      -1.362731214632635,
      -1.4359719124296177,
      -1.4078761117273428,
      0.0,
      -1.4358295638629384,
      -1.4532152456934144,
      -1.4307880099502688,
      -1.4851357201337094,
      -1.4461565946890662,
      -1.502159336503083
    ],
    [
      -1.5223996971400844,
      -1.2872394475494968,
      -1.4439310565799557,
      -1.2665830328655279,
      -1.3417651481363984,
      -1.4102716809886726,
      -1.5255951775111591,
      -1.4157703217418063,
      -1.3334577893313444,
      -1.494429085797316,
      -1.400558041984174,
      -1.5908290998356158,
      -1.4894381059388595,
      -1.383645454289432,
      -1.3965062707884397,
      -1.2967261295324373,
      -1.3705566370221185,
      -1.3147783519853828,
      -1.484217882165799,
      -1.3921746207350265,
      -1.4924455539317463,
      -1.3726718788506407,
      -1.390610308164526,
      0.0,
      -1.5326200244831418,
      -1.3982488553030867,
      -1.4908863679364786,
      -1.3853734917358276,
      -1.5315133582879008
    ],
    [
      -1.4873772100462188,
      -1.4444513747073975,
      -1.3570111641130378,
      -1.414365980725422,
      -1.3888619488287757,
      -1.4430254647073992,
      -1.4969540177448803,
      -1.454345654092778,
      -1.3866124487034182,
      -1.3690302316966039,
      -1.3941307627196478,
      -1.545336082900568,
      -1.4646080229403864,
      -1.420854974328399,
      -1.4443538138326153,
      -1.4479442932697493,
      -1.4145930494354104,
      -1.4075922060765578,
      -1.4161312485213677,
      -1.4383673897854297,
      -1.43075810113192,
      -1.4313693391714084,
      -1.413333894934115,
      -1.4865493287291125,
      0.0,
      -1.4259447433232175,
      -1.4337263023923132,
      -1.4113193438457976,
      -1.3985462217097304
    ],
    [
      -1.5842616109249916,
      -1.3839135087950332,
      -1.4328939252343926,
      -1.4055218401285636,
      -1.4002727354061713,
      -1.469648984656837,
      -1.5933454227646753,
      -1.4452832328959173,
      -1.4303514981965704,
      -1.533045400012888,
      -1.4743325311969793,
      -1.636919223318231,
      -1.4767411222564972,
      -1.4586203243186364,
      -1.4607652881192628,
      -1.3648223668002644,
      -1.4285691983347952,
      -1.4671162999983094,
      -1.492996228353494,
      -1.4703333488011276,
      -1.5278603518093476,
      -1.4102411686568173,
      -1.4681707321261808,
      -1.4434210356274972,
      -1.5503046986967013,
      0.0,
      -1.5056456934237163,
      -1.5162443854806096,
      -1.5459497702081948
    ],
    [
      -1.446172020656417,
      -1.4689685558114705,
      -1.4400589497192626,
      -1.4499364677314803,
      -1.4280952462249823,
      -1.439903071493523,
      -1.4877688311003614,
      -1.390362256517805,
      -1.4489023929545133,
      -1.3563209507775362,
      -1.4543390787787105,
      -1.4524334655857623,
      -1.4237362970368495,
      -1.4314560183030558,
      -1.4566202997128082,
      -1.4688171042650886,
      -1.4098012611049582,
      -1.4535497763940044,
      -1.434837206226394,
      -1.4390423022185903,
      -1.4438822291722986,
      -1.4878919431179913,
      -1.4129176290000904,
      -1.4715343822947158,
      -1.450259591544631,
      -1.4253865798083047,
      0.0,
      -1.451518055199459,
      -1.4561804485229013
    ],
    [
      -1.4272096449762173,
      -1.3254793030062508,
      -1.3635985476212698,
      -1.2998435229734877,
      -1.312240012990394,
      -1.378881883139339,
      -1.5291380018768446,
      -1.389901774353452,
      -1.379503997720743,
      -1.4421177758799713,
      -1.3981077867272393,
      -1.5170322357550605,
      -1.4314705366391591,
      -1.3397752725700436,
      -1.381769184918771,
      -1.348700407940173,
      -1.3591316743640645,
      -1.3523252538645834,
      -1.4059142369725617,
      -1.3651505069369572,
      -1.4440021629494197,
      -1.4102514092749956,
      -1.3974575908620939,
      -1.3657472023682746,
      -1.4879181125582415,
      -1.414873820230081,
      -1.4377257788285562,
      0.0,
      -1.4343069034591474
    ],
    [
      -1.3141996883380231,
      -1.2799846449575552,
      -1.2524041822682368,
      -1.2463005467296129,
      -1.2171156617722663,
      -1.2447035780664772,
      -1.3356545411764915,
      -1.2150591548644802,
      -1.2527089531093887,
      -1.2483520770274974,
      -1.2470542893126346,
      -1.3760718489725645,
      -1.2538434282037798,
      -1.23889155045248,
      -1.2648015245790998,
      -1.2347967389618357,
      -1.2405156580077994,
      -1.2594197198951576,
      -1.2411770241863842,
      -1.2653233763078942,
      -1.233075991424991,
      -1.1106173379998685,
      -1.2387398866623816,
      -1.3410608608828694,
      -1.2388846328332692,
      -1.2632626477095512,
      -1.254561382654234,
      -1.285122322506907,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.21224528860758118,
      0.21634750820779258,
      0.24821842034746933,
      0.21177049543778947,
      0.21300589331323305,
      0.13540551041454707,
      0.20367569049265422,
      0.20092573307268857,
      0.18367245486713601,
      0.1985933450161732,
      0.12735656615035884,
      0.21139964100054875,
      0.21562036393594974,
      0.1861995516013688,
      0.19787754627268628,
      0.19025815920459133,
      0.20522236478165912,
      0.18681049666144567,
      0.2147488276330125,
      0.24070428880083217,
      0.20558470758849667,
      0.18956976162430905,
      0.165556755531711,
      0.17392018897452743,
      0.17841667428487584,
      0.20809870786643492,
      0.2091505842725052,
      0.18837057182998906
    ],
    [
      0.3597833793104459,
      0.0,
      0.4355493467684346,
      0.6465113793339952,
      0.5338742918929886,
      0.4927339988524235,
      0.37319574516665877,
      0.45897179984687253,
      0.5654689332496612,
      0.40938866759006154,
      0.5460784174931073,
      0.3102470248941904,
      0.42662298469289883,
      0.5728767513195407,
      0.503430376928045,
      0.6280920008191331,
      0.5194768995577406,
      0.5379766404431705,
      0.421072652931205,
      0.5004089029087024,
      0.4401685626356975,
      0.546826585517662,
      0.5021233819228941,
      0.5804105621683067,
      0.36657833117132355,
      0.5324181046206737,
      0.3868736949326581,
      0.49723836193656257,
      0.39113986800581335
    ],
    [
      0.36686215799658783,
      0.44616760274056433,
      0.0,
      0.5393359832451152,
      0.5080961660225267,
      0.47941886373278075,
      0.35023448779112876,
      0.4699731429495513,
      0.5038219762235028,
      0.4627878288929481,
      0.4748065050814301,
      0.2733966786117701,
      0.45467506462897767,
      0.4878636444438429,
      0.4539748738308713,
      0.4749667500498973,
      0.45571045931243837,
      0.4758660520782565,
      0.4376392764981618,
      0.47716999403311067,
      0.462874383624279,
      0.4445420886639526,
      0.43893061260614386,
      0.4184095722851304,
      0.41025722173571455,
      0.4709970926098661,
      0.42530316146125435,
      0.4515926324537316,
      0.38062389408137975
    ],
    [
      0.3921963526995267,
      0.5910317569447947,
      0.47103221492757963,
      0.0,
      0.5130692681580058,
      0.5127873755812828,
      0.38581982267344306,
      0.4520809960794696,
      0.5758316284517939,
      0.39888665734839535,
      0.5155676457927192,
      0.3045275258555169,
      0.43707253424820314,
      0.5193767895134043,
      0.4917071934318564,
      0.6243299325454186,
      0.5013131307816505,
      0.5037386686119978,
      0.42090276223641787,
      0.48381334820952104,
      0.45863636509033756,
      0.4605233601772265,
      0.4646315126479894,
      0.560117813353169,
      0.33867793342657504,
      0.46087887600109334,
      0.3853453668525437,
      0.5178117151326747,
      0.3862448162230636
    ],
    [
      0.4066640739135552,
      0.6214783570032605,
      0.5504355525836195,
      0.6232376624823359,
      0.0,
      0.5414807677965074,
      0.38154614241151763,
      0.5449426122019034,
      0.5565752898992011,
      0.5505207608578953,
      0.5733659367291164,
      0.2878085498112397,
      0.4975595243325581,
      0.5669150897359112,
      0.5333715736991671,
      0.6182513408242891,
      0.6497820729609454,
      0.5952761128740434,
      0.4695217036089945,
      0.5718369040172531,
      0.45121627793288166,
      0.5383131517534925,
      0.6309375867758904,
      0.5093414402107295,
      0.46560443306845833,
      0.553037452716278,
      0.4517433514662914,
      0.5097161993890653,
      0.4069768338181483
    ],
    [
      0.37713241441243706,
      0.5684095811832655,
      0.5400473966309352,
      0.5990757892780789,
      0.5333086074644484,
      0.0,
      0.42365711669787,
      0.5290252369871684,
      0.5796375750206264,
      0.47969083514068256,
      0.5771717681014621,
      0.34619141741843706,
      0.5300053911870526,
      0.5638028761452876,
      0.5650705132212519,
      0.5613716274502152,
      0.5737814554064089,
      0.5649032889628425,
      0.5143694008677442,
      0.5372902152064014,
      0.4812803910873744,
      0.4869578550141762,
      0.5424062110802159,
      0.50955674812431,
      0.3942494986208658,
      0.528514266307242,
      0.4889371592699081,
      0.49430007415325505,
      0.45247149494029193
    ],
    [
      0.2633293281823823,
      0.39308863011744233,
      0.3942674223057052,
      0.4304079268035337,
      0.4015132424833532,
      0.4213044803946042,
      0.0,
      0.39454295326148814,
      0.38375235094922644,
      0.3190535268964456,
      0.4240619002999837,
      0.3165510953506423,
      0.39873827081885826,
      0.40265949081822106,
      0.34003077485680655,
      0.39295824338212704,
      0.3359866798630007,
      0.36938652791315274,
      0.39028256724449384,
      0.37188832421143614,
      0.36841053452174144,
      0.4209589978701067,
      0.3461179512983652,
      0.3636732378832914,
      0.3151350703353193,
      0.37669229004122173,
      0.36087510716606075,
      0.33089271723237657,
      0.37360705431475627
    ],
    [
      0.3642240880484895,
      0.48143716510671575,
      0.4905645667341967,
      0.48607940926329296,
      0.5080958911201781,
      0.4869020157303148,
      0.381033825734308,
      0.0,
      0.5051122668356893,
      0.4326138653981435,
      0.5004980872511264,
      0.3294279971522258,
      0.44558721900994613,
      0.483119230217691,
      0.461623611979308,
      0.4481996455188142,
      0.4664844562334445,
      0.49969091864925863,
      0.4629514533217911,
      0.46085047075706886,
      0.4694968090207847,
      0.44797445003506575,
      0.44578706875075835,
      0.40943238048336217,
      0.38401151376393394,
      0.494669180045864,
      0.43058980897166466,
      0.4209491739885116,
      0.3656148547434146
    ],
    [
      0.3330025852751679,
      0.5750798273817928,
      0.49162318281502615,
      0.6671139514657191,
      0.5332247889079582,
      0.5370118584805346,
      0.3523823351069708,
      0.46231069415781345,
      0.0,
      0.44078211739633755,
      0.5529946733692466,
      0.28161109871949996,
      0.43941200946798165,
      0.5321341730293427,
      0.5408140792728438,
      0.6273226712321343,
      0.5249689201440049,
      0.5340205049090287,
      0.42480487832940383,
      0.5019573064046936,
      0.4272463924507892,
      0.4804024811102614,
      0.5173243983983846,
      0.5583726956256976,
      0.3821263401546793,
      0.49335927790711853,
      0.3970819636627678,
      0.47441215322355124,
      0.3965249027417517
    ],
    [
      0.3042076929120643,
      0.3673570336684939,
      0.43318935374049317,
      0.36253400588611173,
      0.4141431765649666,
      0.3703120106209663,
      0.21376969708815907,
      0.3716233228897392,
      0.39499364292606587,
      0.0,
      0.38347463042999563,
      0.2314741043117099,
      0.3663083671908687,
      0.3662143150131545,
      0.35795597145588,
      0.3628381492989514,
      0.4061569602954227,
      0.38503842071635863,
      0.39269229429235897,
      0.35534822505041386,
      0.3349998491109656,
      0.32226109629260513,
      0.38202672835976803,
      0.28315122262232784,
      0.3796226163911445,
      0.3628426637867008,
      0.36933190103690516,
      0.3271607564220469,
      0.329995359192812
    ],
    [
      0.35602368607666235,
      0.5952447542013541,
      0.4650607842049732,
      0.6049956219868158,
      0.6160657112858983,
      0.586697631578327,
      0.43094594249072227,
      0.5224181130085845,
      0.5841593862035845,
      0.43668765886619965,
      0.0,
      0.34000982593746376,
      0.5163601550237129,
      0.5869474169746505,
      0.5399549475673855,
      0.5653955678858646,
      0.5900777390854002,
      0.5546372035694405,
      0.4938221751206202,
      0.5385041156251067,
      0.45379615023258424,
      0.4623694410956214,
      0.5556365966903076,
      0.5019619490599145,
      0.3948092983375697,
      0.4819938482820538,
      0.45365915331113804,
      0.45141588334889016,
      0.4170115079643195
    ],
    [
      0.2749009409110956,
      0.3046017898262423,
      0.31969201423924853,
      0.32217198405035674,
      0.30361462378157134,
      0.31995545413404214,
      0.26343544109453143,
      0.3932608209681885,
      0.31844227160019956,
      0.3651335085416898,
      0.304425589472507,
      0.0,
      0.3163705692581167,
      0.3194496597392822,
      0.29250007163351643,
      0.2931979595235963,
      0.3870584954885532,
      0.2945324168435184,
      0.3567423718419893,
      0.3218936215269472,
      0.3334266915271087,
      0.3055018383589181,
      0.3586338357580998,
      0.30406002533343557,
      0.3087941051706633,
      0.349997152693968,
      0.3569000654111394,
      0.3071939078526671,
      0.3086607365401466
    ],
    [
      0.3679708419358376,
      0.5009826674196733,
      0.49772551643716034,
      0.5390108699800209,
      0.5225622384633799,
      0.552637424370616,
      0.42134640496994735,
      0.5579611433964706,
      0.5108159402532388,
      0.4729957778735021,
      0.5500517160629583,
      0.3801395242779033,
      0.0,
      0.5306554934924073,
      0.4977509617245188,
      0.5083606709411401,
      0.48788433386616337,
      0.5229910248123215,
      0.5394828859362555,
      0.4803268720249243,
      0.5296520960175535,
      0.49277060274261153,
      0.4811528201042876,
      0.4440695703498321,
      0.3846267679749866,
      0.5046888057393066,
      0.5243500571441697,
      0.43091421958261367,
      0.4599593417343586
    ],
    [
      0.3323838231790428,
      0.5155136860304479,
      0.44765438341407915,
      0.5381870837177538,
      0.5161155999342033,
      0.5062712932629896,
      0.36774349746199064,
      0.4741371466368711,
      0.527391271662351,
      0.3920032003210372,
      0.5297041650344909,
      0.3211197823055676,
      0.4592665139052694,
      0.0,
      0.5268804825942448,
      0.539542715201569,
      0.5067401302326524,
      0.48139650606303874,
      0.4277921244933478,
      0.49103105223868004,
      0.4567608235665075,
      0.42841325747484094,
      0.49485912410451816,
      0.454103852227542,
      0.3757655262457136,
      0.48949824928859154,
      0.4010708397614928,
      0.449822004553764,
      0.3882018889684651
    ],
    [
      0.3300180054048336,
      0.5563473666045098,
      0.4759737129250108,
      0.568965801378261,
      0.5025409357316486,
      0.5217991766673233,
      0.3276844498516538,
      0.4928698025754239,
      0.5707913905839028,
      0.43977325629169584,
      0.5259097088014557,
      0.2911302298456895,
      0.4623719976617149,
      0.5785779369907008,
      0.0,
      0.5583936889146173,
      0.524863149692496,
      0.5418020664733945,
      0.5132091643176664,
      0.5296114293548992,
      0.3913376399858395,
      0.4405609257401282,
      0.5139674670925876,
      0.4865739998563705,
      0.36978048704745325,
      0.46385021070750154,
      0.3865921191003925,
      0.456425432274979,
      0.3700651171929201
    ],
    [
      0.30805004201296904,
      0.6318832461101702,
      0.46116590278589276,
      0.6563988501468527,
      0.5473872012957874,
      0.48651947802712026,
      0.36975733028737334,
      0.4665338257498539,
      0.5874425963754033,
      0.412402368980338,
      0.5127609840108087,
      0.30697318329022893,
      0.45462742479077844,
      0.5878043439654148,
      0.5145223315709166,
      0.0,
      0.4991630855243647,
      0.5022947907342914,
      0.43883898544337074,
      0.4639649722472923,
      0.4168622253549119,
      0.4879248323930738,
      0.501897610621028,
      0.5830164135660769,
      0.3615488724467617,
      0.4938789275304758,
      0.4128379677640224,
      0.4635986289924372,
      0.41467448639094595
    ],
    [
      0.33322721163834745,
      0.5212846994466738,
      0.48123262712370907,
      0.5445175847321233,
      0.5625659302547505,
      0.47829545777044524,
      0.2905916448288308,
      0.4728819538457243,
      0.5297456980750646,
      0.4249041429621865,
      0.5324277527434582,
      0.2656738220852941,
      0.4364336257692796,
      0.5450412707672476,
      0.541505301245631,
      0.5198201781933214,
      0.0,
      0.4992137650378292,
      0.40620532307802004,
      0.5084923118440863,
      0.4214645692162611,
      0.37767642098453424,
      0.5348233663259521,
      0.447293915319785,
      0.3584484634313312,
      0.4611562870477379,
      0.3604160670315284,
      0.43207493450376333,
      0.33909628388956725
    ],
    [
      0.27490157665489656,
      0.5190298363286228,
      0.4580523789818851,
      0.5113457991923587,
      0.45258491815368385,
      0.4615366228214506,
      0.304503670042382,
      0.4432569312150467,
      0.4970597921302258,
      0.37386340566011844,
      0.42599893674655176,
      0.2390231407432386,
      0.38405301485879284,
      0.44574776875749533,
      0.4379406769492584,
      0.46965410706920996,
      0.43796160874600476,
      0.0,
      0.39633542123585364,
      0.4722948238103819,
      0.4061983289992932,
      0.4337228744065307,
      0.3964542117631269,
      0.4576401186026231,
      0.3180804246319122,
      0.37801199723406653,
      0.3947672788120735,
      0.39683960531579276,
      0.34243315642486705
    ],
    [
      0.35801214848889606,
      0.5085707063797378,
      0.5189089538539611,
      0.5097218702546009,
      0.4705374765956052,
      0.5891120974658419,
      0.4478346183417845,
      0.5117753607668432,
      0.496317689443899,
      0.4821595497009947,
      0.5258126715757543,
      0.3678110074510961,
      0.5617484383721516,
      0.5300149577391451,
      0.5558233700104895,
      0.4920403456277338,
      0.46929148922457453,
      0.5111737165148518,
      0.0,
      0.5173192013082237,
      0.42609287378411875,
      0.47627099800515516,
      0.4997601471798838,
      0.42478612356834633,
      0.380497817501966,
      0.5059678861580486,
      0.5102920040363912,
      0.43153028146247907,
      0.44328476881137435
    ],
    [
      0.3088407492916323,
      0.5003680975240015,
      0.44526501382269457,
      0.5143310323976877,
      0.5162912969937337,
      0.49973125920472694,
      0.3379839282054864,
      0.46550035053481364,
      0.5260689817721222,
      0.3953034730673164,
      0.5000950494944101,
      0.26433721019364853,
      0.4505279998564584,
      0.5344630733093259,
      0.5206723864536134,
      0.5039745121639991,
      0.4740749360250429,
      0.5606859231230539,
      0.44919030138995475,
      0.0,
      0.41768955025462584,
      0.4220513597063942,
      0.4745624046612831,
      0.4280479420908274,
      0.3677998690499611,
      0.414672123632287,
      0.38371174187036194,
      0.4240448269266168,
      0.38354118336362153
    ],
    [
      0.4274050634675184,
      0.45429199203117965,
      0.5049013465838237,
      0.5214549415478222,
      0.4826692279193825,
      0.4584035919966687,
      0.42201822550936874,
      0.5256466067707517,
      0.48361375934688056,
      0.4123169086861014,
      0.44908807383096416,
      0.3003856496965285,
      0.4210539117381671,
      0.45743957720505657,
      0.435217195067223,
      0.4765515214974432,
      0.4891229482964188,
      0.5110733066124893,
      0.4501959517451355,
      0.4527950888935022,
      0.0,
      0.4903223343826857,
      0.41721532163938546,
      0.4217634256382432,
      0.43904333993461053,
      0.4787042694503254,
      0.4413354655895656,
      0.459355738189843,
      0.4560991582411771
    ],
    [
      0.2961770012013121,
      0.543892510446703,
      0.4613780611686258,
      0.5061941634526501,
      0.5276148320030487,
      0.4708289253584781,
      0.41179366784771876,
      0.4519845740159687,
      0.4700809503191765,
      0.3701423920323923,
      0.43158587747260824,
      0.2487314935729985,
      0.42473152275552706,
      0.45812142719972915,
      0.4458816409005346,
      0.48404299593897737,
      0.4480704172908663,
      0.48615739264280333,
      0.4472950189251792,
      0.44516413975793956,
      0.4599126066773427,
      0.0,
      0.43973893217948823,
      0.4650760369925879,
      0.3917574239588315,
      0.5361313387344704,
      0.3369563671007383,
      0.4360228838805924,
      0.43182854681999605
    ],
    [
      0.37171804788899787,
      0.4739229319185525,
      0.4423000888837527,
      0.5219006042160192,
      0.5905181886664421,
      0.481064419665415,
      0.27758312200925905,
      0.45623842346963595,
      0.5163637063418882,
      0.45092603635554074,
      0.5191569899799882,
      0.2676750657564144,
      0.41225926050411954,
      0.5093346581565821,
      0.5174942503651472,
      0.4762231898039846,
      0.5678766635356471,
      0.48563826978255276,
      0.4335113487555591,
      0.4933534542208542,
      0.42011275642387136,
      0.44820855712614627,
      0.0,
      0.42025510499055074,
      0.4028694231600747,
      0.4252966589032203,
      0.3709489487197797,
      0.4099280741644229,
      0.35392533235040613
    ],
    [
      0.3587566576416463,
      0.5939169072322339,
      0.437225298201775,
      0.6145733219162028,
      0.5393912066453324,
      0.4708846737930581,
      0.35556117727057157,
      0.46538603303992443,
      0.5476985654503863,
      0.3867272689844148,
      0.4805983127975566,
      0.2903272549461149,
      0.3917182488428712,
      0.4975109004922986,
      0.484650083993291,
      0.5844302252492934,
      0.5105997177596122,
      0.5663780027963479,
      0.39693847261593174,
      0.4889817340467042,
      0.38871080084998444,
      0.50848447593109,
      0.4905460466172047,
      0.0,
      0.3485363302985889,
      0.482907499478644,
      0.39026998684525216,
      0.49578286304590313,
      0.3496429964938299
    ],
    [
      0.2753736496430592,
      0.31829948498188054,
      0.40573969557624023,
      0.34838487896385595,
      0.37388891086050235,
      0.3197253949818788,
      0.2657968419443977,
      0.3084052055965001,
      0.3761384109858599,
      0.39372062799267415,
      0.3686200969696303,
      0.21741477678871002,
      0.29814283674889164,
      0.3418958853608791,
      0.31839704585666273,
      0.31480656641952875,
      0.3481578102538676,
      0.35515865361272025,
      0.3466196111679103,
      0.32438346990384836,
      0.3319927585573581,
      0.3313815205178696,
      0.34941696475516304,
      0.27620153096016553,
      0.0,
      0.3368061163660605,
      0.3290245572969648,
      0.3514315158434804,
      0.3642046379795476
    ],
    [
      0.40457043519618674,
      0.6049185373261452,
      0.5559381208867857,
      0.5833102059926147,
      0.5885593107150071,
      0.5191830614643413,
      0.3954866233565031,
      0.543548813225261,
      0.558480547924608,
      0.45578664610829045,
      0.5144995149241991,
      0.35191282280294733,
      0.5120909238646811,
      0.530211721802542,
      0.5280667580019156,
      0.624009679320914,
      0.5602628477863831,
      0.521715746122869,
      0.49583581776768426,
      0.5184986973200507,
      0.4609716943118307,
      0.5785908774643611,
      0.5206613139949976,
      0.5454110104936811,
      0.4385273474244771,
      0.0,
      0.483186352697462,
      0.4725876606405688,
      0.44288227591298357
    ],
    [
      0.4090555569413403,
      0.3862590217862869,
      0.41516862787849473,
      0.40529110986627703,
      0.42713233137277506,
      0.4153245061042343,
      0.36745874649739596,
      0.46486532107995227,
      0.4063251846432441,
      0.49890662682022113,
      0.40088849881904687,
      0.4027941120119951,
      0.4314912805609079,
      0.42377155929470156,
      0.3986072778849492,
      0.38641047333266876,
      0.4454263164927992,
      0.40167780120375296,
      0.42039037137136326,
      0.41618527537916705,
      0.4113453484254588,
      0.367335634479766,
      0.4423099485976669,
      0.3836931953030416,
      0.40496798605312634,
      0.4298409977894526,
      0.0,
      0.40370952239829827,
      0.39904712907485607
    ],
    [
      0.39571907528717376,
      0.4974494172571402,
      0.4593301726421213,
      0.5230851972899033,
      0.5106887072729971,
      0.444046837124052,
      0.29379071838654647,
      0.43302694590993895,
      0.443424722542648,
      0.3808109443834198,
      0.4248209335361517,
      0.3058964845083305,
      0.3914581836242319,
      0.48315344769334745,
      0.44115953534462005,
      0.47422831232321805,
      0.4637970458993266,
      0.4706034663988077,
      0.41701448329082935,
      0.45777821332643387,
      0.3789265573139713,
      0.41267731098839544,
      0.42547112940129717,
      0.4571815178951164,
      0.33501060770514957,
      0.40805490003331,
      0.3852029414348348,
      0.0,
      0.3886218168042437
    ],
    [
      0.3820899156657598,
      0.4163049590462278,
      0.4438854217355461,
      0.44998905727417005,
      0.47917394223151666,
      0.4515860259373057,
      0.3606350628272914,
      0.4812304491393027,
      0.44358065089439425,
      0.4479375269762855,
      0.4492353146911483,
      0.3202177550312184,
      0.4424461758000031,
      0.4573980535513029,
      0.43148807942468315,
      0.4614928650419472,
      0.45577394599598353,
      0.4368698841086254,
      0.4551125798173987,
      0.43096622769588877,
      0.463213612578792,
      0.5856722660039144,
      0.4575497173414014,
      0.35522874312091357,
      0.4574049711705137,
      0.4330269562942317,
      0.44172822134954903,
      0.41116728149687587,
      0.0
    ]
  ],
  "row_avgs": [
    0.19709736063544167,
    0.481626344532531,
    0.4462963631316041,
    0.4688554772498454,
    0.5234805983883767,
    0.5122362930492949,
    0.3714345248862908,
    0.4486793365666201,
    0.481407937897875,
    0.35467941312740886,
    0.5034522237505417,
    0.3215909986829049,
    0.48906559248671994,
    0.45854892942432374,
    0.47113523818089537,
    0.4765975324431772,
    0.4509468074711601,
    0.41176044379599086,
    0.48294530605799807,
    0.44585094915641793,
    0.4549815693395808,
    0.44026046930883167,
    0.44702155628981516,
    0.4613262522598595,
    0.33176890917450386,
    0.5110609058875105,
    0.41305999148083,
    0.42508677234348413,
    0.439371630794364
  ],
  "col_avgs": [
    0.3475927321884952,
    0.4892634948089891,
    0.4542733809306987,
    0.5137980180879285,
    0.488821375651053,
    0.46744859272253436,
    0.3467498498681557,
    0.45778836677898976,
    0.48785931832776913,
    0.4167820726783023,
    0.47115332487600176,
    0.29607732855432073,
    0.4276618960897703,
    0.4831472098808734,
    0.4593818184595001,
    0.48817083863723904,
    0.47464720981985015,
    0.47768283701401704,
    0.4287707105109317,
    0.4581020435341623,
    0.4179821763697534,
    0.4430100107794672,
    0.4576611490104428,
    0.4362281037020389,
    0.37315900747093683,
    0.4473682179887389,
    0.40240822707011953,
    0.4256096297385096,
    0.3830267862446089
  ],
  "combined_avgs": [
    0.27234504641196844,
    0.4854449196707601,
    0.4502848720311514,
    0.49132674766888695,
    0.5061509870197148,
    0.4898424428859146,
    0.35909218737722326,
    0.45323385167280494,
    0.48463362811282207,
    0.3857307429028556,
    0.48730277431327174,
    0.3088341636186128,
    0.4583637442882451,
    0.47084806965259857,
    0.46525852832019776,
    0.4823841855402081,
    0.4627970086455051,
    0.44472164040500395,
    0.4558580082844649,
    0.45197649634529014,
    0.4364818728546671,
    0.44163524004414945,
    0.452341352650129,
    0.4487771779809492,
    0.35246395832272037,
    0.47921456193812473,
    0.40773410927547477,
    0.42534820104099685,
    0.41119920851948644
  ],
  "gppm": [
    607.4309183675111,
    577.8101958545395,
    589.9471001964713,
    566.4601973825701,
    576.5820987305259,
    590.4836246649544,
    641.9573098843845,
    589.2550381572267,
    579.2512365912429,
    605.1957278093769,
    587.3270135424925,
    665.882366119437,
    608.589680998406,
    583.3738909678686,
    594.4156973595203,
    577.9160758287466,
    580.0619526693177,
    578.6189974168644,
    606.0205224230931,
    589.5640894155274,
    606.4883499536099,
    597.4892035855843,
    590.5345893335116,
    598.1911381798493,
    627.761708049131,
    596.4883820831808,
    615.7372289569568,
    603.8957478441622,
    626.2511887230809
  ],
  "gppm_normalized": [
    1.4316819663604305,
    1.409077286904777,
    1.4417889780113082,
    1.386745601735735,
    1.4055744300719586,
    1.443183161364359,
    1.5657275063095717,
    1.4461126133802267,
    1.4152331948641503,
    1.4795326091275993,
    1.4327311745522129,
    1.6381740925116168,
    1.483643831713479,
    1.4228026267578944,
    1.4556781038828441,
    1.4123713417462482,
    1.4192461923274708,
    1.4160304988862242,
    1.480357491058111,
    1.4398348447617557,
    1.482473252631276,
    1.460301651558492,
    1.4420325705804795,
    1.4659362787305195,
    1.5336187012090818,
    1.4581114394815384,
    1.5013990509254462,
    1.4757654992570546,
    1.5286421111735469
  ],
  "token_counts": [
    301,
    388,
    419,
    442,
    388,
    427,
    412,
    466,
    407,
    425,
    397,
    630,
    398,
    392,
    463,
    417,
    423,
    430,
    413,
    414,
    437,
    427,
    409,
    455,
    430,
    420,
    403,
    426,
    422,
    742,
    457,
    402,
    407,
    384,
    425,
    586,
    447,
    476,
    395,
    412,
    440,
    450,
    425,
    400,
    433,
    422,
    379,
    389,
    427,
    392,
    371,
    364,
    413,
    432,
    393,
    358,
    382,
    420,
    606,
    434,
    448,
    474,
    401,
    495,
    477,
    426,
    580,
    412,
    415,
    465,
    498,
    455,
    421,
    458,
    403,
    420,
    442,
    452,
    435,
    381,
    344,
    473,
    422,
    437,
    351,
    428,
    360,
    852,
    466,
    462,
    474,
    415,
    413,
    436,
    422,
    465,
    448,
    470,
    377,
    462,
    415,
    455,
    415,
    425,
    413,
    422,
    411,
    459,
    427,
    407,
    447,
    412,
    368,
    423,
    422,
    431,
    885,
    465,
    444,
    471,
    435,
    421,
    397,
    467,
    393,
    448,
    471,
    447,
    418,
    426,
    423,
    395,
    392,
    431,
    460,
    459,
    395,
    389,
    413,
    412,
    402,
    405,
    364,
    428,
    394,
    389,
    442,
    502,
    431,
    485,
    414,
    543,
    421,
    441,
    441,
    462,
    364,
    465,
    477,
    435,
    486,
    420,
    424,
    410,
    443,
    468,
    375,
    436,
    428,
    405,
    503,
    435,
    423,
    372,
    943,
    435,
    392,
    442,
    409,
    423,
    534,
    391,
    430,
    413,
    411,
    412,
    435,
    471,
    353,
    468,
    380,
    432,
    392,
    446,
    345,
    381,
    360,
    430,
    386,
    343,
    392,
    417,
    386,
    850,
    464,
    481,
    546,
    442,
    472,
    423,
    428,
    515,
    456,
    456,
    499,
    481,
    460,
    443,
    480,
    437,
    444,
    432,
    484,
    476,
    442,
    440,
    579,
    477,
    380,
    401,
    480,
    377,
    333,
    535,
    441,
    415,
    440,
    532,
    467,
    476,
    390,
    400,
    461,
    506,
    501,
    483,
    418,
    403,
    393,
    415,
    434,
    464,
    456,
    391,
    393,
    426,
    444,
    420,
    400,
    420,
    534,
    448,
    422,
    431,
    410,
    445,
    437,
    448,
    356,
    418,
    400,
    408,
    567,
    423,
    428,
    389,
    424,
    419,
    417,
    416,
    470,
    368,
    384,
    403,
    423,
    394,
    366,
    382,
    442,
    412,
    532,
    444,
    478,
    502,
    430,
    533,
    483,
    440,
    480,
    379,
    427,
    503,
    458,
    484,
    371,
    423,
    429,
    400,
    409,
    416,
    406,
    403,
    340,
    427,
    412,
    405,
    403,
    478,
    337,
    881,
    516,
    435,
    467,
    432,
    482,
    427,
    429,
    438,
    480,
    526,
    521,
    442,
    442,
    405,
    427,
    443,
    406,
    409,
    416,
    406,
    404,
    382,
    465,
    409,
    391,
    417,
    484,
    418,
    1833,
    463,
    409,
    431,
    428,
    476,
    461,
    399,
    432,
    424,
    452,
    363,
    494,
    429,
    456,
    471,
    385,
    410,
    444,
    447,
    419,
    436,
    403,
    412,
    406,
    410,
    428,
    387,
    466,
    526,
    485,
    454,
    438,
    400,
    422,
    425,
    397,
    393,
    505,
    445,
    462,
    393,
    394,
    428,
    499,
    360,
    369,
    419,
    488,
    392,
    493,
    368,
    405,
    433,
    442,
    426,
    399,
    369,
    841,
    559,
    462,
    436,
    436,
    428,
    402,
    420,
    440,
    435,
    424,
    530,
    439,
    440,
    430,
    421,
    436,
    366,
    413,
    433,
    585,
    372,
    369,
    432,
    411,
    394,
    425,
    443,
    374,
    668,
    447,
    430,
    474,
    395,
    392,
    409,
    440,
    444,
    462,
    422,
    375,
    403,
    432,
    410,
    453,
    457,
    462,
    371,
    450,
    408,
    449,
    425,
    437,
    431,
    358,
    398,
    428,
    393
  ],
  "response_lengths": [
    3114,
    2387,
    2455,
    2570,
    2205,
    2147,
    2301,
    2457,
    2429,
    2670,
    2357,
    2157,
    2288,
    2412,
    2261,
    2447,
    2551,
    2625,
    2133,
    2485,
    2264,
    2301,
    2390,
    2394,
    2431,
    1885,
    2340,
    2285,
    2148
  ]
}