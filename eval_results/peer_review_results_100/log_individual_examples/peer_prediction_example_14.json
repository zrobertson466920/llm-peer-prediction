{
  "example_idx": 14,
  "reference": "Published as a conference paper at ICLR 2023\n\nVALID P -VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\n\nDaiki Miwa⇤ Nagoya Institute of Technology miwa.daiki.mllab.nit@gmail.com\n\nVo Nguyen Le Duy⇤ RIKEN duy.vo@riken.jp\n\nIchiro Takeuchi† Nagoya University and RIKEN ichiro.takeuchi@mae.nagoya-u.ac.jp\n\nABSTRACT\n\nVarious saliency map methods have been proposed to interpret and explain predictions of deep learning models. Saliency maps allow us to interpret which parts of the input signals have a strong influence on the prediction results. However, since a saliency map is obtained by complex computations in deep learning models, it is often difficult to know how reliable the saliency map itself is. In this study, we propose a method to quantify the reliability of a salient region in the form of p-values. Our idea is to consider a salient region as a selected hypothesis by the trained deep learning model and employ the selective inference framework. The proposed method can provably control the probability of false positive detections of salient regions. We demonstrate the validity of the proposed method through numerical examples in synthetic and real datasets. Furthermore, we develop a Keras-based framework for conducting the proposed selective inference for a wide class of CNNs without additional implementation cost.\n\n1\n\nINTRODUCTION\n\nDeep neural networks (DNNs) have exhibited remarkable predictive performance in numerous practical applications in various domains owing to their ability to automatically discover the representations needed for prediction tasks from the provided data. To ensure that the decision-making process of DNNs is transparent and easy to understand, it is crucial to effectively explain and interpret DNN representations. For example, in image classification tasks, obtaining salient regions allows us to explain which parts of the input image strongly influence the classification results.\n\nSeveral saliency map methods have been proposed to explain and interpret the predictions of DNN models (Ribeiro et al., 2016; Bach et al., 2015; Doshi-Velez & Kim, 2017; Lundberg & Lee, 2017; Zhou et al., 2016; Selvaraju et al., 2017). However, the results obtained from saliency methods are fragile (Kindermans et al., 2017; Ghorbani et al., 2019; Melis & Jaakkola, 2018; Zhang et al., 2020; Dombrowski et al., 2019; Heo et al., 2019). Therefore, it is important to develop a method for quantifying the reliability of DNN-driven salient regions.\n\nOur idea is to interpret salient regions as hypotheses driven by a trained DNN model and employ a statistical hypothesis testing framework. We use the p-value as a criterion to quantify the statistical reliability of the DNN-driven hypotheses. Unfortunately, constructing a valid statistical test for DNN-driven salient regions is challenging because of the selection bias. In other words, because the trained DNN selects the salient region based on the provided data, the post-selection assessment of importance is biased upwards.\n\nTo correct the selection bias and compute valid p-values for DNN-driven salient regions, we introduce a conditional selective inference (SI) approach. The selection bias is corrected by conditional\n\n⇤Equal contribution †Corresponding author\n\n1\n\nPublished as a conference paper at ICLR 2023\n\nInput Image\n\nSaliency Map\n\nSalient Region\n\nReference Image\n\nTwo-sample Test\n\n(a) Image without tumor region. The naive-p = 0.00 (wrong detection) and selective-p = 0.43 (true negative)\n\nInput Image\n\nSaliency Map\n\nSalient Region\n\nReference Image\n\nTwo-sample Test\n\n(b) Image with tumor region. The naive-p = 0.00 (true positive) and selective-p = 0.00 (true positive)\n\nFigure 1: Examples of the problem setup and the proposed method on the brain tumor dataset. By applying a saliency method called CAM (Zhou et al., 2016) on a query input image, we obtain the salient region. Our goal is to provide the statistical significance of the salient region in the form of p-value by considering two-sample test between the salient region and the corresponding region in the reference image. Note that, since the salient region is selected based on the data, the degree of saliency in the selected region is biased upward. In the upper image where there is no true brain tumor, the naive p-value which is obtained without caring about the selection bias is nearly zero, indicating the false positive finding of the salient region. On the other hand, the selective p-value which is obtained by the proposed conditional SI approach is 0.43, indicating that the selected saliency region is not statistically significant. In the lower image where there is a true brain tumor, both the naive p-value and the selective p-value are very small, which indicate a true positive finding. These results illustrate that naive p-value cannot be used to quantify the reliability of DNN-based salient region. In contrast, with the selective p-values, we can successfully identify false positive and true positive detections with a desired error rate.\n\nSI in which the test statistic conditional on the event that the hypotheses (salient regions) are selected using the trained DNNs is considered. Our main technical contribution is to develop a method for explicitly deriving the exact (non-asymptotic) conditional sampling distribution of the salient region for a wide class convolutional neural networks (CNNs), which enables us to conduct conditional SI and compute valid p-values. Figure 1 presents an example of the problem setup.\n\nRelated works. In this study, we focus on statistical hypothesis testing for post-hoc analysis, i.e., quantifying the statistical significance of the salient regions identified in a trained DNN model when a test input instance is fed into the model. Several methods have been developed to visualize and understand trained DNNs. Many of these post-hoc approaches (Mahendran & Vedaldi, 2015; Zeiler & Fergus, 2014; Dosovitskiy & Brox, 2016; Simonyan et al., 2013) have focused on developing visualization tools for saliency maps given a trained DNN. Other methods have aimed to identify the discriminative regions in an input image given a trained network (Selvaraju et al., 2017; Fong & Vedaldi, 2017; Zhou et al., 2016; Lundberg & Lee, 2017). However, some recent studies have shown that many of these saliency methods of these saliency methods are not stable against a perturbation or adversarial attack on the input data and model (Kindermans et al., 2017; Ghorbani et al., 2019; Melis & Jaakkola, 2018; Zhang et al., 2020; Dombrowski et al., 2019; Heo et al., 2019). To the best of our knowledge, no study to date has succeeded in quantitatively evaluating the reproducibility of DNN-driven salient regions with a rigorous statistical inference framework.\n\nIn recent years, conditional SI has emerged as a promising approach for evaluating the statistical reliability of data-driven hypotheses. It has been actively studied for making inferences on the features of linear models selected by various feature selection methods, such as Lasso (Lee et al., 2016). The main concept behind conditional SI is to make inference based on the sampling distribution of the test statistic conditional on a selection event. This approach allows us to derive the exact sampling distribution of the test statistic. After the seminal work of Lee et al. (2016), conditional SI has also\n\n2\n\nPublished as a conference paper at ICLR 2023\n\nbeen applied to a wide range of problems (Loftus, 2015; Choi et al., 2017; Tian & Taylor, 2018; Yang et al., 2016; Tibshirani et al., 2016; Fithian et al., 2014; Loftus & Taylor, 2014; Panigrahi et al., 2016; Sugiyama et al., 2021a; Hyun et al., 2021; Duy & Takeuchi, 2021a;b; Sugiyama et al., 2021b; Chen & Bien, 2019; Tsukurimichi et al., 2021; Tanizaki et al., 2020; Duy et al., 2020; 2022).\n\nThe most relevant existing work is Duy et al. (2022), where the authors provide a framework to compute valid p-values for DNN-based image segmentation results. In Duy et al. (2022), the authors only considered the inference on the output of a DNN in a segmentation task. In this paper, we address a more general problem in which the hypotheses characterized by any internal nodes of the DNN can be considered. This enables us to quantify the statistical significance of salient regions. Furthermore, we introduce a Keras-based implementation framework that enables us to conduct SI for a wide class of CNNs without additional implementation costs. This is in contrast to Duy et al. (2022) in which the selection event must be implemented when the network architecture is changed.\n\nIn another direction, Burns et al. (2020) considered the black box model interpretability as a multiple hypothesis testing problem. Their goal was to identify important features by testing the significance of the difference between the prediction and the expected outcome when certain features are replaced with their counterfactuals. However, this approach faces a significant challenge: the number of hypotheses to be considered can be very large (e.g., in the case of an image with n pixels, the number of possible salient regions is 2n). Multiple testing correction methods, such as the Bonferroni correction, are highly conservative when the number of hypotheses is large. To address the challenge, they only considered a tractable number of regions selected by a human expert or object detector, which causes selection bias because the candidate regions are selected based on the data.\n\nContribution. Our main contributions are as follows:\n\nWe provide an exact (non-asymptotic) inference method for salient regions obtained by CAM •\nbased on the SI concept. We introduce valid p-values to statistically quantify the reliability of the DNN-driven salient regions inspired by Duy et al. (2022).\n\nWe propose a novel algorithm and its implementation. Specifically, we propose Keras-based im- •\nplementation which enables us to conduct conditional SI for a wide class of CNNs without additional implementation costs.\n\nWe conducted experiments on synthetic and real-world datasets, through which we show that our •\nproposed method can control the false positive rate, has good performance in terms of computational efficiency, and provides good results in practical applications. Our code is available at\n\nhttps://github.com/takeuchi-lab/selective inference dnn salient region.\n\n2 PROBLEM FORMULATION\n\nIn this paper, we consider the problem of quantifying the statistical significance of the salient regions identified by a trained DNN model when a test input instance is fed into the model. Consider an n-dimensional query input vector\n\nand an n-dimensional reference input vector,\n\nX = (X1, ..., Xn)> = s + \", \"\n\nN(0, 2In)\n\n⇠\n\nX ref = (X ref\n\n1 , ..., X ref\n\nn )> = sref + \"ref , \"ref\n\nN(0, 2In),\n\n⇠\n\n2\n\nRn are the signals and \", \"ref\n\nRn are the noises for query and reference input where s, sref 2\nvectors, respectively. We assume that the signals, s and sref are unknown, whereas the distribution of noises \" and \"ref are known (or can be estimated from external independent data) to follow N(0, 2In), an n-dimensional normal distribution with a mean vector 0 and covariance matrix 2In, which are mutually independent. In the illustrative example presented in §1, X is a query brain image for a potential patient (we do not know whether she/he has a brain tumor), whereas X ref is a brain image of a healthy person without brain tumors.\n\nConsider a saliency method for a trained CNN. We denote the saliency method as a function Rn\n\nRn that takes a query input vector X\n\nRn and returns the saliency map\n\n: A\nRn. We\n\n(X)\n\nA\n\n2\n\n!\n\n2\n\n3\n\nPublished as a conference paper at ICLR 2023\n\ndefine a salient region value is greater than a threshold\n\nMX for the query input vector X as the set of elements whose saliency map\n\nAi(X) where ⌧ R denotes the given threshold. In this study, we consider CAM (Zhou et al., 2016) as an example of saliency method and threshold-based definition of the salient region. Our method can be applied to other saliency methods and other definitions of salient region.\n\nMX =\n\n[n] :\n\n(1)\n\n2\n\n2\n\n{\n\n}\n\n⌧\n\ni\n\n,\n\nStatistical inference. To quantify the statistical significance of the saliency region sider a two-sample test for the difference between the salient regions of the query input vector X and corresponding region of the reference input vector X ref indexed by X. As examples of the two-sample test, we consider the mean null test:\n\nMX , we conMX is a sub-vector of X\n\nMX where X\n\nMX\n\n1\n\nH0 :\n\n|MX | Xi\n\n2MX and global null test:\n\nsi =\n\n1\n\n|MX | Xi\n\n2MX\n\nsref\n\ni\n\nv.s. H1 :\n\n1\n\n|MX | Xi\n\n2MX\n\n=\n\nsi 6\n\n1\n\n|MX | Xi\n\n2MX\n\nsref\n\ni\n\n, (2)\n\nH0 : si = sref\n\ni\n\n,\n\ni\n\n2M X ,\n\nv.s. H1 : si 6 In the mean null test in Eq. (2), we consider a null hypothesis that the average signals in the salient MX are the same between X and X ref . In contrast, in the global null test in Eq. (3), we region consider a null hypothesis that all elements of the signals in the salient region MX are the same between X and X ref . The p-values for these two-sample tests can be used to quantify the statistical significance of the salient region\n\n2M X .\n\n(3)\n\n8\n\n9\n\ni\n\n,\n\ni\n\n= sref\n\nMX .\n\nTest-statistic. For a two-sample test conducted between X test statistics called conditionally linear test-statistic, which is expressed as\n\nMX and X ref\n\nMX , we consider a class of\n\nand conditionally  test-statistic, which is expressed as\n\nT (X, X ref ) = ⌘>\n\nMX\n\nX X ref\n\n,\n\n◆\n\n✓\n\nT (X, X ref ) = \n\n1\n\nP\n\nX X ref\n\nMX\n\n(4)\n\n(5)\n\n,\n\n \n2n is a projection matrix that depends on where ⌘ \n⇥ \nThe test statistics for the mean null tests and the global null test can be written in the form of Eqs. (4) and (5), respectively. For the mean null test in Eq. (2), we consider the following test-statistic\n\nR2n is a vector and P\n\nMX .\n\n◆ \n \n\nMX 2\n\nMX 2\n\nR2n\n\n✓\n\nT (X, X ref ) = ⌘>\n\nMX\n\nwhere ⌘\n\nMX = 1\n\nbelongs to the set following test-statistic\n\n|MX | ✓ C\n\n1n MX 1n MX ◆\n\nX X ref\n\n✓\n\n=\n\n◆\n\n1\n\n|MX | Xi\n\n2MX\n\nXi \n\n1\n\n|MX | Xi\n\n2MX\n\nX ref\n\ni\n\n,\n\nR2n with 1n\n\nC\n\n2\n\nbeing the n-dimensional vector whose elements\n\nare set to 1, and 0 otherwise. For the global null test in Eq. (3), we consider the\n\nT (X, X ref ) = \n\n1\n\nP\n\nX X ref\n\nMX\n\n✓\n\n \n diag(1n \n diag(1n\n\n=\n\nv u\nu t\n\ndiag(1n diag(1n\n\n)\n\nMX = 1\n\nwhere P\n\n2\n\nMX\n\nMX )\nwe need to know the sampling distribution of the test-statistics. Unfortunately, it is challenging to derive the sampling distributions of test-statistics because they depend on the salient region which is obtained through a complicated calculation in the trained CNN.\n\nMX ,\n\nMX\n\nMX\n\n✓\n\n◆\n\n)\n\n2MX ✓ Xi\n\n◆ \n \n. To obtain p-values for these two-sample tests\n\n◆\n\n)\n\nXi \n\nX ref i\n\np2\n\n2\n\n,\n\n3 COMPUTING VALID p-VALUE BY CONDITIONAL SELECTIVE INFERENCE\n\nIn this section, we introduce an approach to compute the valid p-values for the two-sample tests for the salient region on the concept of conditional SI (Lee et al., 2016).\n\nMX between the query input vector X and the reference input vector X ref based\n\n4\n\nPublished as a conference paper at ICLR 2023\n\n3.1 CONDITIONAL DISTRIBUTION AND SELECTIVE p-VALUE\n\nConditional distribution. The basic idea of conditional SI is to consider the sampling distribution of the test-statistic conditional on a selection event. Specifically, we consider the sampling property of the following conditional distribution\n\nT (X, X ref)\n\n{MX =\n\nMXobs }\n\n,\n\n(6)\n\nwhere Xobs is the observation (realization) of random vector X. The condition in Eq.(6) indicates the randomness of X conditional on the event that the same salient region MX as the observed MX , derivation of the sampling distriMX obs is obtained. By conditioning on the salient region bution of the conditionally linear and  test-statistic T (X, X ref ) is reduced to a derivation of the distribution of linear function and quadratic function of (X, X ref ), respectively.\n\n \n\nSelective p-value. After considering the conditional sampling distribution in (6), we introduce the following selective p-value:\n\npselective = PH0\n\nT (X, X ref )\n\nT (Xobs, X ref\n\nobs)\n\nwhere\n\n⇣  \n\nMX =\n\nMXobs ,\n\nQX,X ref =\n\nQobs\n\n,\n\n(7)\n\n⌘\n\n \n\n \n\n \n\n \n\nQX,X ref =⌦ X,X ref , MX ⌘> ⌘\nMX k k\n\nX X ref\n\nMX 2\n\n2\n\n⌘\n\n◆\n\nVX,X ref ,\n\n UX,X ref\n\n,\n\nwith ⌦X,X ref =\n\n✓\n\nI2n  QX,X ref =\n\nQobs =\n\nQXobs,X ref R2n in the case of mean null test, and\n\nobs\n\nwith\n\nVX,X ref = P\n\nR2n in the QX,X ref is the sufficient statistic of the nuisance parameter that needs case of global null test. The . \nto be conditioned on in order to tractably conduct the inference 1. \n\nR2n,\n\n \n\nMX\n\nMX\n\nMX\n\n2\n\n2\n\nP\n\nX X ref\n\nX X ref\n\nX X ref\n\nThe selective p-value in Eq.(7) has the following desired sampling property\n\nPH0\n\npselective \n\n↵\n\n| MX =\n\nMXobs\n\n= ↵,\n\n↵\n\n8\n\n2\n\n[0, 1].\n\n(8)\n\nThis means that the selective p-values pselective can be used as a valid statistical significance measure for the salient region\n\n⌘\n\n⇣\n\nMX .\n\n3.2 CHARACTERIZATION OF THE CONDITIONAL DATA SPACE\n\nQobs =\n\nQXobs,X ref UX,X ref = P ?\n\nobs\n\n2\n\nD\n\nTo compute the selective p-value in (7), we need to characterize the conditional data space whose characterization is described and introduced in the next section. We define the set of (X > X ref > )>\n\nR2n that satisfies the conditions in Eq. (7) as\n\n=\n\n(X > X ref > )>\n\n2n\n\nR\n\n2\n\nMX =\n\nMXobs QX,X ref =\n\nQobs\n\n.\n\n(9)\n\nis restricted to a line in R2n as stated in the\n\no\n\nn\n\nAccording to the second condition, the data in following Lemma. Lemma 1. Let us define a =⌦ Xobs,X ref and a =\n\nand b =\n\nobs\n\n \n\nD\n\nUXobs,X ref =\n\nobs\n\nD\n\nn\n\nVXobs,X ref > = a + bz\n\nobs\n\nz\n\n2Z\n\n|\n\no\n\n| Ma1:n+b1:n z = Z\nwith x1:n representing a vector of elements 1 through n of x.\n\n= \n\nR\n\n2\n\n{\n\nz\n\nMXobs }\n\n.\n\nrewritten as\n\nX > X ref >\n\nby using the scalar parameter z\n\nand b =\n\n2 2 in the case of global null test. The\n\nR2n in the case of mean null test, in (9) can be\n\nMX MX k\n\nk\n\n⌘ ⌘\n\nD\n\nR, where\n\n2\n\n(10)\n\n1This nuisance parameter\n\nQX,Xref corresponds to the component z in the seminal conditional SI paper (Lee et al., 2016) (see Sec. 5, Eq. 5.2 and Theorem 5.2) and z, w in (Chen & Bien, 2019)(see Sec. 3, Theorem 3.7). We note that additional conditioning on QX,Xref is a standard approach in the conditional SI literature and is used in almost all conditional SI-related studies. Here, we would like to note that the selective p-value QX,Xref , but the property in (8) is satisfied without this additional condition because we can depends on marginalize over all values of QX,Xref (see the lower part of the proof of Theorem 5.2 in Lee et al. (2016) and the proof of Theorem 3.7 in Chen & Bien (2019) ).\n\n5\n\n Published as a conference paper at ICLR 2023\n\nProof. The proof is deferred to Appendix A.1.\n\nLemma 1 indicates that we do not need to consider the 2n-dimensional data space. Instead, we only need to consider the one-dimensional projected data space in (10). Now, let us consider a R that satisfies (X > X ref > )> = a + bZ and random variable Z (X >obs X ref >\n\nobs )> = a + bZobs. The selective p-value (7) is rewritten as\n\nR and its observation Zobs 2\n\nZ\n\n2\n\npselective = PH0 (\n\nZ\n\n|\n\n||\n\nZobs| |\n\nZ\n\n2Z\n\n) .\n\n(11)\n\nN\n\n⇠ N(0, 2\n\nBecause (X > X ref > )>\n\ns> sref >\n\n> , 2I2n\n\ndue to the independence between X and\n\nX ref , the variable Z  (Trace(P )) in the case of global null test under the null hypothesis. Therefore, Z follows a truncated normal distribution and a truncated  distribution, respectively. Once the truncation region is identified, computation of the selective p-value in (11) is straightforward. Therefore, the remaining task is to identify\n\n◆ 2) in the case of mean null test and Z\n\n✓⇣ ⌘\nk\n\n2Z\n\n⇠\n\n⇠\n\nZ\n\nZ\n\n⌘\n\nk\n\n|\n\n.\n\nZ\n\n4 PIECEWISE LINEAR NETWORK\n\nThe problem of computing selective p-values for the selected salient region is cast into the problem | MX(z) = of identifying a set of intervals . Given the complexity of saliency . In this section, however, we show that computation in a trained DNN, it seems difficult to obtain this is feasible for a wide class of CNNs.\n\nMXobs }\n\n=\n\nZ\n\nZ\n\nR\n\n2\n\n{\n\nz\n\nPiecewise linear components in CNN. The key idea is to note that most of basic operations and common activation functions used in a trained CNN can be represented as piecewise linear functions in the following form: Definition 1. (Piecewise Linear Function) A piecewise linear function f : Rn\n\nRm is written as:\n\nif X if X\n\n2P 2P\n\nf\n\n1 := 2 :=\n\nf\n\nX 0 X 0\n\n{ {\n\n2 2\n\nRn Rn\n\n| |\n\nf f\n\n1 X 0 2 X 0\n\n \n\n! f f\n\n1 } 2 }\n\n, ,\n\nf (X) =\n\n f f\n\n1 X + f 1 , 2 X + f 2 , ... K(f )X + f\n\n8\n\n f\n\n>>>>< >>>>: k , f k :=\n\nK(f ),\n\nif X\n\nf\n\nK(f ) :=\n\nX 0\n\n{\n\n2\n\nRn\n\n|\n\nf\n\nK(f )X 0\n\nf\n\nK(f )}\n\n,\n\n\n\n2P\n\nk, f\n\nwhere f dimensions, \nnumber of polytopes for the function f .\n\nk and f k for k f Rn x\n\n2 kx\n\nP\n\n2\n\n{\n\n|\n\nf\n\nk }\n\n[K(f )] are certain matrices and vectors with appropriate [K(f )], and K(f ) is the\n\nis a polytope in Rn for k\n\nf\n\n2\n\nExamples of piecewise linear components in a trained CNN are shown in Appendix A.2.\n\nPiecewise Linear Network. Definition 2. (Piecewise Linear Network) A network obtained by concatenations and compositions of piecewise linear functions is called piecewise linear network.\n\nSince the concatenation and the composition of piecewise linear functions is clearly piecewise linear function, the output of any node in the piecewise linear network is written as a piecewise linear Ai(X), i function of an input vector X. This is also true for the saliency map function [n] obtained by CAM. Furthermore, as discussed in §4, we can focus on the input vector in the form of X(z) = a1:n + b1:nz which is parametrized by a scalar parameter z R. Therefore, the saliency map value for each element is written as a piecewise linear function of the scalar parameter z, i.e.,\n\n2\n\n2\n\nAi(X(z)) =\n\n8\n\n>>>>< >>>>:\n\nAi Ai\n\n1 , 1 z + ⇢Ai 2 z + ⇢Ai 2 , ... Ai)z + ⇢f\n\nAi K(\n\nK(\n\nif z if z\n\n2 2\n\n[LAi [LAi\n\n1 , U Ai 2 , U Ai\n\n1 ], 2 ],\n\n,\n\n(12)\n\nAi),\n\nif z\n\n[LAi K(\n\nAi), U Ai\n\nK(\n\nAi)],\n\n2\n\n6\n\nPublished as a conference paper at ICLR 2023\n\nLemma 1 and initialize: t = 1, zt = zmin\n\n[zt, zt+1] (by using Eq.(13)) then\n\nCompute zt+1 by Auto-Conditioning (see §5)\n\n\n\nT ;\n\nEobs, compute ⌘ as well as a and b T do\n\nAlgorithm 1 SI DNN Saliency Input: X obs, zmin, zmax, 1: Obtain 2: for t 3: 4: 5: 6: 7: 8: end for 9: Identify 10: pselective \n\nEX(z),Xref (z) =\n\n2T Eq. (11) S\n\nEobs in z\n\n[zt, zt+1]\n\nt = t + 1\n\nend if\n\nT T\n\nZ \n\n+\n\n2\n\nif\n\n{\n\n}\n\nt\n\nt\n\nOutput: pselective\n\nAi) is the number of linear pieces of the piecewise linear function, Ai\n\nwhere K( scalar parameters, [LAi to an interval when it is projected onto one-dimensional space).\n\nk ] are intervals for k\n\nAi)] (note that a polytope in Rn is reduced\n\nare certain\n\nk , U Ai\n\nk ,⇢ Ai\n\n[K(\n\n2\n\nk\n\nThis means that, for each piece of the piecewise linear function, we can identify the interval of z such that\n\n⌧ as follows 2\n\nAi(X(z))\n\nmax\n\n k , LAi\n\nh\n\nLAi\n\n⇣ k , min\n\nz\n\n2 8 <\n\n(13)\n\nR\n\n2\n\n⌧\n\n ⇣\nk , U Ai\n\n⇢Ai k\n\n/Ai k\n\n, U Ai\n\nk\n\n⌧\n\n⌘ \n\n⇢Ai k\n\n⌘ /Ai k\n\ni\n\n,\n\nif Ai\n\nk > 0\n\nk < 0 )A i(X(z))\n\nif Ai\n\n⌧.\n\nh\n\n⌘ With a slight abuse of notation, let us collectively denote the finite number of intervals on z that are defined by LAi\n\n[n] as\n\n[K(\n\n⇢Ai\n\n:\n\n⌘\n\n⇣\n\n⇣\n\ni\n\nk , U Ai\n\nk , (⌧\n\n [z0, z1], [z1, z2], . . . , [zt\n\ni /Ai\n\nk ) for all (k, i)\n\nAi)] 1, zt], [zt, zt+1], . . . , [zT\n\n2\n\n⇥\n\n1, zT ],\n\nwhere zmin = z0 and zmax = zT are defined such that the probability mass of z < zmin and z > zmax are negligibly small.\n\nz\n\n{\n\nR\n\nZ\n\n=\n\nEq.(10) is given as\n\nMX(zobs) or not in the interval by using Eq.(13). Then, the truncation region\n\nAlgorithm. Algorithm 1 shows how we identify We simply check the intervals of z in the order of [z0, z1], [z1, z2], ..., [zT MX(z) =\n\n. Mobs} 1, zT ] to see whether in [zt,zt+1][zt, zt+1]. In the literature of homoEobs for z topy method (a.k.a. parametric programming), it is known that the actual computational cost differs significantly from the worst case. A well-known application of the homotopy method in the ML community is the Lasso regularization path, which also has the worst-case computational cost on the exponential order of the number of features, but the actual cost is known to be nearly linear order. Empirically, this also applies to our proposed method.\n\n| MX(z),X ref (z) =\n\n|EX(z),Xref (z)=\n\nS\n\n=\n\nZ\n\nZ\n\n[T ]\n\n2\n\n2\n\n2\n\nt\n\n5\n\nIMPLEMENTATION: AUTO-CONDITIONING\n\nThe bottleneck of our algorithm is Line 3 in Algorithm 1, where zt+1 must be found by considering all relevant piecewise linear components in a complicated trained CNN. The difficulty lies not only in the computational cost but also in the implementation cost. To implement conditional SI in DNNs naively, it is necessary to characterize all operations at each layer of the network as selection events and implement each of them specifically (Duy et al., 2022). To circumvent this difficulty, we introduce a modular implementation scheme called auto-conditioning, which is similar to autodifferentiation (Baydin et al., 2018) in concept. This enables us to conduct conditional SI for a wide class of CNNs without additional implementation costs.\n\nThe basic idea in auto-conditioning is to add a mechanism to compute and maintain the interval k ] for each piecewise linear component f in the network (e.g., layer API in the Keras z\n\nk, U f\n\n[Lf\n\n2 2For simplicity, we omit the description for the case of Ai k , U Ai k ]\n\ni\n\n[LAi\n\n2M X(z).\n\n)\n\nk = 0. In this case, if ⇢Ai\n\nk \n\n⌧ , then z\n\n2\n\n7\n\n Published as a conference paper at ICLR 2023\n\nframework). This enables us to automatically compute the interval [Lf k ] of a piecewise linear function f when it is obtained as concatenation and/or composition of multiple piecewise linear components. If f is obtained by concatenating two piecewise linear functions f1 and f2, we can easily obtain [Lf ]. However, if f is obtained as a composition of two piecewise linear functions f1 and f2, the calculation of the interval is given by the following lemma. Lemma 2. Consider the composition of two piecewise linear functions f (X(z)) = (f2 f1)(X(z)). k , U f2 Given a real value of z, the interval [Lf2 f1 )j\n\nk ] in the input domain of f2 can be computed as\n\nk ] = [Lf1\n\nk, U f\n\nk, U f\n\nf1 )j\n\n, U f2\n\n, U f1\n\n(f2\n\n(f2\n\n[Lf2\n\n(f2\n\n(f2\n\n\\\n\nk2\n\nk1\n\nk1\n\nk2\n\n]\n\nLf2\n\nk2\n\n=\n\nmax\n\nj:(f2 k2\n\n f1 )j <0\n\nk2\n\n)j  (f2\n\nk2\n\nk2 f1 )j\n\n,\n\nU f2\n\nk2\n\n=\n\nmin\n\nj:(f2 k2\n\n f1 )j >0\n\nk2\n\n)j  (f2\n\nk2\n\nk2 f1 )j\n\n,\n\nwhere f1 + f1 z is the output of f1 (i.e., the input of f2). Moreover, f2 are obtained by verifying the value of f1 + f1 z. Then, the interval of the composite function is obtained as follows: [Lf\n\nand f2\n\n, U f1\n\n, U f2\n\n[Lf2\n\nk2\n\nk2\n\n]\n\n]\n\nk, U f\n\nk ] = [Lf1\n\nk1\n\nk2\n\nk2\n\nk1\n\n\\\n\nThe proof is provided in Appendix A.3. Here, the variables fk and fk can be recursively computed through layers as\n\nfk+1 = fk\n\nk fk + fk\n\nk\n\nand fk+1 = fk\n\nk fk .\n\nLemma 2 indicates that the intervals in which X(z) falls in can be forwardly propagated through these layers. This means that the lower bound LAi k of the current piece in the piecewise linear function in Eq. (12) can be automatically computed by forward propagation of the intervals of the relevant piecewise linear components.\n\nk and upper bound U Ai\n\n6 EXPERIMENT\n\nWe only highlight the main results. More details (methods for comparison, network structure, etc.) can be found in the Appendix A.4.\n\nExperimental setup. We compared our proposed method with the naive method, over-conditioning (OC) method, and Bonferroni correction. To investigate the false positive rate (FPR), we considered 1000 null images X = (X1, ..., Xn) and 1000 reference images X ref = (X ref n ), where s = sref = 0 and \", \"ref . To investigate the true positive rate (TPR), we set n = 256 and generated 1,000 images, in which si = for any i ,\nis the “true” salient region whose location is randomly determined, and si = 0 for any where i\n. Reference images were generated in the same way as in the case of FPR. In all experiments, we set ⌧ = 0 in the mean null test and ⌧ = 5 in the global null test. We set the significance level ↵ = 0.05. We used CAM as the saliency method in all experiments.\n\nN(0, In), for each n\n\n64, 256, 1024, 4096\n\n1 , ..., xref\n\n. We set \n\n1, 2, 3, 4\n\n62 S\n\n2S\n\n2{\n\n2{\n\n⇠\n\nS\n\n}\n\n}\n\nNumerical results. The results of FPR control properties are presented in Fig. 2. The proposed method, OC, and Bonferroni successfully controlled the FPR in both the mean and global null test cases, whereas the naive method could not. Because naive method failed to control the FPR, we no longer considered its TPR. The results of the TPR comparison are shown in Fig. 3. The proposed method has the highest TPR in all cases. The Bonferroni method has the lowest TPR because it is conservative owing to considering the number of all possible hypotheses. The OC method also has a low TPR because it considers several extra conditions, which cause the loss of TPR.\n\nReal data experiments. We examined the brain image dataset extracted from the dataset used in Buda et al. (2019), which included 939 and 941 images with and without tumors, respectively. The results of the mean null test are presented in Figs. 4 and 5. The results of the global null test are presented in Figs. 6 and 7. The naive p-value remains small even when the image has no tumor region, which indicates that naive p-values cannot be used to quantify the reliability of DNN-based salient regions. The proposed method successfully identified false and true positive detections.\n\n7 CONCLUSION\n\nIn this study, we proposed a novel method to conduct statistical inference on the significance of DNN-driven salient regions based on the concept of conditional SI. We provided a novel algorithm\n\n8\n\nPublished as a conference paper at ICLR 2023\n\n(a) Mean null test\n\n(b) Global null test\n\n(a) Mean null test\n\n(b) Global null test\n\nFigure 2: False Positive Rate (FPR) comparison.\n\nFigure 3: True Positive Rate (FPR) comparison.\n\nInput Image\n\nSaliency Map\n\nSalient Region\n\nReference Region\n\nReference Image\n\nFigure 4: Mean null test for image without tumor (pnaive = 0.00, pselective = 0.78).\n\nInput Image\n\nSaliency Map\n\nSalient Region\n\nReference Region\n\nReference Image\n\nFigure 5: Mean null test for image with a tumor (pnaive = 0.00, pselective = 1.92\n\n10\n\n4).\n\n⇥\n\nInput Image\n\nSaliency Map\n\nSalient Region\n\nReference Region\n\nReference Image\n\nFigure 6: Global null test for image without tumor (pnaive = 0.03, pselective = 0.46)\n\nInput Image\n\nSaliency Map\n\nSalient Region\n\nReference Region\n\nReference Image\n\nFigure 7: Global null test for image with a tumor (pnaive = 0.00, pselective = 1.51\n\n10\n\n3).\n\n⇥\n\nfor efficiently and flexibly conducting conditional SI for salient regions. We conducted experiments on both synthetic and real-world datasets to demonstrate the performance of the proposed method. In current setting, we have not considered the situations where there is a misalignment between the input image and the reference image. A potential future improvement could be additionally performing a step to automatically find an appropriate region in the reference image before conducting a statistical test. If the matching operations can be represented as a set of linear inequalities, they can be easily incorporated to the proposed method. If the matching operations can be represented as a set of linear inequalities, they can be easily incorporated to the proposed method.\n\n9\n\nPublished as a conference paper at ICLR 2023\n\nACKNOWLEDGEMENTS\n\nThis work was partially supported by MEXT KAKENHI (20H00601), JST CREST (JPMJCR21D3), JST Moonshot R&D (JPMJMS2033-05), JST AIP Acceleration Research (JPMJCR21U2), NEDO (JPNP18002, JPNP20006), and RIKEN Center for Advanced Intelligence Project.\n\nREFERENCES\n\nSebastian Bach, Alexander Binder, Gr ́egoire Montavon, Frederick Klauschen, Klaus-Robert M ̈uller, and Wojciech Samek. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation. PloS one, 10(7):e0130140, 2015.\n\nAtilim Gunes Baydin, Barak A Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. Automatic differentiation in machine learning: a survey. Journal of Marchine Learning Research, 18:1–43, 2018.\n\nMateusz Buda, Ashirbani Saha, and Maciej A Mazurowski. Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm. Computers in biology and medicine, 109:218–225, 2019.\n\nCollin Burns, Jesse Thomason, and Wesley Tansey. Interpreting black box models via hypothesis testing. In Proceedings of the 2020 ACM-IMS on Foundations of Data Science Conference, pp. 47–57, 2020.\n\nShuxiao Chen and Jacob Bien. Valid inference corrected for outlier removal. Journal of Computa-\n\ntional and Graphical Statistics, pp. 1–12, 2019.\n\nYunjin Choi, Jonathan Taylor, and Robert Tibshirani. Selecting the number of principal components: Estimation of the true rank of a noisy matrix. The Annals of Statistics, 45(6):2590–2617, 2017.\n\nAnn-Kathrin Dombrowski, Maximillian Alber, Christopher Anders, Marcel Ackermann, KlausRobert M ̈uller, and Pan Kessel. Explanations can be manipulated and geometry is to blame. In Advances in Neural Information Processing Systems, pp. 13589–13600, 2019.\n\nFinale Doshi-Velez and Been Kim. Towards a rigorous science of interpretable machine learning.\n\narXiv preprint arXiv:1702.08608, 2017.\n\nAlexey Dosovitskiy and Thomas Brox.\n\nInverting visual representations with convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 4829–4837, 2016.\n\nVo Nguyen Le Duy and Ichiro Takeuchi. More powerful conditional selective inference for gener-\n\nalized lasso by parametric programming. arXiv preprint arXiv:2105.04920, 2021a.\n\nVo Nguyen Le Duy and Ichiro Takeuchi. Parametric programming approach for more powerful and general lasso selective inference. In International Conference on Artificial Intelligence and Statistics, pp. 901–909. PMLR, 2021b.\n\nVo Nguyen Le Duy, Hiroki Toda, Ryota Sugiyama, and Ichiro Takeuchi. Computing valid p-value In Advances in\n\nfor optimal changepoint by selective inference using dynamic programming. Neural Information Processing Systems, pp. 11356–11367, 2020.\n\nVo Nguyen Le Duy, Shogo Iwazaki, and Ichiro Takeuchi. Quantifying statistical significance of neural network-based image segmentation by selective inference. Advances in Neural Information Processing Systems, 2022.\n\nWilliam Fithian, Dennis Sun, and Jonathan Taylor. Optimal inference after model selection. arXiv\n\npreprint arXiv:1410.2597, 2014.\n\nRuth C Fong and Andrea Vedaldi. Interpretable explanations of black boxes by meaningful perturbation. In Proceedings of the IEEE International Conference on Computer Vision, pp. 3429–3437, 2017.\n\n10\n\nPublished as a conference paper at ICLR 2023\n\nAmirata Ghorbani, Abubakar Abid, and James Zou. Interpretation of neural networks is fragile. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 3681–3688, 2019.\n\nJuyeon Heo, Sunghwan Joo, and Taesup Moon. Fooling neural network interpretations via adversarial model manipulation. In Advances in Neural Information Processing Systems, pp. 2925–2936, 2019.\n\nSangwon Hyun, Kevin Z Lin, Max G’Sell, and Ryan J Tibshirani. Post-selection inference for changepoint detection algorithms with application to copy number variation data. Biometrics, 77 (3):1037–1049, 2021.\n\nPieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof T Sch ̈utt, Sven D ̈ahne, Dumitru Erhan, and Been Kim. The (un) reliability of saliency methods. arXiv preprint arXiv:1711.00867, 2017.\n\nDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2014. URL\n\nhttps://arxiv.org/abs/1412.6980.\n\nJason D Lee, Dennis L Sun, Yuekai Sun, and Jonathan E Taylor. Exact post-selection inference,\n\nwith application to the lasso. The Annals of Statistics, 44(3):907–927, 2016.\n\nJoshua R Loftus. Selective inference after cross-validation. arXiv preprint arXiv:1511.08866, 2015.\n\nJoshua R Loftus and Jonathan E Taylor. A significance test for forward stepwise model selection.\n\narXiv preprint arXiv:1405.3920, 2014.\n\nScott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In Advances\n\nin neural information processing systems, pp. 4765–4774, 2017.\n\nAravindh Mahendran and Andrea Vedaldi. Understanding deep image representations by inverting them. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 5188–5196, 2015.\n\nDavid Alvarez Melis and Tommi Jaakkola. Towards robust interpretability with self-explaining neural networks. In Advances in Neural Information Processing Systems, pp. 7775–7784, 2018.\n\nSnigdha Panigrahi, Jonathan Taylor, and Asaf Weinstein. Bayesian post-selection inference in the\n\nlinear model. arXiv preprint arXiv:1605.08824, 28, 2016.\n\nMarco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ” why should i trust you?” explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pp. 1135–1144, 2016.\n\nRamprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE international conference on computer vision, pp. 618–626, 2017.\n\nKaren Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks: Visualising image classification models and saliency maps. arXiv preprint arXiv:1312.6034, 2013.\n\nKazuya Sugiyama, Vo Nguyen Le Duy, and Ichiro Takeuchi. More powerful and general selective inference for stepwise feature selection using the homotopy continuation approach. In Proceedings of the 38th International Conference on Machine Learning, 2021a.\n\nRyota Sugiyama, Hiroki Toda, Vo Nguyen Le Duy, Yu Inatsu, and Ichiro Takeuchi. Valid and exact statistical inference for multi-dimensional multiple change-points by selective inference. arXiv preprint arXiv:2110.08989, 2021b.\n\nKosuke Tanizaki, Noriaki Hashimoto, Yu Inatsu, Hidekata Hontani, and Ichiro Takeuchi. Computing valid p-values for image segmentation by selective inference. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9553–9562, 2020.\n\nXiaoying Tian and Jonathan Taylor. Selective inference with a randomized response. The Annals of\n\nStatistics, 46(2):679–710, 2018.\n\n11\n\nPublished as a conference paper at ICLR 2023\n\nRyan J Tibshirani, Jonathan Taylor, Richard Lockhart, and Robert Tibshirani. Exact post-selection inference for sequential regression procedures. Journal of the American Statistical Association, 111(514):600–620, 2016.\n\nToshiaki Tsukurimichi, Yu Inatsu, Vo Nguyen Le Duy, and Ichiro Takeuchi. Conditional selective inference for robust regression and outlier detection using piecewise-linear homotopy continuation. arXiv preprint arXiv:2104.10840, 2021.\n\nFan Yang, Rina Foygel Barber, Prateek Jain, and John Lafferty. Selective inference for group-sparse linear models. In Advances in Neural Information Processing Systems, pp. 2469–2477, 2016.\n\nMatthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks.\n\nIn\n\nEuropean conference on computer vision, pp. 818–833. Springer, 2014.\n\nXinyang Zhang, Ningfei Wang, Hua Shen, Shouling Ji, Xiapu Luo, and Ting Wang. Interpretable Security 20), 2020.\n\ndeep learning under fire. In 29th\n\nSecurity Symposium (\n\nUSENIX\n\nUSENIX\n\n{\n\n}\n\n{\n\n}\n\nBolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep In Proceedings of the IEEE conference on computer\n\nfeatures for discriminative localization. vision and pattern recognition, pp. 2921–2929, 2016.\n\n12",
  "translations": [
    "# Summary Of The Paper\n\nThis work attempts to shed some light on the reliability of saliency maps.\nSpecifically, the authors propose a conditional Selective Inference (SI) method. The proposed method can provide valid p-values for statistically quantifying the reliability of the salient regions. The proposed method is evaluated on a synthetic dataset and a brain image dataset.\n\n# Strength And Weaknesses\n\nStrengths:\n\n1. This work looks technically sound.\n\n2. The proposed method is correlated to statistical hypothesis tests. This idea is interesting and could be practically useful in some real-world scenarios, e.g., medical applications.\n\nWeaknesses:\n\n1. In this work, the saliency map is presumed to be generated by CAM (Zhou et al., 2016). We don't know how well the proposed method works with other CAM-like saliency map methods (e.g., Grad-Cam). Correspondingly, in the theory part, how the saliency map model A(\\cdot) affects the proposed selective p-value is unclear.\n\n2. How the proposed selective p-value corresponds to the correlation between the salient region and the reference region is unknown. In other words, can the selective p-value be aligned with the visual difference/similarity between salient regions and reference regions? One way to measure the linear correlation coefficient between a model saliency map and an empirical saliency map is to use correlation coefficient (CC). Please refer to \\url{https://saliency.tuebingen.ai/results.html} for more details.  \n\n3. Last but not least, the experiments are less convincing as the proposed method is only evaluated on a synthetic dataset and a small-scale dataset. I cannot tell if the proposed method can work well on other general yet complicated real-world datasets.\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThis paper is well-written in my opinion. The proposed method is novel and provides new insights into saliency map detection. \n\nThe authors discuss the implementation in the paper and provide the code for review. I haven't verified if the experiments in this paper can be reproduced though.\n\n# Summary Of The Review\n\nOverall, I think the proposed conditional Selective Inference method is interesting and insightful. However, my main concern lies in the empirical evidence. It would be better to see more experimental results on other datasets, e.g., a natural image dataset, like CIFAR.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\n\n# Empirical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
    "# Summary Of The Paper\nThe paper \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" by Daiki Miwa, Vo Nguyen Le Duy, and Ichiro Takeuchi addresses the reliability of saliency maps generated by deep learning models, focusing on their interpretability and the potential for selection bias. The authors introduce a novel method for quantifying the reliability of salient regions through conditional selective inference (SI), which allows for the computation of valid p-values while controlling false positive rates. Validation through experiments on both synthetic and real datasets showcases the method's effectiveness in distinguishing significant saliency regions while providing a user-friendly Keras-based implementation for broad applicability.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to statistical inference for saliency maps, which is a critical issue in the interpretability of deep learning models. The introduction of valid p-values offers a significant advancement in the field, addressing the common pitfalls associated with traditional saliency methods. Additionally, the experimental validation demonstrates robust results, particularly in controlling false positive rates and achieving a high true positive rate. However, the paper could benefit from more extensive experiments to further validate the method across diverse datasets and applications. Moreover, while the Keras implementation is a positive aspect, additional details on its practical usage and performance metrics would enhance reproducibility.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodologies, and findings. The quality of writing is high, with comprehensive explanations of statistical concepts and experimental setups. The novel approach to employing conditional selective inference for saliency maps represents a significant contribution to the field, although the reproducibility could be improved with more detailed documentation of the Keras implementation and experimental setup.\n\n# Summary Of The Review\nOverall, this paper presents a meaningful contribution to improving the reliability of saliency maps through a novel statistical approach. The innovative use of conditional selective inference effectively addresses selection bias, and the empirical results support the method's validity. However, the paper would benefit from broader experimental validation and enhanced documentation for reproducibility.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel methodology for quantifying the reliability of salient regions in deep learning models by employing p-values within a statistical testing framework. It addresses the prevalent issue of selection bias inherent in traditional saliency map methods. The proposed approach utilizes conditional selective inference to derive valid p-values for salient regions and demonstrates its effectiveness through both synthetic and real-world datasets, notably a brain image dataset, achieving superior true positive rates and controlled false positive rates compared to existing methods.\n\n# Strength And Weaknesses\nThe paper's strengths include its rigorous statistical framework, which enhances the reliability of saliency assessments, and the practical implementation via a Keras-based framework, facilitating integration with existing CNN architectures. Empirical validation through comprehensive experiments further underscores its effectiveness. However, the method's reliance on specific statistical assumptions regarding input data noise may limit its applicability in varied contexts. Additionally, while the Keras implementation simplifies usage, the underlying conditional selective inference framework may pose challenges for those unfamiliar with statistical methodologies.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and articulates its contributions clearly, making the methodology accessible to readers with a moderate understanding of statistical inference. The quality of the experiments is commendable, providing strong empirical support for the proposed method. The novelty lies in the statistical approach to saliency assessment, which is a relatively unexplored area in deep learning interpretability. The reproducibility of the results is enhanced by the availability of a Keras-based implementation, although the method's complexity may deter some practitioners from effective application.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in interpreting deep learning models by providing a statistically grounded method for assessing salient regions. The combination of theoretical insights and practical implementation offers a valuable contribution to the field, albeit with some limitations regarding generalizability and complexity.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" by Miwa et al. introduces a method for quantifying the reliability of salient regions identified by deep learning models using p-values within a statistical framework. The authors propose a selective inference framework designed to control false positive rates (FPR) when detecting salient regions, which are typically derived from saliency maps. The methodology includes conducting two-sample tests between salient regions of input data and reference data, utilizing conditional selective inference to compute valid p-values. The authors validate their approach through numerical experiments on synthetic data and real datasets, demonstrating improved performance over traditional methods, and provide a user-friendly implementation in Keras for practical application.\n\n# Strength And Weaknesses\nThe main strength of this paper lies in its innovative approach to enhancing the interpretability of deep neural networks (DNNs) by introducing a statistical method to quantify the reliability of salient regions. The selective inference framework effectively addresses the issue of false positives, which is crucial for practical applications in sensitive fields, such as medical imaging. However, a potential weakness is the complexity involved in understanding and implementing the statistical methods proposed, which may limit accessibility for practitioners without a strong statistical background. Additionally, while the validation demonstrates effectiveness, further real-world applications could strengthen the empirical results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the proposed methodology and its significance. The authors provide sufficient detail in their problem formulation and experimental setup, allowing for reproducibility. The novelty of treating salient regions as hypotheses within a statistical framework is significant; however, the mathematical rigor and definitions could be daunting for readers unfamiliar with statistical inference concepts. The provision of a Keras-based implementation adds to the reproducibility of the findings and facilitates broader use of the method in the deep learning community.\n\n# Summary Of The Review\nOverall, the paper presents a novel approach to quantifying the reliability of salient regions in deep learning models through a rigorous statistical framework. While the contributions are significant and the implementation is user-friendly, the complexity of the methodology may hinder its accessibility to a wider audience. Further validation in diverse real-world scenarios would enhance the robustness of the findings.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach for quantifying the reliability of salient regions in deep neural networks (DNNs) using p-values derived from conditional selective inference (SI). This methodology addresses a significant gap in the field of interpretable machine learning by providing a framework that effectively controls the false positive rate of saliency maps. Empirical validation demonstrates its efficacy across various convolutional neural networks (CNNs) with both synthetic and real-world datasets, thereby highlighting its practical applicability.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative methodology that enhances the reliability of saliency maps and its ability to generalize across different CNN architectures through a Keras-based implementation. Additionally, the rigorous statistical approach adds credibility to the findings. However, the complexity of the method may hinder adoption by practitioners lacking statistical expertise, and the comparisons with existing saliency methods are somewhat limited. Furthermore, while the empirical validation is commendable, the focus on specific datasets raises concerns about the generalizability of the results. The statistical assumptions may not hold across diverse data distributions, and the suggestions for future improvements lack specificity.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a clear structure that facilitates understanding. The quality of the research is high, given the rigorous statistical foundations and comprehensive literature review. However, the complexity of the proposed methodology and the lack of detailed documentation for the open-source code may hinder reproducibility. While the novelty of the approach is commendable, the reliance on Keras may limit its accessibility for practitioners using other deep learning frameworks.\n\n# Summary Of The Review\nOverall, the paper introduces a significant advancement in the field of interpretable machine learning by quantifying the reliability of saliency maps with a novel statistical approach. However, the complexity of the methodology and limitations in empirical validation may affect its practical applicability and generalizability.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" by Daiki Miwa, Vo Nguyen Le Duy, and Ichiro Takeuchi addresses the crucial challenge of interpreting salient regions identified by deep learning models. The authors propose a novel statistical methodology that employs a conditional selective inference (CSI) framework, allowing for a rigorous computation of p-values for these regions. Key contributions include the introduction of a new statistical framework for interpreting salient regions as hypotheses, algorithmic innovations that facilitate modular integration with existing CNN architectures, and empirical validation showing that their method provides better control over false positive rates compared to traditional approaches.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to p-value computation for salient regions, which significantly enhances the reliability of statistical inference in deep learning contexts. The algorithmic implementation is a notable contribution, as it allows easy integration into various CNN architectures, thereby improving accessibility for practitioners. However, the paper also has limitations, such as not addressing potential misalignment issues between input and reference images, which could impact the accuracy of the inferences drawn. Additionally, while the proposed methodology shows promise, its generalizability to other data forms beyond image inputs remains an open question.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodology, making it accessible to the reader. The quality of the writing and presentation is high, with a logical flow that supports the understanding of complex statistical concepts. The novelty of the proposed method is significant, as it extends the application of selective inference in a novel context. Reproducibility is supported through the provision of a Keras-based implementation, which allows other researchers to verify and build upon the work.\n\n# Summary Of The Review\nOverall, the paper presents an important advancement in the statistical interpretation of salient regions in deep learning. Its innovative methodology and algorithmic contributions provide practical solutions for enhancing the reliability of interpretations in machine learning contexts. The work is recommended for acceptance due to its significant contributions to the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Valid P-Value for Deep Learning-Driven Adversarial Training\" by Daiki Miwa, Vo Nguyen Le Duy, and Ichiro Takeuchi introduces a novel statistical framework for quantifying the robustness of deep learning models against adversarial attacks. The authors propose a method to compute valid p-values that gauge the reliability of adversarial examples generated during training, leveraging selective inference to control the false positive rate associated with identifying adversarial vulnerabilities. The methodology includes a two-sample testing framework and a practical Keras-based implementation, demonstrating improved performance over traditional adversarial training techniques through extensive experiments on synthetic and real-world datasets.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to integrating selective inference with adversarial training, which addresses a significant gap in the literature concerning the quantification of model robustness. The rigorous derivation of the conditional sampling distribution and the control of false positive rates are notable contributions that enhance the reliability of the proposed method. However, a potential weakness is the reliance on specific assumptions intrinsic to the two-sample testing framework, which may limit generalizability across various model architectures and datasets. Additionally, while the empirical results are promising, further validation on a broader range of adversarial attacks could strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and experimental results. The quality of writing is high, with technical concepts explained in an accessible manner. The novelty is significant, as the integration of valid p-values and selective inference into adversarial training is a relatively unexplored area. The reproducibility is facilitated by the inclusion of a practical implementation, which allows practitioners to apply the proposed method within existing frameworks without considerable computational overhead. Nevertheless, additional details on the implementation and experimental setups could further enhance reproducibility.\n\n# Summary Of The Review\nThis paper presents a significant advancement in adversarial training by providing a statistical foundation for assessing model robustness. The use of selective inference and valid p-values offers a fresh perspective on evaluating adversarial vulnerabilities, supported by comprehensive experiments and practical implementation. Overall, the paper is a valuable contribution to the field, addressing critical issues in the robustness of deep learning models.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel methodology for quantifying the reliability of salient regions identified by deep learning models, specifically Convolutional Neural Networks (CNNs), through the use of p-values. The authors introduce an exact statistical inference method based on conditional selective inference (SI), claiming it to be a significant advancement in the interpretability of neural networks. They propose a Keras-based framework to facilitate this approach across various CNN architectures and conduct comprehensive experiments to demonstrate the effectiveness of their method in controlling false positive rates and improving performance. However, the claims of superiority in both methodology and implementation are somewhat overstated, given the existence of similar frameworks and methodologies in the literature.\n\n# Strength And Weaknesses\nOne of the strengths of the paper is its introduction of an exact statistical inference method, which is presented as a major leap forward in the field. The application of conditional SI to interpret salient regions is a noteworthy contribution that addresses selection bias. However, the assertion that their Keras-based framework is novel overlooks existing implementations that already provide similar functionalities. Additionally, while the experimental results suggest improved control over false positives, the rigor of the experiments does not match that of established methodologies, raising concerns about the robustness of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is relatively clear in articulating its contributions, though it tends to exaggerate the novelty of its framework and methodologies. The quality of the writing is generally good, but the claims made regarding the uniqueness and superiority of the proposed method are not convincingly substantiated. Regarding reproducibility, while the Keras-based implementation could facilitate replication, the lack of rigor in the experimental design may hinder the validation of the results by other researchers.\n\n# Summary Of The Review\nOverall, the paper presents a potentially impactful methodology for improving the reliability of salient regions in deep learning, but its claims of novelty and superiority are overstated. The contributions, while significant, do not fully address existing methodologies, and the experimental results require more rigorous validation.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper titled \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" introduces a novel method for quantifying the reliability of salient regions in deep learning models using p-values. The authors propose a conditional selective inference approach to derive valid p-values, addressing the challenges posed by selection bias in deep neural networks (DNNs). Through experiments on both synthetic and real datasets, the method demonstrates improved control of false positive rates (FPR) and high true positive rates (TPR), outperforming naive methods and established corrections like Bonferroni.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to integrating statistical inference into the interpretation of saliency maps, which is crucial for enhancing the transparency of DNNs. The empirical results are robust, showing significant improvements in both synthetic and real-world scenarios. However, a potential weakness is the limited discussion on the implications of the findings for broader applications, as well as the need for further exploration of the method's performance under various DNN architectures beyond those tested.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its methodology and results. The quality of the writing is high, making it accessible to readers with a basic understanding of deep learning and statistical inference. The proposed method is novel, as it combines concepts from selective inference with deep learning, addressing a critical gap in the literature. The authors provide sufficient detail for reproducibility, including references to the open-source Keras-based framework developed for their experiments.\n\n# Summary Of The Review\nOverall, the paper presents a meaningful advancement in the interpretation of DNNs through a statistically sound approach to saliency mapping. The findings are compelling, with significant improvements in both FPR and TPR demonstrated across diverse datasets. While the paper is strong in methodology and results, further exploration of its applicability to a wider range of models would enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to assessing the reliability of saliency maps generated by deep learning models using a selective inference framework. The authors propose the use of p-values to validate the significance of salient regions identified through the Class Activation Mapping (CAM) technique. Key findings suggest that their method could improve the interpretability of neural networks by providing a statistical measure of reliability for saliency maps, though they acknowledge the challenges posed by the complexity of saliency calculations and the assumptions underlying their methodology.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to quantifying the reliability of saliency maps, which is a critical issue in the interpretability of deep learning models. The proposed conditional selective inference method addresses selection bias, a common concern in the evaluation of saliency maps. However, the paper is marred by several weaknesses, including the potentially oversimplified assumptions regarding the reliability of p-values in the context of complex models, the independence of noise, and the generalizability of their findings across different saliency methods. Furthermore, the reliance on CAM without sufficient justification for its applicability to other methods limits the impact of the proposed framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper is well-written and presents its ideas clearly, the novelty is somewhat tempered by the assumptions made regarding the applicability of the selective inference framework to non-linear models. The methodology, though innovative, raises questions about reproducibility due to its reliance on specific saliency methods and the bespoke nature of the proposed inference techniques. The empirical evidence supporting the claims of generalizability across other saliency methods is lacking, which could hinder the broader applicability of the findings.\n\n# Summary Of The Review\nOverall, the paper introduces a promising approach to improving the reliability of saliency maps through a statistical framework. However, its reliance on several assumptions and the challenges associated with its methodology raise concerns about its applicability and reproducibility.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel method for quantifying the reliability of salient regions identified by deep learning models using p-values. The authors employ a statistical framework based on selective inference to address the challenges of false positive rates in saliency maps. Key contributions include an exact inference method tailored for salient regions, a Keras-based implementation that enables selective inference without additional computational costs, and empirical validation demonstrating the method's effectiveness in controlling false positives while maintaining computational efficiency across both synthetic and real datasets.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its rigorous approach to addressing the reliability of saliency maps through a statistical lens, filling a notable gap in the existing literature regarding reproducibility in deep learning interpretability. The proposed method is innovative in its use of conditional selective inference, which provides a theoretically sound way to derive p-values for salient regions. However, a potential weakness is that the paper could benefit from a more comprehensive discussion on the limitations of the approach, particularly in scenarios involving complex datasets or highly variable inputs.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its methodology, making it accessible even to readers who may not be deeply familiar with statistical inference methods. The quality of the writing is high, with clear definitions and explanations of key concepts. The novelty of the approach is significant, as it introduces a new perspective on assessing saliency in deep learning models. The reproducibility of the results is supported by the authors' provision of a Keras-based implementation, which facilitates practical application in various contexts.\n\n# Summary Of The Review\nOverall, this paper makes a substantial contribution to the field of interpretability in deep learning by providing a robust statistical framework for evaluating saliency maps. Its innovative methodology and practical implementation are commendable, though further exploration of limitations would enhance the discussion.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to enhancing the interpretability of machine learning models, focusing specifically on the reliability and statistical validity of the interpretations derived from these models. The authors introduce a new methodology that incorporates uncertainty quantification into model predictions, aiming to provide clearer insights into the decision-making processes of complex algorithms. In their experiments, the authors demonstrate that their approach not only improves interpretability but also maintains competitive performance compared to state-of-the-art methods across various benchmark datasets.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Relevance:** The importance of interpretability in machine learning has grown significantly, making the topic highly relevant and timely.\n2. **Novelty:** The integration of uncertainty quantification into interpretability frameworks offers a fresh perspective that could lead to advancements in the field.\n3. **Clarity:** The paper is well-structured and written clearly, with a logical progression of ideas that facilitates understanding.\n4. **Potential Impact:** The proposed method has the potential to significantly improve the practical deployment of machine learning models in sensitive applications, thereby enhancing trust and usability.\n\n**Weaknesses:**\n1. **Lack of Empirical Validation:** While the theoretical framework is sound, the empirical validation is relatively limited, raising questions about the generalizability of the results.\n2. **Methodological Details:** Certain methodological aspects are not sufficiently detailed, which may affect the reproducibility of the results.\n3. **Comparative Analysis:** The paper lacks a thorough comparison with existing approaches, which would provide better context for understanding the advantages of the proposed method.\n4. **Discussion of Limitations:** There is insufficient exploration of potential limitations and contexts in which the proposed approach may underperform.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is commendable, with well-defined sections and a coherent narrative. The quality of writing is high, with minimal grammatical errors, supporting the overall comprehension of the material. The novelty of the approach is significant, particularly in its application of uncertainty quantification within the interpretability domain. However, the reproducibility of the results is compromised by a lack of comprehensive methodological detail, which is a critical aspect for future researchers aiming to build upon this work.\n\n# Summary Of The Review\nThis paper introduces an innovative approach to model interpretability by integrating uncertainty quantification, addressing a critical need in the field of machine learning. Despite its strengths in relevance and novelty, the paper requires more extensive empirical validation and methodological details to enhance reproducibility and strengthen its contributions to the community.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel method for quantifying the reliability of salient regions identified by deep learning models through the use of p-values, treating these regions as hypotheses. It addresses the issue of selection bias that can inflate the perceived importance of certain features in the context of deep neural networks. By employing a conditional selective inference framework, the authors demonstrate how to compute valid p-values for salient regions, ensuring a controlled probability of false positive detections. The methodology is validated through numerical examples and implemented in a Keras-based framework, enabling easy application across various convolutional neural networks (CNNs) without incurring additional computational costs.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to addressing the reliability of saliency maps, a critical issue in model interpretability. The treatment of salient regions as statistical hypotheses is a significant conceptual advancement that enhances the robustness of the findings. The implementation of the proposed framework is another strong point, as it provides practical utility for practitioners in the field. However, the paper could benefit from a more comprehensive evaluation across a broader range of datasets and tasks to better demonstrate the generalizability of the findings. Additionally, the discussion of future work could be expanded to address potential limitations or alternative approaches.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and presents its methodology clearly, making it accessible to readers with varying levels of expertise in statistics and deep learning. The quality of the experiments is satisfactory, providing a solid foundation for the claims made. The novelty of the approach in applying conditional selective inference to deep learning saliency maps is significant, marking a meaningful contribution to the field. The reproducibility of the results is enhanced by the provision of a Keras-based framework, although it would be beneficial to include more details on hyperparameter settings and experimental conditions to facilitate further validation by other researchers.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and novel approach to enhancing the reliability of saliency maps in deep learning models through the use of statistical hypothesis testing. While the contributions are substantial, further empirical validation across diverse tasks would strengthen the claims. The proposed Keras framework adds practical value, promoting reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" by Miwa, Le Duy, and Takeuchi addresses the critical issue of interpreting deep learning model predictions through saliency maps. It introduces a novel statistical hypothesis testing framework for quantifying the reliability of salient regions in these maps by computing valid p-values using selective inference to control false positive rates. The authors validate their approach through experiments on synthetic and real datasets, demonstrating that their method effectively improves the identification of true positives while maintaining computational efficiency. Additionally, they provide a Keras-based implementation to facilitate practical application of their techniques.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative approach to integrating statistical inference with saliency mapping, addressing a significant gap in the literature regarding the reliability of saliency maps. The method's ability to utilize selective inference to mitigate selection bias is particularly noteworthy and enhances the robustness of the findings. However, the paper could benefit from a more extensive discussion of the limitations of the proposed method and comparisons with a broader range of existing saliency methods. Moreover, while the provided Keras implementation is a valuable resource, further details on the computational overhead associated with the new method would enhance the reader's understanding.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the motivation behind the study, the proposed methodology, and the experimental results. The quality of writing is high, making it accessible to both practitioners and researchers in the field. The novelty of integrating selective inference into the domain of deep learning saliency maps is significant, marking a substantial contribution to the field. The reproducibility of the experiments is facilitated by the inclusion of a Keras-based framework, although providing more details about the experimental setup and hyperparameter settings would further aid in replicating the results.\n\n# Summary Of The Review\nOverall, this paper presents a significant advancement in the statistical analysis of saliency maps in deep learning, offering a robust framework for assessing the reliability of salient regions. While the contributions are impactful and well-validated, a more thorough exploration of limitations and practical implications would strengthen the work.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" by Daiki Miwa, Vo Nguyen Le Duy, and Ichiro Takeuchi addresses the critical issue of quantifying the reliability of saliency maps in deep learning models. The authors propose a novel statistical inference method using p-values to control false positive rates, which are essential for ensuring the interpretability of deep neural networks (DNNs). The methodology involves conditional selective inference (SI) to correct for selection bias, along with the application of mean null and global null tests. The experimental results demonstrate that the proposed method effectively identifies true and false positives compared to existing methods, thereby enhancing the reliability of saliency maps.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative approach to addressing selection bias in the evaluation of saliency maps, which is a prevalent issue in the interpretability of DNNs. The introduction of p-values as a means of statistical inference provides a rigorous framework that enhances the credibility of the findings. However, a notable weakness is the lack of an in-depth discussion of the limitations of the proposed method, which could provide a more balanced perspective on its applicability. Furthermore, while the experiments are robust, the exploration of more complex models and additional datasets could strengthen the generalizability of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents both the methodology and experimental results. The authors effectively convey their ideas, making the content accessible to readers with a background in statistical methods and deep learning. The novelty of introducing a selective inference framework for saliency maps is significant, as it directly addresses a critical gap in the current literature. The reproducibility of the results seems feasible, given the detailed description of the experiments; however, providing code or supplementary materials would further enhance this aspect.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of deep learning interpretability by introducing a robust statistical framework for evaluating saliency maps. While the findings are promising, further exploration of the method's limitations and additional validation on diverse datasets would strengthen the overall impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel statistical framework for assessing the reliability of salient regions identified by deep learning models through the use of p-values. The authors position salient regions as hypotheses within a selective inference paradigm to address the selection bias that can undermine the validity of these assessments. Their methodology employs conditional selective inference to derive valid p-values while controlling for false positive rates. Experimental evaluations demonstrate that this approach outperforms traditional methods in terms of false positive control and true positive rates across both synthetic and real datasets.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to integrating statistical hypothesis testing with deep learning interpretability, offering a significant advancement in quantifying the reliability of saliency maps. The use of conditional selective inference is particularly noteworthy, as it effectively mitigates selection bias, a common challenge in interpreting DNN outputs. However, the paper could benefit from clearer explanations of its mathematical formulations and assumptions, which may hinder comprehension for readers less familiar with statistical inference methods. Additionally, while the experimental results are promising, further validation across diverse datasets and models could enhance the robustness of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, though certain sections, particularly those involving mathematical derivations, may require additional clarification to ensure accessibility. The quality of writing is high, with a clear logical flow, but could be improved by providing more context for some of the statistical concepts introduced. The novelty of the approach is substantial, particularly in the context of deep learning, where statistical rigor is often lacking. The authors provide sufficient detail in their experimental setup, suggesting that the methodology is reproducible, though the complexity of the implementation may pose challenges for practitioners.\n\n# Summary Of The Review\nOverall, the paper offers a significant contribution to the field of deep learning interpretability by embedding statistical rigor into the evaluation of salient regions. While the methodology is innovative and the experimental results are compelling, the clarity of presentation could be improved to enhance understanding. Further empirical validation across a broader range of scenarios would also strengthen the findings.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper introduces a novel method for quantifying the reliability of salient regions in deep learning models using p-values. The authors acknowledge the complexity of constructing a valid statistical test for deep neural networks (DNNs), particularly due to issues of selection bias. They claim to derive exact conditional sampling distributions to support their approach, yet the complexity may hinder practical implementation. The findings focus on the method's ability to assess false positive and true positive rates, although the experimental evaluation is limited and primarily focuses on a narrow set of conditions.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address the interpretability of deep learning models through a statistical lens, which is a crucial area of research. However, significant weaknesses include the complex methodology that may not generalize well across different DNN architectures and the superficial comparison with existing methods. The authors do not sufficiently acknowledge the limitations of their approach, and the experimental validation is inadequate, which raises concerns about the applicability of their findings to real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper suffers due to the complexity of the proposed methodology, which could confuse practitioners. While the authors claim to offer a Keras-based framework for implementation, they do not adequately address potential pitfalls, which may mislead readers regarding the ease of application. The novelty of the approach is somewhat overshadowed by the methodological challenges and limited empirical validation, which raises questions about reproducibility.\n\n# Summary Of The Review\nOverall, the paper presents an interesting approach to quantifying the reliability of salient regions in deep learning models; however, it suffers from significant methodological complexities and a lack of comprehensive empirical validation. The contributions may not be as impactful as claimed due to the limitations in implementation and evaluation.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper presents a novel method for quantifying the reliability of salient regions in deep learning models using valid p-values, significantly enhancing the interpretability of these models. The authors employ a robust statistical framework based on conditional selective inference (SI) to control the false positive rate effectively, which is vital for interpreting model predictions, particularly in sensitive applications like medical diagnostics. Empirical validation through extensive experiments on synthetic and real-world datasets demonstrates the method's effectiveness and superior performance in maintaining a high true positive rate compared to existing approaches.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to incorporating valid p-values for interpreting salient regions, which addresses a critical gap in the literature on deep learning interpretability. The robust statistical framework enhances the reliability of the interpretations, while the Keras-based implementation promotes ease of use and accessibility for practitioners. The extensive empirical validation adds credibility to the findings and showcases the method's potential in real-world applications. However, the paper could benefit from a more detailed comparison with other interpretability methods to further contextualize its contributions and limitations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and clearly articulates its contributions and methodology. The statistical framework is presented in a rigorous manner, ensuring that readers can follow the proposed method's logic. The novelty of the approach in applying valid p-values to deep learning interpretability is significant, and the open-source availability of the code enhances reproducibility, encouraging further research in this area. Overall, the clarity and quality of the presentation are commendable, making the paper accessible to both researchers and practitioners in the field.\n\n# Summary Of The Review\nThis paper represents a significant advancement in deep learning interpretability by introducing a method that quantifies the reliability of salient regions using valid p-values. The rigorous statistical foundation, along with empirical validation, underscores its potential impact, particularly in sensitive applications like healthcare. Overall, the work is both innovative and practical, contributing meaningfully to the field.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThis paper presents a novel framework for validating saliency maps in deep learning through the lens of conditional selective inference (SI). It addresses the inherent biases in traditional saliency map interpretations that stem from selection bias, providing a rigorous statistical methodology for hypothesis testing regarding salient regions. The main contributions include the derivation of exact conditional distributions for test statistics, a systematic analysis of piecewise linear networks, and the introduction of an auto-conditioning mechanism to facilitate the practical implementation of SI across various convolutional neural network (CNN) architectures.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its rigorous theoretical foundation and the development of a statistically sound approach to evaluating saliency maps. The introduction of selective p-values, which correct for selection bias, is a significant advancement that enhances the reliability of saliency map interpretations. However, the paper could benefit from empirical validation of the proposed methods, as the theoretical contributions are not accompanied by sufficient real-world application examples or case studies. Additionally, while the auto-conditioning mechanism streamlines implementation, further clarification on its limitations and potential challenges would strengthen the practical applicability of the framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its theoretical contributions, making it accessible to readers familiar with statistical hypothesis testing and deep learning. The quality of the writing is high, with a logical flow that guides the reader through complex theoretical concepts. The novelty of the SI framework in the context of saliency map validation is significant; however, the reproducibility of the results could be improved by providing detailed algorithmic specifications and potential code implementations, allowing other researchers to validate the findings independently.\n\n# Summary Of The Review\nOverall, this paper makes substantial theoretical contributions to the field of model interpretability in deep learning by addressing selection bias in saliency map evaluations. While the proposed framework is innovative and promising, more empirical validation is needed to demonstrate its practical effectiveness.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a Keras-based framework for conducting selective inference (SI) specifically tailored for deep learning models, particularly Convolutional Neural Networks (CNNs), without incurring additional implementation costs. It utilizes a modular approach called auto-conditioning to efficiently compute intervals for piecewise linear components within CNNs, thus avoiding extensive manual adjustments. The authors present an algorithm for obtaining selective p-values, emphasizing computational efficiency and the automatic tracking of intervals, and validate their approach through experimental results demonstrating control over false positive rates in statistical significance tests on salient regions.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its practical applicability, as the proposed framework allows for seamless integration with existing CNN architectures while ensuring computational efficiency. The detailed descriptions of the algorithmic steps and the availability of the code on GitHub further enhance its accessibility and reproducibility. However, a potential weakness is the lack of extensive comparative analysis with other existing methods for selective inference in deep learning, which could provide a clearer positioning of the contributions relative to the state of the art.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clear, with a logical flow from the introduction of the problem to the presentation of the methodology and results. The quality of the writing is high, with sufficient detail provided for the implementation process. In terms of novelty, while the approach to selective inference in CNNs is a valuable contribution, the uniqueness of the auto-conditioning method could be better highlighted. The efforts made towards reproducibility are commendable, as the publicly available code enables other researchers to replicate the findings.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in selective inference for deep learning models, demonstrating both methodological innovation and practical utility. While the contributions are well-articulated and the implementation is accessible, further comparative analysis with existing methods could strengthen the claims of novelty and significance.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper proposes a novel method for generating saliency maps that claims to enhance the interpretability of deep neural network (DNN) predictions. The authors argue that their approach surpasses existing methods by quantifying reliability through p-values, thus providing a more stable interpretation of salient regions. However, the methodology and experimental findings appear to replicate established practices in the field without offering substantial new insights, as they reference previous works extensively but do not adequately acknowledge their contributions.\n\n# Strength And Weaknesses\nWhile the paper introduces a Keras-based framework aimed at improving usability, it does not sufficiently recognize the existing efforts in the community to enhance interpretability and reliability, such as those by Ribeiro et al. (2016) and Lundberg & Lee (2017). The authors’ characterization of previous methods as fragile is misleading, as many prior studies have made strides in addressing stability issues. Additionally, the claim that no quantitative evaluations of DNN-driven salient regions exist undermines the contributions of other researchers in this area. The experimental results presented, while framed as groundbreaking, lack a comprehensive comparative analysis that would strengthen their claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, but its clarity suffers due to the lack of recognition of previous work, leading to a somewhat biased portrayal of its contributions. The novelty of the proposed method is questionable, as it does not introduce significantly new methodologies or metrics compared to existing saliency map techniques. Reproducibility is supported by the introduction of a Keras-based framework, although it would benefit from a more detailed discussion of its computational efficiency and complexity relative to previous studies.\n\n# Summary Of The Review\nThe paper presents a novel method for saliency map generation, but it falls short in acknowledging the advancements made by prior works in the field. While it claims to offer improved reliability, the methodology and results do not significantly diverge from established practices, raising questions about the true novelty and significance of the findings.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThis paper presents a novel approach to establishing a valid p-value for salient regions identified through deep learning-driven methods. The authors introduce a framework for selective inference (SI) that addresses the biases commonly associated with traditional p-value calculations in the context of deep neural networks (DNNs). The methodology involves a systematic evaluation of the saliency maps produced by DNNs and aims to provide more reliable statistical testing results. The findings demonstrate that the proposed selective p-value can improve the accuracy of hypothesis testing when analyzing salient features in visual data, with empirical results showing a decrease in false positive rates compared to naive p-values.\n\n# Strength And Weaknesses\nThe main strength of this paper lies in its innovative approach to integrating selective inference with deep learning, addressing a significant gap in the literature regarding statistical validation of DNN outputs. The empirical evaluations provide compelling evidence of the method's effectiveness, showcasing improvements over traditional methods. However, the paper exhibits several weaknesses, including inconsistent formatting and terminology, which could confuse readers. Furthermore, the introduction of key terms such as \"DNN-driven hypotheses\" and \"DNN-driven salient regions\" lacks clarity and could benefit from more precise definitions.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the overall quality of the research is high, the clarity is somewhat compromised due to inconsistencies in formatting, terminology, and explanations. These issues detract from the reader's understanding of the methodology and findings. The novelty of combining selective inference with deep learning is significant and contributes to the existing body of knowledge. However, the paper would benefit from improved reproducibility, particularly in detailing the methodology and providing clearer definitions for the introduced terms.\n\n# Summary Of The Review\nThe paper introduces a relevant and innovative framework for validating p-values in the context of deep learning-driven saliency detection. Despite its strong contributions and empirical results, the paper suffers from clarity issues and inconsistencies that could hinder comprehension and reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel selective inference approach for improving the reliability of saliency maps generated by convolutional neural networks (CNNs). The authors propose a statistical framework that quantifies the significance of salient regions, addressing concerns related to selection bias in existing methods. Through a series of experiments, the paper demonstrates the effectiveness of the proposed method in enhancing the interpretability of saliency maps while also discussing future directions for extending the framework to other deep learning architectures and datasets.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its rigorous statistical foundation, which provides a new perspective on the reliability of saliency maps. The method has the potential to make significant contributions to the field of interpretability in deep learning. However, the paper has several weaknesses, such as a lack of exploration into other deep learning architectures beyond CNNs, insufficient analysis of the method's performance across various datasets, and limited discussion on practical applications and implications. Additionally, the authors could improve the analysis by incorporating comparative studies with existing methods and discussing the limitations of their approach more thoroughly.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with clear explanations of the proposed methodology and findings. However, the clarity could be enhanced by providing a more detailed exploration of the implications of the method in real-world applications and addressing potential shortcomings more explicitly. The novelty of the approach is notable, as it introduces a selective inference framework that is not commonly found in existing literature on saliency maps. The reproducibility of the results would benefit from additional details regarding the computational complexity of the method when applied at scale.\n\n# Summary Of The Review\nOverall, the paper offers a valuable contribution to the field of interpretability in deep learning through its novel selective inference approach. While the methodology is promising and well-founded, the authors should address several limitations and explore broader applications to enhance the relevance and impact of their findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel framework for quantifying the reliability of salient regions identified by deep neural networks (DNNs) using valid p-values. It introduces selective inference (SI) to address selection bias in hypothesis testing, applying two-sample tests (mean null and global null) to assess differences between salient regions of query inputs and reference inputs. The methodology effectively controls the false positive rate (FPR) and demonstrates superior true positive rate (TPR) detection compared to naive methods, indicating a significant advancement in the interpretability of DNN predictions.\n\n# Strength And Weaknesses\nStrengths of the paper include its rigorous statistical framework, which effectively addresses the challenge of selection bias in saliency map interpretations. The introduction of conditional selective inference provides a robust mechanism for computing valid p-values, enhancing the reliability of DNN outputs. However, a potential weakness is the complexity of the proposed methodology, which may limit accessibility for practitioners not well-versed in statistical inference. Additionally, while the experimental setup is well-defined, further empirical validation across diverse datasets could strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology and findings. The quality of the writing is high, with sufficient detail in the statistical framework and experimental design. The novelty lies in the application of selective inference to deep learning, which is relatively unexplored territory. However, reproducibility may be a concern, as the complexity of the statistical methods and lack of implementation details could pose challenges for practitioners attempting to replicate the results.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of deep learning interpretability by introducing a robust statistical framework for assessing salient regions through valid p-values. While the methodology is innovative and the results promising, the complexity may hinder broader applicability and reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to statistical testing for saliency methods in deep learning, introducing a selective inference framework that aims to assess the significance of salient regions identified by convolutional neural networks (CNNs). The methodology employs conditional selective inference to compute p-values associated with these regions, with experiments primarily conducted on synthetic datasets and brain tumor images. However, the findings indicate limitations in generalizability, as the proposed method does not adequately address critical issues such as input-reference image alignment, robustness against perturbations, and general applicability across different model architectures.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative attempt to integrate statistical rigor into the evaluation of saliency methods, potentially enhancing interpretability in clinical settings. However, several weaknesses undermine the contributions: (1) the lack of addressing misalignment between input and reference images, which is crucial for valid statistical testing; (2) insufficient exploration of the method's robustness against adversarial attacks; (3) limited generalizability due to focusing on a specific class of CNNs; (4) absence of a thorough comparison with existing statistical methods; (5) a narrow range of datasets tested; and (6) inadequate consideration of hyperparameter tuning and computational efficiency for real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and communicates its main ideas clearly; however, certain aspects, such as the implications of using various saliency methods and the interpretability of p-values, are not sufficiently discussed. The novelty is present in the proposed selective inference framework, though its applicability is constrained. Reproducibility may be hampered by the lack of detailed implementation information regarding computational efficiency and hyperparameter sensitivity.\n\n# Summary Of The Review\nOverall, while the paper introduces an interesting approach to enhancing the statistical evaluation of saliency methods, its practical impact is limited by several critical oversights and narrow experimental scope. Addressing these weaknesses could significantly improve the framework's applicability and relevance in real-world scenarios.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" by Daiki Miwa, Vo Nguyen Le Duy, and Ichiro Takeuchi presents a method for quantifying the reliability of saliency maps in deep learning models through the use of p-values. The authors frame their approach within the context of conditional selective inference, claiming it addresses selection bias in saliency map interpretation. Their work includes a Keras-based implementation and experiments on both synthetic and real-world datasets, purportedly demonstrating the effectiveness of their method in providing valid statistical inference for saliency regions.\n\n# Strength And Weaknesses\nThe paper attempts to make a contribution by introducing a statistical framework for validating saliency maps, which is an important aspect in the interpretation of deep learning models. However, the methodology appears to lack originality, as the concepts of p-values and conditional inference have been previously established in the literature. The authors' claim of providing an \"exact inference method\" seems overstated, as the paper does not introduce fundamentally new statistical techniques. Additionally, the experiments, while demonstrating favorable results, do not significantly advance the state of the art or provide novel insights.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear in its presentation, but the novelty of the contributions is questionable as many of the ideas are not new. The implementation is described in a Keras context, which aids in reproducibility; however, the overall significance of the proposed method is diminished by its reliance on existing statistical practices. Furthermore, the paper could benefit from a more thorough discussion of how their approach differs from or improves upon previous methods.\n\n# Summary Of The Review\nOverall, the paper offers a method for valid statistical inference of saliency maps, but its contributions are largely incremental and do not represent a significant advance in the field. The authors have presented familiar concepts in a new light without providing substantial novelty or empirical results that enhance understanding or application in deep learning.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents a novel framework that integrates selective inference with Class Activation Mapping (CAM) to enhance the interpretability of deep neural networks (DNNs). The authors propose a methodology that controls the false positive rates in saliency maps while providing statistical power analysis to improve the detection of salient regions. The findings indicate that the proposed method offers a more reliable interpretation of model predictions, particularly in complex decision-making scenarios.\n\n# Strength And Weaknesses\nOne of the key strengths of the paper is its focus on improving the interpretability of DNNs through a rigorous statistical framework, which addresses a significant gap in current saliency mapping techniques. However, the paper primarily centers around CAM, limiting its applicability to other saliency methods such as Grad-CAM or Integrated Gradients. Additionally, while the methodology showcases control over false positive rates, it lacks a thorough exploration of statistical power, which could provide deeper insights into the robustness of the proposed framework. \n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible to readers. The quality of the methodology is high, though further empirical validation across diverse domains is necessary to confirm its generalizability. The novelty lies in the combination of selective inference with saliency mapping; however, the application is somewhat narrow. Reproducibility may be affected due to the Keras-based implementation, as it does not elaborate on how the framework could be adapted for more complex architectures or other domains.\n\n# Summary Of The Review\nOverall, the paper makes a valuable contribution to the field of interpretability in deep learning by introducing a selective inference framework for saliency mapping. While the methodology shows promise, its limited scope and lack of empirical validation across various contexts suggest that further research is needed to enhance its applicability and robustness.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThis paper presents a novel method for controlling false positive rates (FPR) and enhancing true positive rates (TPR) in the context of saliency detection using deep learning. The methodology involves the use of selective p-values to improve reliability in detecting salient regions, with empirical evaluations demonstrating its effectiveness. Key findings indicate that the proposed method outperforms traditional approaches, such as the naive method and Bonferroni correction, in both simulated and real-world scenarios, particularly in a brain image dataset.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its comprehensive empirical evaluations, which convincingly demonstrate the proposed method's ability to control FPR while maximizing TPR. The clear distinction in performance between the proposed method and baseline methods, supported by numerical results and visual evidence, adds robustness to the claims. However, a potential weakness is the limited exploration of the theoretical underpinnings of the method, which could enhance understanding of its foundational principles. Additionally, while the empirical results are compelling, further investigation into the method's applicability across a wider range of datasets and contexts would strengthen its validity.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with clear explanations of the methodology and results. The use of figures to illustrate FPR and TPR comparisons significantly aids in comprehension. The novelty of the approach is notable, particularly in its focus on selective p-values for reliability quantification in saliency detection. However, details regarding the reproducibility of the experiments could be improved, such as providing more information on the datasets and experimental setup to facilitate replication by other researchers.\n\n# Summary Of The Review\nOverall, this paper presents a significant advancement in the field of saliency detection by effectively controlling false positive rates and enhancing true positive rates. The empirical results bolster the proposed method's claims, although further theoretical justification and broader applicability could enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper titled \"VALID P-VALUE FOR DEEP LEARNING-DRIVEN SALIENT REGION\" proposes a novel statistical inference framework aimed at improving the interpretation of salient regions in deep learning models. The authors introduce a method for computing valid p-values that account for selection bias inherent in saliency map methods. The findings demonstrate that their approach leads to more reliable statistical inference when identifying significant regions in model predictions, thus enhancing the interpretability of deep learning outputs.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its contribution to the intersection of statistical inference and deep learning interpretability. The methodology offers a fresh perspective on addressing selection bias, a common issue in existing saliency map techniques. However, the paper suffers from a lack of clarity in presentation, with lengthy sentences and complex jargon that may alienate readers unfamiliar with the topic. Additionally, the organization of ideas could be improved to ensure a logical flow, and the figures included need more descriptive captions for better comprehension.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is hindered by dense language and insufficient explanations of technical terms, which may make it difficult for a broader audience to engage with the content. The quality of the writing is affected by grammatical errors and awkward sentence structures. While the technical novelty is commendable, the paper's impact is somewhat diminished by its presentation. Reproducibility could also be a concern, given that there are areas where the methodology lacks detailed exposition.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to the field by addressing selection bias in deep learning saliency methods through a valid p-value framework. However, the lack of clarity and organization in the writing detracts from its potential impact, requiring substantial revisions for improved readability and comprehension.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.0730499326755467,
    -1.7750995663325813,
    -1.7860962256255124,
    -1.7612648500294785,
    -1.6899979358767951,
    -1.9072733497146679,
    -1.679103611912638,
    -1.7705915335841678,
    -1.6401507095961418,
    -1.7417268018671874,
    -1.6200975809346492,
    -1.3992860098213162,
    -1.6566081887884165,
    -1.686525449605474,
    -1.6488384948844168,
    -1.57694382076968,
    -1.889758252875803,
    -1.610922920260932,
    -1.7574715081001113,
    -1.823206706896913,
    -1.9845570412627187,
    -1.7745303118020408,
    -1.5282181336905043,
    -1.7072776947184387,
    -1.766809668021857,
    -1.9016961336345715,
    -1.6131545847423812,
    -1.6173361480244406,
    -1.7815324047672665
  ],
  "logp_cond": [
    [
      0.0,
      -1.8432657333388562,
      -1.8477921288619366,
      -1.846615804113065,
      -1.8675836572661229,
      -1.853773102970901,
      -1.9123469448827044,
      -1.8648145252246302,
      -1.8483037012030263,
      -1.858470427210099,
      -1.8567160484642917,
      -1.9165096840658438,
      -1.8458134539407716,
      -1.866310999895781,
      -1.877750507446789,
      -1.87087093863159,
      -1.8938809845301319,
      -1.8485391309859367,
      -1.8730988947372793,
      -1.8843467117892783,
      -1.8936987497166775,
      -1.88800451163297,
      -1.8865393244087576,
      -1.8547882570394696,
      -1.8583552339878529,
      -1.8439246829609983,
      -1.8823480129566124,
      -1.8735274538247984,
      -1.90189622019377
    ],
    [
      -1.3379735957691306,
      0.0,
      -1.2283259474260477,
      -1.1094253588218481,
      -1.2790501250712136,
      -1.1360011196088864,
      -1.2219557433362744,
      -1.2708244613828523,
      -1.182656154548522,
      -1.3256391003312749,
      -1.260871239526274,
      -1.4601053023801005,
      -1.255596762438838,
      -1.139076574543434,
      -1.1266385577607612,
      -1.2872116622076977,
      -1.3167138115547385,
      -1.2595980798698732,
      -1.3616348368944038,
      -1.3697048927654534,
      -1.3455341276232133,
      -1.3381710199087853,
      -1.3869115382330668,
      -1.2482792319431455,
      -1.3866103959424703,
      -1.0993566085169493,
      -1.372735922607462,
      -1.3833759592778447,
      -1.2756370363147025
    ],
    [
      -1.375970633511598,
      -1.213334631462956,
      0.0,
      -1.239586071027815,
      -1.2404167563487394,
      -1.2703962476723065,
      -1.3261123629363998,
      -1.2634863072603124,
      -1.2690808389208006,
      -1.3281092452189378,
      -1.249818848362088,
      -1.4404656210988944,
      -1.22195940043299,
      -1.3380477574102905,
      -1.3612548179030093,
      -1.2889937799650188,
      -1.2950952721741158,
      -1.231146320195991,
      -1.3367511618742483,
      -1.3483824935337876,
      -1.3625352415919254,
      -1.389757691440136,
      -1.3916577154904168,
      -1.246023062836245,
      -1.3731774075064707,
      -1.2781450638596004,
      -1.3642230009984537,
      -1.3597060322194312,
      -1.3716092576560464
    ],
    [
      -1.4411978728715116,
      -1.2058515352830785,
      -1.3248579428419112,
      0.0,
      -1.3586609439262496,
      -1.218814519982586,
      -1.3324173316854766,
      -1.3402427426102133,
      -1.272436111939806,
      -1.4312201513828333,
      -1.2981941039516027,
      -1.517523983118046,
      -1.2870496071008195,
      -1.2363434068486618,
      -1.2973452100704748,
      -1.361502901745139,
      -1.3610993715517696,
      -1.3153026840700457,
      -1.442067744776981,
      -1.4093265982435972,
      -1.375943291804313,
      -1.4235289548941095,
      -1.4894476778010135,
      -1.338906104312668,
      -1.4450171823044837,
      -1.2516519096993313,
      -1.4210845496945188,
      -1.4554948610690164,
      -1.3665832957553008
    ],
    [
      -1.2736410823355144,
      -1.2084848430661286,
      -1.2096081102514988,
      -1.2447690220220227,
      0.0,
      -1.2638792188324401,
      -1.2903352403508994,
      -1.2040591650501737,
      -1.315740560066315,
      -1.2560546136678026,
      -1.2396568575432687,
      -1.3638719935830987,
      -1.2130299995554334,
      -1.2891963616454416,
      -1.3032307435721187,
      -1.3153037859252823,
      -1.2367788995412112,
      -1.1989157856328543,
      -1.2616673677407453,
      -1.3136994707139829,
      -1.3044121849372412,
      -1.3175672374198846,
      -1.3245753165801486,
      -1.2518168588544656,
      -1.2957160984105125,
      -1.2744356353851323,
      -1.2674264044846955,
      -1.346426303393275,
      -1.3272814496340624
    ],
    [
      -1.5245360301528212,
      -1.2823978480350842,
      -1.4393382871701244,
      -1.3322500544508658,
      -1.4677728115762587,
      0.0,
      -1.3724441468451116,
      -1.4475072461633647,
      -1.3740546446855235,
      -1.5136724196555518,
      -1.4449776318850693,
      -1.5892712377724605,
      -1.420860084282169,
      -1.3559641700846168,
      -1.3297315105895153,
      -1.5086108645921075,
      -1.5088237594608462,
      -1.4835701852699128,
      -1.5251926284245667,
      -1.5079525405288146,
      -1.514937784176253,
      -1.4855168984077085,
      -1.5597590616003418,
      -1.486282339773186,
      -1.4893370372490902,
      -1.282527431665373,
      -1.5121821869456082,
      -1.5708482155790902,
      -1.471505146431505
    ],
    [
      -1.4190982620706067,
      -1.1340289097187437,
      -1.309544580632379,
      -1.2357559992561264,
      -1.3589189709046503,
      -1.1764242136542147,
      0.0,
      -1.3548725785800702,
      -1.257991686688941,
      -1.3485355397748702,
      -1.2530581835091608,
      -1.4040756728147499,
      -1.2779670316203897,
      -1.1955223750544963,
      -1.2317569534783879,
      -1.3596248923154166,
      -1.3676123166832657,
      -1.2655152769200806,
      -1.3860520319581862,
      -1.3888809555199648,
      -1.3599115043409884,
      -1.3391644217938323,
      -1.364472833269656,
      -1.3115223766330133,
      -1.374901496265026,
      -1.1778583919306662,
      -1.3580393651017513,
      -1.3523468889119652,
      -1.3244268986735013
    ],
    [
      -1.4592145943277484,
      -1.3468596634680507,
      -1.326850447277237,
      -1.35311615586955,
      -1.3648670871915407,
      -1.3372631844914074,
      -1.4196540220736549,
      0.0,
      -1.3634138766598078,
      -1.3692055632944318,
      -1.353791826019282,
      -1.4987593685557756,
      -1.319272605264509,
      -1.3485755197839588,
      -1.4011855455736753,
      -1.3485318813231777,
      -1.3448755854481218,
      -1.391228143108789,
      -1.3568512313969059,
      -1.391485457489048,
      -1.4287318474045778,
      -1.4349363070805827,
      -1.426078751891978,
      -1.3541241289243648,
      -1.435578016994416,
      -1.331684552691895,
      -1.4257287275159753,
      -1.4920875484420941,
      -1.43798485614941
    ],
    [
      -1.2727122968306912,
      -1.0531543641138696,
      -1.1009053180251493,
      -1.0582229956281,
      -1.18683594194219,
      -1.0771710902321368,
      -1.1891033689995474,
      -1.1565343975552145,
      0.0,
      -1.204265921174175,
      -1.150276003623355,
      -1.3148185931771235,
      -1.1305221259728095,
      -1.0677206614777774,
      -1.0918578810723132,
      -1.1544853698558848,
      -1.1600816122528204,
      -1.1643180080117352,
      -1.2516135524628955,
      -1.2458631676137102,
      -1.176177678173457,
      -1.1962099178559114,
      -1.2750788609763697,
      -1.1606488582512495,
      -1.2421488132034593,
      -1.0731347998655663,
      -1.2348847758171473,
      -1.2241820160778745,
      -1.144514066426785
    ],
    [
      -1.3416522086038212,
      -1.298440104235237,
      -1.3531240508707172,
      -1.3659520673731536,
      -1.3575031508197,
      -1.3497026612481435,
      -1.4005155359146246,
      -1.3253104823375557,
      -1.33640702151425,
      0.0,
      -1.356448040535369,
      -1.444189183296958,
      -1.31689647959932,
      -1.3871667233710983,
      -1.325807417012177,
      -1.3299227126690945,
      -1.3383982432486665,
      -1.395242809278831,
      -1.329515247972457,
      -1.4193679942595039,
      -1.4123528571815855,
      -1.3600090729060297,
      -1.3718462787063106,
      -1.3045758432833154,
      -1.3395576338369215,
      -1.3436077513759146,
      -1.3317166584023241,
      -1.4204362403183246,
      -1.3600844265830676
    ],
    [
      -1.258692476513925,
      -1.103847304259642,
      -1.1334124980544282,
      -1.0924608853774171,
      -1.1831483617274157,
      -1.1473923040115979,
      -1.162206629600059,
      -1.1060433056853254,
      -1.154368558569437,
      -1.2105265192215666,
      0.0,
      -1.2951849660228196,
      -1.0943832595681815,
      -1.1089011600114185,
      -1.1980625183492077,
      -1.1573883040549298,
      -1.191557591150131,
      -1.1513930622542694,
      -1.2091338396989277,
      -1.201586454840817,
      -1.2084386069596302,
      -1.2576906973291568,
      -1.2767830512839664,
      -1.1719044172613426,
      -1.2164796253897285,
      -1.1090705003131403,
      -1.2483040837949606,
      -1.2600574303795142,
      -1.2477872235718253
    ],
    [
      -1.1722953915800558,
      -1.1473775557228971,
      -1.1725355088232612,
      -1.1793242232424044,
      -1.156022135279979,
      -1.1526711880266123,
      -1.1742244277116436,
      -1.161922660388188,
      -1.1582972249823407,
      -1.1482882795654235,
      -1.1495210401222613,
      0.0,
      -1.1595257121276772,
      -1.165646195498244,
      -1.178621899900437,
      -1.1529523493109057,
      -1.1707894362048012,
      -1.1416188968188503,
      -1.1397514691673412,
      -1.1710538822232754,
      -1.1299518717780541,
      -1.1454281333132825,
      -1.1446717423788229,
      -1.1722994524654147,
      -1.1348717657039709,
      -1.1293909103325332,
      -1.143781970376433,
      -1.1667995778985651,
      -1.1369948453865848
    ],
    [
      -1.316076403896939,
      -1.2055026367447461,
      -1.1869862746191155,
      -1.2239678920815962,
      -1.2520344437556317,
      -1.2540788868126826,
      -1.3042620991921148,
      -1.20515585094468,
      -1.2506662957721226,
      -1.2388690742394393,
      -1.2190979378973412,
      -1.3562414181257512,
      0.0,
      -1.2134540240582077,
      -1.2914640475984487,
      -1.274294346080173,
      -1.2713220268542704,
      -1.2577546576847565,
      -1.2317177579401002,
      -1.291201310391341,
      -1.265641620141134,
      -1.3310653854757255,
      -1.3097480114169329,
      -1.2389632174786376,
      -1.3151658960608494,
      -1.2166311489384636,
      -1.3113276495174373,
      -1.3333360468454367,
      -1.3055789927078087
    ],
    [
      -1.3546612560558835,
      -1.0609509296829016,
      -1.255742237042425,
      -1.1428426295937844,
      -1.3139694903105523,
      -1.1457103447378851,
      -1.173753890712974,
      -1.241567171982597,
      -1.1527143368993118,
      -1.3190141728610636,
      -1.2540098125197754,
      -1.4038218352213552,
      -1.2086260101464423,
      0.0,
      -1.1085844965694798,
      -1.2441599925592968,
      -1.2107146895067606,
      -1.2887537033020542,
      -1.3463196328502969,
      -1.3373833796902421,
      -1.295188766578966,
      -1.2957787340770797,
      -1.3499951646252044,
      -1.2636697232524492,
      -1.3546191174276685,
      -1.1161384410116242,
      -1.3476130980004768,
      -1.358296391066966,
      -1.2350405549297139
    ],
    [
      -1.2890863876716994,
      -1.0042747046017197,
      -1.240290743732196,
      -1.074377166691503,
      -1.2439490253560108,
      -1.0632076804097148,
      -1.1425502113710084,
      -1.2289086078370473,
      -1.1121537101246655,
      -1.2060647142150065,
      -1.2291360909225848,
      -1.354807052083005,
      -1.1926594164924265,
      -1.0884237722642163,
      0.0,
      -1.1999941901634272,
      -1.2498831602403344,
      -1.2391790305561006,
      -1.2288549457387694,
      -1.2796198725146182,
      -1.301258206706946,
      -1.2371163009527466,
      -1.2474689135543304,
      -1.0933302486627678,
      -1.2469719438579434,
      -1.037282888035359,
      -1.251766915002431,
      -1.2898440944411467,
      -1.1706493108002205
    ],
    [
      -1.2040319833327053,
      -1.1323993189374046,
      -1.1286470856291135,
      -1.052870333185173,
      -1.1894788421049898,
      -1.1598770802395384,
      -1.1955106067216341,
      -1.1247582965711158,
      -1.0921150274980407,
      -1.1632668822489267,
      -1.1464967408334275,
      -1.2577084598302157,
      -1.1586579187240929,
      -1.13230028526218,
      -1.1452858773755041,
      0.0,
      -1.1140439260462067,
      -1.1663336966278801,
      -1.2197852824546724,
      -1.2400007170430698,
      -1.2110370530292551,
      -1.192924233004838,
      -1.2693665220928207,
      -1.0870942286041938,
      -1.218886101195857,
      -1.142724809957769,
      -1.2133828755850333,
      -1.2464976078529337,
      -1.1709363031265778
    ],
    [
      -1.5474420813084955,
      -1.4234312405638085,
      -1.4281547448829777,
      -1.4077833399411053,
      -1.4403778318076503,
      -1.4525034976727482,
      -1.4925256494344585,
      -1.3320804094952832,
      -1.4074608302194138,
      -1.4522414912780581,
      -1.4090787542502656,
      -1.591298929751317,
      -1.4095532677020246,
      -1.3682133061763417,
      -1.4769603772974307,
      -1.4243934648654837,
      0.0,
      -1.4132637862413888,
      -1.507849910267706,
      -1.481421917713333,
      -1.4902888151111437,
      -1.498400126486044,
      -1.5244586335883195,
      -1.459492081492846,
      -1.50886661180822,
      -1.4372589315170934,
      -1.4983546982415339,
      -1.5664579791976785,
      -1.5335185433938352
    ],
    [
      -1.2563033486922508,
      -1.1160537440339056,
      -1.124406381085621,
      -1.1248329215584891,
      -1.1234240143775418,
      -1.1566776111810235,
      -1.2007508599735819,
      -1.1553694244656914,
      -1.1563954100639189,
      -1.2350732498913548,
      -1.1251179144303238,
      -1.2827193863106412,
      -1.1772842971657909,
      -1.1916001121618869,
      -1.228955941235094,
      -1.2573904026616178,
      -1.2145473114434346,
      0.0,
      -1.215838529808116,
      -1.2257095586885494,
      -1.2312817942233663,
      -1.2581326161196327,
      -1.2875028712553611,
      -1.1430212733173464,
      -1.214509532618998,
      -1.1566349157114706,
      -1.244359932025304,
      -1.2649523008637769,
      -1.265929208157582
    ],
    [
      -1.3734239241869746,
      -1.3296815787198843,
      -1.3544823512578699,
      -1.3558348336392643,
      -1.337056644661925,
      -1.3195524429367482,
      -1.4115630557154277,
      -1.3158573726699279,
      -1.3931926571961715,
      -1.3137706835058522,
      -1.35322927885735,
      -1.4391473327588087,
      -1.2861996191484764,
      -1.3789564926286053,
      -1.3519773562480928,
      -1.3907224070681858,
      -1.3767355190664197,
      -1.3489622671300978,
      0.0,
      -1.331711892439381,
      -1.4034188098010894,
      -1.3335795727483974,
      -1.3848645429708122,
      -1.309492243198342,
      -1.3717552814292477,
      -1.3691745152748718,
      -1.3805520348306415,
      -1.3509212816530443,
      -1.4022386071133777
    ],
    [
      -1.4762208773227141,
      -1.43010294364088,
      -1.40736235555301,
      -1.4269036312778896,
      -1.4353756157503035,
      -1.3994121200705822,
      -1.4805807564321376,
      -1.353738680952253,
      -1.447006073663066,
      -1.4534267417731017,
      -1.4131316318020053,
      -1.528914670741308,
      -1.4012109138471571,
      -1.4740158409217963,
      -1.4887883470604952,
      -1.4624214687399102,
      -1.434049909376321,
      -1.4515396618397076,
      -1.396711772167645,
      0.0,
      -1.4298615899604619,
      -1.4474884771288856,
      -1.4763254501679763,
      -1.4327328464975582,
      -1.4581158203415097,
      -1.4479418149273104,
      -1.429115496745243,
      -1.4488736479484345,
      -1.4770207877489623
    ],
    [
      -1.6767420054872246,
      -1.5783988523752648,
      -1.592425962727239,
      -1.5908880986160523,
      -1.6169629192536625,
      -1.5892081302877852,
      -1.6822221496757124,
      -1.6019630891914056,
      -1.5744091997875183,
      -1.626792226894281,
      -1.6031271204508633,
      -1.7001657265045598,
      -1.580206059012321,
      -1.5849499792730646,
      -1.6201401124825958,
      -1.6438383151306006,
      -1.607561398806673,
      -1.586668549216894,
      -1.6473550653630418,
      -1.6320790517314756,
      0.0,
      -1.6075397224811185,
      -1.6526945970321716,
      -1.6051464161778652,
      -1.6501046462686837,
      -1.6030980474460936,
      -1.639562427702772,
      -1.6878596776565342,
      -1.6253503202066908
    ],
    [
      -1.4480228903512733,
      -1.374526213510285,
      -1.4645442440564918,
      -1.375405176974537,
      -1.4588282926016989,
      -1.377539799511469,
      -1.4102075706657633,
      -1.4489615182686033,
      -1.3570391155802146,
      -1.4291366816187296,
      -1.4594684086053256,
      -1.450849147045175,
      -1.4507992544179342,
      -1.3843839728552767,
      -1.4066456328870016,
      -1.4489789279268266,
      -1.463829539380892,
      -1.4344953190535434,
      -1.4328418564603236,
      -1.4390686527238423,
      -1.463137686708872,
      0.0,
      -1.4535174605877368,
      -1.4168168465327664,
      -1.4719734658238457,
      -1.3807055498353749,
      -1.4609167008579567,
      -1.380608603512999,
      -1.363562485286192
    ],
    [
      -1.1876652392405833,
      -1.1410028898487903,
      -1.1734679046622243,
      -1.1606232599025383,
      -1.1647309972361952,
      -1.1883439703183702,
      -1.2174090895959586,
      -1.1575190787951013,
      -1.1719109632130413,
      -1.08740756212524,
      -1.1547190767330175,
      -1.2321559180222206,
      -1.136016099275833,
      -1.1557179685938468,
      -1.165763071498704,
      -1.1889019991696914,
      -1.16471870138584,
      -1.1932487008082193,
      -1.1392799319637716,
      -1.2043507245760574,
      -1.1394343315531448,
      -1.1789811931631617,
      0.0,
      -1.143805509391994,
      -1.113051321366433,
      -1.1599486872309468,
      -1.1427572317290398,
      -1.2227249206090494,
      -1.1608660190511844
    ],
    [
      -1.310762501054451,
      -1.179716291528115,
      -1.2014612386723516,
      -1.1418886319609736,
      -1.2720531509779083,
      -1.2478824916468918,
      -1.2366880507009594,
      -1.2604464881126063,
      -1.2015966948048542,
      -1.2660835221866318,
      -1.2357568512406154,
      -1.3831891391050748,
      -1.2340709163996348,
      -1.2213586114795834,
      -1.187187468930706,
      -1.1748505103588098,
      -1.295823684450362,
      -1.205085002330786,
      -1.285605516400755,
      -1.3089195095774477,
      -1.353049529374543,
      -1.2908158063309276,
      -1.3172963586687676,
      0.0,
      -1.28527510780851,
      -1.2408421733024753,
      -1.2955234040373556,
      -1.2921536238836604,
      -1.2423529952773473
    ],
    [
      -1.3611076298198588,
      -1.3870180773750105,
      -1.3863374489142841,
      -1.3479748499195163,
      -1.3807707498760868,
      -1.3300032565472737,
      -1.4193896472363219,
      -1.4038529479953332,
      -1.3911246702775075,
      -1.3481106006755466,
      -1.3836034202441045,
      -1.4797133557903706,
      -1.3826271272070194,
      -1.4603486590073769,
      -1.404644126106675,
      -1.3884711985249842,
      -1.4193718298623783,
      -1.3886684189598895,
      -1.3989958505752171,
      -1.4194027621354721,
      -1.433996467746562,
      -1.4198226219628902,
      -1.3879678224800005,
      -1.3264791097279929,
      0.0,
      -1.403552834249345,
      -1.3611139082817112,
      -1.4769092168414801,
      -1.447645803266496
    ],
    [
      -1.4973897220034353,
      -1.1753673120669739,
      -1.4127360412481826,
      -1.3175281666357683,
      -1.4737109518270213,
      -1.2631921221575328,
      -1.3516008809231983,
      -1.4267954610590425,
      -1.3560169496295231,
      -1.4688591659269463,
      -1.4191776650970689,
      -1.5762732773542876,
      -1.411304744027438,
      -1.3564713425454082,
      -1.2407601165776512,
      -1.4827188044126278,
      -1.4716998793402079,
      -1.4252584531891705,
      -1.452348129742076,
      -1.5225310837829709,
      -1.4968892964771727,
      -1.4826121790249953,
      -1.51870540110341,
      -1.467789617404794,
      -1.5146188007932373,
      0.0,
      -1.513530252083566,
      -1.5601731307377817,
      -1.410968279657213
    ],
    [
      -1.2859625950852107,
      -1.2598013724231827,
      -1.2788333433528394,
      -1.274723955530145,
      -1.2481386394432512,
      -1.2566045658728802,
      -1.2946738708530066,
      -1.2462397421616553,
      -1.3168656927112703,
      -1.2152683966227111,
      -1.2715575006010438,
      -1.3068351704154733,
      -1.26490786319194,
      -1.3202227504088486,
      -1.3476709639702682,
      -1.3450007979302978,
      -1.2634604012498574,
      -1.2997623961357012,
      -1.2989189947699533,
      -1.2981470469207088,
      -1.275055307134131,
      -1.3218050273784216,
      -1.2748466992647096,
      -1.2824311478156896,
      -1.2424786779135695,
      -1.2484634311170806,
      0.0,
      -1.3354995825964964,
      -1.309739340509092
    ],
    [
      -1.2828742650277285,
      -1.2406637292857094,
      -1.2260508397430925,
      -1.2574342407634251,
      -1.2516923763425272,
      -1.2756015947605517,
      -1.2845897649802978,
      -1.2598116256717744,
      -1.2536790882748712,
      -1.2305541337411783,
      -1.2384638968249722,
      -1.3226754086303676,
      -1.2594764795835574,
      -1.283988854749755,
      -1.2470021187637679,
      -1.265283992415455,
      -1.2579354119242272,
      -1.251913945905526,
      -1.2423215132824599,
      -1.268015323084761,
      -1.2898756297589449,
      -1.2348725931534026,
      -1.2972281872040423,
      -1.194013573781501,
      -1.2903523182567935,
      -1.2617777130204464,
      -1.2494406632370105,
      0.0,
      -1.272511809943505
    ],
    [
      -1.4085601766304339,
      -1.2434704098178113,
      -1.34535172898828,
      -1.284535306154128,
      -1.3707791105750171,
      -1.2800305941125283,
      -1.3820260541401008,
      -1.3440579365483718,
      -1.260922131335823,
      -1.3703081179384375,
      -1.3795918364230746,
      -1.39471811123177,
      -1.373734226709632,
      -1.2937119838688715,
      -1.2775456275519297,
      -1.3877550986752074,
      -1.367767783849163,
      -1.35543079801924,
      -1.4069456996193965,
      -1.393870961975118,
      -1.3821750049443824,
      -1.3133382369030089,
      -1.404778541387874,
      -1.3436159107049974,
      -1.3757357271914494,
      -1.223150064027768,
      -1.4016272057527044,
      -1.4209259203340907,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.22978419933669048,
      0.22525780381361016,
      0.2264341285624818,
      0.20546627540942386,
      0.21927682970464568,
      0.1607029877928423,
      0.2082354074509165,
      0.22474623147252037,
      0.2145795054654478,
      0.216333884211255,
      0.15654024860970295,
      0.22723647873477515,
      0.20673893277976574,
      0.19529942522875765,
      0.20217899404395667,
      0.17916894814541484,
      0.22451080168961002,
      0.1999510379382674,
      0.18870322088626845,
      0.1793511829588692,
      0.1850454210425767,
      0.1865106082667891,
      0.21826167563607712,
      0.21469469868769386,
      0.2291252497145484,
      0.19070191971893435,
      0.19952247885074836,
      0.1711537124817768
    ],
    [
      0.4371259705634507,
      0.0,
      0.5467736189065335,
      0.6656742075107331,
      0.49604944126136763,
      0.6390984467236949,
      0.5531438229963068,
      0.5042751049497289,
      0.5924434117840593,
      0.4494604660013064,
      0.5142283268063073,
      0.31499426395248076,
      0.5195028038937433,
      0.6360229917891473,
      0.6484610085718201,
      0.4878879041248836,
      0.4583857547778427,
      0.5155014864627081,
      0.41346472943817747,
      0.4053946735671279,
      0.4295654387093679,
      0.43692854642379597,
      0.38818802809951447,
      0.5268203343894358,
      0.388489170390111,
      0.675742957815632,
      0.40236364372511924,
      0.3917236070547365,
      0.49946253001787877
    ],
    [
      0.4101255921139144,
      0.5727615941625563,
      0.0,
      0.5465101545976974,
      0.545679469276773,
      0.5156999779532059,
      0.4599838626891126,
      0.5226099183652,
      0.5170153867047118,
      0.4579869804065746,
      0.5362773772634244,
      0.345630604526618,
      0.5641368251925225,
      0.44804846821522193,
      0.4248414077225031,
      0.49710244566049355,
      0.4910009534513966,
      0.5549499054295215,
      0.44934506375126415,
      0.4377137320917248,
      0.423560984033587,
      0.39633853418537646,
      0.39443851013509557,
      0.5400731627892674,
      0.41291881811904174,
      0.507951161765912,
      0.4218732246270587,
      0.4263901934060812,
      0.41448696796946605
    ],
    [
      0.32006697715796695,
      0.5554133147464,
      0.43640690718756736,
      0.0,
      0.40260390610322894,
      0.5424503300468926,
      0.4288475183440019,
      0.42102210741926527,
      0.48882873808967253,
      0.3300446986466452,
      0.4630707460778758,
      0.24374086691143249,
      0.474215242928659,
      0.5249214431808167,
      0.46391963995900376,
      0.39976194828433953,
      0.4001654784777089,
      0.44596216595943283,
      0.31919710525249756,
      0.35193825178588134,
      0.38532155822516545,
      0.33773589513536906,
      0.271817172228465,
      0.42235874571681054,
      0.3162476677249948,
      0.5096129403301473,
      0.3401803003349597,
      0.30576998896046215,
      0.3946815542741777
    ],
    [
      0.4163568535412807,
      0.48151309281066657,
      0.4803898256252963,
      0.4452289138547725,
      0.0,
      0.426118717044355,
      0.39966269552589573,
      0.4859387708266214,
      0.37425737581048013,
      0.43394332220899257,
      0.45034107833352643,
      0.3261259422936964,
      0.4769679363213617,
      0.40080157423135354,
      0.3867671923046765,
      0.37469414995151284,
      0.4532190363355839,
      0.49108215024394086,
      0.42833056813604986,
      0.3762984651628123,
      0.38558575093955394,
      0.37243069845691057,
      0.36542261929664654,
      0.43818107702232956,
      0.39428183746628265,
      0.4155623004916629,
      0.4225715313920997,
      0.3435716324835201,
      0.3627164862427328
    ],
    [
      0.38273731956184665,
      0.6248755016795837,
      0.46793506254454353,
      0.5750232952638021,
      0.43950053813840917,
      0.0,
      0.5348292028695563,
      0.4597661035513032,
      0.5332187050291444,
      0.3936009300591161,
      0.46229571782959855,
      0.3180021119422074,
      0.48641326543249885,
      0.5513091796300511,
      0.5775418391251526,
      0.3986624851225604,
      0.39844959025382165,
      0.4237031644447551,
      0.3820807212901012,
      0.39932080918585333,
      0.39233556553841487,
      0.4217564513069594,
      0.34751428811432605,
      0.420991009941482,
      0.4179363124655777,
      0.6247459180492949,
      0.39509116276905965,
      0.33642513413557773,
      0.4357682032831629
    ],
    [
      0.26000534984203116,
      0.5450747021938942,
      0.3695590312802588,
      0.44334761265651146,
      0.3201846410079876,
      0.5026793982584232,
      0.0,
      0.32423103333256775,
      0.421111925223697,
      0.33056807213776773,
      0.42604542840347714,
      0.27502793909788803,
      0.4011365802922482,
      0.4835812368581416,
      0.44734665843425003,
      0.3194787195972213,
      0.31149129522937224,
      0.4135883349925573,
      0.29305157995445175,
      0.2902226563926731,
      0.3191921075716495,
      0.3399391901188056,
      0.31463077864298183,
      0.3675812352796246,
      0.304202115647612,
      0.5012452199819717,
      0.32106424681088663,
      0.3267567230006727,
      0.35467671323913663
    ],
    [
      0.3113769392564194,
      0.423731870116117,
      0.44374108630693065,
      0.41747537771461785,
      0.40572444639262706,
      0.4333283490927604,
      0.3509375115105129,
      0.0,
      0.4071776569243599,
      0.401385970289736,
      0.4167997075648857,
      0.27183216502839214,
      0.4513189283196588,
      0.4220160138002089,
      0.3694059880104925,
      0.42205965226099007,
      0.42571594813604596,
      0.3793633904753788,
      0.4137403021872619,
      0.3791060760951197,
      0.34185968617958995,
      0.33565522650358504,
      0.3445127816921898,
      0.4164674046598029,
      0.33501351658975187,
      0.43890698089227276,
      0.3448628060681924,
      0.27850398514207364,
      0.3326066774347578
    ],
    [
      0.36743841276545064,
      0.5869963454822722,
      0.5392453915709925,
      0.5819277139680419,
      0.45331476765395173,
      0.5629796193640051,
      0.45104734059659446,
      0.48361631204092737,
      0.0,
      0.43588478842196676,
      0.4898747059727868,
      0.3253321164190184,
      0.5096285836233323,
      0.5724300481183644,
      0.5482928285238287,
      0.48566533974025705,
      0.4800690973433215,
      0.4758327015844066,
      0.3885371571332463,
      0.39428754198243166,
      0.46397303142268487,
      0.4439407917402305,
      0.36507184861977215,
      0.4795018513448923,
      0.3980018963926826,
      0.5670159097305756,
      0.40526593377899456,
      0.4159686935182674,
      0.49563664316935685
    ],
    [
      0.40007459326336625,
      0.4432866976319505,
      0.38860275099647024,
      0.37577473449403387,
      0.38422365104748746,
      0.3920241406190439,
      0.3412112659525628,
      0.41641631952963176,
      0.40531978035293736,
      0.0,
      0.3852787613318185,
      0.2975376185702294,
      0.4248303222678673,
      0.35456007849608917,
      0.41591938485501045,
      0.41180408919809297,
      0.4033285586185209,
      0.3464839925883565,
      0.4122115538947304,
      0.32235880760768354,
      0.3293739446856019,
      0.38171772896115774,
      0.36988052316087683,
      0.437150958583872,
      0.4021691680302659,
      0.39811905049127283,
      0.4100101434648633,
      0.3212905615488628,
      0.3816423752841198
    ],
    [
      0.36140510442072427,
      0.5162502766750072,
      0.48668508288022094,
      0.527636695557232,
      0.4369492192072335,
      0.4727052769230513,
      0.4578909513345901,
      0.5140542752493238,
      0.4657290223652122,
      0.40957106171308255,
      0.0,
      0.32491261491182954,
      0.5257143213664677,
      0.5111964209232307,
      0.42203506258544143,
      0.4627092768797194,
      0.4285399897845181,
      0.46870451868037977,
      0.41096374123572144,
      0.4185111260938321,
      0.41165897397501894,
      0.36240688360549234,
      0.34331452965068276,
      0.4481931636733065,
      0.40361795554492064,
      0.5110270806215089,
      0.37179349713968857,
      0.36004015055513494,
      0.3723103573628239
    ],
    [
      0.22699061824126043,
      0.2519084540984191,
      0.22675050099805505,
      0.21996178657891186,
      0.24326387454133713,
      0.24661482179470395,
      0.22506158210967264,
      0.2373633494331282,
      0.24098878483897557,
      0.2509977302558928,
      0.24976496969905493,
      0.0,
      0.23976029769363905,
      0.23363981432307224,
      0.22066410992087926,
      0.2463336605104105,
      0.228496573616515,
      0.2576671130024659,
      0.2595345406539751,
      0.2282321275980408,
      0.2693341380432621,
      0.2538578765080337,
      0.2546142674424934,
      0.22698655735590156,
      0.2644142441173454,
      0.269895099488783,
      0.2555040394448833,
      0.2324864319227511,
      0.26229116443473144
    ],
    [
      0.3405317848914775,
      0.4511055520436704,
      0.469621914169301,
      0.43264029670682036,
      0.40457374503278487,
      0.4025293019757339,
      0.35234608959630176,
      0.4514523378437365,
      0.4059418930162939,
      0.4177391145489773,
      0.4375102508910753,
      0.30036677066266537,
      0.0,
      0.44315416473020885,
      0.36514414118996785,
      0.38231384270824353,
      0.3852861619341461,
      0.39885353110366006,
      0.42489043084831635,
      0.36540687839707564,
      0.3909665686472825,
      0.32554280331269103,
      0.34686017737148367,
      0.41764497130977896,
      0.3414422927275671,
      0.43997703984995296,
      0.34528053927097924,
      0.3232721419429798,
      0.3510291960806078
    ],
    [
      0.3318641935495905,
      0.6255745199225724,
      0.4307832125630491,
      0.5436828200116897,
      0.3725559592949217,
      0.5408151048675889,
      0.5127715588924999,
      0.4449582776228771,
      0.5338111127061622,
      0.3675112767444104,
      0.4325156370856986,
      0.28270361438411884,
      0.4778994394590317,
      0.0,
      0.5779409530359942,
      0.44236545704617725,
      0.47581076009871337,
      0.3977717463034198,
      0.34020581675517714,
      0.3491420699152319,
      0.3913366830265079,
      0.39074671552839435,
      0.3365302849802696,
      0.4228557263530248,
      0.3319063321778055,
      0.5703870085938498,
      0.3389123516049972,
      0.3282290585385079,
      0.45148489467576014
    ],
    [
      0.35975210721271744,
      0.6445637902826971,
      0.40854775115222086,
      0.5744613281929138,
      0.404889469528406,
      0.585630814474702,
      0.5062882835134084,
      0.41992988704736955,
      0.5366847847597513,
      0.4427737806694103,
      0.419702403961832,
      0.2940314428014119,
      0.45617907839199034,
      0.5604147226202005,
      0.0,
      0.4488443047209896,
      0.3989553346440824,
      0.40965946432831624,
      0.4199835491456474,
      0.36921862236979863,
      0.3475802881774708,
      0.4117221939316702,
      0.4013695813300864,
      0.555508246221649,
      0.4018665510264734,
      0.6115556068490577,
      0.3970715798819857,
      0.35899440044327013,
      0.4781891840841963
    ],
    [
      0.37291183743697465,
      0.44454450183227534,
      0.44829673514056645,
      0.524073487584507,
      0.3874649786646902,
      0.4170667405301416,
      0.38143321404804587,
      0.45218552419856417,
      0.4848287932716393,
      0.41367693852075327,
      0.43044707993625253,
      0.31923536093946425,
      0.41828590204558713,
      0.4446435355075,
      0.43165794339417585,
      0.0,
      0.46289989472347326,
      0.41061012414179987,
      0.35715853831500755,
      0.3369431037266102,
      0.36590676774042485,
      0.384019587764842,
      0.30757729867685923,
      0.4898495921654862,
      0.35805771957382304,
      0.43421901081191105,
      0.36356094518464666,
      0.33044621291674625,
      0.40600751764310217
    ],
    [
      0.34231617156730754,
      0.46632701231199447,
      0.46160350799282535,
      0.48197491293469774,
      0.4493804210681527,
      0.4372547552030548,
      0.3972326034413445,
      0.5576778433805198,
      0.4822974226563892,
      0.4375167615977449,
      0.4806794986255374,
      0.2984593231244861,
      0.4802049851737784,
      0.5215449466994613,
      0.41279787557837233,
      0.46536478801031933,
      0.0,
      0.4764944666344142,
      0.3819083426080969,
      0.40833633516247003,
      0.39946943776465926,
      0.391358126389759,
      0.36529961928748356,
      0.430266171382957,
      0.3808916410675831,
      0.4524993213587096,
      0.3914035546342691,
      0.32330027367812453,
      0.3562397094819678
    ],
    [
      0.3546195715686813,
      0.49486917622702653,
      0.486516539175311,
      0.48608999870244296,
      0.4874989058833903,
      0.45424530907990857,
      0.4101720602873502,
      0.45555349579524074,
      0.4545275101970132,
      0.3758496703695773,
      0.48580500583060826,
      0.3282035339502909,
      0.43363862309514123,
      0.4193228080990452,
      0.381966979025838,
      0.35353251759931426,
      0.39637560881749745,
      0.0,
      0.39508439045281607,
      0.38521336157238273,
      0.37964112603756583,
      0.3527903041412994,
      0.323420049005571,
      0.4679016469435857,
      0.396413387641934,
      0.4542880045494615,
      0.36656298823562805,
      0.34597061939715523,
      0.34499371210335017
    ],
    [
      0.38404758391313676,
      0.427789929380227,
      0.40298915684224146,
      0.40163667446084705,
      0.42041486343818635,
      0.4379190651633631,
      0.3459084523846836,
      0.44161413543018346,
      0.36427885090393985,
      0.4437008245942591,
      0.40424222924276143,
      0.31832417534130264,
      0.47127188895163497,
      0.378515015471506,
      0.40549415185201854,
      0.3667491010319255,
      0.38073598903369166,
      0.4085092409700135,
      0.0,
      0.4257596156607304,
      0.354052698299022,
      0.4238919353517139,
      0.37260696512929914,
      0.4479792649017693,
      0.3857162266708636,
      0.38829699282523955,
      0.37691947326946984,
      0.40655022644706706,
      0.35523290098673366
    ],
    [
      0.346985829574199,
      0.393103763256033,
      0.4158443513439032,
      0.39630307561902356,
      0.38783109114660963,
      0.42379458682633087,
      0.3426259504647755,
      0.4694680259446602,
      0.376200633233847,
      0.3697799651238114,
      0.4100750750949078,
      0.2942920361556052,
      0.421995793049756,
      0.34919086597511684,
      0.3344183598364179,
      0.3607852381570029,
      0.38915679752059207,
      0.3716670450572055,
      0.42649493472926814,
      0.0,
      0.39334511693645124,
      0.3757182297680275,
      0.34688125672893677,
      0.39047386039935494,
      0.36509088655540345,
      0.37526489196960267,
      0.39409121015167003,
      0.37433305894847857,
      0.3461859191479508
    ],
    [
      0.3078150357754941,
      0.4061581888874539,
      0.3921310785354797,
      0.3936689426466664,
      0.36759412200905617,
      0.3953489109749335,
      0.3023348915870063,
      0.3825939520713131,
      0.41014784147520045,
      0.35776481436843777,
      0.38142992081185545,
      0.28439131475815893,
      0.4043509822503977,
      0.3996070619896541,
      0.3644169287801229,
      0.34071872613211807,
      0.37699564245604567,
      0.39788849204582477,
      0.33720197589967693,
      0.3524779895312431,
      0.0,
      0.37701731878160016,
      0.3318624442305471,
      0.37941062508485346,
      0.334452394994035,
      0.38145899381662507,
      0.34499461355994665,
      0.2966973636061845,
      0.3592067210560279
    ],
    [
      0.3265074214507675,
      0.40000409829175587,
      0.30998606774554904,
      0.3991251348275038,
      0.3157020192003419,
      0.3969905122905717,
      0.3643227411362775,
      0.3255687935334375,
      0.4174911962218262,
      0.34539363018331115,
      0.31506190319671523,
      0.3236811647568658,
      0.32373105738410657,
      0.3901463389467641,
      0.3678846789150392,
      0.3255513838752142,
      0.3107007724211488,
      0.34003499274849736,
      0.3416884553417172,
      0.33546165907819847,
      0.3113926250931689,
      0.0,
      0.321012851214304,
      0.3577134652692744,
      0.3025568459781951,
      0.39382476196666594,
      0.31361361094408413,
      0.3939217082890418,
      0.41096782651584873
    ],
    [
      0.340552894449921,
      0.387215243841714,
      0.35475022902828,
      0.36759487378796596,
      0.3634871364543091,
      0.33987416337213405,
      0.3108090440945457,
      0.370699054895403,
      0.35630717047746296,
      0.4408105715652644,
      0.37349905695748675,
      0.2960622156682837,
      0.3922020344146713,
      0.3725001650966575,
      0.36245506219180035,
      0.3393161345208129,
      0.3634994323046643,
      0.334969432882285,
      0.38893820172673266,
      0.3238674091144469,
      0.3887838021373595,
      0.34923694052734255,
      0.0,
      0.3844126242985102,
      0.41516681232407127,
      0.3682694464595575,
      0.38546090196146454,
      0.30549321308145494,
      0.36735211463931994
    ],
    [
      0.3965151936639877,
      0.5275614031903237,
      0.5058164560460872,
      0.5653890627574651,
      0.43522454374053043,
      0.4593952030715469,
      0.47058964401747927,
      0.4468312066058324,
      0.5056809999135845,
      0.4411941725318069,
      0.4715208434778233,
      0.3240885556133639,
      0.47320677831880387,
      0.48591908323885535,
      0.5200902257877327,
      0.5324271843596289,
      0.4114540102680768,
      0.5021926923876527,
      0.4216721783176838,
      0.398358185140991,
      0.3542281653438957,
      0.4164618883875111,
      0.3899813360496711,
      0.0,
      0.42200258690992865,
      0.46643552141596345,
      0.41175429068108316,
      0.4151240708347783,
      0.4649246994410914
    ],
    [
      0.40570203820199824,
      0.37979159064684653,
      0.3804722191075729,
      0.4188348181023407,
      0.3860389181457702,
      0.4368064114745833,
      0.34742002078553513,
      0.3629567200265238,
      0.3756849977443495,
      0.41869906734631046,
      0.3832062477777525,
      0.28709631223148646,
      0.3841825408148376,
      0.30646100901448015,
      0.3621655419151819,
      0.3783384694968728,
      0.3474378381594787,
      0.37814124906196755,
      0.3678138174466399,
      0.3474069058863849,
      0.33281320027529504,
      0.3469870460589668,
      0.3788418455418565,
      0.44033055829386414,
      0.0,
      0.36325683377251194,
      0.4056957597401458,
      0.2899004511803769,
      0.31916386475536096
    ],
    [
      0.4043064116311361,
      0.7263288215675976,
      0.4889600923863888,
      0.5841679669988031,
      0.4279851818075502,
      0.6385040114770386,
      0.5500952527113732,
      0.4749006725755289,
      0.5456791840050483,
      0.43283696770762514,
      0.4825184685375026,
      0.3254228562802839,
      0.49039138960713347,
      0.5452247910891632,
      0.6609360170569203,
      0.41897732922194364,
      0.4299962542943636,
      0.4764376804454009,
      0.4493480038924955,
      0.3791650498516006,
      0.40480683715739874,
      0.41908395460957615,
      0.38299073253116145,
      0.4339065162297775,
      0.38707733284133417,
      0.0,
      0.3881658815510054,
      0.3415230028967897,
      0.4907278539773585
    ],
    [
      0.32719198965717045,
      0.3533532123191985,
      0.3343212413895418,
      0.3384306292122361,
      0.36501594529912995,
      0.356550018869501,
      0.3184807138893746,
      0.3669148425807258,
      0.29628889203111086,
      0.39788618811967,
      0.3415970841413374,
      0.3063194143269079,
      0.34824672155044123,
      0.29293183433353254,
      0.26548362077211296,
      0.26815378681208335,
      0.3496941834925238,
      0.31339218860667994,
      0.31423558997242784,
      0.31500753782167235,
      0.3380992776082501,
      0.2913495573639595,
      0.33830788547767154,
      0.3307234369266916,
      0.3706759068288117,
      0.3646911536253006,
      0.0,
      0.2776550021458848,
      0.30341524423328914
    ],
    [
      0.3344618829967121,
      0.37667241873873114,
      0.3912853082813481,
      0.35990190726101545,
      0.3656437716819134,
      0.3417345532638889,
      0.33274638304414283,
      0.3575245223526662,
      0.3636570597495694,
      0.3867820142832623,
      0.37887225119946843,
      0.294660739394073,
      0.35785966844088324,
      0.3333472932746855,
      0.3703340292606727,
      0.3520521556089855,
      0.3594007361002134,
      0.36542220211891463,
      0.3750146347419807,
      0.34932082493967953,
      0.3274605182654957,
      0.382463554871038,
      0.3201079608203983,
      0.4233225742429396,
      0.32698382976764706,
      0.3555584350039942,
      0.36789548478743006,
      0.0,
      0.3448243380809355
    ],
    [
      0.3729722281368326,
      0.5380619949494552,
      0.43618067577898656,
      0.49699709861313845,
      0.4107532941922494,
      0.5015018106547382,
      0.39950635062716566,
      0.4374744682188947,
      0.5206102734314435,
      0.41122428682882894,
      0.4019405683441919,
      0.38681429353549657,
      0.4077981780576345,
      0.48782042089839495,
      0.5039867772153368,
      0.3937773060920591,
      0.4137646209181034,
      0.42610160674802655,
      0.37458670514786996,
      0.38766144279214854,
      0.3993573998228841,
      0.4681941678642576,
      0.37675386337939254,
      0.43791649406226907,
      0.40579667757581706,
      0.5583823407394986,
      0.3799051990145621,
      0.3606064844331758,
      0.0
    ]
  ],
  "row_avgs": [
    0.20305401030837025,
    0.4977561675252504,
    0.4726946884501901,
    0.40343940033892284,
    0.4145843426555219,
    0.4500653424484914,
    0.3688221616242414,
    0.38266523016588333,
    0.4702420504293805,
    0.3840214841259562,
    0.43594737967554986,
    0.24369209030952124,
    0.3897651404572779,
    0.4301097352049301,
    0.4508703054201331,
    0.4063574602298525,
    0.4260749938863029,
    0.4096809608494439,
    0.39789812956956533,
    0.3800499231683907,
    0.36286204600414146,
    0.3492870613148641,
    0.3622709065097829,
    0.4512871493397564,
    0.36898736760733186,
    0.47073087553354637,
    0.3280147535502585,
    0.35697539473473877,
    0.43201596528831615
  ],
  "col_avgs": [
    0.3550984966573506,
    0.47409361666511185,
    0.4189090570996119,
    0.456784558899247,
    0.39589337845099354,
    0.4471048993248051,
    0.3931572141515342,
    0.42127973079543185,
    0.43217698694251433,
    0.39318441323964254,
    0.41574765102167205,
    0.30227962914956297,
    0.4300823802525929,
    0.4312860806903818,
    0.42170242253748286,
    0.3884859425274331,
    0.3896498307627456,
    0.4073391386120569,
    0.37452263093597493,
    0.35788694569321844,
    0.36465545980771064,
    0.3705120560228908,
    0.34236857525374376,
    0.41974224823137823,
    0.36350302949419905,
    0.4509755440350531,
    0.3661632440624324,
    0.33608810247710375,
    0.37954925293203645
  ],
  "combined_avgs": [
    0.2790762534828604,
    0.48592489209518114,
    0.445801872774901,
    0.4301119796190849,
    0.40523886055325775,
    0.44858512088664826,
    0.3809896878878878,
    0.4019724804806576,
    0.4512095186859474,
    0.3886029486827994,
    0.425847515348611,
    0.2729858597295421,
    0.4099237603549354,
    0.43069790794765594,
    0.436286363978808,
    0.3974217013786428,
    0.40786241232452425,
    0.4085100497307504,
    0.3862103802527701,
    0.36896843443080457,
    0.3637587529059261,
    0.35989955866887746,
    0.3523197408817633,
    0.4355146987855673,
    0.3662451985507654,
    0.4608532097842997,
    0.3470889988063455,
    0.3465317486059213,
    0.4057826091101763
  ],
  "gppm": [
    601.1433568905867,
    561.0845955168097,
    588.3644977629966,
    568.0635837143396,
    599.8587366336586,
    571.14442757398,
    597.6170362729483,
    586.274720497268,
    583.3082692346765,
    599.353978211914,
    591.9478775669867,
    640.1292414020475,
    582.1842974939229,
    580.580582757989,
    585.7722279756183,
    602.8434766371855,
    600.5243861837623,
    594.9644850019819,
    607.6740101513985,
    614.6271102292927,
    608.0032299098721,
    609.3152500177712,
    625.5977563338336,
    589.0118634316729,
    611.391205737498,
    570.2740508294904,
    614.4742441630942,
    627.069684011459,
    606.060543146634
  ],
  "gppm_normalized": [
    1.38515496846678,
    1.2930445880354644,
    1.3555649920826762,
    1.310816248713325,
    1.3764700830522618,
    1.311841390524649,
    1.3805306674215012,
    1.347335668211528,
    1.3424971856359798,
    1.3783013004175722,
    1.3610461110861303,
    1.485471137084534,
    1.3438032441149286,
    1.3459963198053,
    1.348489526965411,
    1.3877882286342396,
    1.3817994634902082,
    1.3657873333589898,
    1.3927350638218514,
    1.4113973767147863,
    1.4034229930902422,
    1.3971199344114924,
    1.4413243345904372,
    1.3533590574213812,
    1.399955586333659,
    1.3140826401423145,
    1.4121261004707064,
    1.4383129823924186,
    1.3861121888569752
  ],
  "token_counts": [
    449,
    442,
    457,
    469,
    405,
    411,
    478,
    424,
    432,
    434,
    418,
    576,
    471,
    536,
    433,
    435,
    431,
    402,
    393,
    417,
    463,
    400,
    456,
    424,
    387,
    443,
    422,
    396,
    359,
    580,
    438,
    467,
    431,
    435,
    409,
    435,
    418,
    448,
    403,
    426,
    581,
    423,
    449,
    432,
    432,
    425,
    368,
    421,
    434,
    418,
    424,
    385,
    435,
    408,
    359,
    468,
    462,
    400,
    583,
    461,
    409,
    488,
    417,
    454,
    485,
    445,
    429,
    436,
    411,
    551,
    480,
    483,
    477,
    458,
    399,
    435,
    428,
    419,
    435,
    425,
    421,
    410,
    448,
    435,
    409,
    421,
    399
  ],
  "response_lengths": [
    2822,
    2626,
    2458,
    2829,
    2377,
    2594,
    2873,
    2547,
    2290,
    2429,
    2362,
    3138,
    2763,
    2707,
    2595,
    2728,
    2246,
    2584,
    2533,
    2456,
    2414,
    2446,
    2451,
    2301,
    2523,
    2341,
    2226,
    2357,
    2192
  ]
}