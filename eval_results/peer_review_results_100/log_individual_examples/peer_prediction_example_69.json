{
  "example_idx": 69,
  "reference": "Under review as a conference paper at ICLR 2023\n\nTIGHT NON-ASYMPTOTIC INFERENCE VIA SUB-GAUSSIAN INTRINSIC MOMENT NORM\n\nAnonymous authors Paper under double-blind review\n\nABSTRACT\n\nIn non-asymptotic statistical inferences, variance-type parameters of sub-Gaussian distributions play a crucial role. However, direct estimation of these parameters based on the empirical moment generating function (MGF) is infeasible. To this end, we recommend using a sub-Gaussian intrinsic moment norm [Buldygin and Kozachenko (2000), Theorem 1.3] through maximizing a series of normalized moments. Importantly, the recommended norm can not only recover the exponential moment bounds for the corresponding MGFs, but also lead to tighter Hoeffiding’s sub-Gaussian concentration inequalities. In practice, we propose an intuitive way of checking sub-Gaussian data with a finite sample size by the sub-Gaussian plot. Intrinsic moment norm can be robustly estimated via a simple plug-in approach. Our theoretical results are applied to non-asymptotic analysis, including the multi-armed bandit.\n\n1\n\nINTRODUCTION\n\nWith the advancement of machine learning techniques, computer scientists have become more interested in establishing rigorous error bounds for desired learning procedures, especially those with finite sample validity (Wainwright, 2019; Zhang & Chen, 2021; Yang et al., 2020). In specific settings, statisticians, econometricians, engineers and physicist have developed non-asymptotic inferences to quantify uncertainty in data; see Romano & Wolf (2000); Chassang (2009); Arlot et al. (2010); Yang et al. (2020); Horowitz & Lee (2020); Armstrong & Koles ́ar (2021); Zheng & Cheng (2021); Lucas et al. (2008); Owhadi et al. (2013); Wang (2020). Therefore, the concentration-based statistical inference has received a considerable amount of attention, especially for bounded data (Romano & Wolf, 2000; Auer et al., 2002; Hao et al., 2019; Wang et al., 2021; Shiu, 2022) and Gaussian data (Arlot et al., 2010; Duy & Takeuchi, 2022; Bettache et al., 2021; Feng et al., 2021). For example, Hoeffding’s inequality can be applied to construct nonasymptotic confidence intervals based on bounded data1.\n\nHowever, in reality, it may be hard to know the support of data or its underlying distribution. In this case, misusing Hoeffding’s inequality (Hoeffding, 1963) for unbounded data will result in a notably loose confidence interval (CI); see Appendix A.1. Hence, it is a common practice to assume that data follow sub-Gaussian distribution (Kahane, 1960). (cid:8) exp{−st}E exp{sX}(cid:9), ∀ t ≥ 0. Hence, tightness of a By the Chernoff inequality2, we have P(X ≥ t) ≤ inf s>0 confidence interval relies on how we upper bound the moment generating function (MGF) E exp{sX} for all s > 0. This can be further translated into the following optimal variance proxy of sub-Gaussian distribution. Definition 1. A r.v. X is sub-Gaussian (sub-G) with a variance proxy σ2 [denoted as X ∼ subG(σ2)] if its MGF satisfies E exp(tX) ≤ exp(σ2t2/2) for all t ∈ R. The sub-Gaussian parameter σopt(X) is defined by the optimal variance proxy (Chow, 1966):\n\nopt(X) := inf (cid:8)σ2 > 0 : E exp(tX) ≤ exp{σ2t2/2}, σ2\n\n∀ t ∈ R(cid:9) = 2 sup t∈Rt−2log[E exp(tX)].\n\n(1)\n\nNote that σ2 (Arbel et al., 2020). Based on Theorems 1.5 in Buldygin & Kozachenko (2000), we have\n\nopt(X) ≥ Var X; see (14) in Appendix A.2. When σ2\n\nopt(X) = Var X, it is called strict sub-Gaussianity\n\nP (X ≥ t) ≤ exp\n\n−\n\n(cid:26)\n\nt2\n\n2σ2\n\nopt(X)\n\n(cid:27)\n\n(cid:16)\n\n, P\n\nn (cid:88)\n\n|\n\ni=1\n\n(cid:17)\n\nXi| ≥ t\n\n(cid:26)\n\n≤ 2 exp\n\n−\n\nt2 i=1 σ2\n\n2 (cid:80)n\n\nopt(Xi)\n\n(cid:27)\n\n.\n\n(2)\n\n1Recently, Phan et al. (2021) obtained a sharper result than Hoeffding’s inequality for bounded data. 2For simplicity, we consider centered random variable (r.v.) with zero mean throughout the paper for all sub-Gaussian r.v..\n\n1\n\nUnder review as a conference paper at ICLR 2023\n\nfor independent sub-G r.v.s X and {Xi}n P(X > t) ≤ exp(−Ct2) (or P(| (cid:80)n\n\ni=1. The above inequality (2) provides the tightest upper bound over the form i=1 Xi| > t) ≤ exp(−Ct2)) for some positive constant C via Chernoff inequality.\n\nGiven {Xi}n\n\ni=1\n\ni.i.d.∼ subG(σ2\n\nopt(X)), a straightforward application of (2) gives an non-asymptotic 100(1 − α)% CI\n\nEX = 0 ∈ [X n ± σopt(X)(cid:112)2n−1 log(2/α)].\n\nA naive plug-in estimate3 of σ2\n\nopt(X) := 2 sup t∈Rt−2log[E exp(tX)] (Arbel et al., 2020) is\n\nopt(X) := 2 sup t∈Rt−2log[n−1Σn (cid:98)σ2\n\ni=1 exp(tXi)].\n\n(3)\n\n(4)\n\nHowever, two weaknesses of (4) substantially hinder its application: (i) the optimization result is unstable due to the possible non-convexity of the objective function; (ii) exponentially large n is required to ensure the variance term Var(n−1 (cid:80)n\n\ni=1 exp(tXi)) not to explode when t is large. In Section 3, we present some simulation evidence.\n\nOn the other hand, we are aware of other forms of variance-type parameter. For instance, van der Vaart & Well- := inf{c > 0 : E exp{|X|2/c2} ≤ 2}, frequently used in ner (1996) introduced the Orlicz norm as ∥X∥w2 empirical process theory. Additionally, Vershynin (2010) suggested a norm based on the scale of moments as ∥X∥ψ2 := maxk≥2 k−1/2(E|X|k)1/k in Page 6 of Buldygin & Kozachenko (2000). However, as shown in Table 1 and Appendix A.2.1, both types of norm fail to deliver sharp probability bounds even for strict sub-G distributions, such as the standard Gaussian distribution and symmetric beta distribution.\n\nTable 1: Comparison of sub-Gaussian norms ∥ · ∥∗ for centralized and symmetric X.\n\n∥ · ∥∗-norm\n\nσopt(X)\n\n∥X∥w2 ∥X∥ψ2 ∥X∥G (Def. 2)\n\nsharp tail for P(|X| ≥ t) Yes [2exp{− t2 Yes [2 exp{− t2 No [2exp{− t2 Yes [2exp{− t2\n\n2 /σ2 2 /( 2 /(2e∥X∥2 2 /∥X∥2 G}]\n\nopt(X)}] ∥X∥w2√\n\nψ2\n\n2\n\n)2]}]\n\n)}]\n\nsharp MGF bound\n\nopt(X) t2\n\nYes [exp{σ2 2 }] No [exp{(2∥X∥w2 )2 t2\n\nNo [exp{(4 Yes [exp{∥X∥2\n\n√\n\n2 }] e∥X∥ψ2 )2 t2 t2 2 }]\n\nG\n\nhalf length of (1 − δ)-CI (cid:112)2 log(2/δ)σopt(X) (cid:112)2 log(2/δ)∥X∥w2 /\n\n√\n\n2\n\n2 }] (cid:112)2 log(2/δ)\n\n2e∥X∥ψ2\n\n√\n\n(cid:112)2 log(2/δ)∥X∥G\n\neasy to estimate\n\nNo\n\nNo\n\nYes\n\nYes\n\n1.1 CONTRIBUTIONS\n\nIn light of the above discussions, we advocate the use of the intrinsic moment norm in the Definition 2 in the construction of tight non-asymptotic CIs. There are two specific reasons: (i) it approximately recovers tight inequalities (2); (ii) it can be estimated friendly (with a closed form) and robustly.\n\nThe following definition 2 is from Page 6 and Theorem 1.3 in Buldygin & Kozachenko (2000). Definition 2 (Intrinsic moment norm). ∥X∥G := maxk≥1 [ 2kk!\n\n(2k)! EX 2k]1/(2k) = maxk≥1 [\n\n1\n\n(2k−1)!! EX 2k]1/(2k).\n\nFrom the sub-G characterization (see Theorem 2.6 in Wainwright (2019)), ∥X∥G < ∞ iff σopt(X) < ∞ for any zeromean r.v. X. Hence, the finite intrinsic moment norm of a r.v. X ensures sub-Gaussianity (satisfying Definition 1).\n\nOur contributions in this paper can be summarized as follows.\n\n1. By ∥X∥G, we achieve a sharper Hoeffding-type inequality under asymetric distribution; see Theorem 2(b).\n\n2. Compared to the normal approximation based on Berry-Esseen (B-E) bounds, our results are more applicable to data of extremely small sample size. We illustrate Bernoulli observations with the comparison of two types of CIs based on the B-E-corrected CLT and Hoeffding’s inequality in Figure 1; see Appendix A for details.\n\n3. A novel method called sub-Gaussian plot is proposed for checking whether the unbounded data are subGaussian. We introduce plug-in and robust plug-in estimators for ∥X∥G, and establish finite sample theories.\n\n4. Finally, we employ the intrinsic moment norm estimation in the non-asymptotic inference for a bandit problem: Bootstrapped UCB-algorithm for multi-armed bandits. This algorithm is shown to achieve feasible error bounds and competitive cumulative regret on unbounded sub-Gaussian data.\n\n3We point out that a conservative and inconsistent estimator 2 inf t∈R log(n−1 (cid:80)n\n\ni=1 exp(tXi))/t2 was proposed in statistical\n\nphysics literature (Wang, 2020).\n\n2\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 1: CIs via Hoeffding’s inequality (red line) and B-E-corrected CLT (blue line). It describes a deficiency of B-E-corrected CLT under small sample, and it suggests that a simple Hoeffding’s inequality can even perform better.\n\n2\n\nSUB-GAUSSIAN PLOT AND TESTING\n\nBefore estimating ∥X∥G, the first step is to verify X is indeed sub-G given its i.i.d. copies {Xi}n in Zhang & Chen (2021) shows for r.v.s Xi ∼ subG(σ2\n\nopt(X)) (without independence assumption)\n\ni=1. Corollary 7.2 (b)\n\nP(max1≤i≤j Xi ≤ σopt(X)(cid:112)2(log j + t)) ≥ 1 − exp{−t},\n\n(5)\n\nwhich implies max1≤i≤j Xi = OP( unbound sub-G r.v.s characterized by the lower intrinsic moment norm below.\n\nlog j). Moreover, we will show the above rate is indeed sharp for a class of\n\n√\n\nDefinition 3 (Lower intrinsic moment norm). The lower intrinsic moment norm for a sub-G X is defined as\n\n∥X∥ ̃G := mink≥1{[(2k − 1)!!]−1EX 2k}1/(2k).\n\nBy the method in Theorem 1 of Zhang & Zhou (2020), we obtain the following the tight rate result with a lower bound. Theorem 1. (a). If ∥X∥ ̃G > 0 for i.i.d. symmetric sub-G r.v.s {Xi}n\n\ni=1 ∼ X, then with probability at least 1 − δ\n\n(cid:115)\n\n∥X∥ ̃G/∥X∥G G/∥X∥2 2∥X∥2\n\n ̃G − 1\n\n(cid:113)\n\n2\n\nlog n − log C −2(X) − log log\n\n(cid:19)\n\n(cid:18) 2 δ\n\n≤ max 1≤i≤n\n\nXi ∥X∥G\n\n(cid:115)\n\n≤\n\n2[log n + log\n\n(cid:19)\n\n],\n\n(cid:18) 2 δ\n\nwhere C(X) < 1 is constant defined in Lemma 1 below; (b) if X is bounded variable, then ∥X∥ ̃G = 0.\n\nThe upper bound follows from the proof of (5) similarly. The proof of lower bound relies on the sharp reverse Chernoff inequality from Paley–Zygmund inequality (see Paley & Zygmund (1932)). Lemma 1 (A reverse Chernoff inequality). Suppose ∥X∥ ̃G > 0 for a symmetric sub-G r.v. X. For t > 0, then\n\nP(X ≥ t) ≥ C 2(X) exp{−4[2∥X∥2\n\nG/∥X∥4\n\n ̃G − ∥X∥−2\n\n ̃G ]t2},\n\nwhere C(X) :=\n\n(cid:16)\n\n∥X∥2 ̃G G−∥X∥2 ̃G\n\n4∥X∥2\n\n(cid:17) (cid:16) 4∥X∥2 4∥X∥2\n\nG−2∥X∥2 ̃G G−∥X∥2 ̃G\n\n(cid:17)2[2∥X∥2\n\nG/∥X∥2 ̃G\n\n−1]\n\n∈ (0, 1).\n\nTheorem 1 of Zhang & Zhou (2020) does not optimize the constant in Paley–Zygmund inequality. In contrast, our Lemma 1 has an optimal constant; see Appendix C for details.\n\nSub-Gaussian plot under unbounded assumption4. By Theorem 1, we propose a novel sub-Gaussian plot check whether i.i.d data {Xi}n i=1 are independently sampled from the empirical distribution Fn(x) = 1 i=1. Specifically, we plot the order statistics {max1≤i≤j X ∗ log j + 1 and y axis the value of\n\ni=1 follow a sub-G distribution. Suppose that for each j, {X ∗\n\nj=1 on the plane coordinate axis, where x axis represents\n\ni=1 1(Xi ≤ x) of {Xi}n\n\ni }n\n\ni }j\n\n(cid:80)n\n\n√\n\nn\n\n4Sub-G plot can only be applied to data with enough samples. When n is very small, there is not enough information to suggest unbounded trends. We roughly treat the data as bounded r.v. for a very small n, and there is no need to use a sub-G plot in this case.\n\n3\n\nn >= 269n >= 3570.51.01.52.00100200300400500nConfidence Lengthdelta = 0.05n >= 120n >= 1630.51.01.50100200300400500nConfidence Lengthdelta = 0.075n >= 68n >= 950.51.01.50100200300400500nConfidence Lengthdelta = 0.1Under review as a conference paper at ICLR 2023\n\nmax1≤i≤j X ∗ tendency of a beeline, the more we can trust the data are sub-Gaussian.\n\ni . We check whether those points have a linear tendency at the boundary: the more they are close to the\n\nThe Figure 2 shows sub-Gaussian plot of N (0, 1) and Exp(1). It can be seen that sub-Gaussian plot of N (0, 1) shows linear tendency at the boundary, while Exp(1) shows quadratic tendency at the boundary. For the quadratic tendency, we note that if {Xi}n i=1 have heavier tails such as sub-exponentiality, then max1≤i≤j Xi = OP(log j) instead of the √\norder O(\n\nlog j); see Corollary 7.3 in Zhang & Chen (2021).\n\nFigure 2: sub-Gaussian plot of standard Gaussian and standard exponential distribution for n = 1000. Left: The two dot lines indicate the points drop in a triangle region with a high probability. Right: The points in the case of exponential distribution approximately live curve triangle region with quadratic trends.\n\n3 FINITE SAMPLE PROPERTIES OF INTRINSIC MOMENT NORM\n\nIn this section, we characterize two important properties of the intrinsic moment norm that are used in constructing non-asymptotic confidence intervals.\n\n3.1 BASIC PROPERTIES\n\nLemma 2 below establishes that the intrinsic moment norm is estimable.\n\nLemma 2. For sub-G X, we have arg maxm∈2N\n\n(cid:104) EXm\n\n(m−1)!!\n\n(cid:105)1/m\n\n< ∞, where 2N := {2, 4, · · · } is the even number set.\n\nLemma 2 ensure that for any sub-Gaussian variable X, its intrinsic moment norm can be computed as\n\n∥X∥G := maxm∈2N\n\n(cid:104) EXm\n\n(m−1)!!\n\n(cid:105)1/m\n\n= max1≤k≤kX\n\n(cid:104) EX 2k\n\n(2k−1)!!\n\n(cid:105)1/(2k)\n\nwith some finite kX < ∞.\n\nThis is an important property that other norms may not have. The ∥X∥ψ2 := maxk≥2 k−1/2(E|X|k)1/k for Gaussian X achieves its optimal point at k = ∞; see Example 3 in Appendix A.2.1. As for σ2 ,\nit is unclear that its value can be achieved at a finite t. Note that if kX = 1, one has ∥X∥2\n\nopt(X) := 2 supt∈R G = Var(X).\n\nlog[E exp(tX)] t2\n\nNext, we present an example in calculating the values of kX . Denote Exp(1)|[0,M ] as the truncated standard exponene−x tial distribution on [0, M ] with the density as f (x) = 0 e−x dx Example 1. a. X ∼ U [−a, a], kX = 1 for any a ∈ R; b. X ∼ Exp(1)|[0,2.75] − E Exp(1)|[0,2.75], kX = 2; c. X ∼ Exp(1)|[0,3] − E Exp(1)|[0,3], kX = 3. Indeed, for any fixed k0 ∈ N, we can construct a truncated exponential r.v. X := Exp(1)|[0,M ] such that kX = k0 by properly adjusting the truncation level M .\n\n1{x∈[0,M ]}.\n\n(cid:82) M\n\n3.2 CONCENTRATION FOR SUMMATION\n\nIn what follows, we will show another property of ∥X∥G that it recovers nearly tight MGF bounds in Definition 1. More powerfully, it enables us to derive the sub-G Hoeffding’s inequality (2).\n\n4\n\n-101231.01.52.02.53.0log (j)+1Valuesub-Gaussian plot of standard Gaussian024681.01.52.02.53.0log (j)+1Valuesub-Gaussian plot of standard exponentialUnder review as a conference paper at ICLR 2023\n\nTheorem 2. Suppose that {Xi}n\n\ni=1 are independent r.v.s with maxi∈[n] ∥Xi∥G < ∞. We have\n\n(a). If Xi is symmetric about zero, then Eexp{tXi} ≤ exp{t2 ∥Xi∥2\n\nG /2} for any t ∈ R, and\n\nP (| (cid:80)n\n\ni=1 Xi| ≥ s) ≤ 2 exp{−s2/[2 (cid:80)n\n\ni=1 ∥Xi∥2\n\nG]},\n\ns ≥ 0.\n\n(b). If Xi is not symmetric, then Eexp{tXi} ≤ exp{(17/12)t2 ∥Xi∥2\n\nG /2} for any t ∈ R, and\n\nP (| (cid:80)n\n\ni=1 Xi| ≥ s) ≤ 2 exp{−(12/17)s2/[2 (cid:80)n\n\ni=1 ∥Xi∥2\n\nG]},\n\ns ≥ 0.\n\nTheorem 2(a) is an existing result in Theorem 2.6 of Wainwright (2019). For Theorem 2(b), we obtain (cid:112)17/12 ≈ 1.19, while Lemma 1.5 in Buldygin & Kozachenko (2000) obtained Eexp{tXi} ≤ exp (cid:8) t2 3.1∥Xi∥G)2(cid:9) for √\n3.1 ≈ 1.32. Essentially, (cid:112)17/12 > 1 appears for asymmetric variables, since ∥ · ∥G is defined by t ∈ R with 4 comparing a Gaussian variable G that is symmetric. A technical reason for this improvement is that ∥ · ∥G does not need Stirling’s approximation for attaining a sharper MGF bound when expanding the exponential function by Taylor’s formula. To show the tightness of Theorem 2(b), in Figure 5 of Appendix C, we gives some comparisons with σopt(X), (cid:112)17/12∥X∥G, Var X in terms of confidence length in Table 1, when X is Bernoulli or beta distribution.\n\n2e∥X∥ψ2, ∥X∥w2/\n\n√ 2 ( 4\n\n2 and\n\n√\n\n√\n\n√\n\n4 ESTIMATION OF THE INTRINSIC MOMENT NORM\n\nA first thought to estimate ∥X∥G is by the plug-in approach. Although kX is proven to be finite in Lemma 2, its (possibly large) exact value is still unknown in practice. Instead, we use a non-decreasing index sequence {κn} to replace kX in the estimation. Hence, we suggest a plug-in feasible estimator\n\n(cid:100)∥X∥G = max\n\n1≤k≤κn\n\n(cid:34)\n\n1 (2k − 1)!!\n\n1 n\n\nn (cid:88)\n\ni=1\n\nX 2k\n\ni\n\n(cid:35)1/(2k)\n\n.\n\n(6)\n\nDeriving the non-asymptotic property of the (cid:100)∥X∥G is not an easy task: arg max1≤k≤κn [\n\n]1/(2k) will change with the sample size n even κn is fixed.\n\n(cid:80)n\n\ni=1 X 2k\n\n1 (2k−1)!!\n\n1 n\n\ni\n\nthe maximum point ˆk(κn)\n\n:=\n\nTo resolve this, we first examine the oracle estimator defined as (cid:103)∥X∥G = . Here, based on Orlicz norm ∥Y ∥ψθ := inf{t > 0 : E exp{|Y |θ/tθ} ≤ 2} of sub-Weibull r.v. Y with θ > 0 (Hao et al., 2019; Zhang & Wei, 2022), we present the non-asymptotic concentration of (cid:103)∥X∥G around it ture value ∥X∥G. Proposition 1. Suppose {Xi}n\n\ni.i.d.∼ X and X satisfies ∥X∥ψ1/kX\n\n< ∞, then for any t > 0,\n\ni=1\n\ni\n\n1 (2kX −1)!!\n\n1 n\n\n(cid:80)n\n\ni=1 X 2kX\n\n(cid:104)\n\n(cid:105)1/2kX\n\n(cid:18)(cid:12) (cid:12) (cid:12) (cid:103)∥X∥\n\nP\n\n2kX\n\nG − ∥X∥2kX\n\nG\n\n(cid:12) (cid:12) (cid:12) ≤ 2e∥X∥ψ1/kX\n\nC(k−1 X )\n\n(cid:110)(cid:113) t\n\nn + γ2kX A(k−1\n\nX ) tkX\n\nn\n\n(cid:111) (cid:19)\n\n≥ 1 − 2e−t,\n\nwhere the constant γ ≈ 1.78, and the constant functions C(·) and A(·) are defined in Appendix C.\n\nThe exponential-moment condition ∥X∥ψ1/kX Proposition 1, although it has exponential decay probability 1 − 2exp(−t).\n\n< ∞ is too strong for the error bound of (cid:103)∥X∥\n\n2kX\n\nG − ∥X∥2kX\n\nG\n\nin\n\nExcept for the direct plug-in estimator, here we resort to the median-of-means (MOM, Page244 in Nemirovskij & Yudin (1983)) as the robust plug-in estimator of intrinsic moment norm. Let m and b be a positive integer such that n = mb and let B1, . . . , Bb be a partition of [n] into blocks of equal cardinality m. For any s ∈ [b], let PBs m X = m−1 (cid:80) i=1. The MOM version intrinsic moment norm estimator is defined as\n\nXi for independent data {Xi}n\n\ni∈Bs\n\n(cid:100)∥X∥b,G := max\n\n1≤k≤κn\n\nmed s∈[b]\n\n(cid:110)(cid:2)[(2k − 1)!!]−1PBs\n\nm X 2k(cid:3)1/(2k)(cid:111)\n\n.\n\n(7)\n\nAs stated in Proposition 1, the naive plug-in estimator (cid:100)∥X∥G = (cid:100)∥X∥1,G is not robust. MOM estimators (7) with b ≫ 1 have two merits: (a) it only needs finite moment conditions, but the exponential concentration bounds are still\n\n5\n\nUnder review as a conference paper at ICLR 2023\n\nachieved; (b) it permits some outliers in the data. Non-asymptotic inferences require to bound for ∥X∥G exactly by a feasible estimator (cid:100)∥X∥b,G up to a sharp constants. Next, we establish a high-probability upper bound for the estimated norm, if the data has O ∪ I outlier assumptions as follows.\n\n• (M.1) Suppose that the data {Xi}n\n\ni=1 contains n − no inliers {Xi}i∈I drawn i.i.d. according to a target\n\ndistribution, and there are no distributional assumptions on no outliers {Xi}i∈O;\n\n• (M.2) b = bO + bS, where bO is the number of blocks containing at least one outliers and bS is the number 2 . Assume\n\nof sane blocks containing no outliers. Let ε := no/n be the fraction of the outliers and no b < 1 here exists a fraction function η(ε) for sane block such that bS ≥ η(ε)b for a function η(ε) ∈ (0, 1].\n\nTo serve for error bounds in the presence of outliers, (M.2) considers the specific fraction function of the polluted inputs; see Laforgue et al. (2021). Define g\n\n(σk) and ̄gk,m(σk) as the sequences for any m ∈ N and 1 ≤ k ≤ κn:\n\nk,m\n\ngk,m(σk) := 1 − (cid:2)EX 2k/(2k − 1)!!(cid:3)−1/(2k)\n\n(cid:104)\n\nmax 1≤k≤κn\n\n−2[m/η(ε)]−1/2σk\n\nk /(EX 2k) + EX 2k/(2k − 1)!!\n\n(cid:105)1/(2k)\n\n; (8)\n\nand g\n\nk,m\n\n(σk) := [2[m/η(ε)]−1/2σk\n\nk /(EX 2k) + 1]1/(2k) − 1. We obtain a robust and non-asymptotic CI for ∥X∥G.\n\nTheorem 3 (Finite sample guaranteed coverage). Suppose\n\nVarX 2k ≤ σk\n\nk for a sequence {σk}κn\n\nk=1, we have\n\n√\n\n(cid:26)\n\nP\n\n∥X∥G ≤ [1 − max\n\n1≤k≤κn\n\ngk,m(σk)]−1 (cid:100)∥X∥b,G\n\n(cid:27)\n\n> 1 − κn · e−2bη(ε)(1− 3\n\n4η(ε) )2\n\n;\n\nand P{∥X∥G ≥ [1 + max1≤k≤κn g\n\n(σk)]−1 (cid:100)∥X∥b,G} > 1 − κn · e−2bη(ε)(1− 3\n\n4η(ε) )2\n\nk,m\n\nfor κn ≥ κX under (M.1-M.2).\n\nTheorem 3 ensures the concentration of the estimator (cid:100)∥X∥b,G when κn ≥ kX under enough sample. If η(ε) = 1 with ε = 0, then the data are i.i.d., which have no outlier, and outlier assumptions in M.1-M.2 can be dropped in Theorem 3. When the data is i.i.d. Gaussian vector, Proposition 4.1 in Auer et al. (2002) also gave a high-probability estimated upper bound for lp-norm of the vector of Gaussian standard deviations, our result is for intrinsic moment norm.\n\nIn practice, the block number b can be taken by the adaptation method based on the Lepski method (Depersin & Lecu ́e, 2022). To guarantee high probability events in Theorem 3, it is required that the index sequence κn should not be very large for fixed b. The larger κn needs larger b in blocks B1, . . . , Bb. In the simulation, we will see that an increasing index sequence κn with slow rate will lead a good performance.\n\nFinally, we compare our two estimators (6) and (7), as well as the estimator (4) in Figure 3. We consider the standard Gaussian and Rademacher variable distributed X, in the two case we have ∥X∥2 opt(X) = Var(X) = 1. The following figure shows the performance of three estimators under sample n = 10 to 1000 with κn just chosen as ⌈log n⌉. For the MOM method, we use five blocks in this simple setting. For a more complex case, one can use Lepski’s method to choose b (see Page & Gr ̈unew ̈alder (2021)), but some considerable computation cost may be introduced. From Figure 3, we know that the performance of the MOM estimator is best, while the naive estimator (4) is worst. For the high-quality data of extremely small sample size, we can apply the leave-one-out Hodges-Lehmann method (Rousseeuw & Verboven, 2002) for further numerical improvement; see Appendix B for details.\n\nG = σ2\n\n5 APPLICATION IN MULTI-ARMED BANDIT PROBLEM\n\nIn the multi-armed bandit problem (MAB), a player chooses between K different slot machines (an K-armed bank=1 ⊆ R, while each realization of a fixed arm k is dit), each with a different unknown random reward r.v.s {Yk}K independent and shares the same distribution. Further, we assume the rewards are sub-Gaussian, i.e.\n\n∥Yk − μk∥G < ∞,\n\nk ∈ [K].\n\n(9)\n\nOur goal is to find the best arm with the largest expected reward, say Yt∗, by pulling arms. In each round t ∈ [T ], the player pulls an arm (an action) At ∈ [K]. Conditioning on {At = k}, we define the observed reward i.i.d.∼ Pk. The goal of the exploration in MAB is to minimize the cumulative regret after T steps: {Yk,t}t∈[T ]\n\n6\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 3: DE represents the naive plug-in estimator (6), MOM represents the MOM estimator (7), and OP is the estimator plug-in naive estimator (4) for the optimal variance proxy.\n\nRegT (Y, A) := (cid:80)T the performance of any exploration strategy {At}t∈[T ]. The exploration performance is better, if we have smaller RegT (Y, A). Without loss of generality, we assume t⋆ = 1. We seek to evaluate the expected bounds from the decomposition (see Lemma 4.5 in Lattimore & Szepesv ́ari (2020)),\n\nt=1(μt⋆ − μAt), i.e.\n\nRegT := E RegT (Y, A) = (cid:80)K\n\nk=1∆kE\n\nt=11 {At = k}\n\n(cid:104)(cid:80)T\n\n(cid:105)\n\n,\n\n(10)\n\nwhere E is taken on the randomness of the player’s actions {At}t∈[T ], and ∆k = μ1 − μk is the sub-optimality gap for arm k ∈ [K]/{1}. The upper bound of RegT is called problem-independent if the regret bound depends on the distribution of the data and does not rely on the gap ∆k.\n\n(cid:80)\n\nTk(t)\n\nFor each iteration t, let Tk(t) := card{1 ≤ τ ≤ t : Aτ = k} be the number of pull for arm k until time t during the bandit process. Then if we define Y Tk(t) := 1 τ ≤t,Aτ =k Yk,τ as the running average of the rewards of arm k at time t. Suppose we obtain a 100(1 − δ)% CI (cid:2)Y Tk(t) − ck(t), Y Tk(t) + ck(t)(cid:3) for μk from a tight concentration inequality. Therefore, we confidently reckon that the reward of arm k is Y Tk(t) + ck(t), and play the arm At = k, hoping to maximize the reward with a high probability for finite t. This is upper confidence bound (UCB, Auer et al. (2002)) algorithms. And many works based on this methods appears recently, for example, Hao et al. (2019) use bootstrap method with the second order correction to give a algorithm with the explicit regret bounds for subGaussian rewards. However, many existent algorithms contain unknown norms for the random rewards, they are actually infeasible. And Theorem 4 is one example with explicit regret bound. For instance, the algorithm Hao et al. (2019) needs to use the unknown Orlicz-norm of Y k − μk in the algorithm. Thus, it is actually infeasible in practice.\n\nFortunately, our estimator can solve this problem. Suppose that Yk − μk is symmetric around zero, by one-side version δ ) ≤ δ. Let subof Theorem 2, the (9) implies that for all k and all t, P(Y Tk(t) > μk + ∥Yk − μk∥G (cid:92)∥Yk − μk∥bk,G in\n\nsample size mk and block size bk be positive integer such that Tk(t) = mkbk for MOM estimators\n\nTk(t) log 1\n\n(cid:113) 2\n\n7\n\n1.01.52.02.5050100150200250nEstimated ValuetypeDEMOMOPStandard Gaussian051015050100150200250nEstimated ValuetypeDEMOMOPStandard Gaussian with 0.5% Cauchy Noise0.51.01.52.0050100150200250nestimated normtypeDEMOMOPRademacher123050100150200250nestimated normtypeDEMOMOPRademacher with 0.5% Cauchy NoiseUnder review as a conference paper at ICLR 2023\n\nSection 3. Theorem 3 (a) guarantee that true norms can be replaced by MOM-estimated norms such that P(Y Tk(t) ≤\n\nμk +\n\n(cid:92)∥Yk−μk∥bk ,G\n\n(cid:113) 2\n\n1−o(1)\n\nTk(t) log 1\n\nδ ) ≥ 1 − δ − kYk · exp(−bk/8) if η(ε) = 1 with ε = 0.\n\nIf the UCB algorithm is correctly applied, for a finite Tk(t), with high probability, we will pull the best arm.\n\nIn practice, we nearly do not know any knowledge about the data. As a flexible way of uncertainty qualification, the multiplier bootstrap (Arlot et al., 2010) enables mimicking the non-asymptotic properties of the target statistic by reweighing its summands of the centralized empirical mean. The multiplier bootstrapped quantile for the i.i.d. observation Yn := {Yi}n i=1wi(Yi − Y n), which is defined as\n\ni=1 is the (1 − α)-quantile of the distribution of n−1(cid:80)n\n\nqα(Yn − Y n, w) := inf{x ∈ R | Pw(n−1(cid:80)n\n\ni=1wi(Yi − Y n) > x) ≤ α},\n\nwhere w := {wi}n satisfying PYn(|Y n − EY1| ≥ (cid:98)φG(Yn)) ≤ α.\n\ni=1 are bootstrap random weights independent of Yn. We denote the statistics (cid:98)φG(Yn) as something\n\nAlgorithm 1: Bootstrapped UCB Input: (cid:98)φG(YTk(t)) is given by (11). for t = 1, . . . , K do\n\nPull each arm once to initialize the algorithm.\n\nend for t = K + 1, . . . , T do\n\nSet a confidence level α ∈ (0, 1). Calculate the boostrapped quantile qα/2(YTk(t) − Y Tk(t), w) with the Rademacher bootstrapped\n\nweights w independent with any Y .\n\nPull the arm\n\nAt = argmax\n\nUCBk(t) := argmax\n\nk∈[K]\n\nk∈[K]\n\nReceive reward YAt .\n\nend\n\n(cid:0)Y Tk(t) + qα/2(YTk(t) − Y Tk(t), w) +\n\n(cid:113) 2 log(4/α)\n\nTk(t) (cid:98)φG(YTk(t))(cid:1).\n\nMotivated by Hao et al. (2019), we design Algorithm 1 based on some estimators of the UCB. It guarantees a relatively small regret by bootstrapped threshold qα/2(YTk(t)−Y Tk(t), w) adding a concentration based second-order correction (cid:98)φG(YTk(t)) that is specified in Theorem 3. In the following regret bounds, we assume the mean reward from the k-th arm μk is known. In practice, it can be replaced by a robust estimator, and we obtain the results of MOM estimator.\n\nTheorem 4. Consider a K-armed sub-G bandit under (9) and suppose that Yk − μk is symmetric around zero. For any round T , according to moment conditions in Theorem 3, choosing (cid:98)φG(YTk(t)) as\n\n(cid:98)φG(YTk(t)) =\n\n(cid:112)2 log(4/α) T 1/2\n\n(t) − 1\n\nk\n\n(cid:92)∥Yk − μk∥bk,G\n\n(11)\n\nas a re-scaled version of MOM estimator (cid:92)∥Yk − μk∥bk,G with block number bk satisfying the moment assumptions C[UCB1] and C[UCB2] in Appendix C. Fix a confidence level α = 4/T 2, if the player pull an arm At ∈ [K] according to Algorithm 1, then we have the problem-dependent regret of Algorithm 1 is bounded by\n\nRegT ≤ 16(2 +\n\n√\n\n2)2 max k∈[K]\n\n∥Yk − μk∥2\n\nG log T\n\nK (cid:88)\n\nk=2\n\n∆−1\n\nk + (4T −1 + 2T −25−16\n\n√\n\n2 + 8)\n\nK (cid:88)\n\nk=2\n\n∆k,\n\nwhere ∆k is the sub-optimality gap. Moreover, let μ∗ rewards, the problem-independent regret\n\n1 := maxk1∈[K] μk1 − mink2∈[K] μk2 be the range over the\n\nRegT ≤ 8(2 +\n\n√\n\n2) max k∈[K]\n\n∥Yk − μk∥G\n\n(cid:112)T K log T + (4T −1 + 2T −25−16\n\n√\n\n2 + 8)Kμ∗ 1.\n\nFrom Theorem 4, we know that the regret of our method achieve minimax rate log T for a problem-dependent problem KT for a problem-independent case (see Tao et al. (2022)), so Algorithm 1 can be seen as an optimal algorithm. and\n\n√\n\n8\n\nUnder review as a conference paper at ICLR 2023\n\nCompared with the traditional vanilla UCB, we do improve the constant. When Yk ∼ N (μk, 1), the constant factor in regret bound in Auer et al. (2002) is 256, which is larger than 16(2 +\n\n2)2 in our theorem.\n\n√\n\nWhen the UCB has unknown sub-G parameters, Theorem 4 first studies a feasible UCB algorithm with sub-G parameter plugging estimation. Many previous UCB algorithms based on non-asymptotic inference in the literature assume that the sub-G parameter is a preset constant, see the algorithm in Hao et al. (2019) for instance.\n\nNext, we give an simulation for Theorem 4 in two sub-G cases to verify the performance of estimated norms. Similar to Hao et al. (2019); Wang et al. (2020), we design the three methods as follows:\n\n1. Use our method (cid:98)φ(YTk(t)) with Estimated Norm in Theorem 4; 2. Use Asymptotic Naive varphi (cid:101)φ(YTk(t)) satisfying P(cid:0)|Y Tk(t) − μk| ≤ (cid:101)φ(YTk(t))(cid:1) → α by CLT, i.e. τ ≤t,Aτ =k(Yk,τ − Y Tk(t))2 as the estimated\n\n(cid:101)φ(YTk(t)) = (cid:98)σkΦ−1(1 − α/2)/(cid:112)Tk(t) with (cid:98)σk =\n\n(cid:113) 1\n\nTk(t)\n\n(cid:80)\n\nstandard deviation;\n\n3. Regard all the unbounded rewards as bounded r.v. and use Hoeffding’s inequality (wrongly use Hoeffding’s\n\ninequality) to construct φ, i.e. ˇφ(YTk(t)) = (cid:2) max{YTk(t)} − min{YTk(t)}(cid:3)(cid:113) log(2/α) 2Tk(t) .\n\nAnd for our detailed MAB simulation, we consider as follows, in each case, the number of arms is assigned as K = 5, and (μ1, . . . , μ5) = (0.1, 0.05, 0.02, 0.01, 0.01)⊤,\n\nEG1. Yk ∼ N (μk, μ2\n\nk);\n\nEG2. Yk ∼ 0.9N (μk, μk) + 0.1N (μk+1, μk+1) where μ6 := μ5.\n\nFigure 4: The regret of MAB with sub-G rewards under three methods. x-axis represents the round and y-axis is the cumulative regret.\n\nAs we can see, EG1 and EG2 are both sub-Gaussian rewards. In the simulation, μk is assigned sightly small for bounded maxk ∆k, which is a standard-setting in the MAB problem (see the condition of Corollary 1 in Wang et al. (2020) for instance). The simulation results are shown in Figure 4, which illustrates that our method outperforms the other two methods under the unbounded sub-Gaussian rewards and small sample T ∈ [1, 150]. In the Gaussian case, Algorithm 1 can also give better results compared with the CLT-based UCB when the round is relatively small. For the Gaussian mixture case, the algorithm based on the intrinsic moment norm has smaller regret than the other two methods under T ∈ [1, 800].\n\nREFERENCES\n\nJulyan Arbel, Olivier Marchal, and Hien D Nguyen. On strict sub-gaussianity, optimal proxy variance and symmetry\n\nfor bounded random variables. ESAIM: Probability and Statistics, 24:39–55, 2020.\n\n9\n\n0.00.51.01.52.02.50200400600Round TRegrettypeAsymptotic Naive VarphiEstimated NormWrongly Use HoeffdingGaussian02460200400600Round TRegrettypeAsymptotic Naive VarphiEstimated NormWrongly Use HoeffdingGaussian MixtureUnder review as a conference paper at ICLR 2023\n\nSylvain Arlot, Gilles Blanchard, Etienne Roquain, et al. Some nonasymptotic results on resampling in high dimension,\n\ni: confidence regions. The Annals of Statistics, 38(1):51–82, 2010.\n\nTimothy B. Armstrong and Michal Koles ́ar. Finite-sample optimal estimation and inference on average treatment\n\neffects under unconfoundedness. Econometrica, 89(3):1141–1177, 2021.\n\nPeter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine\n\nlearning, 47(2):235–256, 2002.\n\nNayel Bettache, Cristina Butucea, and Marianne Sorba. Fast nonasymptotic testing and support recovery for large\n\nsparse toeplitz covariance matrices. Journal of Multivariate Analysis, pp. 104883, 2021.\n\nSt ́ephane Boucheron, G ́abor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymptotic theory of\n\nindependence. Oxford university press, 2013.\n\nValeri ̆ı Vladimirovich Buldygin and IU V Kozachenko. Metric characterization of random variables and random\n\nprocesses, volume 188. American Mathematical Soc., 2000.\n\nSylvain Chassang. Non-asymptotic tests of model performance. Economic Theory, 41(3):495–514, 2009.\n\nYS Chow. Some convergence theorems for independent random variables. The Annals of Mathematical Statistics, 37\n\n(6):1482–1493, 1966.\n\nJules Depersin and Guillaume Lecu ́e. Robust sub-gaussian estimation of a mean vector in nearly linear time. The\n\nAnnals of Statistics, 50(1):511–536, 2022.\n\nVo Nguyen Le Duy and Ichiro Takeuchi. Exact statistical inference for the wasserstein distance by selective inference.\n\nAnnals of the Institute of Statistical Mathematics, 2022.\n\nYihao Feng, Ziyang Tang, na zhang, and qiang liu. Non-asymptotic confidence intervals of off-policy evaluation:\n\nPrimal and dual bounds. In International Conference on Learning Representations, 2021.\n\nEvarist Gin ́e and Richard Nickl. Mathematical foundations of infinite-dimensional statistical models. Cambridge\n\nuniversity press, 2016.\n\nBotao Hao, Yasin Abbasi Yadkori, Zheng Wen, and Guang Cheng. Bootstrapping upper confidence bound. In Ad-\n\nvances in Neural Information Processing Systems, volume 32, pp. 12123–12133, 2019.\n\nTim Hesterberg. Bootstrap. Wiley Interdisciplinary Reviews: Computational Statistics, 3(6):497–526, 2011.\n\nWassily Hoeffding. Probability inequalities for sums of bounded random variables. Journal of the American Statistical\n\nAssociation, 58(301):13–30, 1963.\n\nJoel Horowitz and Sokbae Lee. Inference in a class of optimization problems: Confidence regions and finite sample bounds on errors in coverage probabilities. Cemmap, Centre for Microdata Methuods and Practice, The Institute for Fiscal., 2020.\n\nJean-Pierre Kahane. Propri ́et ́es locales des fonctions `a s ́eries de fourier al ́eatoires. Studia Mathematica, 19(1):1–25,\n\n1960.\n\nMichael Kearns and Lawrence Saul. Large deviation methods for approximate probabilistic inference. In Proceedings\n\nof the Fourteenth conference on Uncertainty in artificial intelligence, pp. 311–319, 1998.\n\nAryeh Kontorovich. Concentration in unbounded metric spaces and algorithmic stability. In International Conference\n\non Machine Learning, pp. 28–36. PMLR, 2014.\n\nPierre Laforgue, Guillaume Staerman, and Stephan Cl ́emenc ̧on. Generalization bounds in the presence of outliers: a\n\nmedian-of-means study. In International Conference on Machine Learning, pp. 5937–5947. PMLR, 2021.\n\nTor Lattimore and Csaba Szepesv ́ari. Bandit algorithms. Cambridge University Press, 2020.\n\nLeonard J Lucas, H Owhadi, and M Ortiz. Rigorous verification, validation, uncertainty quantification and certification through concentration-of-measure inequalities. Computer Methods in Applied Mechanics and Engineering, 197(5152):4591–4609, 2008.\n\n10\n\nUnder review as a conference paper at ICLR 2023\n\nOlivier Marchal, Julyan Arbel, et al. On the sub-gaussianity of the beta and dirichlet distributions. Electronic Com-\n\nmunications in Probability, 22, 2017.\n\nArkadij Semenoviˇc Nemirovskij and David Borisovich Yudin. Problem complexity and method efficiency in opti-\n\nmization. 1983.\n\nHouman Owhadi, Clint Scovel, Timothy John Sullivan, Mike McKerns, and Michael Ortiz. Optimal uncertainty\n\nquantification. Siam Review, 55(2):271–345, 2013.\n\nStephen Page and Steffen Gr ̈unew ̈alder. The goldenshluger–lepski method for constrained least-squares estimators\n\nover rkhss. Bernoulli, 27(4):2241–2266, 2021.\n\nREAC Paley and Antoni Zygmund. A note on analytic functions in the unit circle. In Mathematical Proceedings of\n\nthe Cambridge Philosophical Society, volume 28, pp. 266–272. Cambridge University Press, 1932.\n\nMy Phan, Philip Thomas, and Erik Learned-Miller. Towards practical mean bounds for small samples. In ICML 2021:\n\n38th International Conference on Machine Learning, pp. 8567–8576, 2021.\n\nPhillippe Rigollet and Jan-Christian H ̈utter. High dimensional statistics. Lecture notes for course 18S997, 2019.\n\nJoseph P Romano and Michael Wolf. Finite sample nonparametric inference and large sample efficiency. Annals of\n\nStatistics, pp. 756–778, 2000.\n\nPeter J Rousseeuw and Sabine Verboven. Robust estimation in very small samples. Computational Statistics & Data\n\nAnalysis, 40(4):741–758, 2002.\n\nIrina Gennad’evna Shevtsova. On the absolute constants in the berry–esseen inequality and its structural and nonuni-\n\nform improvements. Informatika i Ee Primeneniya, 7(1):124–125, 2013.\n\nDaniel Shiu. Efficient computation of tight approximations to chernoff bounds. Computational Statistics, pp. 1–15,\n\n2022.\n\nYouming Tao, Yulian Wu, Peng Zhao, and Di Wang. Optimal rates of (locally) differentially private heavy-tailed multi-armed bandits. In International Conference on Artificial Intelligence and Statistics, pp. 1546–1574. PMLR, 2022.\n\nA. W. van der Vaart and Jon A. Wellner. Weak Convergence and Empirical Processes: With Applications to Statistics.\n\nSpringer, 1996.\n\nRoman Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint arXiv:1011.3027,\n\n2010.\n\nMartin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge University\n\nPress, 2019.\n\nChi-Hua Wang, Yang Yu, Botao Hao, and Guang Cheng. Residual bootstrap exploration for bandit algorithms. arXiv\n\npreprint arXiv:2002.08436, 2020.\n\nJie Wang, Rui Gao, and Yao Xie. Two-sample test using projected wasserstein distance. In Proc. ISIT, volume 21,\n\n2021.\n\nYan Wang. Sub-gaussian and subexponential fluctuation-response inequalities. Physical Review E, 102(5):052105,\n\n2020.\n\nAndreas Winkelbauer. Moments and absolute moments of the normal distribution. arXiv preprint arXiv:1209.4340,\n\n2012.\n\nYun Yang, Zuofeng Shang, and Guang Cheng. Non-asymptotic analysis for nonparametric testing. In Conference on\n\nLearning Theory, pp. 3709–3755. PMLR, 2020.\n\nAnru R Zhang and Yuchen Zhou. On the non-asymptotic and sharp lower tail bounds of random variables. Stat, 9(1):\n\ne314, 2020.\n\nHuiming Zhang and Song Xi Chen. Concentration inequalities for statistical inference. Communications in Mathe-\n\nmatical Research, 37(1):1–85, 2021.\n\n11\n\nUnder review as a conference paper at ICLR 2023\n\nHuiming Zhang and Haoyu Wei. Sharper sub-weibull concentrations. Mathematics, 10(13):2252, 2022.\n\nYao Zheng and Guang Cheng.\n\nFinite-time analysis of vector autoregressive models under linear restrictions.\n\nBiometrika, 108(2):469–489, 2021.\n\nAnatolii Zolotukhin, Sergei Nagaev, and Vladimir Chebotarev. On a bound of the absolute constant in the berry–esseen inequality for iid bernoulli random variables. Modern Stochastics: Theory and Applications, 5(3):385–410, 2018.\n\n12",
  "translations": [
    "# Summary Of The Paper\n\nThis paper considers the problem of constructing tight non-asymptotic confidence intervals for sub-gaussian random variables. To achieve this, the authors propose to use a sub-gaussian intrinsic moment norm, which can be robustly estimated using a simple plug-in approach. The paper then applies the analysis for multi-armed bandits, derives  matching regret upper bounds.\n\n# Strength And Weaknesses\n\nThe paper is well-written. I try to check the derivations as much as I can given the limited time, and I don't find any major problem. \n\nHowever, I am not an expert on statistics and therefore I cannot judge the paper in terms of novelty and how significant the contribution is. I sincerely apology for this. Also, if the authors want to submit this paper to a machine learning conference, I think ICLR might not be the best place, maybe it’s more suitable for COLT, ALT and AISTATS? \n\nMy major concern is how significant the contribution is to the machine learning community. I have the following questions. \n\n1. In the experiment the reward gaps are fixed. Maybe it’s better to show the performance under different reward gaps? It’s especially interesting to see how the algorithm performs with different minimum reward gap.\n\n2. How does the proposed algorithm compare to common baselines such as UCB and Thompson Sampling? \n\n3. Could the proposed method be applied to linear bandits? Or can it be applied to problems where UCB and TS have limitations? \n\n4. From the theoretical perspective, how does Theorem 4 improve over the regret bound of UCB? I believe it’s at most a constant improvement as UCB is both minimax and instance-dependent optimal. It’s still great to see the regret bound of the proposed method if it achieves better practical results than UCB and Thompson Sampling, but the author needs to show that.\n\n# Clarity, Quality, Novelty And Reproducibility\n\nPlease see the detailed comments in the previous section.\n\n# Summary Of The Review\n\nMy decision is mostly based on how significant the contribution is for the machine learning community. I recommend rejecting this paper as I am not convinced that proposed method has significant contribution to multi-armed bandit setting, which is the application this paper considers. Please correct me if I missed anything important. I am happy to adjust my score based on how well the authors answer the questions in the rebuttal.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.\n\n# Empirical Novelty And Significance\n\nNot applicable",
    "# Summary Of The Paper\nThe paper presents a novel approach to non-asymptotic statistical inference for variance-type parameters of sub-Gaussian distributions. It introduces the concept of the intrinsic moment norm, which is maximized to derive tighter Hoeffding-type inequalities and better exponential moment bounds for moment generating functions (MGFs) in finite samples. Additionally, it provides a practical tool called the sub-Gaussian plot to assess data for sub-Gaussian properties and applies its theoretical findings to improve performance in multi-armed bandit problems, demonstrating more reliable error bounds and competitive cumulative regret.\n\n# Strength And Weaknesses\nThe strengths of the paper include its innovative methodology that effectively addresses the shortcomings of traditional Hoeffding-type inequalities, particularly for asymmetric distributions. The introduction of the sub-Gaussian plot offers practical utility for practitioners working with real data. Furthermore, the application to multi-armed bandit problems highlights the method's relevance in current machine learning contexts. However, the paper could benefit from more extensive empirical validation across a broader range of datasets and scenarios to solidify its claims regarding the advantages of the proposed techniques.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is commendable, with well-structured sections that guide the reader through the theoretical developments and practical implications. The quality of the presented results is high, as they are backed by rigorous theoretical proofs and simulations. The novelty lies in the introduction of the intrinsic moment norm and the sub-Gaussian plot, which provide fresh perspectives on non-asymptotic inference. Reproducibility is supported by the clear presentation of methodologies and the inclusion of relevant figures illustrating key findings, although providing additional experimental details could enhance this aspect.\n\n# Summary Of The Review\nOverall, the paper makes significant contributions to the field of statistical inference for sub-Gaussian distributions by offering tighter bounds and practical tools for empirical assessment. Its application to multi-armed bandit problems demonstrates the method's utility in machine learning contexts, although further empirical validation is recommended to bolster the claims made.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Tight Non-Asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm\" introduces a novel approach to estimating variance-type parameters for sub-Gaussian distributions, crucial for non-asymptotic statistical inference. The authors propose the sub-Gaussian intrinsic moment norm, which is defined through a maximization of normalized moments, facilitating the development of tighter Hoeffding-type inequalities applicable to asymmetric distributions. They provide robust estimation techniques, particularly the median-of-means (MOM) estimator, and demonstrate the application of their methods in multi-armed bandit problems, showing improvements in cumulative regret through a bootstrapped UCB algorithm.\n\n# Strengths And Weaknesses\nThe paper's strengths are underscored by its innovative definition of the intrinsic moment norm, which significantly enhances the estimation of variance-type parameters and leads to tighter concentration inequalities. Its broad applicability, particularly in machine learning and statistics with limited sample sizes, is commendable. The robust performance of the MOM estimator against outliers further enhances its practical utility. However, the complexity involved in estimating the intrinsic moment norm, especially in high-dimensional scenarios, presents challenges for practical implementation. Moreover, the reliance on sample size and specific distributional assumptions may limit its generalizability, and there is a potential risk of overfitting with the MOM estimator.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodologies and findings clearly, backed by solid theoretical guarantees. The novelty of the intrinsic moment norm and its applications in both theoretical and empirical contexts is significant. However, the reproducibility of the methods may be hindered by the complexity of the estimation process and the assumptions made regarding the data distribution. The simulation studies provide useful insights, though further validation in diverse real-world scenarios would strengthen its reproducibility claims.\n\n# Summary Of The Review\nOverall, the paper provides a substantial contribution to the field of non-asymptotic statistical inference through innovative methodologies and robust estimation techniques. While it presents clear advancements and theoretical foundations, practical implementation may pose challenges that warrant further exploration.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"TIGHT NON-ASYMPTOTIC INFERENCE VIA SUB-GAUSSIAN INTRINSIC MOMENT NORM\" addresses the challenge of non-asymptotic statistical inference for variance-type parameters in sub-Gaussian distributions. The authors propose the use of the sub-Gaussian intrinsic moment norm to derive tighter concentration inequalities and to produce more accurate confidence intervals for finite sample sizes. They introduce a methodology that includes estimating intrinsic moment norms and applying these results to scenarios such as multi-armed bandit problems. The theoretical contributions are complemented by empirical validation through simulations that demonstrate the effectiveness of the proposed methods in providing tighter estimates compared to traditional methods.\n\n# Strength And Weaknesses\nThe main strength of this paper lies in its rigorous theoretical framework, which presents a new approach to constructing tight non-asymptotic confidence intervals using the intrinsic moment norm. The derivation of concentration inequalities for both symmetric and non-symmetric random variables is a significant contribution, as it enhances the robustness of statistical inference methods. Furthermore, the applicability of the proposed techniques to multi-armed bandit problems showcases the practical relevance of the findings. However, a potential weakness is the reliance on assumptions about the sub-Gaussian nature of the data, which may limit the generalizability of the results to distributions that do not fit this framework. Additionally, while the empirical results are promising, more diverse datasets could strengthen the validation of the methodology.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The mathematical formulations are precise, and the definitions provided, such as the intrinsic moment norm and optimal variance proxy, are clearly explained. The novelty of the approach is significant, as it introduces a new norm for statistical inference that is both robust and theoretically grounded. The reproducibility of the results is supported by the inclusion of detailed estimators and the discussion of the empirical validation through simulations. However, further details on implementation and potential limitations of the method could enhance reproducibility.\n\n# Summary Of The Review\nIn summary, this paper presents a compelling approach to non-asymptotic inference using sub-Gaussian intrinsic moment norms, offering theoretical advancements and practical applications. While the findings are significant and well-supported, the assumptions regarding the distributional characteristics may limit broader applicability. Overall, the paper contributes valuable insights to the field of statistical inference.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces the sub-Gaussian intrinsic moment norm as a novel framework for constructing tighter non-asymptotic confidence intervals (CIs) that enhance the quality of statistical inference. Through theoretical advancements, the authors demonstrate that their approach recovers tighter Hoeffding-type inequalities and achieves sharper bounds for various distributions, which are crucial for finite sample validity. Furthermore, the paper offers practical tools for data analysis, including a sub-Gaussian plot and robust estimation methods like the median-of-means (MOM) estimator, with applications to multi-armed bandit problems, supported by simulation evidence.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its introduction of the sub-Gaussian intrinsic moment norm, which has the potential to improve statistical inference quality, and its theoretical contributions to confidence intervals that can benefit practical applications. However, the reliance on sub-Gaussian assumptions may limit its applicability across diverse datasets, and the theoretical results may not directly translate to practical settings due to assumptions of independence and symmetry. While the sub-Gaussian plot is a valuable tool, its effectiveness is contingent on sample size. Moreover, the complexity of the theoretical framework may pose comprehension challenges for practitioners, potentially hindering the broader adoption of the methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its findings clearly, although the advanced statistical theory may be challenging for less experienced practitioners. The novelty of the proposed methods is notable, yet some contributions appear incremental rather than groundbreaking. The reproducibility of results is supported by simulation evidence, although further validation with real-world datasets is necessary to confirm the practical effectiveness of the methods.\n\n# Summary Of The Review\nOverall, the paper makes significant contributions to the field of statistical inference through the introduction of the sub-Gaussian intrinsic moment norm and robust estimation methods. While the theoretical advancements are promising, practical applicability might be limited by certain assumptions and the complexity of the framework. Further empirical validation is needed to establish the methods' effectiveness across diverse scenarios.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel statistical inference framework utilizing a **sub-Gaussian intrinsic moment metric**, which significantly enhances the estimation of variance-type parameters for sub-Gaussian distributions. Through a two-step methodology that involves initial data verification and the application of a robust plug-in estimator, the authors demonstrate improved performance in finite sample scenarios. The findings include the introduction of a **sub-Gaussian verification plot** for practical data assessment and successful applications of the proposed framework in multi-armed bandit problems, achieving tighter concentration inequalities and competitive error bounds.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to statistical inference, particularly through the introduction of the intrinsic moment norm which provides tighter bounds than traditional methods. The practical implications are underscored by the application to multi-armed bandit scenarios, illustrating the framework's effectiveness in real-world applications. However, a potential weakness is the assumption of the sub-Gaussian nature of data, which might not hold in all practical situations, potentially limiting the applicability of the proposed methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured, with clear explanations of the methodologies employed and the theoretical foundations laid out systematically. The technical quality is high, with robust empirical results supporting the claims made. The novelty is pronounced, particularly in the context of the intrinsic moment norm and its implications for concentration inequalities. Reproducibility is facilitated by the detailed description of the methods and the provision of simulations, although it would benefit from additional clarity in the description of the implementation aspects.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to non-asymptotic statistical inference by introducing a new framework that enhances estimation methods for sub-Gaussian distributions. The robust theoretical and empirical results presented support its potential impact on future research in statistical inference and machine learning.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to adversarial training in machine learning using sub-Gaussian intrinsic moment norms. It argues that traditional methods for generating adversarial examples often result in weak bounds on model robustness, especially under finite sample conditions. By utilizing sub-Gaussian distributions, the authors aim to establish tighter error bounds and enhance the stability of adversarial training processes. The key contributions include the introduction of sub-Gaussian norms, the demonstration of tighter robustness bounds, practical implementation strategies, and an extension of the framework to multi-armed bandit problems.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative integration of sub-Gaussian norms into the adversarial training paradigm, which provides a fresh perspective on improving model robustness. The empirical evaluations are robust, showing significant improvements in performance across various datasets, supporting the authors' claims. However, the paper has some weaknesses; it lacks a thorough examination of the limitations of the proposed approach, particularly in real-world scenarios that may not conform to sub-Gaussian assumptions. Additionally, while the sub-Gaussian plot is introduced as a diagnostic tool, its practical utility requires further validation in varied adversarial contexts.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, making it accessible to the audience. The quality of the theoretical insights is high, with rigorous derivations and guarantees provided. However, while the methodology is detailed, aspects of reproducibility could be enhanced by providing more comprehensive implementation details and an exploration of various data distribution scenarios. The novelty is significant, as it introduces a fresh statistical approach to a well-studied problem in adversarial training.\n\n# Summary Of The Review\nThis paper advances the state of adversarial training by incorporating sub-Gaussian statistics, resulting in tighter robustness bounds and improved model performance. While the findings are compelling and the theoretical contributions are strong, the paper could benefit from a more nuanced discussion of its limitations and broader applicability. Overall, it represents a meaningful contribution to the field.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Tight Non-Asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm\" proposes a novel method for non-asymptotic statistical inference, introducing a sub-Gaussian intrinsic moment norm that is claimed to enhance parameter estimation efficiency. The authors assert that their methodology leads to sharper Hoeffding-type inequalities, demonstrates practical applicability for small sample sizes, and introduces a new technique for assessing sub-Gaussian distributions. Additionally, the paper presents applications to multi-armed bandit problems, suggesting substantial improvements in algorithm performance. The findings are supported by simulation results that reportedly indicate significant advantages over traditional statistical approaches.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its ambitious contributions, particularly the introduction of the sub-Gaussian intrinsic moment norm and its application to various statistical domains. The proposed sharper Hoeffding-type inequality could have far-reaching implications in the field of probability inequalities, and the practical application for small samples is noteworthy. However, the paper exhibits weaknesses in its empirical validation, as the simulation results, while impressive, may not fully capture the complexities of real-world data and could lead to overstatements about the method's effectiveness.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, presenting its contributions and methodology in an understandable manner. However, the ambitious claims regarding the revolutionary nature of the findings could benefit from more cautious wording to avoid potential misinterpretation. While the introduction of new concepts is indeed novel, reproducibility may be a concern, especially regarding the simulation results, as the methodology for achieving near-perfect outcomes is not adequately detailed.\n\n# Summary Of The Review\nOverall, the paper presents a potentially significant advancement in non-asymptotic statistical inference through the introduction of a sub-Gaussian intrinsic moment norm. While the proposed methods exhibit promising theoretical contributions and practical applications, the empirical validation may overstate their effectiveness, necessitating further scrutiny.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper titled \"TIGHT NON-ASYMPTOTIC INFERENCE VIA SUB-GAUSSIAN INTRINSIC MOMENT NORM\" introduces a new method for statistical inference using the intrinsic moment norm to establish tighter non-asymptotic confidence intervals for sub-Gaussian distributions. The authors define the sub-Gaussian parameter, σ_opt(X), and demonstrate that the intrinsic moment norm offers sharper concentration inequalities compared to traditional norms. The paper presents empirical evidence through simulations and details a multi-armed bandit algorithm that utilizes the intrinsic moment norm, reporting modest improvements in cumulative regret over existing methods.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to refining statistical inference methods, particularly the introduction of the intrinsic moment norm, which is shown to provide tighter bounds and more reliable estimations. Additionally, the inclusion of a new sub-Gaussian plot enhances the practical applicability of the findings. However, the weaknesses include some overstatements regarding the performance of the proposed methods, as results were adjusted to reflect a more moderate improvement in effectiveness than initially claimed. This raises concerns about the robustness of the empirical results presented.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, with a logical flow from definitions to results. The quality of the writing is high, maintaining a professional tone throughout. The novelty of the intrinsic moment norm and its application in non-asymptotic inference is significant, contributing to the ongoing discourse in statistical learning. However, the reproducibility of results could be improved by providing more detailed descriptions of the simulations and algorithms used, which are currently somewhat vague.\n\n# Summary Of The Review\nOverall, the paper presents a meaningful contribution to statistical inference through the introduction of the intrinsic moment norm, with promising empirical results. However, claims regarding the performance enhancements should be tempered, as the improvements observed may not be as pronounced as initially suggested.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper proposes novel statistical methods that leverage the assumption of sub-Gaussianity to estimate variance-type parameters through empirical moment generating functions (MGF). The authors argue that their methods demonstrate robustness to outliers and provide non-asymptotic results under finite sample sizes. However, the paper also highlights the limitations of their approaches, such as the challenges posed by plug-in estimators and the dependency on theoretical bounds that may not hold in practical scenarios. The findings suggest that while the proposed methods can outperform traditional norms, their effectiveness is not universally guaranteed.\n\n# Strength And Weaknesses\nThe strength of the paper lies in its theoretical contributions, particularly the introduction of the intrinsic moment norm, which the authors claim is superior to alternative norms. However, the reliance on the assumption of sub-Gaussianity may limit the applicability of the methods to datasets that do not conform to this distribution. Additionally, the paper lacks a comprehensive empirical validation, as the presented simulations are limited in scope and do not address the robustness of the methods under non-standard distributions or extreme values. The absence of real-world applications and detailed case studies further diminishes the practical relevance of the proposed techniques.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is compromised by its lack of thorough justifications for dismissing alternative norms and the implications of its assumptions. While the novelty of the proposed methods is apparent, the practical reproducibility is questionable due to the reliance on unobserved constants and the assumption of independence among random variables. The paper does not provide sufficient guidance on the implementation of its methods in real-world contexts, particularly regarding computational complexity and the potential for overfitting.\n\n# Summary Of The Review\nOverall, the paper presents an interesting approach to statistical estimation under the assumption of sub-Gaussianity, but it suffers from significant limitations related to its assumptions, empirical validation, and practical applicability. The theoretical contributions are noteworthy, yet the lack of robustness checks and real-world examples raises concerns about their generalizability and utility.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThis paper addresses the estimation of variance-type parameters in sub-Gaussian distributions, focusing on non-asymptotic statistical inference. The authors introduce the sub-Gaussian intrinsic moment norm, which facilitates tighter concentration inequalities and a practical method for assessing sub-Gaussian data through a novel sub-Gaussian plot. Key contributions include robust estimation techniques, particularly a median-of-means estimator that accounts for outliers, and applications of their findings to the multi-armed bandit problem, demonstrating the framework's effectiveness in providing improved error bounds and cumulative regret metrics.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its theoretical foundations, particularly the introduction of the intrinsic moment norm, which is a significant advancement in the field of statistical inference for sub-Gaussian distributions. The sub-Gaussian plot serves as a valuable tool for practitioners to visually assess data distribution, enhancing practical applicability. However, the paper could benefit from a more extensive empirical evaluation to validate the proposed methodologies across diverse datasets and scenarios, as the current applications are somewhat limited to theoretical demonstrations and a specific problem setting.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions, methodologies, and findings. The writing is generally precise, with technical concepts explained adequately for readers familiar with statistical inference. However, the technical details may be challenging for a broader audience without a strong background in the subject. The reproducibility of results is supported through well-defined methodologies, although additional empirical results would enhance confidence in the practical utility of the proposed techniques.\n\n# Summary Of The Review\nOverall, the paper presents a compelling advancement in the estimation of variance-type parameters for sub-Gaussian distributions, supported by a solid theoretical framework and a practical visualization tool. While the contributions are significant and novel, further empirical validation is necessary to fully substantiate the proposed methodologies.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a novel framework designed to enhance the capabilities of unsupervised learning algorithms in high-dimensional spaces. The methodology combines a new regularization technique with existing clustering algorithms to improve both convergence rates and clustering quality. The findings demonstrate significant improvements over baseline methods across several benchmark datasets, suggesting that the proposed approach effectively captures the underlying structure of complex data distributions.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Relevance:** The research addresses a critical challenge in unsupervised learning, which has widespread applications in areas such as clustering and dimensionality reduction.\n2. **Innovation:** The incorporation of a novel regularization technique presents a fresh perspective that could influence future developments in the field.\n3. **Theoretical Foundations:** The paper provides a solid theoretical framework that supports the proposed method, enhancing its credibility.\n4. **Clarity:** The writing is clear and well-organized, making complex ideas accessible to the audience.\n\n**Weaknesses:**\n1. **Experimental Evaluation:** The range of datasets used for testing is somewhat limited, which may restrict the generalizability of the results.\n2. **Comparative Analysis:** There is insufficient comparison with a broader set of existing methodologies, making it challenging to comprehensively assess the performance benefits of the proposed approach.\n3. **Implementation Details:** The specifics around the implementation are not adequately outlined, which could pose challenges for reproducibility.\n4. **Limitations Discussion:** The manuscript lacks a thorough discussion of potential limitations and scenarios where the proposed method may underperform.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its ideas in a clear manner. The theoretical contributions are significant; however, the lack of detailed experimental setups and comparisons may affect the paper's reproducibility. The novelty of the proposed regularization technique is noteworthy, but further empirical validation across diverse contexts would enhance its impact.\n\n# Summary Of The Review\nOverall, the paper presents a compelling approach to improving unsupervised learning through a novel regularization framework. While the contributions are significant, addressing the limitations in experimental validation and detailed implementation would strengthen the work and its applicability in the broader research community.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"Tight Non-Asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm\" presents a novel approach to estimating variance-type parameters of sub-Gaussian distributions for non-asymptotic statistical inference. The authors introduce the sub-Gaussian intrinsic moment norm, which can be maximized through a series of normalized moments, allowing for tighter bounds on moment-generating functions (MGFs) and enhancing Hoeffding's concentration inequalities. Additionally, the paper proposes a sub-Gaussian plot for practical verification of data, emphasizing its application in scenarios like multi-armed bandit problems, where robust statistical guarantees are critical.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to estimating sub-Gaussian parameters and its practical implications for finite sample analysis. The introduction of the intrinsic moment norm is a significant contribution, as it addresses the limitations of existing methods by providing tighter confidence intervals. However, a potential weakness is the reliance on the assumption that data follows a sub-Gaussian distribution; the performance of the proposed method in cases of non-sub-Gaussian data could be further explored. Additionally, while the theoretical foundations are solid, empirical validation on diverse datasets could strengthen the paper's claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its methodology and findings, making it accessible to researchers familiar with statistical inference and machine learning. The quality of the theoretical results is high, and the novelty of the intrinsic moment norm is evident. The reproducibility of results appears feasible, as the authors provide a simple plug-in approach for estimation. However, additional details on the implementation and empirical testing would enhance clarity regarding reproducibility.\n\n# Summary Of The Review\nOverall, the paper makes a valuable contribution to the field of non-asymptotic statistical inference by introducing the sub-Gaussian intrinsic moment norm, which offers tighter estimates for variance parameters. While the theoretical advancements are robust, further empirical validation is necessary to fully establish its effectiveness across diverse scenarios.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper focuses on tight non-asymptotic statistical inference for sub-Gaussian distributions by introducing the sub-Gaussian intrinsic moment norm. The authors propose methods for estimating variance-type parameters and constructing confidence intervals (CIs) that address the limitations of empirical moment generating functions. Key contributions include establishing improved inequalities for asymmetric distributions, developing a sub-Gaussian plot to test for data sub-Gaussianity, and applying these findings to multi-armed bandit problems with robust estimators.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its rigorous theoretical foundation and practical applicability. The introduction of the intrinsic moment norm is a significant contribution that enhances the robustness of statistical inference methodologies. Additionally, the empirical validation through simulations provides convincing evidence of the proposed methods' effectiveness. However, the paper could be critiqued for its reliance on theoretical constructs that may not be readily accessible to practitioners without a strong statistical background. Moreover, while the multi-armed bandit application is relevant, further exploration of its applicability across different domains would strengthen the paper.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its objectives, methodology, and findings. The theoretical aspects are elaborated upon with sufficient detail, although some sections may benefit from more intuitive explanations for broader accessibility. The novelty of the proposed intrinsic moment norm and its implications for statistical inference is noteworthy, marking a significant advance in the field. The reproducibility of the results is supported by the detailed descriptions of the methods and the empirical simulations provided.\n\n# Summary Of The Review\nOverall, this paper presents a compelling advancement in non-asymptotic statistical inference for sub-Gaussian distributions through the introduction of the intrinsic moment norm. The rigorous theoretical contributions and practical applications, particularly in multi-armed bandit contexts, are valuable, although some aspects may require clearer exposition for wider accessibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"TIGHT NON-ASYMPTOTIC INFERENCE VIA SUB-GAUSSIAN INTRINSIC MOMENT NORM\" presents significant advancements in non-asymptotic statistical inference, particularly for sub-Gaussian distributions. Its main contributions include the introduction of sharp Hoeffding-type inequalities for asymmetric distributions, which allow for improved error bounds even in small sample sizes. The authors define sub-Gaussian intrinsic moment norms and propose two estimators: a naive plug-in estimator and a robust median-of-means estimator, supported by theoretical results demonstrating their efficacy. The application of these concepts is showcased in multi-armed bandit problems, where empirical simulations indicate performance improvements over existing methods.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its novel approach to non-asymptotic inference, particularly through the introduction of intrinsic moment norms, which enhance concentration inequalities. The applicability of the proposed methods to small sample sizes is particularly valuable in practical scenarios. However, a notable weakness is the complexity of some theoretical results, which may hinder understanding for readers not deeply familiar with the underlying statistical concepts. Additionally, while the empirical validation is solid, more diverse examples could further substantiate the proposed methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nOverall, the paper is well-written and generally clear, although some sections could benefit from additional explanations to enhance accessibility for a broader audience. The quality of the theoretical contributions is high, with a solid grounding in existing literature. The novelty is significant, as the introduction of sub-Gaussian intrinsic moment norms represents a fresh perspective in statistical inference, particularly in the context of machine learning. Reproducibility is supported through detailed descriptions of methodologies and simulations, though further empirical examples would reinforce this aspect.\n\n# Summary Of The Review\nThis paper makes a substantial contribution to the field of non-asymptotic statistical inference, presenting novel methodologies and theoretical results that could significantly impact applications in machine learning. While the clarity of certain sections could be improved, the innovative nature of the work and its practical implications are commendable.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled \"Tight Non-Asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm\" addresses the challenge of non-asymptotic statistical inference for variance-type parameters associated with sub-Gaussian distributions. The authors propose the use of a sub-Gaussian intrinsic moment norm, which is optimized through a sequence of normalized moments, providing tighter Hoeffding-style concentration inequalities. They present a robust methodology for estimating this norm using a median-of-means approach, particularly useful in scenarios with outliers. The theoretical framework is contextualized within applications such as multi-armed bandit problems, demonstrating the practical implications of the proposed techniques.\n\n# Strength And Weaknesses\nThe strengths of the paper include its innovative approach to addressing limitations in existing methods for estimating variance-type parameters and its application to real-world scenarios like multi-armed bandits. The introduction of the median-of-means method for estimating the intrinsic moment norm is particularly valuable, as it enhances robustness against outliers. However, the paper could benefit from a more detailed empirical validation of the proposed methods, as the theoretical contributions, while solid, may not sufficiently illustrate their practical effectiveness without extensive experimental results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodologies. The mathematical derivations, while complex, are presented with sufficient clarity for readers familiar with the field. The novelty of the approach, particularly the introduction of the intrinsic moment norm and its estimation methods, is significant. However, the reproducibility of the results may be limited by the lack of detailed experimental setups and datasets used for validation, which could hinder independent verification of the findings.\n\n# Summary Of The Review\nOverall, this paper presents a meaningful contribution to the field of non-asymptotic statistical inference by introducing a novel framework that enhances the estimation of variance-type parameters in sub-Gaussian distributions. While the theoretical insights are strong, more empirical work is needed to solidify the practical implications of the proposed methodologies.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper proposes a method for non-asymptotic inference based on sub-Gaussian intrinsic moment norms. The authors draw on established theoretical foundations, particularly the work of Buldygin and Kozachenko (2000), to develop their methodology. They present a naive plug-in estimator and a median-of-means (MOM) estimator, claiming improvements in robustness. However, the paper's empirical validation is lacking, and the practical applications of the proposed methods, including their relevance to the multi-armed bandit problem, are inadequately justified.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address non-asymptotic inference, a relevant and complex area of study. However, the methodology suffers from significant weaknesses, including the instability of the plug-in estimator and the lack of substantial improvement offered by the MOM estimator. The paper's reliance on historical literature creates concerns about originality, and its contributions appear overstated as they seem to reiterate established techniques without clear advancements. Furthermore, the lack of empirical validation undermines the practical applicability of the proposed methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is dense and laden with jargon, which hinders comprehension of its key contributions. The theoretical underpinnings are not sufficiently articulated, and the connections between the proposed methods and their practical applications remain vague. This lack of clarity diminishes the overall quality of the work. The novelty is questionable, as the methods presented do not significantly deviate from existing approaches. Reproducibility is also a concern, given the insufficient details provided regarding simulation designs and experimental setups.\n\n# Summary Of The Review\nOverall, the paper struggles with clarity, originality, and empirical validation. While it addresses a pertinent topic in non-asymptotic inference, the contributions appear minimal and lack robust support, leading to skepticism regarding the proposed methodologies.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents a novel method for tight non-asymptotic statistical inference using the sub-Gaussian intrinsic moment norm. Key contributions include enhanced statistical bounds that recover tighter Hoeffding-type inequalities, a user-friendly estimation approach for practitioners, and a versatile application in multi-armed bandit problems. The method demonstrates finite sample validity and is backed by rigorous theoretical insights, making it applicable across various domains such as statistics, machine learning, and engineering.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to deriving tighter concentration inequalities, which significantly enhance the precision of confidence intervals for non-asymptotic analysis. The introduction of a sub-Gaussian plot simplifies the validation process for practitioners, fostering accessibility. Additionally, the empirical results in multi-armed bandit applications validate the practical utility of the proposed methodology. However, a potential weakness is the limited empirical validation outside the multi-armed bandit context; further applications could strengthen the claims made regarding its broad applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and clearly articulates its contributions, making it accessible to both theoretical and practical audiences. The quality of the theoretical framework is high, with rigorous proofs supporting the claims made. The novelty of the approach is significant, particularly in the context of sub-Gaussian distributions. The proposed method appears reproducible, particularly due to the intuitive plug-in estimation approach presented, which facilitates implementation across diverse scenarios.\n\n# Summary Of The Review\nOverall, this paper offers a substantial advancement in non-asymptotic statistical inference through the introduction of the sub-Gaussian intrinsic moment norm. Its theoretical rigor combined with practical applicability positions it as a valuable resource for researchers and practitioners alike. The paper's contributions are likely to inspire further exploration and application in various fields.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a theoretical framework for non-asymptotic inference using a newly introduced sub-Gaussian intrinsic moment norm. It highlights the importance of variance-type parameters in statistical inference for sub-Gaussian distributions and discusses the limitations of direct estimation from empirical moment generating functions (MGFs). The proposed intrinsic moment norm is shown to achieve tighter concentration inequalities and is robustly estimable in closed form. The findings indicate that this norm can be effectively used in constructing confidence intervals and for applications in multi-armed bandit problems, thus demonstrating its broad applicability in statistical learning and inference.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its rigorous theoretical contributions, including the introduction of the intrinsic moment norm which provides sharper probability bounds and a strong foundation for variance estimation in sub-Gaussian contexts. The theoretical results, including the derivation of concentration inequalities and bounds for multi-armed bandit scenarios, add significant value to the field. However, the paper predominantly focuses on theoretical developments, with limited empirical validation of the proposed methods. This may hinder the practical applicability of the findings, as real-world data can exhibit complexities not fully captured by the theoretical models.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its theoretical constructs, making it accessible to readers familiar with statistical theory. The quality of the writing is high, and the theoretical arguments are presented coherently. The novelty of the intrinsic moment norm and its implications for concentration inequalities and statistical inference is significant. However, the reproducibility of the results may be challenging due to the lack of empirical experiments that demonstrate the practical effectiveness of the proposed norm in real-world scenarios.\n\n# Summary Of The Review\nOverall, the paper makes a substantial theoretical contribution to the understanding of non-asymptotic inference using sub-Gaussian intrinsic moment norms. While the theoretical advancements are promising, the lack of empirical validation may limit the immediate applicability of the findings in practical contexts.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel method for tight non-asymptotic inference using the Sub-Gaussian Intrinsic Moment Norm. The authors introduce a robust plug-in estimator that leverages the Median-of-Means (MOM) approach for estimating this norm. They apply this methodology to enhance the performance of multi-armed bandit algorithms by incorporating bootstrapping techniques for uncertainty quantification. The empirical findings demonstrate that the proposed method yields improved confidence intervals and reduced cumulative regret compared to existing estimators in simulations with both Gaussian and Rademacher distributions.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its rigorous statistical foundation and the practical implications of the proposed methodology in the context of multi-armed bandit problems. The introduction of the Sub-Gaussian Intrinsic Moment Norm and the robust plug-in estimator represent significant advancements in the field of non-asymptotic statistical inference. However, the paper has notable weaknesses such as a lack of high-level conclusions regarding the broader implications of the findings and insufficient detail on the code availability for replication of results. Additionally, while the focus on computational aspects is commendable, it detracts from understanding the overall impact of the work.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its contributions clearly, although the high density of technical details may impede comprehension for readers less familiar with the specific methodologies. The quality of the research is high, with thorough evaluations of the proposed methods through simulations. However, the novelty is primarily within the context of specific statistical norms, as the approach itself builds upon well-established concepts in statistical inference and bandit algorithms. The reproducibility of results is hindered by the vague references to code availability and external methods for parameter tuning, which could discourage potential users from implementing the proposed techniques.\n\n# Summary Of The Review\nOverall, the paper makes a commendable contribution to the field of non-asymptotic inference and multi-armed bandits through the introduction of the Sub-Gaussian Intrinsic Moment Norm and robust estimators. While the methodology is sound and the empirical results promising, the lack of broader contextual analysis and clarity in reproducibility diminish its impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper proposes utilizing the sub-Gaussian intrinsic moment norm for non-asymptotic statistical inference, aiming to provide tighter Hoeffding bounds and enhance the robustness of estimators. The methodology involves a novel sub-Gaussian plot to evaluate distributional assumptions and introduces a median-of-means (MOM) estimator. The authors claim that their approach is particularly beneficial for small sample sizes and presents improvements over existing algorithms in the context of multi-armed bandits.\n\n# Strength And Weaknesses\nWhile the authors assert that their method yields tighter Hoeffding bounds, the findings appear to reiterate earlier results from Buldygin and Kozachenko (2000) and Wainwright (2019) without adequately demonstrating significant improvements. The discussions surrounding the novel aspects of the sub-Gaussian plot and the MOM estimator do not convincingly distinguish these contributions from prior methodologies, such as those by Zhang & Chen (2021) and Auer et al. (2002). Furthermore, the paper tends to dismiss previous works like Arbel et al. (2020) without a fair comparative analysis, which undermines the robustness of its arguments.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, but the clarity of the contributions is compromised by insufficient differentiation from existing literature. The quality of the proposed methods is presented but lacks compelling evidence of their superiority over established techniques, particularly regarding Orlicz norms. The novelty of the contributions is questionable, as many aspects are reminiscent of previous works. Reproducibility is not adequately addressed, as the methodological descriptions do not provide enough detail for independent verification.\n\n# Summary Of The Review\nThe paper attempts to contribute to statistical inference through the introduction of the sub-Gaussian intrinsic moment norm but fails to provide substantial evidence of innovation or improvement over existing methodologies. The contributions seem to lack standalone merit, leaving the reader with doubts about the necessity of this work given the depth of prior research in the field.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper presents a novel approach for tight non-asymptotic inference using sub-Gaussian intrinsic moment norms. The methodology revolves around developing efficient estimation techniques based on the empirical moment generating function (MGF), addressing the challenge of direct parameter estimation. The findings indicate that the proposed norm not only recovers crucial statistical properties but also demonstrates robustness in finite sample scenarios, thereby enhancing the reliability of statistical inference.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative methodology, which effectively bridges the gap between theoretical statistics and practical applications. The empirical results support the theoretical claims, showcasing the utility of the proposed norm in various statistical settings. However, the paper has weaknesses regarding clarity and technical consistency. Several instances of awkward phrasing and typographical errors detract from its overall readability. Additionally, while the findings are promising, further exploration of their applicability in diverse contexts is warranted.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is hindered by grammatical issues and inconsistent notation, which could confuse readers. Despite these challenges, the quality of the research is solid, and the novelty is evident through the introduction of the sub-Gaussian intrinsic moment norm. However, reproducibility could be improved by providing more detailed explanations of the methodology and clearer references to figures and equations.\n\n# Summary Of The Review\nOverall, the paper introduces a significant advancement in statistical inference through the use of sub-Gaussian norms. While the contributions are noteworthy, the paper requires substantial improvements in clarity and consistency to enhance its impact and reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper explores the properties and applications of sub-Gaussian distributions, presenting a novel sub-Gaussian plot for data verification and proposing methods for estimating variance-type parameters. The authors focus on multi-armed bandit problems, detailing a theoretical framework built around the intrinsic moment norm. The findings suggest improvements in quantifying uncertainty, yet the paper predominantly addresses sub-Gaussian scenarios without considering broader distributional contexts.\n\n# Strength And Weaknesses\nStrengths of the paper include the introduction of a unique sub-Gaussian plot and the theoretical analysis of variance-type parameters, which contribute to the understanding of uncertainty quantification in statistical learning. However, the study's narrow focus on sub-Gaussian distributions limits its applicability. The lack of discussion on generalizing findings to non-Gaussian cases, or extending the framework to other machine learning problems, presents a significant shortcoming. Furthermore, the paper does not adequately address the implications of its methods for large-scale datasets or high-dimensional settings, areas crucial to modern statistical applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is written in a clear and concise manner, making the mathematical concepts accessible to readers familiar with statistical learning. However, the novelty is somewhat constrained by the limited scope of analysis, primarily focusing on a specific subset of distributions. The lack of comprehensive comparisons with existing statistical norms raises questions about the reproducibility of the results, as the methods are not thoroughly validated against a broader range of scenarios.\n\n# Summary Of The Review\nOverall, the paper presents interesting methodologies for working with sub-Gaussian distributions, but its limited scope and lack of generalizability significantly detract from its potential impact. A broader exploration of the implications of the proposed methods and their applications across different contexts would enhance the work's relevance and significance.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThis paper presents a robust framework for non-asymptotic statistical inference within sub-Gaussian distributions. The authors introduce the concept of the sub-Gaussian intrinsic moment norm, which is utilized to derive tighter Hoeffding’s sub-Gaussian concentration inequalities and to establish confidence intervals based on optimal variance proxies. Additionally, they propose a sub-Gaussian plot for finite sample checking and demonstrate applications in the multi-armed bandit problem, providing theoretical guarantees for cumulative regret bounds.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to addressing the limitations of traditional asymptotic methods in statistical inference, particularly for bounded and Gaussian data. The introduction of the sub-Gaussian intrinsic moment norm and its applications offer significant advancements in creating tighter confidence intervals. However, the paper also presents weaknesses, notably the instability of the naive plug-in estimator due to non-convex optimization issues and the requirement for large sample sizes to achieve reliable variance estimates, which may limit practical applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its methodology and findings. The definitions and theorems are articulated with mathematical rigor, making the theoretical contributions accessible to readers with a solid foundation in statistics. The novelty is significant as it introduces a new perspective on sub-Gaussian distributions and their properties. However, the reproducibility may be impacted by the challenges identified in the optimization of the intrinsic moment norm, which could hinder practical implementation without further refinement.\n\n# Summary Of The Review\nOverall, the paper offers substantial contributions to non-asymptotic statistical inference by providing new theoretical insights and practical applications in machine learning contexts. While the innovations are commendable, the practical challenges related to estimator stability and sample size requirements warrant careful consideration.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a methodology for estimating variance-type parameters within sub-Gaussian distributions using an intrinsic moment norm. The authors propose a sub-Gaussian plot method aimed at improving estimation accuracy while addressing some limitations associated with traditional plug-in estimators. However, the findings reveal significant challenges related to sample size requirements, the applicability of the proposed methods under various distributional conditions, and the instability of the naive plug-in estimator in non-convex optimization landscapes.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to innovate the estimation of variance-type parameters through the intrinsic moment norm, which could offer improvements in certain conditions. However, the paper has notable weaknesses, including its limited applicability due to the reliance on specific distributional assumptions, the lack of robustness in estimation methods, and the requirement for large sample sizes that may render the approach impractical for real-world applications. Furthermore, the performance under heavy-tailed distributions and the effects of outliers are not sufficiently addressed, which raises concerns about the method's robustness.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, though certain sections could benefit from greater clarity, particularly regarding the limitations of the proposed methodologies. The quality of the research is solid, but the novelty is constrained by the narrow focus on specific conditions and distributions. Reproducibility may be hampered by the lack of detailed exploration into the computational complexity of the proposed estimators, particularly in high-dimensional settings. Additionally, the absence of empirical validation across diverse data scenarios limits the assessment of the methods' efficacy.\n\n# Summary Of The Review\nOverall, the paper introduces an interesting approach to variance estimation in sub-Gaussian distributions, but it suffers from critical limitations that hinder its practical applicability and generalizability. The reliance on specific assumptions and the instability of proposed methods under certain conditions may restrict its usefulness in real-world scenarios.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"Tight Non-Asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm\" explores the statistical properties of sub-Gaussian distributions, focusing on variance-type parameters and the challenges associated with empirical moment generating functions (MGF). The authors propose maximizing a series of normalized moments to improve statistical inference, particularly for small sample sizes. Key contributions include the introduction of a sharper Hoeffding-type inequality, a novel \"sub-Gaussian plot,\" and applications of these concepts to the multi-armed bandit problem.\n\n# Strength And Weaknesses\nThe paper presents several contributions that, while framed as novel, largely build upon established statistical principles. The proposed sharper Hoeffding-type inequality and the focus on small sample sizes are relevant; however, they do not provide significant advancements over existing methods. The introduction of the \"sub-Gaussian plot\" appears to be an unnecessary complication rather than a meaningful contribution. Additionally, the paper struggles with clarity and conciseness, often veering into convoluted explanations that may obfuscate its findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is compromised by its reliance on jargon and complex formulations that do not sufficiently elucidate the underlying concepts. While the methodology is presented in a structured manner, the exposition lacks the straightforwardness that would enhance reproducibility. The novelty of the technical contributions is questionable, as many are rehashes of well-understood statistical techniques, leaving the paper feeling less innovative than intended.\n\n# Summary Of The Review\nOverall, the paper attempts to contribute to the field of statistical inference through the lens of sub-Gaussian distributions but ultimately fails to provide significant new insights. The findings are presented in a convoluted manner, detracting from their potential impact. The paper would benefit from a clearer articulation of its contributions and a stronger focus on practical implications.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents a novel method for estimating sub-Gaussian intrinsic moment norms, highlighting the limitations of traditional empirical moment generating functions (MGFs) and proposing the integration of Bayesian approaches for improved parameter estimation. The authors introduce a sub-Gaussian plot for visualizing data distribution, discuss the importance of tighter Hoeffding-type inequalities, and explore the implications of intrinsic moment norms in multi-armed bandit problems. The findings suggest that the proposed methods can enhance statistical inference in finite sample settings, with potential applications across various fields.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to estimating intrinsic moment norms and the emphasis on finite sample properties, which addresses a significant gap in the literature. The method's integration of Bayesian techniques is a noteworthy contribution that enhances the robustness of the estimates. However, the paper could benefit from a more thorough exploration of alternative estimation techniques, such as variational inference and adaptive sampling, as well as comparisons to existing methods in non-asymptotic statistics. Additionally, the discussion on outlier handling and robust statistics could be expanded to provide a more comprehensive understanding of the proposed methods' applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured, presenting its ideas clearly and logically. The methodology is described in sufficient detail, allowing for reproducibility of the results. The novelty of the approach is significant, particularly in the context of Bayesian parameter estimation and the proposed sub-Gaussian plot. However, the paper would benefit from additional empirical comparisons and theoretical insights to strengthen its claims and enhance its contribution to the field.\n\n# Summary Of The Review\nOverall, the paper presents a compelling approach to estimating sub-Gaussian intrinsic moment norms, with several innovative contributions and practical applications. While the clarity and quality of the writing are commendable, further exploration of alternative methodologies and comparative analyses could enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel method for estimating sub-Gaussian intrinsic moment norms and explores its applications in non-asymptotic statistical inference, particularly within multi-armed bandit frameworks. The authors introduce a Bootstrapped UCB algorithm that demonstrates competitive performance, especially in scenarios with limited sample sizes. Empirical results show that their intrinsic moment norm estimator outperforms traditional methods, such as asymptotic naive estimators and incorrect applications of Hoeffding's inequality, in terms of cumulative regret and robustness across various problem settings.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its clear demonstration of the proposed method's effectiveness through comprehensive empirical evaluations, which highlight its superiority over established algorithms in small sample scenarios. The numerical evidence supporting the achievement of minimax rates further solidifies the paper's contributions to the field. However, a potential weakness could be the limited discussion on the theoretical underpinnings of the proposed method, which might leave readers seeking deeper insights into its mathematical foundations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its ideas clearly, making it accessible to readers with varying levels of expertise in statistical inference and machine learning. The quality of the writing is high, with clear figures and comparisons that effectively illustrate the advantages of the proposed method. The novelty is significant, particularly in its approach to addressing the challenges of small sample sizes in multi-armed bandit problems. The reproducibility of the results may depend on the availability of sufficient implementation details, which should be addressed to enhance the paper's impact.\n\n# Summary Of The Review\nOverall, the paper makes a substantial contribution to the field of statistical inference by introducing an effective method for estimating sub-Gaussian intrinsic moment norms and demonstrating its practical applications in multi-armed bandit problems. While the empirical results are compelling, a deeper exploration of the theoretical framework could strengthen the paper further.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel approach to analyzing sub-Gaussian intrinsic moment norms using a tailored moment-generating function. The authors propose a methodology that integrates theoretical insights with empirical validation, demonstrating the efficacy of their approach through various experiments on benchmark datasets. Key findings indicate that their method outperforms existing techniques in terms of accuracy and computational efficiency, making significant contributions to the field of statistical learning.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative methodology, which bridges theoretical exploration and practical application. The empirical results are compelling, showcasing a clear advantage over traditional methods. However, the paper exhibits weaknesses in clarity and accessibility, particularly due to the heavy use of jargon and complex sentence structures. Additionally, while the results are promising, the lack of diversity in the datasets used raises concerns about the generalizability of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is hindered by the use of technical jargon and dense sentences, which may alienate readers unfamiliar with the subject matter. The overall quality of the writing would benefit from simplification and better integration of figures and tables into the narrative. In terms of novelty, the paper presents significant advancements in the analysis of sub-Gaussian norms, although the reproducibility of results may be affected by the lack of detailed methodological descriptions and the need for clearer mathematical explanations.\n\n# Summary Of The Review\nOverall, the paper offers valuable contributions to the understanding of sub-Gaussian intrinsic moment norms and provides a promising methodology supported by empirical validation. However, improvements in clarity and accessibility are needed to enhance the paper's impact and reach a wider audience.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.170227158813876,
    -1.6811604395264739,
    -1.841361198175994,
    -1.5607223490767301,
    -1.8727130891468584,
    -1.9322682453186695,
    -1.7854990456337216,
    -1.96033652313612,
    -1.8458188468859635,
    -1.8083529584851281,
    -1.7550394943703,
    -1.4958482928816512,
    -1.785380573031415,
    -1.7338131472443425,
    -1.6980870886519293,
    -1.5738573584073716,
    -1.791293702621392,
    -1.8871808427559622,
    -1.67214248267478,
    -1.800041170698267,
    -1.9140493577728588,
    -1.8372921975656455,
    -1.9125881233349462,
    -1.9322379844532145,
    -1.8308108826126954,
    -2.0227127446166295,
    -1.814043580446514,
    -1.6974785152202247,
    -1.6877081888722267
  ],
  "logp_cond": [
    [
      0.0,
      -1.9533203100792886,
      -1.9462425758156172,
      -1.9376787608055048,
      -1.9563877942139705,
      -1.9254953030701452,
      -1.9643106678672628,
      -1.9558205577248065,
      -1.926566890974297,
      -1.9834394456247955,
      -1.9567751851078452,
      -2.0111249832895672,
      -1.9213296535176965,
      -1.936876822980706,
      -1.9304983629006156,
      -1.9346833460333206,
      -1.9587733297809715,
      -1.9458611557841863,
      -1.947306864228833,
      -1.9372017269376394,
      -1.9621135043000024,
      -1.9737870890537133,
      -1.9653321767990515,
      -1.927864456837707,
      -1.9711064892794192,
      -1.9421190173340623,
      -1.9419334315369947,
      -1.9601042474465478,
      -1.9884235135014163
    ],
    [
      -1.338481992780808,
      0.0,
      -1.1980627846127279,
      -1.223490537946205,
      -1.232887799285758,
      -1.2197162065106302,
      -1.2911357472455671,
      -1.2700693946306263,
      -1.223707823796493,
      -1.2874705900342656,
      -1.1852239811393028,
      -1.397153563951179,
      -1.1438901744466576,
      -1.1576643354390634,
      -1.281190502641712,
      -1.2445784331992549,
      -1.271297464417949,
      -1.2317191668807685,
      -1.3054028131829365,
      -1.3495493990758545,
      -1.2851612036680267,
      -1.3254892597011638,
      -1.2291099221232864,
      -1.2025211265727778,
      -1.2777904853180064,
      -1.153164574838937,
      -1.2146933925142849,
      -1.3187118257170225,
      -1.369856322987567
    ],
    [
      -1.5115072794875244,
      -1.3901003899364852,
      0.0,
      -1.4182864814849179,
      -1.387491128777371,
      -1.4345732608671602,
      -1.5139550582196304,
      -1.3665589193968468,
      -1.4255053306744165,
      -1.5070243268375054,
      -1.3788177156214965,
      -1.618770012573849,
      -1.3152407835412667,
      -1.3547263167051107,
      -1.3706349176069543,
      -1.3933082707335642,
      -1.4532901002087653,
      -1.395347578234468,
      -1.45938005586354,
      -1.438449971250125,
      -1.454799476250215,
      -1.470876121438962,
      -1.4827550393011577,
      -1.35384049805971,
      -1.472217818100463,
      -1.3437624895737512,
      -1.4433691482702642,
      -1.424221138355065,
      -1.560097300468273
    ],
    [
      -1.2283744059976214,
      -1.1926581246003842,
      -1.1378282744725672,
      0.0,
      -1.2074129993794456,
      -1.1801870056219392,
      -1.2386189298081631,
      -1.1234008370924582,
      -1.12256519184151,
      -1.253150403261015,
      -1.1758557683153352,
      -1.3513582332325156,
      -1.1357081517746472,
      -1.1586811221356221,
      -1.1464799905975789,
      -1.075361037207936,
      -1.2106208909298994,
      -1.1732526134611432,
      -1.164307601994718,
      -1.1820831463020127,
      -1.22377413626735,
      -1.186820967553947,
      -1.220429366046077,
      -1.1741588798515243,
      -1.2403040352869177,
      -1.13522265294067,
      -1.2351298309927317,
      -1.2393462056507045,
      -1.2673233386652953
    ],
    [
      -1.5037409570287348,
      -1.4482265316962384,
      -1.4012796902281561,
      -1.487489411363213,
      0.0,
      -1.486670889015784,
      -1.492380955284481,
      -1.421685105754241,
      -1.4512170024204232,
      -1.4861859079312534,
      -1.420144139601312,
      -1.6045951044311544,
      -1.4104020258021424,
      -1.4187167235543736,
      -1.4537035365469881,
      -1.44858047191708,
      -1.4367501902372755,
      -1.3995386941233043,
      -1.5007674591460642,
      -1.476064922656004,
      -1.4473966788651564,
      -1.5191908714381643,
      -1.4510820264226918,
      -1.4205542680571968,
      -1.4704648450568407,
      -1.3941084704535405,
      -1.4259346988993844,
      -1.5396166083919465,
      -1.5655515062789398
    ],
    [
      -1.4937530544909952,
      -1.2818928550772286,
      -1.3735356758831396,
      -1.4023493072977282,
      -1.3900958377394488,
      0.0,
      -1.476742181896813,
      -1.4167089852889596,
      -1.397991967513432,
      -1.4963542652423387,
      -1.2795646994206995,
      -1.5831529816693377,
      -1.303124925792812,
      -1.3243675826724612,
      -1.3903406344000486,
      -1.3857916699927324,
      -1.430150541235489,
      -1.3883980880729117,
      -1.4361953675640384,
      -1.4291423237692982,
      -1.3962632393217809,
      -1.4450118974781598,
      -1.4048172220216344,
      -1.354011015892128,
      -1.458633972510625,
      -1.3663614047358092,
      -1.3947882291987272,
      -1.4365708418634484,
      -1.5192567788375966
    ],
    [
      -1.456669469380287,
      -1.3764357597122188,
      -1.4454312133536746,
      -1.4159214343253894,
      -1.3835270485366433,
      -1.374136618827906,
      0.0,
      -1.390504339289184,
      -1.4024577437965622,
      -1.434007065233239,
      -1.408085009863872,
      -1.4907599113076966,
      -1.3759021764707529,
      -1.3978266128626315,
      -1.4525335335357101,
      -1.4624562994449986,
      -1.410718846523983,
      -1.3754010032007595,
      -1.4397991775193377,
      -1.4379987349369434,
      -1.3725652070015972,
      -1.40954160706609,
      -1.389210523842848,
      -1.376163309547838,
      -1.4169826471146731,
      -1.3480442913417503,
      -1.3521555207235858,
      -1.4372806992207097,
      -1.4455521906504532
    ],
    [
      -1.5946764126001154,
      -1.5433669147928348,
      -1.5047022251851812,
      -1.489555743653452,
      -1.5081018693266135,
      -1.558282448584966,
      -1.6051347956908693,
      0.0,
      -1.4698528400315456,
      -1.6044521239991696,
      -1.525109211795203,
      -1.6929759457344622,
      -1.4799123182182103,
      -1.4906334076158383,
      -1.471698958692422,
      -1.491627362621534,
      -1.53582100504548,
      -1.5111097018695698,
      -1.5384606857187992,
      -1.503937533915787,
      -1.4846368181686058,
      -1.5431228696536532,
      -1.5789211359407858,
      -1.5017257391527694,
      -1.6217823092741543,
      -1.3942104635986923,
      -1.5285312012673506,
      -1.586899845462149,
      -1.6001888868830487
    ],
    [
      -1.4539795709704344,
      -1.3832156138770466,
      -1.3553207390212758,
      -1.3299527358875458,
      -1.37530586089541,
      -1.3802020100457093,
      -1.4359670521873433,
      -1.3353547814003124,
      0.0,
      -1.4645695207085374,
      -1.3577833169871034,
      -1.5707526702049368,
      -1.3242387008437682,
      -1.3533360734964075,
      -1.3038585257792483,
      -1.3563250660805852,
      -1.4174145906231617,
      -1.382654758586587,
      -1.3580302212146578,
      -1.3806912227785495,
      -1.399688478517348,
      -1.3728577549227348,
      -1.4071533773626927,
      -1.3782756567952383,
      -1.4649197110432628,
      -1.3133518212552684,
      -1.425478056380663,
      -1.4196383554491292,
      -1.465621050357174
    ],
    [
      -1.5374378046379407,
      -1.4319702787194546,
      -1.4261285279797535,
      -1.4218779969246222,
      -1.4238735959399016,
      -1.4422068992088104,
      -1.4767770066568047,
      -1.4701268963661165,
      -1.4641643085651743,
      0.0,
      -1.4155052005253979,
      -1.5246726274866655,
      -1.4131532206084054,
      -1.426121177788444,
      -1.5174529385503,
      -1.4350197250723271,
      -1.4152300829223177,
      -1.4630873039761074,
      -1.4179269032005744,
      -1.4829361525215454,
      -1.497205846980433,
      -1.3932643600088939,
      -1.378964341214038,
      -1.424815584714236,
      -1.4070610664795171,
      -1.3626871411453068,
      -1.3936193434732553,
      -1.4639708573025958,
      -1.4832236068062377
    ],
    [
      -1.3577572904221906,
      -1.2154967453823207,
      -1.2239655995876755,
      -1.307004269139955,
      -1.2717929492706284,
      -1.2372034017518945,
      -1.3474162432394845,
      -1.293922695972641,
      -1.2959081863248854,
      -1.3482505090512715,
      0.0,
      -1.462317716252215,
      -1.208610696170291,
      -1.252599034789976,
      -1.327381581230393,
      -1.2258231047074153,
      -1.3244392301423118,
      -1.3286550258918624,
      -1.3153247148474405,
      -1.3735162319588736,
      -1.3147758065964281,
      -1.36804105190888,
      -1.2607260977157564,
      -1.2308670381739653,
      -1.3023415670876521,
      -1.2167615590727225,
      -1.2939606404037651,
      -1.4067726427052933,
      -1.407486810517138
    ],
    [
      -1.2917833304902333,
      -1.2576856553616143,
      -1.2631518601287004,
      -1.272290300729753,
      -1.2703210280999992,
      -1.2613225524982772,
      -1.2337900825678532,
      -1.2614558031372418,
      -1.2401090494403109,
      -1.2454121331139358,
      -1.2420266912276892,
      0.0,
      -1.2559441673446046,
      -1.2643387198939784,
      -1.2711441103370094,
      -1.2523614336366058,
      -1.236883056048314,
      -1.2478946382029734,
      -1.2414816513420863,
      -1.239097310681751,
      -1.2699185411082305,
      -1.2270622556709747,
      -1.2181917847878991,
      -1.256548639288108,
      -1.2260716382672596,
      -1.2486870540739692,
      -1.2277721557367895,
      -1.245000064134392,
      -1.2490385198696365
    ],
    [
      -1.3961901031427568,
      -1.1782509418424212,
      -1.1756061147382444,
      -1.265960373823683,
      -1.2849204398741234,
      -1.2476586745441482,
      -1.3800697173416474,
      -1.2800307029097426,
      -1.2754829419059297,
      -1.411855869671682,
      -1.2526574049536812,
      -1.5150664183231484,
      0.0,
      -1.2559967119971212,
      -1.3423096080488912,
      -1.200052983878887,
      -1.361541679127956,
      -1.222230717398627,
      -1.326627802104726,
      -1.3537605568217785,
      -1.3622536884805352,
      -1.3722955349718784,
      -1.3431027677499288,
      -1.248382382972025,
      -1.4026407133656282,
      -1.1938833162256488,
      -1.2975896866830188,
      -1.3842251479043908,
      -1.4349852371992773
    ],
    [
      -1.3096451549085404,
      -1.1571754756729344,
      -1.1830879483025176,
      -1.1668861271482072,
      -1.1655610389794429,
      -1.1741225502058121,
      -1.3161826230357203,
      -1.2510319541612218,
      -1.214043581566252,
      -1.2801861506170653,
      -1.1878866165510593,
      -1.4362280077024456,
      -1.1589050910184653,
      0.0,
      -1.1829518643977857,
      -1.2145088760297977,
      -1.262936941424124,
      -1.1784339870706129,
      -1.2042150414955317,
      -1.277125111484629,
      -1.2679091401834512,
      -1.2553113959527111,
      -1.232500742300338,
      -1.2164291903550966,
      -1.2709858045138311,
      -1.1084165041769407,
      -1.1980568866550882,
      -1.2951649227076862,
      -1.3741188369038582
    ],
    [
      -1.3414273602898674,
      -1.275105750831531,
      -1.1481062938482067,
      -1.1948302615164403,
      -1.2905629539375694,
      -1.297397426580255,
      -1.2951041866237203,
      -1.1442036186736542,
      -1.2201522699547265,
      -1.4005764799864047,
      -1.3012116706243557,
      -1.4367480463729843,
      -1.217370474543499,
      -1.2560063875309593,
      0.0,
      -1.241565924701897,
      -1.2626374329366894,
      -1.2677206325607364,
      -1.339101052878943,
      -1.2671993189273107,
      -1.2409184450331865,
      -1.28967659523216,
      -1.3469345641267965,
      -1.2327708594846722,
      -1.3695384762033684,
      -1.207333946298039,
      -1.294276754615897,
      -1.314487057117913,
      -1.3312170057814938
    ],
    [
      -1.2215462162679356,
      -1.1242931719982376,
      -1.0595945565205842,
      -1.0687965763809721,
      -1.1432763488340074,
      -1.149527675341396,
      -1.2238933135187369,
      -1.1085525085693801,
      -1.1645100743590042,
      -1.2241666363327206,
      -1.0869301487324625,
      -1.3180225526244547,
      -1.0220485626573106,
      -1.0965973830312477,
      -1.141549494563073,
      0.0,
      -1.117983436017425,
      -1.1624425464839785,
      -1.0991063365447786,
      -1.1752694457748318,
      -1.1800547100040861,
      -1.1772321239469878,
      -1.1781190407264597,
      -1.1134809737728306,
      -1.1973405786363358,
      -1.019764958064926,
      -1.1667661324560947,
      -1.236586292647852,
      -1.268250647989927
    ],
    [
      -1.406553106488829,
      -1.3809920814550123,
      -1.334054654831383,
      -1.325994716899722,
      -1.347822491150067,
      -1.3584408959579202,
      -1.4043698302981882,
      -1.3472251695907371,
      -1.3301181989392117,
      -1.4189837288186797,
      -1.3462598711127034,
      -1.5103890741522448,
      -1.3546551869577688,
      -1.3444380142903416,
      -1.3171292081238866,
      -1.3425022297313647,
      0.0,
      -1.3778512536728984,
      -1.3573883993410287,
      -1.3646013696403607,
      -1.3609348139432234,
      -1.3745608363812354,
      -1.3949187794586981,
      -1.3057296611840425,
      -1.3952280745527967,
      -1.336076239067951,
      -1.3601339232825227,
      -1.3544791031415895,
      -1.4324108412712335
    ],
    [
      -1.4906855707054865,
      -1.3707285446242412,
      -1.4031143410201379,
      -1.4075262960758268,
      -1.3079519356392877,
      -1.399427962475524,
      -1.461757712835187,
      -1.4182361064310867,
      -1.405799537377332,
      -1.51448346901265,
      -1.4253733106443454,
      -1.5859037301516348,
      -1.2715601376274686,
      -1.4045039562906934,
      -1.417120029485633,
      -1.4199210038053673,
      -1.451200637429419,
      0.0,
      -1.4594372303970948,
      -1.4610682178673857,
      -1.4590980017326947,
      -1.4731789207539725,
      -1.4622593928030012,
      -1.3397473248084186,
      -1.4871600282632962,
      -1.38464807360586,
      -1.4061075007548327,
      -1.4710970211288066,
      -1.5580139079184945
    ],
    [
      -1.3162771561767634,
      -1.2873574680624236,
      -1.229858229190141,
      -1.2269951089842823,
      -1.2470304318939947,
      -1.2511213493041173,
      -1.2985835963155588,
      -1.2835085323246782,
      -1.245559676344234,
      -1.2715232067631457,
      -1.239469682519156,
      -1.372282048074427,
      -1.204655691537335,
      -1.2272498476630984,
      -1.2892016206577013,
      -1.2042200710145454,
      -1.2721726302938963,
      -1.2851593780701478,
      0.0,
      -1.3271387656107074,
      -1.34163047409618,
      -1.263578405698912,
      -1.2463756797078005,
      -1.2435949167176934,
      -1.2744095714147818,
      -1.2263121200841247,
      -1.220744794534991,
      -1.2439705533033105,
      -1.3461382568520852
    ],
    [
      -1.4551514570450548,
      -1.4511839746326314,
      -1.404962177842986,
      -1.4298960971112349,
      -1.4101998728938236,
      -1.444132976163165,
      -1.4775114589738698,
      -1.3739194187047825,
      -1.4214088276854133,
      -1.4800207845975502,
      -1.4306978164134956,
      -1.574748006245263,
      -1.406945251332588,
      -1.4434172644116041,
      -1.3666193402363573,
      -1.4217314206620664,
      -1.410651968486717,
      -1.4227397593202995,
      -1.4445469892406888,
      0.0,
      -1.3881509746879763,
      -1.4060935497142208,
      -1.4537917941583376,
      -1.4226331936794703,
      -1.4684993137843834,
      -1.4098448822719012,
      -1.4472110416441544,
      -1.432411227311728,
      -1.4609569380276473
    ],
    [
      -1.6160700088335174,
      -1.5411958667351404,
      -1.5341290933662926,
      -1.5572307149941764,
      -1.4627430712891545,
      -1.55120633838657,
      -1.5551790334519007,
      -1.4842842289985456,
      -1.5366896834844916,
      -1.6004337671750615,
      -1.5013769699104107,
      -1.6574530527432898,
      -1.5073423411539444,
      -1.489698651555584,
      -1.4876230508210067,
      -1.548002342517444,
      -1.4969325718186406,
      -1.519342036456307,
      -1.5907742426543847,
      -1.5042553481006105,
      0.0,
      -1.5766611201337588,
      -1.5338056610049633,
      -1.4982674745791036,
      -1.5653263623117997,
      -1.465893745870583,
      -1.5236052962412143,
      -1.5781610546392562,
      -1.578132793340851
    ],
    [
      -1.340681017375485,
      -1.3530628321423712,
      -1.3561060735317054,
      -1.3406664801998023,
      -1.3025916239715296,
      -1.3560204946950134,
      -1.3370011754274649,
      -1.3136485999448908,
      -1.3346735215280399,
      -1.346773706412542,
      -1.3660630273750736,
      -1.4504824103169305,
      -1.305193283442851,
      -1.3519413110646195,
      -1.3596250362140552,
      -1.3398285680386357,
      -1.3162183533134468,
      -1.306299975397035,
      -1.3091366784790197,
      -1.3410988108617885,
      -1.3616298724396336,
      0.0,
      -1.361288733451726,
      -1.3543667175281966,
      -1.3915335399258486,
      -1.2669128652446315,
      -1.292950311519412,
      -1.3637502120032585,
      -1.3852543193226394
    ],
    [
      -1.5110090761495292,
      -1.406795249987828,
      -1.4366917745453596,
      -1.4524033666669782,
      -1.4291776230380802,
      -1.424065907200554,
      -1.4792850566585147,
      -1.4595255170754082,
      -1.404302260809261,
      -1.4170509070647899,
      -1.4122447127090922,
      -1.5489008140857234,
      -1.427957837311942,
      -1.426207697007821,
      -1.5005791134113555,
      -1.462437877262331,
      -1.448972937963696,
      -1.4684572076960314,
      -1.4623143018255136,
      -1.4992777762203628,
      -1.4678797647304282,
      -1.4851452895701858,
      0.0,
      -1.4420447077412781,
      -1.3879928526297434,
      -1.3906035265903227,
      -1.3752341464391131,
      -1.4737488324066734,
      -1.4865512731041235
    ],
    [
      -1.5148647248006915,
      -1.4571897991415972,
      -1.429324468520778,
      -1.404586231013179,
      -1.4194803266089915,
      -1.4410814297590249,
      -1.4997338697926352,
      -1.4703901531180745,
      -1.417297838097624,
      -1.5068197015968945,
      -1.4348136376186462,
      -1.6267547237192197,
      -1.348282235849485,
      -1.4051060250937284,
      -1.4625278522540324,
      -1.4561135249048864,
      -1.4453016002617198,
      -1.4123726719421914,
      -1.4553377458929506,
      -1.4976904685238164,
      -1.5046718508839991,
      -1.5057544858276122,
      -1.4354975533697638,
      0.0,
      -1.3836934928514237,
      -1.4112403774673405,
      -1.4425201627168305,
      -1.46399985637048,
      -1.5599887374345556
    ],
    [
      -1.4643784441936716,
      -1.3822120221306098,
      -1.3706273966347802,
      -1.3751284552296272,
      -1.3948182314478346,
      -1.3646248787742823,
      -1.410419037976422,
      -1.4424947240286046,
      -1.4060975648385705,
      -1.3744050277821638,
      -1.3825431464734161,
      -1.5227431674579315,
      -1.3612200283717388,
      -1.3794843090611981,
      -1.438987705989831,
      -1.3982241560245579,
      -1.3653030587366317,
      -1.4107834108833934,
      -1.4008991393900514,
      -1.4482123204969555,
      -1.4749473549159764,
      -1.425591798717073,
      -1.3472852995472226,
      -1.2855926428427962,
      0.0,
      -1.3687975580424734,
      -1.3706770437417657,
      -1.443704248146246,
      -1.485077004668654
    ],
    [
      -1.6052336488321841,
      -1.4659611905141445,
      -1.4599154104294045,
      -1.4882089945185242,
      -1.4954667622455575,
      -1.5204018435436644,
      -1.5465512709487752,
      -1.45970638864875,
      -1.4885935786764009,
      -1.5156500493774834,
      -1.479620761009606,
      -1.6938336587640108,
      -1.3678022772684313,
      -1.4103564446778214,
      -1.5534174269460719,
      -1.46493553077595,
      -1.5294688606995253,
      -1.4820999993930994,
      -1.497601616765137,
      -1.5798951609490506,
      -1.4784421180398488,
      -1.5046838275610217,
      -1.521188461166529,
      -1.4786650703188395,
      -1.585941274829965,
      0.0,
      -1.45147740321805,
      -1.5847731121956417,
      -1.6653615100759251
    ],
    [
      -1.4210992584192879,
      -1.2999011447088629,
      -1.349293973141823,
      -1.374741657577355,
      -1.2620563690844075,
      -1.3694105986097453,
      -1.3854284781095068,
      -1.3276050172713683,
      -1.3402278547136885,
      -1.3527337084946305,
      -1.3246461949545163,
      -1.509483097792388,
      -1.3168109708667677,
      -1.3126402392016905,
      -1.3533094456329158,
      -1.3712864176249842,
      -1.377119918072779,
      -1.2932769531676105,
      -1.3111064784782989,
      -1.4087534213940291,
      -1.346481682983776,
      -1.3251643405573346,
      -1.3323656389178764,
      -1.3092364678306663,
      -1.3795142629182457,
      -1.2664339859991058,
      0.0,
      -1.3665958787296004,
      -1.413789843205531
    ],
    [
      -1.3487810655959178,
      -1.28187243589639,
      -1.262587560146597,
      -1.2815768325085581,
      -1.292912400207062,
      -1.2797944349504744,
      -1.303962048881064,
      -1.2531628127778245,
      -1.2639899192348312,
      -1.3411087986550856,
      -1.3092444237978254,
      -1.3843283313710184,
      -1.282219885640044,
      -1.3209843187682249,
      -1.3005162192936002,
      -1.2947359749258662,
      -1.2708702649938384,
      -1.2855237220470614,
      -1.299943170380825,
      -1.2890118490390357,
      -1.301635348328052,
      -1.2757878938767526,
      -1.3210694000639023,
      -1.2539150204259937,
      -1.3326262592925526,
      -1.2807940037944072,
      -1.2500478057912179,
      0.0,
      -1.3000330963492774
    ],
    [
      -1.3350694670038061,
      -1.329825149397537,
      -1.3279023957888916,
      -1.2969914414996364,
      -1.2877295676647325,
      -1.329680877255896,
      -1.3137675487537153,
      -1.2478099182052909,
      -1.2998713222050162,
      -1.3389923760912337,
      -1.2973348213343234,
      -1.3716331512565396,
      -1.3221385134457946,
      -1.3108965673454303,
      -1.2705451290065322,
      -1.3404807620323327,
      -1.2995959929460548,
      -1.3104406090141394,
      -1.3118618703802798,
      -1.2562759526703564,
      -1.2974446751787845,
      -1.2495119496054492,
      -1.3246316769933413,
      -1.3058552827072525,
      -1.3728429548005616,
      -1.2793260405125568,
      -1.2977200108673592,
      -1.299643660683728,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.21690684873458732,
      0.22398458299825874,
      0.23254839800837113,
      0.2138393645999055,
      0.2447318557437308,
      0.20591649094661313,
      0.2144066010890695,
      0.24366026783957895,
      0.1867877131890805,
      0.21345197370603075,
      0.15910217552430872,
      0.2488975052961795,
      0.2333503358331699,
      0.23972879591326035,
      0.23554381278055536,
      0.21145382903290444,
      0.22436600302968968,
      0.22292029458504303,
      0.2330254318762366,
      0.20811365451387354,
      0.1964400697601627,
      0.20489498201482448,
      0.24236270197616894,
      0.19912066953445673,
      0.22810814147981362,
      0.22829372727688124,
      0.2101229113673282,
      0.18180364531245963
    ],
    [
      0.34267844674566583,
      0.0,
      0.483097654913746,
      0.45766990158026877,
      0.4482726402407158,
      0.4614442330158437,
      0.39002469228090675,
      0.4110910448958476,
      0.45745261572998097,
      0.3936898494922083,
      0.49593645838717104,
      0.2840068755752949,
      0.5372702650798162,
      0.5234961040874104,
      0.3999699368847618,
      0.436582006327219,
      0.40986297510852476,
      0.4494412726457053,
      0.3757576263435374,
      0.3316110404506194,
      0.3959992358584472,
      0.35567117982531005,
      0.45205051740318747,
      0.4786393129536961,
      0.40336995420846744,
      0.5279958646875369,
      0.466467047012189,
      0.36244861380945137,
      0.31130411653890677
    ],
    [
      0.3298539186884697,
      0.45126080823950887,
      0.0,
      0.4230747166910762,
      0.45387006939862307,
      0.4067879373088339,
      0.3274061399563637,
      0.47480227877914727,
      0.41585586750157755,
      0.33433687133848866,
      0.4625434825544976,
      0.2225911856021452,
      0.5261204146347274,
      0.4866348814708834,
      0.47072628056903976,
      0.44805292744242986,
      0.38807109796722883,
      0.4460136199415261,
      0.38198114231245417,
      0.402911226925869,
      0.3865617219257791,
      0.370485076737032,
      0.3586061588748364,
      0.487520700116284,
      0.36914338007553105,
      0.49759870860224287,
      0.3979920499057299,
      0.41714005982092917,
      0.2812638977077211
    ],
    [
      0.33234794307910875,
      0.3680642244763459,
      0.42289407460416295,
      0.0,
      0.35330934969728456,
      0.3805353434547909,
      0.322103419268567,
      0.43732151198427194,
      0.4381571572352201,
      0.3075719458157151,
      0.3848665807613949,
      0.20936411584421455,
      0.4250141973020829,
      0.402041226941108,
      0.41424235847915125,
      0.48536131186879405,
      0.3501014581468307,
      0.38746973561558695,
      0.3964147470820121,
      0.3786392027747174,
      0.33694821280938014,
      0.3739013815227832,
      0.34029298303065314,
      0.3865634692252058,
      0.32041831378981245,
      0.4254996961360602,
      0.3255925180839985,
      0.3213761434260256,
      0.2933990104114348
    ],
    [
      0.36897213211812363,
      0.42448655745062003,
      0.4714333989187023,
      0.3852236777836453,
      0.0,
      0.3860422001310744,
      0.3803321338623775,
      0.4510279833926174,
      0.42149608672643524,
      0.38652718121560503,
      0.4525689495455465,
      0.268117984715704,
      0.46231106334471606,
      0.4539963655924848,
      0.41900955259987027,
      0.42413261722977835,
      0.43596289890958295,
      0.4731743950235541,
      0.37194563000079417,
      0.3966481664908543,
      0.425316410281702,
      0.3535222177086941,
      0.4216310627241666,
      0.45215882108966166,
      0.4022482440900177,
      0.47860461869331794,
      0.446778390247474,
      0.33309648075491194,
      0.3071615828679186
    ],
    [
      0.4385151908276743,
      0.6503753902414409,
      0.5587325694355298,
      0.5299189380209413,
      0.5421724075792207,
      0.0,
      0.45552606342185653,
      0.5155592600297099,
      0.5342762778052375,
      0.43591398007633075,
      0.65270354589797,
      0.34911526364933176,
      0.6291433195258576,
      0.6079006626462082,
      0.5419276109186209,
      0.5464765753259371,
      0.5021177040831806,
      0.5438701572457578,
      0.49607287775463105,
      0.5031259215493713,
      0.5360050059968886,
      0.48725634784050964,
      0.5274510232970351,
      0.5782572294265416,
      0.4736342728080445,
      0.5659068405828602,
      0.5374800161199422,
      0.49569740345522106,
      0.4130114664810729
    ],
    [
      0.32882957625343456,
      0.4090632859215029,
      0.340067832280047,
      0.3695776113083322,
      0.4019719970970783,
      0.4113624268058156,
      0.0,
      0.3949947063445376,
      0.38304130183715945,
      0.3514919804004826,
      0.37741403576984967,
      0.29473913432602505,
      0.4095968691629688,
      0.3876724327710901,
      0.3329655120980115,
      0.3230427461887231,
      0.3747801991097386,
      0.4100980424329621,
      0.3456998681143839,
      0.3475003106967782,
      0.4129338386321244,
      0.37595743856763164,
      0.3962885217908736,
      0.4093357360858836,
      0.3685163985190485,
      0.43745475429197134,
      0.43334352491013584,
      0.34821834641301197,
      0.3399468549832685
    ],
    [
      0.36566011053600467,
      0.4169696083432852,
      0.4556342979509389,
      0.47078077948266817,
      0.45223465380950656,
      0.40205407455115405,
      0.3552017274452508,
      0.0,
      0.49048368310457446,
      0.35588439913695047,
      0.4352273113409171,
      0.26736057740165786,
      0.4804242049179097,
      0.46970311552028177,
      0.488637564443698,
      0.4687091605145861,
      0.42451551809064014,
      0.4492268212665502,
      0.4218758374173208,
      0.45639898922033306,
      0.47569970496751424,
      0.41721365348246686,
      0.3814153871953343,
      0.45861078398335064,
      0.3385542138619657,
      0.5661260595374278,
      0.4318053218687694,
      0.37343667767397104,
      0.36014763625307133
    ],
    [
      0.39183927591552914,
      0.4626032330089169,
      0.4904981078646877,
      0.5158661109984177,
      0.47051298599055347,
      0.46561683684025423,
      0.4098517946986202,
      0.5104640654856512,
      0.0,
      0.38124932617742613,
      0.4880355298988601,
      0.27506617668102673,
      0.5215801460421954,
      0.49248277338955604,
      0.5419603211067152,
      0.4894937808053783,
      0.4284042562628019,
      0.4631640882993766,
      0.48778862567130576,
      0.46512762410741404,
      0.4461303683686155,
      0.4729610919632288,
      0.4386654695232708,
      0.4675431900907252,
      0.38089913584270074,
      0.5324670256306951,
      0.4203407905053005,
      0.42618049143683434,
      0.3801977965287895
    ],
    [
      0.27091515384718745,
      0.3763826797656735,
      0.3822244305053746,
      0.38647496156050587,
      0.3844793625452265,
      0.3661460592763177,
      0.33157595182832345,
      0.33822606211901163,
      0.3441886499199538,
      0.0,
      0.39284775795973026,
      0.28368033099846257,
      0.3951997378767227,
      0.3822317806966842,
      0.29090001993482817,
      0.373333233412801,
      0.39312287556281045,
      0.3452656545090207,
      0.39042605528455376,
      0.3254168059635827,
      0.3111471115046951,
      0.41508859847623425,
      0.4293886172710901,
      0.38353737377089203,
      0.401291892005611,
      0.44566581733982136,
      0.4147336150118728,
      0.3443821011825323,
      0.32512935167889045
    ],
    [
      0.3972822039481094,
      0.5395427489879794,
      0.5310738947826246,
      0.448035225230345,
      0.4832465450996717,
      0.5178360926184056,
      0.40762325113081554,
      0.46111679839765896,
      0.4591313080454147,
      0.4067889853190285,
      0.0,
      0.2927217781180851,
      0.5464287982000091,
      0.502440459580324,
      0.427657913139907,
      0.5292163896628848,
      0.43060026422798825,
      0.4263844684784377,
      0.43971477952285953,
      0.3815232624114264,
      0.4402636877738719,
      0.3869984424614201,
      0.49431339665454366,
      0.5241724561963348,
      0.4526979272826479,
      0.5382779352975775,
      0.4610788539665349,
      0.3482668516650067,
      0.34755268385316196
    ],
    [
      0.20406496239141791,
      0.23816263752003697,
      0.23269643275295082,
      0.2235579921518982,
      0.22552726478165197,
      0.23452574038337404,
      0.26205821031379806,
      0.2343924897444094,
      0.25573924344134036,
      0.2504361597677154,
      0.25382160165396206,
      0.0,
      0.23990412553704665,
      0.23150957298767283,
      0.22470418254464186,
      0.24348685924504543,
      0.2589652368333373,
      0.2479536546786778,
      0.2543666415395649,
      0.2567509821999001,
      0.22592975177342067,
      0.2687860372106765,
      0.2776565080937521,
      0.23929965359354322,
      0.2697766546143916,
      0.24716123880768204,
      0.26807613714486167,
      0.2508482287472593,
      0.24680977301201468
    ],
    [
      0.38919046988865813,
      0.6071296311889938,
      0.6097744582931706,
      0.5194201992077319,
      0.5004601331572915,
      0.5377218984872667,
      0.40531085568976755,
      0.5053498701216723,
      0.5098976311254853,
      0.37352470335973287,
      0.5327231680777338,
      0.2703141547082666,
      0.0,
      0.5293838610342938,
      0.44307096498252374,
      0.585327589152528,
      0.42383889390345897,
      0.5631498556327879,
      0.458752770926689,
      0.4316200162096364,
      0.42312688455087977,
      0.41308503805953656,
      0.4422778052814862,
      0.5369981900593899,
      0.3827398596657867,
      0.5914972568057661,
      0.4877908863483962,
      0.4011554251270242,
      0.35039533583213767
    ],
    [
      0.42416799233580216,
      0.5766376715714081,
      0.5507251989418249,
      0.5669270200961354,
      0.5682521082648997,
      0.5596905970385304,
      0.41763052420862223,
      0.48278119308312073,
      0.5197695656780905,
      0.45362699662727723,
      0.5459265306932832,
      0.2975851395418969,
      0.5749080562258773,
      0.0,
      0.5508612828465569,
      0.5193042712145448,
      0.4708762058202185,
      0.5553791601737297,
      0.5295981057488108,
      0.4566880357597136,
      0.4659040070608913,
      0.4785017512916314,
      0.5013124049440045,
      0.517383956889246,
      0.4628273427305114,
      0.6253966430674018,
      0.5357562605892543,
      0.4386482245366563,
      0.3596943103404844
    ],
    [
      0.35665972836206183,
      0.42298133782039815,
      0.5499807948037225,
      0.5032568271354889,
      0.4075241347143599,
      0.4006896620716742,
      0.40298290202820897,
      0.5538834699782751,
      0.4779348186972028,
      0.2975106086655246,
      0.39687541802757353,
      0.261339042278945,
      0.48071661410843025,
      0.44208070112097,
      0.0,
      0.45652116395003217,
      0.43544965571523986,
      0.43036645609119284,
      0.35898603577298616,
      0.4308877697246185,
      0.45716864361874276,
      0.4084104934197692,
      0.3511525245251328,
      0.465316229167257,
      0.3285486124485608,
      0.4907531423538902,
      0.40381033403603217,
      0.38360003153401623,
      0.36687008287043543
    ],
    [
      0.35231114213943604,
      0.449564186409134,
      0.5142628018867874,
      0.5050607820263995,
      0.4305810095733642,
      0.4243296830659755,
      0.34996404488863475,
      0.4653048498379915,
      0.4093472840483674,
      0.349690722074651,
      0.4869272096749091,
      0.25583480578291695,
      0.551808795750061,
      0.47725997537612397,
      0.43230786384429853,
      0.0,
      0.4558739223899466,
      0.41141481192339313,
      0.474751021862593,
      0.3985879126325398,
      0.3938026484032855,
      0.3966252344603838,
      0.39573831768091194,
      0.460376384634541,
      0.3765167797710358,
      0.5540924003424457,
      0.4070912259512769,
      0.3372710657595197,
      0.3056067104174447
    ],
    [
      0.38474059613256295,
      0.4103016211663797,
      0.457239047790009,
      0.46529898572167006,
      0.44347121147132507,
      0.4328528066634718,
      0.3869238723232038,
      0.44406853303065486,
      0.4611755036821803,
      0.37230997380271225,
      0.4450338315086886,
      0.2809046284691472,
      0.4366385156636232,
      0.4468556883310504,
      0.4741644944975054,
      0.4487914728900273,
      0.0,
      0.4134424489484936,
      0.43390530328036325,
      0.42669233298103126,
      0.4303588886781686,
      0.4167328662401566,
      0.39637492316269385,
      0.48556404143734944,
      0.39606562806859524,
      0.45521746355344095,
      0.4311597793388693,
      0.4368145994798025,
      0.35888286135015846
    ],
    [
      0.39649527205047574,
      0.516452298131721,
      0.48406650173582433,
      0.4796545466801354,
      0.5792289071166745,
      0.4877528802804383,
      0.42542312992077513,
      0.46894473632487554,
      0.4813813053786302,
      0.37269737374331213,
      0.46180753211161685,
      0.30127711260432744,
      0.6156207051284937,
      0.48267688646526885,
      0.4700608132703292,
      0.46725983895059486,
      0.43598020532654314,
      0.0,
      0.4277436123588674,
      0.4261126248885765,
      0.42808284102326755,
      0.4140019220019897,
      0.424921449952961,
      0.5474335179475436,
      0.400020814492666,
      0.5025327691501023,
      0.4810733420011295,
      0.4160838216271556,
      0.32916693483746773
    ],
    [
      0.3558653264980165,
      0.38478501461235637,
      0.44228425348463896,
      0.4451473736904976,
      0.4251120507807853,
      0.4210211333706626,
      0.3735588863592212,
      0.38863395035010173,
      0.4265828063305459,
      0.40061927591163426,
      0.4326728001556239,
      0.29986043460035283,
      0.46748679113744496,
      0.4448926350116815,
      0.38294086201707866,
      0.4679224116602345,
      0.3999698523808837,
      0.38698310460463214,
      0.0,
      0.3450037170640725,
      0.33051200857859997,
      0.40856407697586783,
      0.42576680296697944,
      0.42854756595708654,
      0.3977329112599981,
      0.4458303625906552,
      0.451397688139789,
      0.4281719293714694,
      0.3260042258226947
    ],
    [
      0.3448897136532123,
      0.3488571960656357,
      0.39507899285528114,
      0.3701450735870322,
      0.38984129780444343,
      0.35590819453510214,
      0.32252971172439726,
      0.42612175199348457,
      0.37863234301285376,
      0.3200203861007169,
      0.3693433542847715,
      0.22529316445300407,
      0.3930959193656791,
      0.35662390628666296,
      0.43342183046190974,
      0.3783097500362007,
      0.38938920221155016,
      0.3773014113779676,
      0.3554941814575783,
      0.0,
      0.41189019601029075,
      0.39394762098404623,
      0.3462493765399295,
      0.3774079770187968,
      0.3315418569138837,
      0.3901962884263659,
      0.3528301290541127,
      0.3676299433865391,
      0.3390842326706198
    ],
    [
      0.2979793489393414,
      0.37285349103771837,
      0.37992026440656623,
      0.35681864277868236,
      0.4513062864837043,
      0.3628430193862888,
      0.3588703243209581,
      0.42976512877431317,
      0.37735967428836714,
      0.3136155905977973,
      0.4126723878624481,
      0.256596305029569,
      0.4067070166189144,
      0.4243507062172749,
      0.42642630695185213,
      0.3660470152554147,
      0.4171167859542182,
      0.39470732131655173,
      0.32327511511847407,
      0.4097940096722483,
      0.0,
      0.3373882376391,
      0.3802436967678955,
      0.4157818831937552,
      0.3487229954610591,
      0.4481556119022758,
      0.39044406153164446,
      0.33588830313360263,
      0.3359165644320077
    ],
    [
      0.4966111801901605,
      0.4842293654232743,
      0.4811861240339401,
      0.49662571736584327,
      0.5347005735941159,
      0.48127170287063215,
      0.5002910221381807,
      0.5236435976207547,
      0.5026186760376057,
      0.49051849115310353,
      0.471229170190572,
      0.38680978724871506,
      0.5320989141227945,
      0.4853508865010261,
      0.4776671613515904,
      0.49746362952700984,
      0.5210738442521987,
      0.5309922221686105,
      0.5281555190866258,
      0.49619338670385704,
      0.4756623251260119,
      0.0,
      0.47600346411391947,
      0.48292548003744895,
      0.44575865763979694,
      0.570379332321014,
      0.5443418860462335,
      0.473541985562387,
      0.4520378782430061
    ],
    [
      0.40157904718541704,
      0.5057928733471182,
      0.47589634878958664,
      0.460184756667968,
      0.48341050029686605,
      0.4885222161343923,
      0.4333030666764315,
      0.453062606259538,
      0.5082858625256852,
      0.49553721627015634,
      0.500343410625854,
      0.36368730924922277,
      0.4846302860230043,
      0.4863804263271252,
      0.4120090099235907,
      0.4501502460726152,
      0.46361518537125024,
      0.4441309156389148,
      0.4502738215094326,
      0.41331034711458337,
      0.44470835860451796,
      0.42744283376476044,
      0.0,
      0.4705434155936681,
      0.5245952707052028,
      0.5219845967446235,
      0.5373539768958331,
      0.4388392909282728,
      0.4260368502308227
    ],
    [
      0.41737325965252303,
      0.4750481853116173,
      0.5029135159324365,
      0.5276517534400356,
      0.512757657844223,
      0.4911565546941896,
      0.43250411466057925,
      0.46184783133513996,
      0.5149401463555905,
      0.42541828285632,
      0.49742434683456827,
      0.3054832607339948,
      0.5839557486037295,
      0.5271319593594861,
      0.4697101321991821,
      0.47612445954832805,
      0.48693638419149465,
      0.5198653125110231,
      0.47690023856026387,
      0.4345475159293981,
      0.42756613356921536,
      0.4264834986256023,
      0.4967404310834507,
      0.0,
      0.5485444916017908,
      0.5209976069858739,
      0.489717821736384,
      0.4682381280827346,
      0.3722492470186589
    ],
    [
      0.36643243841902384,
      0.44859886048208564,
      0.46018348597791525,
      0.4556824273830682,
      0.43599265116486086,
      0.46618600383841313,
      0.4203918446362733,
      0.38831615858409085,
      0.4247133177741249,
      0.45640585483053164,
      0.4482677361392793,
      0.30806771515476394,
      0.4695908542409566,
      0.4513265735514973,
      0.39182317662286437,
      0.43258672658813757,
      0.4655078238760637,
      0.420027471729302,
      0.429911743222644,
      0.38259856211573995,
      0.35586352769671903,
      0.40521908389562245,
      0.4835255830654728,
      0.5452182397698992,
      0.0,
      0.46201332457022204,
      0.46013383887092973,
      0.38710663446644933,
      0.3457338779440413
    ],
    [
      0.4174790957844454,
      0.556751554102485,
      0.562797334187225,
      0.5345037500981054,
      0.527245982371072,
      0.5023109010729652,
      0.47616147366785433,
      0.5630063559678795,
      0.5341191659402287,
      0.5070626952391462,
      0.5430919836070236,
      0.3288790858526187,
      0.6549104673481982,
      0.6123562999388081,
      0.46929531767055765,
      0.5577772138406796,
      0.4932438839171043,
      0.5406127452235301,
      0.5251111278514926,
      0.44281758366757895,
      0.5442706265767807,
      0.5180289170556078,
      0.5015242834501006,
      0.54404767429779,
      0.4367714697866645,
      0.0,
      0.5712353413985796,
      0.4379396324209879,
      0.3573512345407044
    ],
    [
      0.3929443220272262,
      0.5141424357376512,
      0.46474960730469106,
      0.43930192286915903,
      0.5519872113621065,
      0.4446329818367687,
      0.4286151023370073,
      0.4864385631751458,
      0.4738157257328255,
      0.46130987195188355,
      0.48939738549199774,
      0.30456048265412594,
      0.49723260957974635,
      0.5014033412448236,
      0.46073413481359826,
      0.4427571628215299,
      0.43692366237373514,
      0.5207666272789035,
      0.5029371019682152,
      0.4052901590524849,
      0.467561897462738,
      0.4888792398891795,
      0.48167794152863763,
      0.5048071126158478,
      0.4345293175282683,
      0.5476095944474082,
      0.0,
      0.4474477017169136,
      0.4002537372409831
    ],
    [
      0.34869744962430693,
      0.41560607932383475,
      0.43489095507362774,
      0.4159016827116666,
      0.40456611501316275,
      0.41768408026975035,
      0.3935164663391608,
      0.44431570244240026,
      0.4334885959853936,
      0.35636971656513916,
      0.3882340914223994,
      0.31315018384920634,
      0.4152586295801808,
      0.3764941964519999,
      0.3969622959266246,
      0.4027425402943585,
      0.4266082502263864,
      0.4119547931731633,
      0.3975353448393997,
      0.4084666661811891,
      0.3958431668921727,
      0.4216906213434721,
      0.37640911515632247,
      0.4435634947942311,
      0.3648522559276721,
      0.4166845114258175,
      0.44743070942900687,
      0.0,
      0.3974454188709473
    ],
    [
      0.3526387218684206,
      0.3578830394746897,
      0.35980579308333516,
      0.3907167473725903,
      0.3999786212074943,
      0.35802731161633083,
      0.37394064011851147,
      0.4398982706669359,
      0.3878368666672105,
      0.34871581278099306,
      0.3903733675379033,
      0.3160750376156871,
      0.36556967542643215,
      0.3768116215267965,
      0.4171630598656946,
      0.34722742683989405,
      0.38811219592617197,
      0.37726757985808734,
      0.37584631849194694,
      0.4314322362018703,
      0.39026351369344225,
      0.43819623926677753,
      0.36307651187888546,
      0.38185290616497425,
      0.3148652340716651,
      0.4083821483596699,
      0.3899881780048675,
      0.3880645281884987,
      0.0
    ]
  ],
  "row_avgs": [
    0.217995813712948,
    0.4229750529315156,
    0.4078288078960348,
    0.36856470117381124,
    0.4090688144110697,
    0.5231479757872473,
    0.3755680458254597,
    0.4260711383327892,
    0.45417822925481605,
    0.3651215014931575,
    0.45078526435903843,
    0.2452488561952159,
    0.47232242167421756,
    0.5002414484757295,
    0.41865204410859785,
    0.42222512830744174,
    0.4239993542736905,
    0.45442691769649163,
    0.4047810804172716,
    0.36575267865257394,
    0.37612736053828727,
    0.494263642166801,
    0.4630575016241591,
    0.4746510006877798,
    0.427408054878964,
    0.5093108284598649,
    0.46402524835870007,
    0.4023701117547498,
    0.3796432001348492
  ],
  "col_avgs": [
    0.3666790721107791,
    0.44290831656772855,
    0.4542175984138431,
    0.4419652329160243,
    0.4455661818950067,
    0.42534587240580174,
    0.3839120663282601,
    0.4417423347074395,
    0.4380493481588164,
    0.3780582844449879,
    0.44363431970436334,
    0.285056544580822,
    0.4768614373515642,
    0.4498156920093487,
    0.4250374555670808,
    0.43927658355165217,
    0.41851693811328694,
    0.4344567911006117,
    0.4155050531316014,
    0.40066863716308,
    0.4087012275697156,
    0.40240997180248755,
    0.4130589021418697,
    0.4541346249316826,
    0.38836801981092334,
    0.4800924912190707,
    0.4361977661223581,
    0.3863448412526612,
    0.34323061851040454
  ],
  "combined_avgs": [
    0.29233744291186353,
    0.4329416847496221,
    0.43102320315493897,
    0.40526496704491777,
    0.4273174981530382,
    0.47424692409652447,
    0.3797400560768599,
    0.43390673652011436,
    0.44611378870681623,
    0.3715898929690727,
    0.44720979203170086,
    0.26515270038801897,
    0.47459192951289086,
    0.4750285702425391,
    0.4218447498378393,
    0.430750855929547,
    0.4212581461934887,
    0.44444185439855166,
    0.4101430667744365,
    0.38321065790782693,
    0.3924142940540014,
    0.4483368069846443,
    0.43805820188301436,
    0.4643928128097312,
    0.40788803734494367,
    0.4947016598394678,
    0.45011150724052906,
    0.3943574765037055,
    0.36143690932262684
  ],
  "gppm": [
    606.0103436031438,
    589.7355156788508,
    580.8764989586213,
    588.1676411422866,
    585.6563390939981,
    594.7337825492625,
    612.8409315144712,
    585.6210358053613,
    589.5142086713415,
    615.2815105209853,
    589.6393315770403,
    658.4174636256918,
    573.2405446385462,
    586.7183133501197,
    595.5306653367643,
    592.1326101364591,
    599.1467675238349,
    591.835972496863,
    601.6879233602122,
    603.2412682778177,
    600.186476639837,
    608.4447736850572,
    601.267767990975,
    583.075606428861,
    611.6008289227924,
    569.5443074530351,
    591.8619332286002,
    614.2576601388342,
    634.9025365887486
  ],
  "gppm_normalized": [
    1.3999320809438789,
    1.3419123492665463,
    1.3217704848134078,
    1.3335902836328632,
    1.3258489425085869,
    1.3532973950885931,
    1.3983629028482023,
    1.3286026569984286,
    1.335847907475301,
    1.3988707165551104,
    1.339975094084758,
    1.500559503719235,
    1.302146890698528,
    1.3299751667769002,
    1.3514850518344346,
    1.3465624006724308,
    1.3590833977161394,
    1.3376298066624444,
    1.364033314110149,
    1.3752590705772503,
    1.3533003328468551,
    1.380924525187779,
    1.3592258353893212,
    1.3238929591127462,
    1.3863654505660112,
    1.2924304324535025,
    1.343296496531972,
    1.3914698744527134,
    1.442544999483972
  ],
  "token_counts": [
    592,
    468,
    467,
    422,
    415,
    464,
    502,
    432,
    416,
    451,
    450,
    475,
    446,
    415,
    432,
    462,
    427,
    385,
    414,
    484,
    370,
    426,
    385,
    441,
    414,
    437,
    435,
    402,
    438,
    900,
    449,
    438,
    451,
    629,
    382,
    443,
    461,
    435,
    409,
    435,
    495,
    472,
    420,
    449,
    474,
    395,
    386,
    412,
    477,
    383,
    361,
    437,
    433,
    378,
    393,
    417,
    384,
    389,
    740,
    463,
    467,
    478,
    461,
    468,
    475,
    424,
    581,
    430,
    387,
    456,
    472,
    459,
    354,
    472,
    425,
    461,
    402,
    393,
    396,
    429,
    371,
    422,
    405,
    465,
    409,
    350,
    388,
    536,
    459,
    459,
    406,
    437,
    447,
    406,
    427,
    392,
    413,
    380,
    518,
    437,
    441,
    395,
    410,
    398,
    387,
    409,
    434,
    399,
    372,
    389,
    407,
    400,
    391,
    415,
    433,
    358,
    540,
    392,
    429,
    465,
    427,
    412,
    424,
    454,
    458,
    449,
    425,
    493,
    453,
    403,
    390,
    398,
    403,
    431,
    446,
    448,
    445,
    336,
    419,
    447,
    420,
    363,
    416,
    440,
    360,
    291,
    469,
    439,
    398,
    434,
    444,
    418,
    397,
    434,
    460,
    385,
    550,
    495,
    392,
    392,
    425,
    406,
    446,
    408,
    417,
    413,
    456,
    377,
    432,
    375,
    407,
    451,
    421,
    383,
    1292,
    479,
    439,
    421,
    436,
    487,
    414,
    463,
    426,
    473,
    416,
    542,
    483,
    494,
    468,
    463,
    409,
    419,
    400,
    433,
    436,
    451,
    463,
    441,
    435,
    449,
    393,
    488,
    390,
    598,
    457,
    460,
    436,
    400,
    434,
    419,
    406,
    415,
    415,
    403,
    522,
    419,
    414,
    456,
    429,
    399,
    402,
    402,
    449,
    381,
    459,
    396,
    420,
    394,
    407,
    389,
    458,
    364,
    668,
    476,
    491,
    435,
    399,
    469,
    505,
    387,
    435,
    421,
    416,
    456,
    451,
    447,
    366,
    429,
    444,
    439,
    432,
    365,
    436,
    383,
    403,
    437,
    433,
    512,
    444,
    453,
    398,
    556,
    436,
    455,
    520,
    439,
    403,
    443,
    430,
    421,
    442,
    402,
    469,
    440,
    412,
    457,
    437,
    417,
    397,
    430,
    478,
    440,
    351,
    389,
    390,
    417,
    413,
    412,
    418,
    373
  ],
  "response_lengths": [
    2722,
    2514,
    2600,
    2955,
    2559,
    2393,
    2511,
    2464,
    2338,
    2527,
    2394,
    2719,
    2454,
    2420,
    2574,
    2483,
    2224,
    2314,
    2505,
    2647,
    2322,
    2036,
    2259,
    2290,
    2425,
    2241,
    2396,
    2401,
    2119
  ]
}