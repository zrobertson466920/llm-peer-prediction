{
  "example_idx": 3,
  "reference": "Published as a conference paper at ICLR 2023\n\nGENERATING SEQUENCES BY LEARNING TO [SELF-]CORRECT\n\nSean Welleck1,3,* Ximing Lu1,* Peter West3,† Faeze Brahman1,3,†\n\nTianxiao Shen3 Daniel Khashabi2 Yejin Choi1,3 1Allen Institute for Artificial Intelligence 2Center for Language and Speech Processing, Johns Hopkins University 3Paul G. Allen School of Computer Science & Engineering, University of Washington\n\nABSTRACT\n\nSequence generation applications require satisfying semantic constraints, such as ensuring that programs are correct, using certain keywords, or avoiding undesirable content. Language models, whether fine-tuned or prompted with few-shot demonstrations, frequently violate these constraints, and lack a mechanism to iteratively revise their outputs. Moreover, some powerful language models are of extreme scale or inaccessible, making it inefficient, if not infeasible, to update their parameters for task-specific adaptation. We present SELF-CORRECTION, an approach that decouples an imperfect base generator (an off-the-shelf language model or supervised sequence-to-sequence model) from a separate corrector that learns to iteratively correct imperfect generations. To train the corrector, we propose an online training procedure that can use either scalar or natural language feedback on intermediate imperfect generations. We show that SELFCORRECTION improves upon the base generator in three diverse generation tasks– mathematical program synthesis, lexically-constrained generation, and toxicity control– even when the corrector is much smaller than the base generator.\n\n1\n\nINTRODUCTION\n\nThe standard practice for natural language generation tasks is inherently single-pass: applying a decoding procedure to either a few-shot prompted language model or one tuned for a given task, then considering the generation as “finished” (e.g. Radford et al. (2019); Brown et al. (2020); Chen et al. (2021)). Powerful generation models often meet most of the task requirements, yet miss a few (e.g., omitting a subset of keywords), or generate incorrect hypotheses that nevertheless provide useful structure (e.g., a correct problem solving strategy with a missing step). However, after generating even a slightly sub-optimal sequence, the single-pass paradigm requires models to “start from scratch”, effectively discarding work already done. A more natural, intuitive approach is leveraging the generation as a useful starting point to refine into a higher quality output.\n\nTo formalize this intuition, we introduce Self-Correction for Sequence Generation. Figure 1 demonstrates its central principle: a generation model is re-framed as a base generator, which produces a reasonable initial hypothesis but does not need to solve the task in one pass, and a second module–the corrector–trained to make up the difference between the hypothesis and an optimal solution. Neither the generator nor the corrector must solve the full task in one pass, and the corrector can be applied multiple times to iteratively improve the output (§3.6). We propose a simple, general procedure for training the corrector (Figure 2) by pairing generator outputs with carefully selected targets. The result is a system which self-corrects, producing outputs through multiple generation passes and breaking the task into steps that can be solved by dedicated and efficient sub-systems.\n\nSelf-Correction builds on past work for correction in the code and text (e.g. Yasunaga et al. (2021); Faltings et al. (2021)) domains, but provides a unified formalism with minimal assumptions about\n\n∗First authors, contributed equally. †Second authors, contributed equally.\n\n1\n\nPublished as a conference paper at ICLR 2023\n\nFigure 1: SELF-CORRECTORs decompose generation into a base generator that proposes an initial hypothesis, and a corrector that iteratively improves its quality.\n\ndata and feedback, which applies generally to diverse tasks. A corrector model improves the base generator on 3 such tasks in our experiments: mathematical program synthesis (§3.1), lexically constrained generation (§3.2), and toxicity reduction (§3.3). The trained corrector model even transfers to a larger generator with similar performance to training from scratch (§3.4). Finally, we explore introducing a third module to the Self-Correction system (§3.5)–explicitly using natural language feedback to guide corrections–with promising results. Self-Correction is an exciting path to build on the generations of strong models, with efficient, effective, and transferable corrector networks.\n\n2 SELF-CORRECTING SEQUENCE GENERATORS\n\nA typical autoregressive text generator (e.g. GPT-3 (Brown et al., 2020)) maps an input prompt to a distribution over outputs using a single parameterized module (e.g. a large transformer), p0(y|x). We explore an alternative that decomposes into two modules, a base generator, and a corrector,\n\np(y|x) =\n\n(cid:88)\n\ny0\n\np0(y0|x) (cid:124) (cid:123)(cid:122) (cid:125) generator\n\npθ(y|y0, x) (cid:125) (cid:123)(cid:122) (cid:124) corrector\n\n(1)\n\nwhere the generator provides an initial hypothesis that is refined by the corrector. In practice, the corrector can be applied multiple times, p(yT |x) = (cid:80) t pθ(yt+1|yt, x). Since a model of this form can both generate and correct its generations, we call it a Self-Corrector.\n\np0(y0|x) (cid:81)\n\n· · · (cid:80)\n\nyT −1\n\n(cid:80)\n\ny1\n\ny0\n\nSelf-correctors have several unique properties compared to typical generators. First, a self-corrector decouples generation and correction, allowing us to freely parameterize each module – for instance, by prompting a single language model or using two different language models. In this paper, we develop a framework to train a separate corrector model (§2.1). We find that the resulting selfcorrector improves upon the generator alone (§3), even when the corrector is much smaller (§3.4).\n\nSecond, since the generator and the corrector are separated, we can keep the generator as a generalpurpose language model and train the corrector with different objectives for different task requirements. In §2.1, we propose a training algorithm for the corrector that is dedicated to improving generations, where the improvement can be in any aspect, measured by scalar values.\n\nThird, the corrector can receive explicit feedback about intermediate generations to guide subsequent generations. Formally, p(y|x) = (cid:80) p0(y0|x)pθ(y|y0, x, f (y0)), where f is the feedback. The feedback can be of many forms, e.g. a sentence, a compiler trace, etc. In contrast, a typical generator that generates in a single pass does not leverage feedback on its own generation. In this paper, we show that the corrector can learn to exploit explicit natural language feedback to achieve better performance (§3.5). Next, we describe our training framework of the corrector.\n\ny0\n\n2.1 LEARNING A CORRECTOR\n\nOur goal is to have the generator generate an initial hypothesis, then improve the hypothesis with the corrector (Eq. 1). We train the corrector to improve the quality of a hypothesis, while staying as close as possible to the original hypothesis. Here, quality is measured with a scalar value function v(y) which is accessible at training time (e.g. 0/1 indicator of program correctness, a toxicity score).\n\n2\n\nPublished as a conference paper at ICLR 2023\n\nFigure 2: SELF-CORRECTIVE LEARNING iteratively trains a corrector by generating hypotheses and corrections, forming value-improving pairs, and selecting those with high similarity for learning.\n\nAlgorithm 1 Self-corrective learning input Generator p0, corrector pθ, prompts X, value v(·), feedback f (·)\n\nInitialize datapool D by sampling from p0 for iteration ∈ {1, 2, . . .} do\n\nForm value-improving pairs P from D for step in 1, 2, . . . , M do\n\nSample a batch of value-improving pairs from P using Eq. 4 Compute the loss and update θ using gradient descent\n\nfor x ∈ X do\n\nSample hypotheses y from datapool D Generate corrections y′ ∼ pθ(·|y, x, f (y)) Add all (x, y′, v(y′), f (y′)) to the datapool D\n\n▷ Initialization: Eq. 2\n\n▷ Pairing: Eq. 3\n\n▷ Learning\n\n▷ Exploration: Eq. 5\n\nSince direct supervision on how to improve hypotheses is not available, we design a new algorithm to train the corrector, which we refer to as self-corrective learning. The algorithm collects a pool of generations, pairs them and selects pairs of generation that increase in value and are nearby, then updates the corrector on these pairs. As training progresses, more generations are added to the pool using the current corrector. Algorithm 1 summarizes self-corrective learning, detailed below.\n\nInitialization. Self-corrective learning begins with a generator p0(y0|x), a corrector pθ(y′|y, x) , a set of training prompts X, and a value function v : Y → R. Optionally, we can use additional feedback f : Y → F and learn pθ(y′|y, x, f (y)), where F is arbitrary.\n\nThe algorithm initializes a datapool of (input, output, value, feedback) examples by using the generator to generate multiple outputs for each input. Formally,\n\nDx = {(x, y, v(y), f (y)) | for all y ∈ y1:N ∼ q(p0(·|x))}, D =\n\n(cid:91)\n\nx∈X\n\nDx,\n\n(2)\n\nwhere y1:N denotes N outputs generated with decoding algorithm q (e.g. temperature sampling). When available, (x, y, v(y), f (y)) examples from another source (e.g. a dataset) can also be added.\n\nPairing. Next, self-corrective learning forms value-improving pairs: examples of mapping a hypothesis to a higher-valued correction. We use the datapool D to form a set of (input, hypothesis, correction) pairs. A pair is formed when an output has a higher value than another ∗:\n\nPx = {(x, y, y′) | v(y) < v(y′) for all y, y′ ∈ Dx × Dx}, P =\n\n(cid:91)\n\nx∈X\n\nPx,\n\n(3)\n\nLearning. Next, self-corrective learning selects (input, hypothesis, correction) pairs to update the corrector with. We sample an input, x ∼ U(X), then sample a (x, y, y′) pair proportional to its\n\n∗We also store the value and feedback for y and y′ along with (x, y, y′), which we omit to reduce clutter.\n\n3\n\nPublished as a conference paper at ICLR 2023\n\nimprovement in value as well as the proximity between the hypothesis y and the correction y′:,\n\nP[(x, y, y′)|x] ∝ exp (cid:0) α · (v(y′) − v(y)) (cid:125)\n\n+ β · s(y, y′) (cid:125)\n\n(cid:124)\n\n(cid:123)(cid:122) improvement where s(y, y′) is a similarity function and Z(y) normalizes over the available corrections for y in Px. Increasing the hyperparameter α ∈ R≥0 puts more weight on targets that add more value, while increasing β ∈ R≥0 retains more similar targets. We update the corrector using the cross-entropy loss L(θ) = − log pθ(y′|y, x, f (y)) on batches sampled in this way.\n\n(cid:123)(cid:122) proximity\n\n(cid:124)\n\n(cid:1)/Z(y),\n\n(4)\n\nExploration. During exploration, self-corrective learning adds new generations to the datapool by generating from the current corrector:\n\nD′\n\nx = {(x, y′, v(y′), f (y′)) | for all y′ ∈ y′1:N ∼ q(pθ(·|y, x, f (y))}, D′ =\n\n(cid:91)\n\nD′\n\nx\n\nx∈X\n\n(5)\n\nand updating the datapool D ← D ∪D′. The hypotheses y to correct can come from any source, e.g. newly sampled from the base generator, or from the datapool; we use the latter in our experiments.\n\nInference. We use the trained corrector along with a generator to generate a trajectory y0, y1, . . . , yT , and consider yT the final output. Since marginalizing over the intermediate generations in Eq. 1 is intractable, we approximate each summation with a single sequence generated with a decoding algorithm q(·). That is, we decode from the generator, then repeatedly from the corrector:\n\n• Generation: y0 ∼ q(p0(y0|x)); • Correction: yt+1 ∼ q(pθ(yt+1|yt, x, f (yt))),\n\nt = 0, 1, . . . , T − 1.\n\nThe stopping time T is either fixed, or when a target value is obtained (if v(y) is available).\n\n3 EXPERIMENTS\n\nWe evaluate SELF-CORRECTION on a diversity of tasks: mathematical program synthesis, in which generations are strictly correct or incorrect, and generators typically have low performance; lexically-constrained generation, which allows for partial credit, and generators usually give partially-correct solutions (e.g. matching 3 out of 5 constraints); and toxicity control, where ‘correctness’ is more loosely defined, and the output space is much more open-ended. Our experiments are organized to study three settings:\n\n1. Using self-correctors to improve upon generators (§3.1,3.2,3.3). 2. Correcting generators that are much larger than the corrector (§3.4). 3. Leveraging explicit feedback during training and inference (§3.5).\n\nNext, we describe the self-correction setup and baselines for each task, along with their results. ∗\n\n3.1 MATHEMATICAL PROGRAM SYNTHESIS\n\nFirst, we consider mathematical program synthesis (Austin et al., 2021; Mishra et al., 2022). Given a natural language problem specification x, the task is to generate a program y that upon execution returns the correct answer to x. The task is challenging as it draws on language understanding, multiple-step mathematical problem solving (e.g. identifying a solution strategy, decomposing a problem), and leveraging symbolic tools (e.g. built-in operations, variables). Furthermore, the task demands a high level of precision, e.g. a single misplaced operation makes the program incorrect.\n\nExperimental setup. As the corrector we use GPT-Neo 1.3B (Black et al., 2021), an open-source autoregressive language model. GPT-Neo is pre-trained on language and code (Gao et al., 2021), and hence is widely used for code-related generation (e.g. Chen et al. (2021); Ni et al. (2022); Mishra et al. (2022)). We consider two settings for the initial generator: (1) a separate fine-tuned instance of GPT-Neo 1.3B, and (2) few-shot prompted GPT-3 (Brown et al., 2020). For GPT-3, we evaluate the davinci and text-davinci-002 engines, representative of large (≈ 175B∗) generators that are state-of-the-art in related tasks (Wei et al., 2022). See the Appendix for additional details.\n\n∗Code will be available at www.github.com/wellecks/self_correction. ∗Estimated size of davinci (https://blog.eleuther.ai/gpt3-model-sizes). Further details not available.\n\n4\n\nPublished as a conference paper at ICLR 2023\n\nDataset\n\nModel\n\nCorrect\n\nDataset Model\n\nParams Correct\n\nMultiarith GPT-NEO 1.3B\n\nMultitask\n\n+SELF-CORRECT +SELF-CORRECT∗\n\nGPT-NEO 1.3B +SELF-CORRECT +SELF-CORRECT∗\n\n60.00 98.33 99.17\n\n49.02 73.53 78.24\n\nGSM OpenAI 3B [6] OpenAI 6B [6] GPT-NEO [34] NEO FCP+PCP [34]\n\nGPT-NEO +SELF-CORRECT +SELF-CORRECT∗\n\n3B 6B 2.7B 2.7B\n\n1.3B 1.3B 1.3B\n\n15.50 20.00 18.80 19.50\n\n8.57 21.26 24.22\n\nTable 1: Evaluation results of mathematical program synthesis experiments. GPT-NEO (1.3B) is the initial generator for SELF-CORRECT. SELF-CORRECT∗ means only applying the corrector to incorrect outputs. Italicized: original non-program version of GSM.\n\nProblem: It takes Jennifer 20 minutes to groom each of her 2 long hair dachschunds. If she grooms her dogs every day, how many hours does she spend grooming her dogs in 30 days?\n\nProblem: Mrs. Wilsborough saved $500 to buy concert tickets for her family. She bought 2 VIP tickets at $100 each and 3 regular tickets at $50 each. How much of her savings does Mrs. Wilsborough have after she buys the tickets?\n\nGenerator:\n\nCorrector:\n\nGenerator:\n\nCorrector:\n\na=20*2 b=a*30 answer=b print(answer)\n\na=20*2 b=a*30 c=b/60 #fix answer=c print(answer)\n\na=2*100 b=3*50 c=a+b answer=c print(answer)\n\na=2*100 b=3*50 c=500-a-b #fix answer=c print(answer)\n\nFigure 3: Grade-school-math (GSM) self-corrections. On the left, the corrector fixes the units (from minutes to hours) in the generator’s solution. On the right, the corrector revises the logic so that the program computes the total savings instead of the spent on tickets. We add #fix here to indicate the change. See Figure 7 and Figure 8 for additional examples.\n\nSelf-correction setup. As the value function we use correctness, which is 1 when the program y executes and outputs the ground-truth answer and 0 otherwise. Our main experiments do not use explicit feedback, i.e. f (y) = ∅. At inference time, we study two settings for the corrector: (1) applying k corrections and selecting the final generation, (2) an oracle setting that only corrects a draft if the draft is incorrect. We use greedy decoding for the generator and corrector, and k = 1.\n\nDatasets. We evaluate on problems from 5 problem solving datasets: MultiArith (Roy et al., 2015), AddSub (Hosseini et al., 2014), SingleOp (Roy et al., 2015), SVAMP (Patel et al., 2021), and GSM8k (Cobbe et al., 2021). As in prior work (Austin et al., 2021; Ni et al., 2022; Mishra et al., 2022), we frame these as program synthesis by converting their solutions to Python programs. We separate our experiments into three increasingly difficult settings:\n\n1. MultiArith, using problems from the MultiArith arithmetic word problem dataset. 2. Multitask, using problems from 4 arithmetic datasets (MultiArith, AddSub, SingleOp, SVAMP). 3. GSM, using problems from the challenging GSM8k dataset.\n\nFor the MultiArith and Multitask settings, we make train/valid/test splits using 60/20/20% of the respective datasets. Similar to Ni et al. (2022), for the GSM setting we use the official GSM8k test split, and create a validation split using 20% of the training set. Note that the problems and answers in all datasets are the same as those from the original non-program datasets.\n\nBaselines. We compare SELF-CORRECT with its fine-tuned baseline generator (GPT-Neo 1.3B) in all three settings. For the GSM setting, we compare with existing work that uses models within the same magnitude of scale, including NEO FCP+PCP (Ni et al., 2022), which tunes GPT-NEO 2.7B with additional self-sampled programs, and their fine-tuned GPT-NEO 2.7B baseline. We also report 3B and 6B fine-tuned GPT3-like language models from Cobbe et al. (2021), which were trained on the non-program version of GSM8k. We evaluate larger models later in (§3.4).\n\n5\n\nPublished as a conference paper at ICLR 2023\n\nMethod\n\nRuntime CIDER Constraints\n\nMethod\n\nFluency Constraints\n\nNeuroLogic [28] NeuroLogic-A* [30]\n\n2.04s 19.24s\n\nGPT-2 SELF-CORRECT +NeuroLogic\n\n0.20s 0.80s 2.24s\n\n14.70 15.20\n\n14.97 15.30 15.28\n\n97.70 97.80\n\n91.38 94.58 97.80\n\nPrefix-Tuning [21] NeuroLogic [28] NeuroLogic-A* [30]\n\nGPT-2 SELF-CORRECT\n\n2.96 2.80 2.85\n\n2.94 2.98\n\n91.16 96.91 96.97\n\n91.50 98.77\n\nTable 2: Lexically-constrained generation. By training a corrector to optimize constraint satisfaction, SELF-CORRECT improves constraints while maintaining fluency, without modifying the underlying generator. Due to space, we show CIDER for COMMONGEN and human judgement for E2E as measures of fluency. Other metrics show similar trends and can be found in the Appendix.\n\nResults. As seen in Table 1, the self-corrector improves upon the generator in all three settings, using either inference strategy: always correcting (SELF-CORRECT), or only correcting incorrect solutions (SELF-CORRECT∗). The self-corrector’s performance on Multiarith is very high after correction (9899%), a 38 point improvement over the generator, with a similar gain in the Multitask arithmetic setting. On the challenging GSM dataset, the self-corrector achieves 21%, and 24% with only correcting incorrect solutions, up from 8.57% for the generator. Notably, this is higher than the larger 2.7B GPT-Neo (also larger than generator+corrector), or larger models tuned on the language version of GSM. The results show that self-corrective learning can improve task performance via training a corrector. Qualitatively, the self-corrector can correct values in a correctly structured solution, fix the order of operations within a multistep solution, adjust unit conversions, and make larger multipart revisions (see Figures 3,7,8). Notably, these are learned automatically.\n\n3.2 LEXICALLY CONSTRAINED GENERATION\n\nNext, we consider lexically constrained generation. Given a set of constraint words x, the task is to generate a sentence y that includes all the given constraints. Faithful constraint satisfaction is crucial for many downstream tasks, e.g., those that require converting information to text (McKeown, 1985).\n\nDatasets and Metrics. We experiment on COMMONGEN (Lin et al., 2020) and E2E (Novikova et al., 2017). COMMONGEN is a benchmark for generative commonsense reasoning where the task is to generate a coherent sentence given a set of words (e.g., dog, catch). E2E involves converting structured inputs into natural language. For both tasks, we report standard metrics including human/automatic measures of fluency (BLEU, CIDER, etc.) as well as constraint coverage. We collect human measures of fluency on Amazon Mechanical Turk; see the Appendix for details.\n\nSetup. We parameterize the base generator with GPT-2 Radford et al. (2019) (large-size for COMMONGEN and medium-size for E2E). We fine-tuned the generator for each task. As the value function for self-corrective learning we use coverage, i.e. the percentage of constraints that are present in the output. For inference, we use beam search with the generator, then do up to 3 corrections using beam search, stopping early if all constraints are met. See the Appendix for additional details.\n\nResults. Table 2 shows the evaluation results. The self-corrector substantially improves constraint coverage over its GPT-2 generator for both tasks, while maintaining or improving its language quality. On the COMMONGEN benchmark, the self-corrector paired with the NeuroLogic constrained decoding algorithm (Lu et al., 2021) achieves the best results, outperforming the more sophisticated NeuroLogic-A* decoding algorithm, while being an order of magnitude faster. Notably, on E2E, self-correction outperforms Neurologic-A* decoding, despite only using standard beam search. This suggests that a corrector can be viewed as an alternative to using a more sophisticated decoding procedure (A*) for improving performance without modifying the underlying model. See Figure 9.\n\n3.3 TOXICITY REDUCTION\n\nNext, we consider the task of toxicity reduction (Gehman et al., 2020; Liu et al., 2021). Given a prompt x, the task is to generate a fluent continuation y while avoiding offensive content. This task is important for ensuring safe language model deployment, yet challenging: due to misaligned pretraining objectives (i.e. modeling internet text vs. non-toxic text), language models are suscepti-\n\n6\n\nPublished as a conference paper at ICLR 2023\n\nToxicity\n\nFluency\n\nDiversity\n\nAvg. Max. Prob. Perplexity dist-2 dist-3\n\nGPT-2\n\nPPLM [7] GeDi [17] DExpert [27] DAPT [15] PPO [29] Quark [29]\n\nSELF-CORRECT\n\n0.527\n\n0.520 0.363 0.314 0.428 0.218 0.196\n\n0.171\n\n0.520\n\n0.518 0.217 0.128 0.360 0.044 0.035\n\n0.026\n\n11.31\n\n32.58 43.44 25.21 31.22 14.27 12.47\n\n11.81\n\n0.85\n\n0.86 0.84 0.84 0.84 0.79 0.80\n\n0.80\n\n0.85\n\n0.86 0.83 0.84 0.84 0.82 0.84\n\n0.83\n\nTable 3: Toxicity reduction. GPT-2 is the base generator.\n\nFigure 4: Applying multiple corrections reduces toxicity.\n\nble to generating toxic completions, even when prompted with seemingly innocuous text (Gehman et al., 2020). Along with its practical importance, the task tests whether (self-)correctors can be an effective mechanism for controlling the outputs of language models in an open-ended setting.\n\nDatasets and Metrics. We use the REALTOXICITYPROMPTS benchmark (Gehman et al., 2020) which contains 100k prompts designed to elicit toxic generations. Following the experimental setup of Liu et al. (2021), during training we use 85K prompts from the training set, and for evaluation we use the same 10K non-toxic prompts from test set as Liu et al. (2021). We use Perspective API to measure maximum toxicity, defined as the average maximum toxicity over 25 sampled generations, and the (empirical) toxicity probability of at least 1 out of 25 generations being toxic.\n\nBaselines. We compare SELF-CORRECT with its generator (GPT-2) and previously reported baselines from Lu et al. (2022a), including PPLM (Dathathri et al., 2020), GeDi (Krause et al., 2021), DExpert (Liu et al., 2020), DAPT (Gururangan et al., 2020), PPO (Lu et al., 2022a), and Quark (Lu et al., 2022a). The latter two – Proximal Policy Optimization (PPO) and Quantized Reward Konditioning (Quark) – represent strong, state-of-the art approaches based on reinforcement learning.\n\nSetup. We use the off-the-shelf GPT-2 Large as the generator, and finetune another GPT-2 Large as the corrector. During inference, we use nucleus sampling with p = 0.9 to generate 25 samples for all baselines. As the value function, we use the Perspective API score, v(y) ∈ [0, 1], which measures the toxicity of the completed sequence. We do up to three corrections with the corrector model.\n\nResults. Table 3 shows that SELF-CORRECT reduces the rate of toxic generations substantially, while also maintaining fluency and diversity. SELF-CORRECT outperforms all baselines. This includes inference-time algorithms (PPLM, GeDi, DExpert), which do not modify the generator but degrade fluency and yield higher toxicity compared to SELF-CORRECT, as well as reinforcement learning methods (PPO, Quark) that adjust the generator using toxicity as a (negative) reward. The strong baselines use equal or more parameters: PPO and Quark use 3 and 2 model copies. The results show that SELF-CORRECT is effective for detoxification, without modifying the generator.\n\n3.4 CHANGING MODULES – CORRECTING GPT-3\n\nNext, we show that a self-corrector can improve the outputs of a generator that is much larger than the corrector. We consider two cases: (1) training with a small generator, then swapping in the larger generator at test time; (2) training with the larger generator, i.e. using the large generator to initialize the datapool for self-corrective learning, then using the large generator at test time.\n\nToxicity. We evaluate case (1) for reducing the toxicity of a large generator (GPT-2 XL, GPT-3). We generate an initial sequence using the large generator, then refine it with our corrector trained in the previous experiments (§3.3). Table 4 shows that the resulting self-corrector (large generator + corrector) has substantially reduced toxicity compared to the large generator. This shows the promise of using (self-)correctors for controlling the outputs of large language models.\n\nMath program synthesis. Table 4 shows results for math. Analogous to toxicity, the corrector is able to correct larger generators swapped in at test-time. For instance, the GPT-3 Instruct generator has quite high performance (84.90 Multitask, 36.80 GSM), which improves to 90.90 and 45.00,\n\n7\n\nPublished as a conference paper at ICLR 2023\n\nTask\n\nDataset\n\nGenerator (train) Generator (test) Generator\n\nSelf-corrector\n\nMath Synthesis ↑\n\nGSM\n\nNeo 1.3B Neo 1.3B GPT-3 Instruct\n\nDetoxification ↓\n\nGPT2-L RTPrompts GPT2-L GPT2-L\n\nGPT-3 GPT-3 Instruct GPT-3 Instruct\n\nGPT2-XL GPT-3 GPT-3 Instruct\n\n6.96 36.80 36.80\n\n0.383 0.182 0.275\n\n24.30 45.00 45.92\n\n0.027 0.025 0.023\n\nTable 4: Modularity (program synthesis and detoxification). Self-correctors can correct very large generators, either by swapping in the generator at test-time, or training with the generator. For math synthesis, the corrector is GPT-Neo 1.3B, and here we only correct incorrect outputs. For detoxification, the correction is GPT2-L, and we correct all the outputs.\n\nToxicity ↓\n\nConstrained Gen. ↑\n\nMath ↑\n\nAvg. Max.\n\nProb.\n\nFluency\n\nFluency Constraints Correct Correct∗\n\nGenerator SELF-CORRECT + FEEDBACK\n\n0.527 0.171 0.156\n\n0.520 0.026 0.020\n\n11.31 11.81 11.86\n\n14.97 15.30 15.24\n\n91.38 94.58 95.88\n\n49.02 74.31 81.76\n\n49.02 79.80 82.35\n\nTable 5: Explicit natural language feedback. Correct∗ means only correcting incorrect outputs.\n\nrespectively, by adding in a corrector. The self-corrector (large generator + corrector) improves further by training with the GPT-3 Instruct generator, to 92.75 and 45.92, respectively.\n\n3.5 LEVERAGING EXPLICIT FEEDBACK\n\nNext, we demonstrate SELF-CORRECT’s capacity to incorporate explicit natural language feedback. This amounts to defining a feedback function f , then using the same self-corrective learning and inference algorithms (§2.1) as in our preceding experiments (in those experiments, f returned ∅). We show that correctors learn to use the feedback, as evidenced by higher performance.\n\nToxicity. We use additional fine-grained information from the toxicity API as natural language feedback. Specifically, besides the overall toxicity score, Perspective API also provides scores for fine-grained attributes of toxicity (e.g. identity attack, profanity, flirtation, etc.). At training time, we compare the attribute scores from a hypothesis and its selected correction, and use the attribute with the largest decrease as natural language feedback (e.g. \"decrease toxicity in profanity\"). At inference time, we call the API on the current hypothesis and use the attribute with the highest score.\n\nLexical constraints. In training time, we generate natural language feedback for every example pair (x, y, y′) by elaborating the extra lexical constraints satisfied by y′ but not y. e.g. “adding constraint word: read”. At inference time, we elaborate all missing constraints in the current hypothesis.\n\nMath program synthesis. Math program synthesis contains a variety of problem types and errors, without an automated means for identifying the errors (e.g. an API). We explore obtaining natural language feedback about the current program by prompting a large language model. We prompt the model with a problem, hypothesis program, a gold solution, and few-shot demonstrations that show feedback on one part of the program; e.g. In the initial guess, 3 should be subtracted. When the program is correct, the feedback is Correct. At inference time, we also use feedback from the language model. We allow the feedback model access to a gold solution, which we expect makes the feedback higher quality, with the risk of solution leakage at inference-time. Our results in this task are thus used only to study the feasibility of explicit feedback for math program synthesis.\n\nSetup. For toxicity, lexical constraints, and math we use REALTOXICITYPROMPTS, COMMONGEN, and the MULTITASK arithmetic setting, respectively. We follow the setup of each task’s previous experiments (§3.3,§3.2,§3.1), except for math we use 5 correction iterations (previously 1). For math, we use GPT-3 (text-davinci-002) with 6 demonstrations as the feedback model.\n\nResults. Table 5 shows that explicit natural language feedback improves performance in all three tasks. For toxicity, this means that providing fine-grained attributes (e.g. identity attack, profanity,\n\n8\n\nPublished as a conference paper at ICLR 2023\n\nAblation\n\nMath COMMONGEN\n\nSELF-CORRECT ✗ proportional sampling ✗ value pairing\n\n78.24 77.25 62.35\n\n94.55 93.49 91.76\n\nTable 6: Effect of pairing and proportional sampling.\n\nExploration Multiarith Multitask GSM8k\n\n✗ ✓\n\n89.20 99.17\n\n73.49 78.24\n\n17.60 23.96\n\nTable 7: Effect of exploration on program synthesis.\n\nFigure 5: Math: multiple corrections.\n\netc.) during learning and inference improves upon using only the scalar toxicity score. Intuitively, feedback may help the model to focus on a useful correction; e.g., see Figure 6.\n\n3.6 ADDITIONAL ABLATIONS AND ANALYSIS\n\nEffect of multiple corrections. Previously, Figure 4 showed that multiple corrections led to better toxicity reduction. On math (Multitask setting), Figure 5 shows that performance improves with more than one correction, and that multiple corrections are more beneficial with feedback. Intuitively, in this math task, after 2-3 corrections the model needs additional guidance.\n\nEffect of pairing and proportional sampling. Self-corrective learning (i) samples pairs for learning proportional to Equation 4, (ii) only pairs sequences that improve value. We ablate these features by training on Multitask using a data pool that samples a pair for learning uniformly (rather than Equation 4), and a data pool without value pairing. Table 6 shows that both improve performance.\n\nEffect of exploration. To ablate the effect of exploration, we train a baseline only on correction pairs induced from the base generator. Table 7 shows results on the three math datasets, indicating that exploration improves performance.\n\n4 RELATED WORK\n\nSelf-Correction relates to work modeling text edits including supervised Wikipedia edits (Reid & Neubig, 2022; Faltings et al., 2021; Schick et al., 2022), unsupervised perturbations (Miao et al., 2019; Liu et al., 2020), training on human-written critiques (Saunders et al., 2022), or refining continuous variables (Lee et al., 2020; Li et al., 2022; Qin et al., 2022). In contrast, Self-Correction learns a text corrector online to improve a quality measure without supervised edits or critiques. Recently, Scheurer et al. (2022) use natural language feedback to improve generations. Denoising sequences is a common pretraining objective (Devlin et al., 2019; Lewis et al., 2020; Raffel et al., 2020), while self-correction ‘denoises’ generations to improve a scalar quality measure. Reinforcement learning (RL) is often used to improve scalar measures in a generator (Ziegler et al., 2019; Stiennon et al., 2020; Lu et al., 2022a), yet is infeasible for many models (e.g. those accessed by API), and uses only scalar feedback. Moreover, RL-tuned generators can be used within Self-Correction. Self-Correction decomposes generation into multiple steps, similar to methods that generate rationales (Wei et al., 2022; Dohan et al., 2022), but Self-Correction produces intermediate steps of the same form as the output, allowing iterative application. Self-Correction relates to work on program synthesis (Fu et al., 2019; Balog et al., 2020; Gupta et al., 2020; Le et al., 2022) and repair (Gupta et al., 2020; Yasunaga & Liang, 2020). Yasunaga & Liang (2021) is closest in methodology, but Self-Correction uses a domain-agnostic formulation; see the Appendix for discussion.\n\n5 CONCLUSION\n\nWe introduced self-correctors, a class of models that decompose generation into initial generation and correction steps. We study self-correctors with a fixed base generator along with a corrector trained to improve outputs according to a scalar measure of quality. We presented a simple, general procedure for training the corrector, and find that self-correction is applicable and effective for improving performance, and controlling the outputs of both small and large generators. Moreover, we found that self-correction along with our learning framework provides a promising mechanism for using natural language feedback to improve generation, opening many avenues for future work.\n\n9\n\nPublished as a conference paper at ICLR 2023\n\nREFERENCES\n\nJacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie J. Cai, Michael Terry, Quoc V. Le, and Charles Sutton. Program synthesis with large language models. ArXiv, abs/2108.07732, 2021.\n\nMatej Balog, Rishabh Singh, Petros Maniatis, and Charles Sutton. Neural program synthesis with a\n\ndifferentiable program fixer, 2020. URL https://arxiv.org/abs/2006.10924.\n\nSid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, March 2021. URL https://doi.org/ 10.5281/zenodo.5297715. If you use this software, please cite it using these metadata.\n\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, T. J. Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are few-shot learners. ArXiv, abs/2005.14165, 2020.\n\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large language models trained on code. 2021.\n\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems, 2021. URL https://arxiv. org/abs/2110.14168.\n\nSumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, and Rosanne Liu. Plug and play language models: A simple approach to controlled text generation. ArXiv, abs/1912.02164, 2020.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https: //aclanthology.org/N19-1423.\n\nDavid Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A. Saurous, Jascha Narain Sohl-Dickstein, Kevin Murphy, and Charles Sutton. Language model cascades. ArXiv, abs/2207.10342, 2022.\n\nFelix Faltings, Michel Galley, Gerold Hintz, Chris Brockett, Chris Quirk, Jianfeng Gao, and Bill Dolan. Text editing by command. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 5259–5274, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/ 2021.naacl-main.414. URL https://aclanthology.org/2021.naacl-main.414.\n\nCheng Fu, Huili Chen, Haolan Liu, Xinyun Chen, Yuandong Tian, Farinaz Koushanfar, and Jishen In Advances in Neural Information\n\nZhao. Coda: An end-to-end neural program decompiler. Processing Systems, 2019.\n\n10\n\nPublished as a conference paper at ICLR 2023\n\nLeo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The pile: An 800gb dataset of diverse text for language modeling, 2021. URL https://arxiv.org/ abs/2101.00027.\n\nSamuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. RealToxicityPrompts: Evaluating neural toxic degeneration in language models. In Findings of the Association for Computational Linguistics: EMNLP 2020, pp. 3356–3369, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.301. URL https://aclanthology.org/2020.findings-emnlp.301.\n\nKavi Gupta, Peter Ebert Christensen, Xinyun Chen, and Dawn Song. Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis. In H Larochelle, M Ranzato, R Hadsell, M F Balcan, and H Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 17685–17695. Curran Associates, Inc., 2020. URL https://proceedings.neurips. cc/paper/2020/file/cd0f74b5955dc87fd0605745c4b49ee8-Paper.pdf.\n\nSuchin Gururangan, Ana Marasovi ́c, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A. Smith. Don’t stop pretraining: Adapt language models to domains and tasks. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 8342–8360, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/ 2020.acl-main.740. URL https://aclanthology.org/2020.acl-main.740.\n\nMohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, and Nate Kushman. Learning to solve arithmetic word problems with verb categorization. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 523–533, Doha, Qatar, October 2014. Association for Computational Linguistics. doi: 10.3115/v1/D14-1058. URL https://aclanthology.org/D14-1058.\n\nBen Krause, Akhilesh Deepak Gotmare, Bryan McCann, Nitish Shirish Keskar, Shafiq Joty, Richard Socher, and Nazneen Fatema Rajani. GeDi: Generative discriminator guided sequence generation. In Findings of the Association for Computational Linguistics: EMNLP 2021, pp. 4929–4952, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.findings-emnlp.424. URL https://aclanthology.org/2021. findings-emnlp.424.\n\nHung Le, Yue Wang, Akhilesh Deepak Gotmare, Silvio Savarese, and Steven C. H. Hoi. Coderl: Mastering code generation through pretrained models and deep reinforcement learning. arXiv preprint arXiv:2207.01780, 2022.\n\nJason Lee, Raphael Shu, and Kyunghyun Cho.\n\nIterative refinement in the continuous space for non-autoregressive neural machine translation. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1006–1015, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.73. URL https://aclanthology.org/2020.emnlp-main.73.\n\nMike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. BART: Denoising sequence-to-sequence preIn Proceedings of training for natural language generation, translation, and comprehension. the 58th Annual Meeting of the Association for Computational Linguistics, pp. 7871–7880, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.703. URL https://aclanthology.org/2020.acl-main.703.\n\nXiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 4582–4597, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/ v1/2021.acl-long.353. URL https://aclanthology.org/2021.acl-long.353.\n\nXiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori Hashimoto. Diffusion-\n\nlm improves controllable text generation. ArXiv, abs/2205.14217, 2022.\n\n11\n\nPublished as a conference paper at ICLR 2023\n\nJared Lichtarge, Christopher Alberti, Shankar Kumar, Noam M. Shazeer, Niki Parmar, and Simon\n\nTong. Corpora generation for grammatical error correction. ArXiv, abs/1904.05780, 2019.\n\nBill Yuchen Lin, Wangchunshu Zhou, Ming Shen, Pei Zhou, Chandra Bhagavatula, Yejin Choi, and Xiang Ren. CommonGen: A constrained text generation challenge for generative comIn Findings of the Association for Computational Linguistics: EMNLP monsense reasoning. 2020, pp. 1823–1840, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.165. URL https://aclanthology.org/2020. findings-emnlp.165.\n\nAlisa Liu, Maarten Sap, Ximing Lu, Swabha Swayamdipta, Chandra Bhagavatula, Noah A. Smith, and Yejin Choi. DExperts: Decoding-time controlled text generation with experts and antiexperts. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 6691–6706, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.522. URL https://aclanthology.org/2021. acl-long.522.\n\nJiacheng Liu, Alisa Liu, Ximing Lu, Sean Welleck, Peter West, Ronan Le Bras, Yejin Choi, and Hannaneh Hajishirzi. Generated knowledge prompting for commonsense reasoning. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3154–3169, 2022.\n\nXianggen Liu, Lili Mou, Fandong Meng, Hao Zhou, Jie Zhou, and Sen Song. Unsupervised paraphrasing by simulated annealing. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 302–312, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.28. URL https://aclanthology.org/2020. acl-main.28.\n\nXiming Lu, Peter West, Rowan Zellers, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. NeuroLogic decoding: (un)supervised neural text generation with predicate logic constraints. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 4288–4299, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.339. URL https://aclanthology.org/2021.naacl-main.339.\n\nXiming Lu, Sean Welleck, Liwei Jiang, Jack Hessel, Lianhui Qin, Peter West, Prithviraj Ammanabrolu, and Yejin Choi. Quark: Controllable text generation with reinforced unlearning. CoRR, abs/2205.13636, 2022a. doi: 10.48550/arXiv.2205.13636. URL https://doi.org/ 10.48550/arXiv.2205.13636.\n\nXiming Lu, Sean Welleck, Peter West, Liwei Jiang, Jungo Kasai, Daniel Khashabi, Ronan Le Bras, Lianhui Qin, Youngjae Yu, Rowan Zellers, Noah A. Smith, and Yejin Choi. NeuroLogic In Proceedings of a*esque decoding: Constrained text generation with lookahead heuristics. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 780–799, Seattle, United States, July 2022b. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.57. URL https: //aclanthology.org/2022.naacl-main.57.\n\nKathleen McKeown. Text Generation. Studies in Natural Language Processing. Cambridge Univer-\n\nsity Press, 1985. doi: 10.1017/CBO9780511620751.\n\nNing Miao, Hao Zhou, Lili Mou, Rui Yan, and Lei Li. Cgmh: Constrained sentence generation by metropolis-hastings sampling. Proceedings of the AAAI Conference on Artificial Intelligence, 33 (01):6834–6842, Jul. 2019. doi: 10.1609/aaai.v33i01.33016834. URL https://ojs.aaai. org/index.php/AAAI/article/view/4659.\n\nSwaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, and Ashwin Kalyan. Lila: A unified benchmark for mathematical reasoning. ArXiv, 2022.\n\n12\n\nPublished as a conference paper at ICLR 2023\n\nAnsong Ni, Jeevana Priya Inala, Chenglong Wang, Oleksandr Polozov, Christopher Meek, Dragomir Radev, and Jianfeng Gao. Learning from self-sampled correct and partially-correct programs, 2022. URL https://arxiv.org/abs/2205.14318.\n\nJekaterina Novikova, Ondˇrej Dušek, and Verena Rieser. The E2E dataset: New challenges for end-to-end generation. In Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pp. 201–206, Saarbrücken, Germany, August 2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-5525. URL https://aclanthology.org/W17-5525.\n\nArkil Patel, Satwik Bhattamishra, and Navin Goyal. Are NLP models really able to solve simple math word problems? In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2080– 2094, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021. naacl-main.168. URL https://aclanthology.org/2021.naacl-main.168.\n\nLianhui Qin, Sean Welleck, Daniel Khashabi, and Yejin Choi. Cold decoding: Energy-based con-\n\nstrained text generation with langevin dynamics. arXiv preprint arXiv:2202.11705, 2022.\n\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language\n\nmodels are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-totext transformer. Journal of Machine Learning Research, 21(140):1–67, 2020. URL http: //jmlr.org/papers/v21/20-074.html.\n\nMachel Reid and Graham Neubig. Learning to model editing processes, 2022. URL https:\n\n//openreview.net/forum?id=1bEaEzGwfhP.\n\nNils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bertnetworks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 11 2019. URL https://arxiv. org/abs/1908.10084.\n\nSubhro Roy, Tim Vieira, and Dan Roth. Reasoning about quantities in natural language. Transac-\n\ntions of the Association for Computational Linguistics, 3:1–13, 2015.\n\nWilliam Saunders, Catherine Yeh, Jeff Wu, Steven Bills, Long Ouyang, Jonathan Ward, and Jan Leike. Self-critiquing models for assisting human evaluators, 2022. URL https://arxiv. org/abs/2206.05802.\n\nJérémy Scheurer, Jon Ander Campos, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, and Ethan Perez. Training language models with language feedback, 2022. URL https://arxiv.org/ abs/2204.14146.\n\nTimo Schick, Jane Dwivedi-Yu, Zhengbao Jiang, Fabio Petroni, Patrick Lewis, Gautier Izacard, Qingfei You, Christoforos Nalmpantis, Edouard Grave, and Sebastian Riedel. Peer: A collaborative language model, 2022. URL https://arxiv.org/abs/2208.11663.\n\nVered Shwartz, Peter West, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Unsupervised commonsense question answering with self-talk. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4615–4629, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.373. URL https://aclanthology.org/2020.emnlp-main.373.\n\nNisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedIn H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Adback. vances in Neural Information Processing Systems, volume 33, pp. 3008–3021. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/ 1f89885d556929e98d3ef9b86448f951-Paper.pdf.\n\n13\n\nPublished as a conference paper at ICLR 2023\n\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. ArXiv, abs/2201.11903, 2022.\n\nMichihiro Yasunaga and Percy Liang. Graph-based, self-supervised program repair from diagnostic ISBN\n\nIn 37th International Conference on Machine Learning, ICML 2020, 2020.\n\nfeedback. 9781713821120.\n\nMichihiro Yasunaga and Percy Liang. Break-it-fix-it: Unsupervised learning for program repair. In\n\nInternational Conference on Machine Learning (ICML), 2021.\n\nMichihiro Yasunaga, Jure Leskovec, and Percy Liang. LM-critic: Language models for unsupervised grammatical error correction. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 7752–7763, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main. 611. URL https://aclanthology.org/2021.emnlp-main.611.\n\nDaniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. Fine-tuning language models from human preferences. arXiv preprint arXiv:1909.08593, 2019. URL https://arxiv.org/abs/1909.08593.\n\n14\n\nPublished as a conference paper at ICLR 2023\n\nAPPENDIX\n\nA RELATED WORK\n\nSelf-correction provides a flexible framework for improving the performance of off-the-shelf and fine-tuned language models on a wide range of tasks by decomposing generation into a base generator and a corrector. Our framework’s minimal assumptions on the form of the corrector, value function, and data used to train the corrector, as well as its wide applicability differ from prior work.\n\nLearning to fix code. Our work relates to two streams of research in the code domain. One stream deals with program synthesis, in which a corrector model corrects code from a base synthesizer until it meets a given specification (Fu et al., 2019; Balog et al., 2020; Gupta et al., 2020; Le et al., 2022), while another stream deals with program repair: correcting code that is provided as input (Gupta et al., 2020; Yasunaga & Liang, 2020; 2021). Recently, Le et al. (2022) developed a modular program synthesis approach that involves a correction module trained on ground-truth outputs. In contrast, self-corrective learning supports cases without ground-truth outputs, e.g. toxicity.\n\nClosest to our methodology is Yasunaga & Liang (2021). Unlike Yasunaga & Liang (2021), selfcorrection does not assume a mechanism for generating synthetic negatives, a dataset of negatives, or a separate model that generates negatives. This is important because engineering these components for each new task can be prohibitive. Second, Yasunaga & Liang (2021) assume a 0/1 value function, while self-correction supports general scalar value functions. This is important for tasks such as toxicity that do not have a strict notion of correctness. Finally, we propose new pairing and proportional sampling mechanisms found to be important (Table 6).\n\nIterative text edits. Self-correction relates to recent works on editing text, including modeling Wikipedia edits (Reid & Neubig, 2022; Faltings et al., 2021; Schick et al., 2022), which relies on supervised edits, unsupervised methods (Miao et al., 2019; Liu et al., 2020) that perturb sequences with simple operations (e.g. insertion, deletion), editing with models trained on human-written critiques (Saunders et al., 2022), or iteratively updating continuous variables (Lee et al., 2020; Li et al., 2022; Qin et al., 2022). In contrast to these, self-correction learns an expressive text-to-text corrector that is trained online to improve a quality measure, without requiring a supervised dataset of edits or critiques. Recently, Scheurer et al. (2022) incorporate human feedback by fine-tuning on refinements that are similar to the feedback, rather than through an iterative corrector module. Finally, correcting text is inherent to the task of grammatical error correction (e.g. Lichtarge et al. (2019); Yasunaga et al. (2021); our work differs in that we correct a module within a generation system, and provide a framework for addressing a variety of tasks.\n\nDenoising and reinforcement learning. Separately, denoising ground-truth sequences is a common pretraining objective (Devlin et al., 2019; Lewis et al., 2020; Raffel et al., 2020), while selfcorrection ‘denoises’ generations to improve a scalar quality measure. Scalar measures are often improved with reinforcement learning (RL) on a base generator (Ziegler et al., 2019; Stiennon et al., 2020; Lu et al., 2022a), which is infeasible for improving many language models (e.g. those accessed through an API), and uses only scalar feedback. Moreover, self-correction learns a delta between a generation and solution, and is complementary to RL-tuned generators, which can be used within a self-corrector. Finally, RL can be used as an alternative learning algorithm for training a corrector, which is an interesting direction for future work.\n\nModular generation. Self-correction decomposes generation into multiple steps, and is thus part of the general class of methods that decompose generation into a ‘cascade’ of modules (Dohan et al., 2022). Examples include using separate knowledge generation modules (Shwartz et al., 2020; Liu et al., 2022), or generating rationales before a response (Wei et al., 2022). Self-correction also produces a chain of intermediate steps, but each step is of the same form as the output, allowing for re-using previous generations.\n\n15\n\nPublished as a conference paper at ICLR 2023\n\nB ADDITIONAL EXPERIMENTAL DETAILS\n\nB.1 CROSS-EXPERIMENT DETAILS\n\nIn all of our experiments we use an off-the-shelf embedding similarity function from SentenceTransformers (Reimers & Gurevych, 2019): sentence-transformers/all-MiniLM-L6-v2.\n\nB.2 MATHEMATICAL PROGRAM SYNTHESIS\n\nWe fine-tune a separate instance of GPT-Neo 1.3B as an initial generator, using the Huggingface library with default hyperparameters, except for evaluation steps, which we set to a small number to ensure a strong checkpoint is selected for each dataset. We use the finetuned initial generator as initialization for the corrector, and tune the corrector on sequences [SC]x[CURR]yi[START]yj[END], where x is a problem, yi and yj form a residual pair, and [·] are special tokens. The loss is on tokens after [START].\n\nFeedback. We write 6 demonstrations using training problems and generations from our GPTNeo base generator, and use GPT-3 (text-davinci-002) as a feedback model. We use the same training procedure and hyperparameters, except that the sequences now include feedback, [SC]x[CURR]yi[FEEDBACK]F(x,yi)[START]yj[END], where x is a problem, yi and yj form a residual pair, and F (x, yi) is feedback. We include loss on tokens after [FEEDBACK].\n\nB.3 LEXICALLY-CONSTRAINED GENERATION\n\nHyper-parameters. Table 8 and Table 9 show hyperparameters for CommonGen and E2E.\n\nHuman Evaluation. We evaluate fluency of generations in E2E task using human annotators on Amazon Mechanical Turk (AMT). We randomly sampled 100 instances, along with generations of different baselines and self-corrections. For each instance, we ask 3 annotators to evaluate the fluency of generations on a 3-point Likert scale. We aggregate annotations from 3 annotators using majority vote. We restricted the pool of annotators to those who are located in US or CA, and had 98% approval rate for at least 5,000 previous annotations.\n\nHyperparameter\n\nAssignment\n\nHyperparameter\n\nAssignment\n\nPredictor steps batch size optimizer learning rate decoding alg.\n\nGPT-2Large 6000 128 Adam 1.e−5 beam search (k=5)\n\nPredictor steps batch size optimizer learning rate decoding alg.\n\nGPT-2M edium 10000 100 Adam 1.e−5 beam search (k=5)\n\nTable 8: Hyperparameters for COMMONGEN.\n\nTable 9: Hyperparameters for E2E.\n\nC ADDITIONAL RESULTS\n\nToxicity\n\nFluency\n\nDiversity\n\nAvg. Max.\n\nProb.\n\nPerplexity\n\ndist-2\n\ndist-3\n\nGPT2-L SELF-CORRECT SELF-CORRECT + FEEDBACK\n\n0.527 0.171 0.156\n\n0.520 0.026 0.020\n\n11.31 11.81 11.86\n\n0.85 0.80 0.80\n\n0.85 0.83 0.83\n\nTable 10: Evaluation results of toxicity reduction experiments with natural language feedback.\n\nD QUALITATIVE EXAMPLES\n\n16\n\nPublished as a conference paper at ICLR 2023\n\nTask\n\nDataset\n\nGenerator (train) Generator (test) Generator\n\nSelf-corrector\n\nMath Synthesis ↑\n\nMultitask\n\nGSM\n\nNeo 1.3B Neo 1.3B GPT-3 Instruct\n\nNeo 1.3B Neo 1.3B GPT-3 Instruct\n\nDetoxification ↓\n\nGPT2-L RTPrompts GPT2-L GPT2-L\n\nGPT-3 GPT-3 Instruct GPT-3 Instruct\n\nGPT-3 GPT-3 Instruct GPT-3 Instruct\n\nGPT2-XL GPT-3 GPT-3 Instruct\n\n46.70 84.90 84.90\n\n6.96 36.80 36.80\n\n0.383 0.182 0.275\n\n80.00 90.90 92.75\n\n24.30 45.00 45.92\n\n0.027 0.025 0.023\n\nTable 11: Modularity (program synthesis and detoxification). Self-correctors can correct very large generators, either by swapping in the generator at test-time, or training with the generator. For math synthesis, the corrector is GPT-Neo 1.3B, and here we only correct incorrect outputs. For detoxification, the correction is GPT2-L, and we correct all the outputs.\n\nBleu-4 CIDER Coverage\n\nRuntime\n\nNeuroLogic [28] NeuroLogic-A*esque [30]\n\nGPT-2 SELF-CORRECT SELF-CORRECT + feedback SELF-CORRECT+NeuroLogic\n\n26.70 28.20\n\n27.90 27.98 27.82 28.17\n\n14.70 15.20\n\n14.97 15.30 15.24 15.28\n\n97.70 97.80\n\n91.38 94.58 95.88 97.80\n\n2.04s/sent 19.24s/sent\n\n0.2s/sent 0.8s/sent 0.8s/sent 2.24s/sent\n\nTable 12: Evaluation rresults of lexically-constrained generation on COMMONGEN.\n\nCoverage BLEU-4 NIST R-L METEOR CIDER\n\nPREFIX-TUNING (Li & Liang, 2021)\n\n91.16\n\n70.30\n\n8.82 72.10\n\nGPT-2 SELF-CORRECT\n\n91.50 98.77\n\n67.12 68.81\n\n8.67 70.25 8.78 68.60\n\n46.30\n\n45.58 45.11\n\n2.46\n\n2.33 2.38\n\nTable 13: Evaluation results of lexically-constrained generation on E2E.\n\nProblem: Melanie had 19 dimes in her bank. Her dad gave her 39 dimes and her mother gave her 25 dimes. How many dimes does Melanie have now?\n\nProblem: Lana’s favorite band was holding a concert where tickets were 6 dollars each. Lana bought 8 tickets for herself and her friends and 2 extra tickets in case anyone else wanted to go. How much did she spend?\n\nGenerator (GPT-Neo):\n\nanswer = 19 + 25 print(answer)\n\nFeedback (GPT-3):\n\n# In the initial guess, # 39 is not included.\n\nCorrector (GPT-Neo):\n\nanswer = 19 + 25 + 39 print(answer)\n\nGenerator (GPT-Neo):\n\nanswer=(6.0*8.0) print(answer)\n\nFeedback (GPT-3):\n\n# In the initial guess, # 2 tickets are not included.\n\nCorrector (GPT-Neo):\n\nanswer=(6.0*(8.0+2.0)) print(answer)\n\nFigure 6: Self-correction with natural language feedback.\n\n17\n\nPublished as a conference paper at ICLR 2023\n\nProblem: Ralph watches TV for 4 hours a day from Monday to Friday, and 6 hours a day on Saturday and Sunday. How many hours does Ralph spend watching TV in one week?\n\nGenerator:\n\nCorrector:\n\na=4*7 b=6*7 c=a+b answer=c print(answer)\n\na=4*5 b=6*2 c=a+b answer=c print(answer)\n\nProblem: The pirates plan to explore 4 islands. Two islands require walking 20 miles per day while the other two islands require 25 miles per day. How many miles will they have to walk if it takes 1.5 days to explore each island?\n\nGenerator:\n\nCorrector:\n\na=20*2 b=25*2 c=a+b d=c*1.5 e=d+b answer=e print(answer)\n\na=20*2 b=25*2 c=a+b d=c*1.5 answer=d print(answer)\n\nFigure 7: Grade school math (GSM) self-corrections. Left: the structure of the generator’s solution is valid, but it incorrectly uses the total number of days in a week for both a and b; the corrector fixes the program to correctly account for the 5 weekdays and 2 weekend days. Right: the generator’s solution contains an incorrect addition at the end; the corrector removes this line, resulting in a correct program.\n\nProblem: A spiral notebook costs 15, and a personal planner costs $10. How much would it cost in total to buy 4 spiral notebooks and 8 personal planners at a 20% discount?\n\nProblem: Julia has $40. She spends half of her money to buy a new game for her phone. She spends a quarter of what she has left on in-game purchases. How much money does she have left?\n\nGenerator:\n\nCorrector:\n\nGenerator:\n\nCorrector:\n\na=4*15 b=8*10 c=a+b answer=c print(answer)\n\na=4*15 b=8*10 c=a+b d=c*20/100 e=c-d answer=e print(answer)\n\na=40/2 b=40-a c=b/4 d=b-c e=d+40 answer=e print(answer)\n\na=40/2 b=a/4 c=a-b answer= c print(answer)\n\nFigure 8: Grade school math (GSM) self-corrections. Left: the generator’s program doesn’t include the discount; the corrector appends the discount to the program. Right: a more sophisticated multipart correction. The generator’s assignment of b (line 2), and addition to e (line 5) are incorrect. The corrector removes these lines and adjusts the variable names accordingly.\n\n18\n\nPublished as a conference paper at ICLR 2023\n\nConstraints: ‘table’, ‘paper’, ‘read’ Generator: A man is reading book on a table. Corrector: A man is reading a book on a table and writing on a piece of paper.\n\nConstraints: ’stand’, ’wait’, ’look’ Generator: He waits for someone to look at him. Corrector: He waits for someone to stand and look him in the eye.\n\nConstraints: ’walk’, ’park’, ’bench’, ’dog’, ’sit’ Generator: A dog sitting on a bench in a park. Corrector: A dog sitting on a bench and a man walking a dog in a park.\n\nConstraints: name : The Mill | Type : restaurant | food : English | price : high | customer rating : average | area : riverside | family friendly : yes | near : Cafe Rouge Generator: The Mill is an expensive, three star restaurant located near Cafe Rouge. Corrector: The Mill is a children friendly English restaurant in the riverside area near Cafe Rouge.\n\nIt has an average customer rating and a high price range.\n\nConstraints: name : Blue Spice | Type : restaurant | food : Chinese | area : riverside | family friendly : yes | near : Rainbow Vegetarian Cafe Generator: Blue Spice is a restaurant providing Chinese food. It is near Rainbow Vegetarian Cafe. Corrector: Blue Spice is a family friendly Chinese restaurant in the riverside area near Rainbow Vegetarian Cafe.\n\nIt is located in the riverside.\n\nFigure 9: Constrained generation self-corrections. Top: COMMONGEN, and Bottom: E2E. Words in green indicate constraints that were previously missing.\n\nPrompt: Waters then went on to call the Trump Generator: administration a \"bunch of idiots\" and \"insolent clowns [who are] running\" Corrector: Administration’s support for the Trans-Pacific Partnership on trade \"a total non-event.\"\n\nFigure 10: Toxicity control self-corrections. Words in red indicate toxic language.\n\n19",
  "translations": [
    "# Summary Of The Paper\n\nThis paper proposes a self-correction method which trains a corrector to iteratively correct imperfect generation results. The authors first train a generator on the downstream datasets (or directly prompt a large language model), and use it to construct a data pool. Then, the authors select value-improving pairs based on a task-specific value function to build the training set of the corrector. Finally, the corrector is trained based on these samples and generates samples to augment the original data pool. Experimental results show the effectiveness of self-correction in three generation tasks.\n\n# Strength And Weaknesses\n\nStrengths:\n\n1) This paper is well organized and easy to follow.\n2) The proposed method can be applied to a wide range of text generation tasks. The experimental results show the superior performance of self-correction over some competitive baselines.\n\nWeaknesses:\n\n1) The name of the method “self-correction” is confusing for me, because the authors train a separate corrector to improve the base generator. The generator / corrector cannot consistently correct itself in this paper. They should cooperate with each other to achieve better generation performance.\n\n2) From the perspective of correctors, the proposed method seems to train a text editing model (corrector) via pseudo-labeled data generated by a pre-trained model (generator). Specifically, the fixed generator is used to construct the training dataset of the corrector via generating data and selecting value-improving pairs. Then, the corrector is trained on these \"pseudo-labeled\" data and augment the original data pool iteratively. Thus, I feel that the novelty of this method is somewhat limited because using pre-trained models to automatically generate training data is common in recent works. I don’t find any specific design when training the corrector.\n\n3) The feedback has been mentioned for many times in this paper. But this part is individual compared with the whole design. I don’t find any specific module to properly incorporate the feedback signal into the corrector.\n\n4) The experimental setting may be unfair because the corrector has a relatively large amount of model parameters. Thus, the total number of parameters in self-correction (including the generator and the corrector) is significantly larger than that of other baselines.\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThe authors should further clarify the method design and the experimental settings. The overall quality of this paper is OK. But in my view, the novelty of the proposed method is somewhat limited from the perspective of correctors. The reproducibility of this paper is degraded due to the lack of codes.\n\n# Summary Of The Review\n\nThe proposed method can adapt to various text generation tasks and achieve good performance. However, as mentioned in my review, the authors should solve the concerns about the novelty, the method design, and the experimental settings to make this paper ready for publication.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\n\n# Empirical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
    "# Summary Of The Paper\nThe paper introduces SELF-CORRECTION, a novel framework for sequence generation that decouples a base generator from a corrector to enhance the quality of generated outputs. This two-module approach involves an initial hypothesis generated by a base model followed by iterative refinements from a corrector, which can be trained using scalar or natural language feedback. The authors demonstrate the effectiveness of their method across three tasks: mathematical program synthesis, lexically-constrained generation, and toxicity control, reporting significant improvements in performance metrics.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to addressing the limitations of single-pass generation methods, allowing for more nuanced and higher-quality outputs through iterative corrections. The modular design enables flexibility, as the corrector can enhance outputs from various generator models. However, a notable weakness is the reliance on explicit feedback, which may not always be feasible in real-world applications. Additionally, while the improvements in performance metrics are substantial, the paper could benefit from a deeper exploration of the computational costs associated with the proposed method.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly presents its methodology and findings. The writing is precise, and the mathematical formulations are adequately explained, making the concepts accessible. The novelty of the approach is commendable, as it proposes a new paradigm in sequence generation. Reproducibility appears strong, given that the authors provide sufficient details about the experimental setups and the models used, although further information on hyperparameter settings would enhance this aspect.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to sequence generation through the SELF-CORRECTION framework. Its modular design and significant empirical results demonstrate its potential to improve existing generation methods, although some concerns regarding feedback dependency and computational efficiency remain.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n5/5",
    "# Summary Of The Paper\nThe paper presents a novel method called SELF-CORRECTION for sequence generation, which separates the generation process into two distinct modules: a base generator and a corrector. This innovative approach allows for iterative refinement of initial outputs instead of treating them as final. The methodology includes a self-corrective learning algorithm that utilizes feedback to enhance the quality of generated sequences across three tasks: mathematical program synthesis, lexically-constrained generation, and toxicity control. The findings demonstrate significant improvements in correctness, constraint coverage, and toxicity reduction, indicating that the SELF-CORRECTION framework is both effective and adaptable.\n\n# Strengths And Weaknesses\nThe paper's strengths lie in its introduction of iterative improvement in sequence generation, providing a more natural and flexible framework for enhancing outputs. The ability to leverage explicit feedback for performance gains is another notable advantage. Additionally, the efficiency of achieving high accuracy with smaller models is commendable. However, the paper also presents some limitations, such as the dependency on the quality of feedback, which may not always be readily available. The single-pass nature of the base generator may restrict its effectiveness in handling more complex tasks, and the requirement for task-specific training could pose scalability challenges.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and clearly articulates the proposed methodology and its applications. The quality of the experimental design is high, with appropriate metrics for evaluation. The novelty of the self-correction approach is significant, as it introduces a new paradigm in sequence generation. However, the reproducibility could be impacted by the need for tailored corrector training for specific tasks, which may require additional resources.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to sequence generation through self-correction, demonstrating substantial improvements across various tasks. While the method is effective and flexible, challenges related to feedback dependency and task-specific adaptations warrant further exploration.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel sequence generation method called SELF-CORRECTION, which enhances traditional generation models by introducing a two-step process involving a base generator and a corrector model. The corrector iteratively refines the outputs produced by the base generator, addressing issues with semantic constraints and improving the quality of generated sequences. The authors demonstrate the effectiveness of this approach across three diverse tasks: mathematical program synthesis, lexically constrained generation, and toxicity control, achieving significant performance improvements even with smaller corrector models.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its innovative approach to sequence generation, which combines a base generator with a corrector, allowing for iterative refinement. The clear framework for self-correcting sequence generators is well-structured and provides a solid basis for understanding the methodology. The empirical results are compelling, showcasing substantial improvements in correctness and constraint satisfaction across various tasks. However, the paper could benefit from a more extensive comparison with existing methods and a deeper analysis of the limitations of the proposed approach. Additionally, while the framework is general, it would be useful to explore potential challenges in applying it to more complex tasks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and organized, with a clear explanation of the methodology and results. The presentation of the self-corrective learning algorithm is particularly clear, making it easy to follow the steps involved. The novelty of the approach lies in its iterative correction mechanism, which has not been extensively explored in the literature. The reproducibility of the experiments is supported by the inclusion of experimental details, hyperparameters, and evaluation metrics in the appendix, although further details on the implementation could enhance reproducibility.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in sequence generation through the introduction of a self-correcting framework, demonstrating notable empirical improvements across multiple tasks. While the contributions are strong, the paper would benefit from a more thorough comparison to existing methods and consideration of potential limitations.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper \"Generating Sequences by Learning to [Self]-Correct\" introduces a novel Self-Correction framework that separates the generation and correction processes in sequence generation tasks. By employing a base generator followed by a corrector that utilizes natural language feedback, the methodology aims to enhance the quality of generated outputs across various applications, such as mathematical program synthesis, lexically constrained generation, and toxicity control. The findings demonstrate significant improvements in performance metrics, highlighting the effectiveness of the Self-Correction mechanism in producing higher-quality sequences.\n\n# Strength And Weaknesses\nThe paper presents several strengths, including a novel approach to sequence generation that decouples generation from correction, which potentially leads to improved output quality. It shows versatility across diverse tasks and incorporates natural language feedback to enhance the corrector's learning. Additionally, the results indicate substantial performance improvements, and the framework effectively addresses common limitations of traditional language models.\n\nHowever, the paper also has notable limitations. The effectiveness of the framework appears dependent on the quality of the base generator, and the generalizability of results to contexts not covered in the experiments is not thoroughly explored. Furthermore, while the integration of natural language feedback is innovative, it introduces variability that could affect performance. The focus on quantitative metrics leaves qualitative aspects underexplored, and the trade-offs of using a smaller corrector model are not fully addressed. Additionally, potential latency issues from the multiple-pass correction process and the limitations of the evaluated toxicity benchmarks warrant further investigation.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and provides a clear description of the experimental setup, contributing to the reproducibility of results. The thorough review of related works situates the contributions effectively within the existing literature. However, the clarity of the limitations and trade-offs associated with the proposed framework could be improved. Overall, the novelty of the approach is significant, presenting a fresh perspective on sequence generation.\n\n# Summary Of The Review\nIn summary, this paper presents a promising Self-Correction framework for sequence generation that demonstrates significant performance improvements across various tasks. While it introduces innovative methodologies and addresses important issues in language model outputs, there are several limitations that could be explored further to enhance its applicability and robustness.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel methodology for sequence generation called \"Recursive Adjustment,\" designed to enhance the quality of outputs from language models through a multi-stage correction process. The approach involves a two-module system consisting of a base generator that produces initial outputs and a recursive adjuster that iteratively refines these outputs using both scalar and rich feedback mechanisms. The methodology is validated across various tasks, including mathematical reasoning, constrained lexical generation, and toxicity moderation, demonstrating improved performance without requiring extensive retraining of large models.\n\n# Strength And Weaknesses\n**Strengths:**\n- The Recursive Adjustment framework offers a robust alternative to traditional single-pass generation methods by emphasizing iterative refinement, which leads to higher quality outputs.\n- The comprehensive experimentation across diverse tasks showcases the versatility and effectiveness of the proposed method, reinforcing its applicability in different contexts.\n- The integration of feedback mechanisms into the adjustment process is a significant innovation that enhances the model's adaptability and contextual accuracy.\n\n**Weaknesses:**\n- The paper could benefit from a deeper exploration of the limitations of the Recursive Adjustment method in highly complex tasks or domains, where the benefits may not be as pronounced.\n- A more detailed discussion on the computational efficiency of the recursive adjuster compared to the base generator, particularly for real-time applications, is warranted to evaluate practical usability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly articulates the methodology, contributions, and experimental results. The quality of the writing is high, with a logical flow that facilitates understanding. The novelty of the approach is evident, particularly in the incorporation of feedback into the generation process. Reproducibility is supported by detailed descriptions of the model architecture and training protocols, although additional specifics on hyperparameters and datasets used could further enhance this aspect.\n\n# Summary Of The Review\nOverall, this paper introduces an innovative and effective framework for sequence generation that leverages iterative correction and feedback, significantly improving output quality across multiple tasks. While the methodology shows promise, further exploration of its limitations and computational efficiency in real-world applications would strengthen the findings.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled \"Generating Robust Adversarial Examples through Iterative Correction\" introduces a novel framework called SELF-CORRECTION designed to enhance the robustness of neural networks against adversarial attacks. The main contributions include the decoupling of adversarial example generation and correction into two distinct modules: a base generator that produces initial adversarial examples and a corrector that iteratively refines these examples using feedback mechanisms. The authors demonstrate the effectiveness of their approach through extensive experiments across various tasks, such as image classification and text generation, showing that SELF-CORRECTION outperforms traditional adversarial training methods, leading to improved accuracy and robustness against adversarial attacks.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to decoupling the generation and correction processes, which offers a structured and potentially more effective means of adversarial training. The experimental design is robust, with comprehensive evaluations on standard datasets, showcasing the generalizability of the proposed method. However, weaknesses include the added complexity of implementing the two-module framework, which may pose challenges in real-world applications. Additionally, the performance heavily relies on the quality of feedback provided during the training process, which can be inconsistent across different tasks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and clearly articulates its contributions, methodology, and findings. The quality of the experiments conducted is high, with thorough analyses of results. The novelty of the approach is significant, particularly in separating generation from correction, a concept that has not been extensively explored in the literature. While the methodology is described in sufficient detail for reproduction, the complexity of the framework may hinder straightforward implementation.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in adversarial training techniques through its innovative SELF-CORRECTION framework. It effectively demonstrates improved robustness of neural networks against adversarial attacks, although the complexity of the implementation and dependence on feedback quality are notable concerns.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper \"Generating Sequences by Learning to Self-Correct\" introduces a novel methodology termed SELF-CORRECTION, which comprises a two-module system consisting of a generator and a corrector that iteratively refines outputs. The authors claim that this framework can effectively handle complex semantic constraints and report near-perfect performance on several tasks, including mathematical program synthesis, lexically-constrained generation, and toxicity control. However, the reported improvements are often presented in an exaggerated manner, suggesting a transformative impact on natural language generation.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach of combining a generator with a self-corrector, which theoretically enhances the output quality of sequence generation models. Additionally, the methodology is applicable to a variety of tasks, showcasing some versatility. However, the weaknesses are significant; the paper tends to overstate the revolutionary nature of its contributions, and the experimental results often lack the robustness needed to substantiate the claims. Moreover, the framing of the corrector as a universal solution to existing issues in sequence generation is misleading, as it downplays the limitations and real-world applicability of the proposed method.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its ideas clearly, but the excessive claims detract from the overall quality. While the concept of a self-correcting model is novel, the manner in which the authors present their findings lacks sufficient empirical backing, leading to questions about reproducibility. The experimental setup is not detailed enough to allow for straightforward replication, and the claims of near-perfect results are not adequately contextualized, making it difficult to assess their validity comprehensively.\n\n# Summary Of The Review\nThe paper presents an interesting concept in the realm of sequence generation through its SELF-CORRECTION methodology. However, the claims regarding its transformative potential and the extent of performance improvements are exaggerated and not fully supported by the experimental evidence. As such, while the approach is promising, its actual impact may be more modest than suggested.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper introduces a novel framework termed SELF-CORRECTION, which consists of a base generator and a corrector that iteratively refines generated outputs, enhancing performance in various tasks. The methodology includes testing this two-module approach across three primary tasks: mathematical program synthesis, lexically-constrained generation, and toxicity control. The findings demonstrate significant performance improvements, with notable increases in accuracy and fluency, particularly in mathematical tasks and toxicity reduction, suggesting that the proposed framework effectively enhances sequence generation capabilities.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to sequence generation through a decoupled generator-corrector system, which shows empirical performance improvements across diverse tasks. The results are compelling, particularly the substantial accuracy gains in mathematical synthesis and the marked reduction in toxicity. However, the paper could benefit from a more in-depth exploration of the limitations and potential drawbacks of the self-correcting mechanism, such as computational efficiency and the impact of the corrector's size relative to the generator.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions and findings, making it accessible to readers. The methodology is sound, and the results are convincingly reported with appropriate metrics, enhancing the quality of the work. The novelty of the self-correction framework is significant, as it diverges from traditional single-pass generation methods. However, reproducibility could be improved by providing more comprehensive details on the implementation and hyperparameter settings used in the experiments.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to sequence generation through the SELF-CORRECTION framework, demonstrating impressive empirical results across various tasks. While the contributions are significant, further exploration of limitations and enhanced reproducibility would strengthen the overall impact of the work.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a self-corrective framework for improving the outputs of generative models by decoupling the generation process from the correction process. The proposed methodology involves a base generator model, which produces initial outputs, followed by a smaller corrector model that refines these outputs based on scalar feedback. The authors claim that this separation enhances output quality across various tasks by leveraging explicit feedback mechanisms. However, the effectiveness and generalizability of this approach are not thoroughly validated, raising questions about its practical implications.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to addressing the limitations of single-pass generation models and its potential to improve output quality through iterative correction. However, significant weaknesses include the lack of rigorous justification for the assumptions made about the inherent limitations of single-pass models, as well as concerns over the efficiency and scalability of maintaining two separate models. The reliance on scalar feedback for training the corrector raises doubts about the model's generalizability across diverse tasks, while the effectiveness of the feedback mechanism itself is inadequately analyzed.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper is generally well-written, the clarity of certain arguments could be improved, particularly regarding the assumptions made about the efficacy of the corrector and the quality of feedback. The novelty of the approach is notable, yet it lacks comprehensive evaluation against existing state-of-the-art methods, which challenges the reproducibility and validity of the claims made. The empirical results presented, though promising, do not sufficiently address the concerns around task-specific performance and the potential biases in feedback mechanisms.\n\n# Summary Of The Review\nOverall, the paper introduces a compelling self-corrective framework for generative models, but it is marred by a number of unaddressed assumptions and a lack of rigorous empirical validation. The potential benefits of the proposed approach are overshadowed by concerns about its efficiency, scalability, and practical applicability across various tasks.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents SELF-CORRECTION, a novel approach for enhancing sequence generation by dividing the generation process into two distinct components: a base generator and a separate corrector. This framework allows for iterative improvements of outputs based on feedback, addressing common limitations in existing language models, particularly in maintaining semantic constraints. The authors evaluate the effectiveness of SELF-CORRECTION across three tasks—mathematical program synthesis, lexically constrained generation, and toxicity control—demonstrating substantial improvements in output quality and task performance through this method.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative decoupling of the generation process, which allows for more flexible and task-specific adaptations. The results from the experiments show significant enhancements in performance compared to baseline models, indicating the practical utility of the proposed method. However, a potential weakness is the reliance on scalar value functions for training the corrector, which may limit the approach's generalizability to other types of feedback mechanisms. Furthermore, the paper could benefit from a more thorough exploration of the limitations and edge cases of the SELF-CORRECTION framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The presentation of the experiments is thorough, providing sufficient detail to understand the implementation of the proposed method. The novelty of the approach is significant, as it introduces a new paradigm in sequence generation. However, while the methodology is described in detail, the reproducibility could be improved with clearer documentation of experimental setups, hyperparameters, and datasets used.\n\n# Summary Of The Review\nOverall, the paper introduces a compelling framework for improving sequence generation through iterative corrections, which shows promise across various tasks. While the novelty and effectiveness of the SELF-CORRECTION method are clear, there are areas for improvement in the discussion of limitations and in providing reproducibility details.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper proposes a novel framework for enhancing model interpretability in neural networks, addressing the critical challenge of understanding complex deep learning models. The methodology involves a new type of attention mechanism that allows for greater transparency in decision-making processes. Through extensive experiments on benchmark datasets, the authors demonstrate that their approach not only improves interpretability but also maintains competitive performance on standard tasks.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Innovative Approach:** The introduction of a new attention mechanism provides a fresh lens through which to view model interpretability, potentially influencing future research in the area.\n2. **Solid Theoretical Framework:** The theoretical basis for the proposed method is well-articulated, offering insights into how the attention mechanism operates and its implications for interpretability.\n3. **Broad Applicability:** The method's design allows it to be integrated into various neural network architectures, indicating a wide range of potential applications across multiple domains.\n4. **Clear Presentation:** The paper is well-structured, with logical progression of ideas that facilitate understanding of the complex concepts presented.\n\n**Weaknesses:**\n1. **Limited Experimental Scope:** While the results are promising, the experiments are somewhat limited in diversity, as they primarily focus on a narrow set of tasks and datasets.\n2. **Reproducibility Concerns:** Key details regarding the implementation and hyperparameter tuning are insufficiently described, which may hinder the ability of others to replicate the results.\n3. **Inadequate Discussion of Limitations:** The paper lacks a thorough examination of the limitations of the proposed approach, particularly in scenarios where interpretability might not align with performance.\n4. **Comparative Analysis Weaknesses:** The comparisons with existing interpretability methods may not be exhaustive, leading to potential biases in assessing the advantages or disadvantages of the proposed framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear and well-written, effectively communicating complex ideas. However, the lack of detailed explanations for the methodology and experimental setups detracts from its reproducibility. The novelty of the approach is significant, particularly in its attempt to bridge interpretability and performance in neural networks.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to enhancing interpretability in neural networks through a new attention mechanism. While the theoretical contributions and potential applications are noteworthy, the authors should address the limitations in experimental validation and reproducibility to strengthen their submission.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper introduces SELF-CORRECTION, a novel approach aimed at enhancing sequence generation models by dividing the generation process into two distinct components: a base generator and a corrector. This method addresses the common challenges faced by traditional sequence generation models, such as maintaining semantic constraints and enabling iterative output improvement. The proposed system allows the base generator to produce an initial output, which is subsequently refined by a smaller corrector model trained on feedback. The framework demonstrates its effectiveness across various tasks, including mathematical program synthesis, lexically-constrained generation, and toxicity control, revealing a significant improvement in output quality even when the corrector model is considerably smaller than the generator.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to sequence generation, providing a structured method for iterative refinement that can adapt to semantic constraints. The ability to train the corrector using both scalar and natural language feedback is a notable advantage, allowing for flexible and intuitive improvements in output quality. However, a potential weakness is the reliance on the corrector's training data; the performance may vary significantly based on the quality and diversity of the feedback used. Additionally, while the paper suggests broad applicability, further empirical evidence demonstrating the approach's effectiveness across a wider range of tasks would strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written, with a clear presentation of the methodology and findings. The novelty of the SELF-CORRECTION framework is evident in its dual-component structure, which distinguishes it from existing sequence generation methods. However, the reproducibility of results could be enhanced with more detailed descriptions of the training process and datasets used for both the generator and corrector. Providing specific metrics and examples would facilitate better understanding and validation of the proposed method.\n\n# Summary Of The Review\nOverall, the paper presents a compelling framework for improving sequence generation through a decoupled and iterative process. The proposed SELF-CORRECTION approach demonstrates promise in enhancing output quality across various tasks, although it would benefit from further empirical validation and detail regarding reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework called SELF-CORRECTION, designed to enhance sequence generation in language models by incorporating a two-module approach that includes both a base generator and a corrector. This methodology allows for iterative output refinement, addressing the inadequacies of traditional single-pass generation methods. The authors demonstrate the effectiveness of their approach across three diverse tasks—mathematical program synthesis, lexically-constrained generation, and toxicity control—reporting significant performance improvements through the use of feedback mechanisms.\n\n# Strength And Weaknesses\nThe main strength of this paper lies in its innovative approach to sequence generation, which allows for iterative refinement and adapts well to complex tasks. The clear division between the generator and corrector is a valuable contribution that may enhance the adaptability of models to various tasks without extensive retraining. However, a potential weakness is the reliance on feedback mechanisms, which may complicate the training process and require additional data for effective learning. The paper could also benefit from a more detailed discussion on the limitations of the approach and the generalizability of the results to other tasks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The authors provide sufficient detail in describing the self-correcting sequence generators and their training process, which aids in the reproducibility of the results. The novelty of the approach is evident in its dual-module design and the emphasis on iterative improvements. Overall, the quality of the writing and presentation is high, making the research accessible to a broad audience.\n\n# Summary Of The Review\nIn summary, this paper introduces a compelling framework for enhancing language generation through iterative correction, demonstrating significant improvements across multiple tasks. While the methodology is innovative and well-presented, the reliance on feedback mechanisms may pose challenges in practical applications. Overall, the work contributes valuable insights to the field of sequence generation.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper titled \"Generating Sequences by Learning to [Self]-Correct\" addresses the limitations of single-pass generation in sequence generation tasks within natural language processing. It proposes a novel framework called SELF-CORRECTION, which consists of a base generator and a corrector that iteratively refines generated outputs based on feedback. The methodology is evaluated across several tasks, including mathematical program synthesis, lexically-constrained generation, and toxicity control, demonstrating significant improvements in performance metrics compared to existing methods.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to sequence generation by incorporating a self-correction mechanism, which enhances the quality of outputs by allowing for iterative refinements. The experiments are well-structured, providing robust comparisons against baseline methods and showcasing quantitative improvements. However, the paper could benefit from a more in-depth discussion of the limitations of the current approach, particularly regarding the scalability of the corrector and potential computational costs associated with the iterative process.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized, with clear section headings and a logical flow from the problem statement to methodology, results, and conclusion. The use of figures and tables is effective in illustrating key concepts and results. The methodology is described with sufficient detail for reproducibility, although additional information on hyperparameter tuning and specific training procedures could enhance clarity. The novelty of the self-correction framework is evident, as it represents a significant advancement in the field of sequence generation.\n\n# Summary Of The Review\nOverall, this paper presents a valuable contribution to the field of sequence generation by introducing a self-correction framework that addresses critical limitations of existing methods. The rigorous experimental evaluation and clear presentation of results further strengthen its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework named SELF-CORRECTION for enhancing sequence generation models by introducing a two-component architecture: a base generator and a corrector. This framework allows for iterative refinement of outputs, addressing issues of constraint violations in conventional generative models. The methodology involves training the corrector to improve generated sequences based on scalar metrics or natural language feedback, demonstrating significant performance improvements across three tasks: mathematical program synthesis, lexically-constrained generation, and toxicity mitigation.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to decomposing the generation process, which allows for flexibility in optimizing the generator and corrector independently. The empirical evaluations provide strong evidence of effectiveness across diverse tasks, showcasing the generalizability of the SELF-CORRECTION framework. However, the paper could benefit from a more detailed investigation into the potential limitations and constraints of the corrector, particularly concerning its scalability and applicability to different model architectures.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and well-structured, making it accessible to readers with a background in natural language processing and machine learning. The quality of the presented methodology is high, with a solid theoretical foundation and comprehensive empirical evaluations. The novelty of introducing a self-correcting mechanism in sequence generation is significant, although the paper would benefit from a clearer discussion on the reproducibility of results, including specific implementation details and hyperparameter settings.\n\n# Summary Of The Review\nOverall, the paper makes a valuable contribution to the field of sequence generation by introducing a self-correcting framework that significantly improves output quality. While the methodology is innovative and empirically validated, more attention to the scalability and reproducibility aspects would enhance the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a self-correction framework aimed at improving the performance of existing language models through a two-module system consisting of a generator and a corrector. The authors claim that this approach enhances outputs across various tasks, including mathematical program synthesis and toxicity reduction. However, the methodology raises concerns regarding the complexity, scalability, and generalizability of the results, as the experiments conducted do not sufficiently demonstrate robustness across diverse contexts.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address the limitations of current language models by proposing an innovative feedback mechanism for enhancing output quality. However, the reliance on a two-module system raises questions about increased complexity without guaranteed significant improvements. The results presented appear inconsistent and may reflect inherent variability in language generation rather than the framework's effectiveness. Furthermore, the lack of thorough ablation studies limits the understanding of which components contribute meaningfully to the self-correcting process. Ethical considerations regarding the deployment of such models in sensitive contexts are also inadequately addressed.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is undermined by an insufficient critical examination of its limitations and the potential pitfalls of the proposed approach. While the novelty of introducing explicit feedback mechanisms is noteworthy, the practical implications of requiring high-quality feedback are questionable. The reproducibility of findings is further compromised by a lack of comprehensive analysis and ablation studies, making it difficult to ascertain the validity of the claims.\n\n# Summary Of The Review\nOverall, while the paper presents an innovative self-correction framework with promising intentions, it suffers from significant weaknesses in methodology, clarity, and empirical validation. The complexity introduced by the two-module system and the lack of robustness in experimental results raise doubts about the practicality and effectiveness of the proposed approach in real-world applications.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper introduces an innovative approach called Self-Correction for enhancing sequence generation in natural language processing. It decouples the generation and correction processes, leading to improved performance across various tasks, including mathematical program synthesis, lexically-constrained generation, and toxicity control. Key findings indicate that the Self-Corrector achieves high accuracy—up to 99% in challenging tasks—while maintaining efficiency and speed, and can integrate natural language feedback during both training and inference stages.\n\n# Strength And Weaknesses\nThe Self-Corrector demonstrates several strengths, including its iterative refinement mechanism that allows for substantial improvements without the need to restart the generation process. Its versatility enables application across different model sizes and tasks, which is significant for developers. Moreover, the effective reduction of toxicity in outputs is a critical advantage for ethical AI deployment. However, the paper could benefit from more comprehensive empirical comparisons with existing methodologies to fully establish the superiority of the proposed approach.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clear and well-structured, providing a logical flow from introduction to results. It presents novel concepts, particularly the integration of natural language feedback, which enhances the model's learning process. The methodology appears reproducible, but it would be beneficial to include more detailed descriptions of the experimental setup and hyperparameter choices to facilitate understanding and replication by other researchers.\n\n# Summary Of The Review\nOverall, the Self-Corrector represents a significant advancement in the field of sequence generation, offering notable improvements in performance, efficiency, and ethical considerations. While the contributions are substantial, additional empirical validation could further solidify its impact on the research community.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThis paper introduces a novel theoretical framework for **Self-Correction** in sequence generation, proposing a decoupled approach where a generation model (base generator) iteratively refines its outputs through a dedicated correction module. The methodology includes a two-component architecture: a base generator that produces preliminary hypotheses and a corrector module that enhances output quality using a scalar value function for feedback. The findings suggest that this iterative refinement can improve generated outputs without requiring optimality in a single pass, thereby broadening the applicability of the model across various tasks in natural language processing.\n\n# Strength And Weaknesses\nThe paper's strength lies in its innovative approach to decoupling generation and correction processes, allowing for independent optimization of each component, which can enhance adaptability. The theoretical foundation is well-articulated, providing a clear rationale for the proposed mechanisms of improvement and the flexibility of the training procedures. However, a notable weakness is the lack of empirical validation and real-world application examples, which could strengthen the claims made regarding the efficacy of the self-correcting framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its ideas in a clear and structured manner. The theoretical framework is novel, offering a significant departure from traditional sequence generation models. However, the reproducibility of results could be questioned due to the absence of empirical data; practical implementations and validations of the proposed methods are needed to assess their applicability in real-world scenarios.\n\n# Summary Of The Review\nOverall, the paper presents a compelling theoretical advancement in sequence generation through its self-correction framework. While the contributions to the theoretical understanding of iterative refinement are notable, the lack of empirical validation limits the practical implications of the proposed model.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"Generating Sequences by Learning to [Self]-Correct\" by Welleck et al. presents a novel framework called SELF-CORRECTION, which separates the process of generation and correction into distinct components. The methodology involves a base generator, which can be a pre-existing language model, and a corrector trained to iteratively refine the outputs of the generator using feedback. The authors demonstrate that their approach improves performance on various tasks, including mathematical program synthesis and toxicity reduction, through an online training procedure that pairs generator outputs with selected targets. Their experimental results show that SELF-CORRECTION surpasses the performance of the base generator alone and can effectively correct outputs from larger models.\n\n# Strength And Weaknesses\nThe strengths of the paper include its clear modularization of the generation and correction processes, which allows for focused improvements in each component. The use of diverse tasks for evaluation, including mathematical program synthesis and toxicity reduction, showcases the versatility of the proposed method. However, the paper could benefit from a more detailed exploration of the limitations of the corrector, particularly regarding its reliance on feedback and whether this approach generalizes well across varying domains. Additionally, while the empirical results are promising, further comparisons with baseline methods would strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the motivation, methodology, and findings. The descriptions of the framework, training procedure, and evaluation metrics are coherent, allowing for a good understanding of the approach. The novelty of the method lies in its unique separation of generation and correction, which has not been extensively explored in existing literature. The authors mention that code will be made available on GitHub, which supports reproducibility efforts; however, more details on the training data and hyperparameters could enhance clarity regarding implementation.\n\n# Summary Of The Review\nOverall, the paper presents a compelling approach to sequence generation through a self-corrective framework that shows promise across multiple tasks. The modular design facilitates targeted improvements, and the empirical results indicate significant performance enhancements. Nevertheless, the paper could improve by addressing potential limitations and providing more exhaustive comparisons to existing methods.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach called SELF-CORRECTION, aimed at enhancing single-pass generation in natural language processing tasks. Utilizing a corrector network trained through reinforcement learning, the authors claim to improve performance in mathematical program synthesis and lexically constrained generation tasks. However, the reported gains appear modest when benchmarked against existing methods, raising questions about the overall impact and novelty of the proposed framework.\n\n# Strength And Weaknesses\nThe strengths of the paper include the introduction of explicit feedback mechanisms and the modular approach to generation, which could theoretically enhance flexibility and performance. However, these contributions are overshadowed by significant weaknesses, including a lack of depth in formalism compared to prior works, limited empirical advancements, and insufficient evidence supporting claims of transferable corrector networks. The paper also fails to outperform notable existing models in various tasks, and its ablation studies are not as thorough as those conducted in previous research.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper is generally well-structured and clear, the novelty of the contributions is undermined by their resemblance to established methodologies. The quality of the results is mixed, with some improvements noted but lacking substantial evidence to support their significance. Reproducibility may be a concern due to the reliance on techniques that have not been rigorously validated in this context.\n\n# Summary Of The Review\nOverall, the paper offers an interesting approach to natural language generation but does not provide significant advancements over existing models. The contributions feel derivative and lack the rigorous validation needed to establish their significance in the field.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"GENERATING SEQUENCES BY LEARNING TO [SELF-CORRECT]\" introduces a novel approach to sequence generation that employs self-correcting mechanisms to enhance the accuracy of generated outputs. The methodology integrates a self-corrector component into traditional generative models, allowing for iterative refinement of outputs based on a feedback loop. The findings demonstrate substantial improvements in generation quality across various benchmarks, showcasing the effectiveness of the proposed method compared to existing techniques.\n\n# Strength And Weaknesses\nOne of the primary strengths of this paper lies in its innovative approach to sequence generation through self-correction, which represents a significant advancement in the field. The empirical results are compelling, indicating that the self-corrector mechanism can be successfully integrated without significant overhead. However, the paper suffers from various clarity issues, including inconsistent terminology and formatting, which detract from the overall presentation. Additionally, the lack of a clear structure in the abstract and conclusion may hinder reader comprehension of the core contributions.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a novel concept in sequence generation, the clarity of presentation could be improved. Notable inconsistencies in terminology, variable definitions, and formatting choices (e.g., inconsistent use of \"Self-Corrector\" and mathematical notation) can confuse readers. The reproducibility of the results is somewhat compromised by the lack of detailed descriptions of the experiments, particularly regarding hyperparameter settings and data preprocessing steps. A more structured presentation of results with clear metric definitions would enhance quality.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to sequence generation through self-correction, addressing an important challenge in the field. However, issues related to clarity, consistency, and reproducibility must be addressed to fully realize the impact of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper investigates a self-correction mechanism for sequence generation tasks, focusing on its application in three specific tasks. The authors propose a model that utilizes natural language feedback to iteratively refine generated outputs. Key findings include improved performance in these tasks compared to baseline models, highlighting the potential for enhancing sequence generation through interactive correction.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to self-correction and the empirical results demonstrating its effectiveness in the chosen tasks. However, its contributions are somewhat limited by the narrow scope of tasks evaluated, which does not showcase the versatility of the self-corrector. Additionally, the lack of discussion regarding the interaction with existing models and the potential for multi-modal applications weakens the paper's impact. There is also a notable absence of attention to the limitations of the feedback mechanisms and a lack of empirical evidence from real-world user studies.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and easy to follow, with clear explanations of the methodology and results. However, the novelty is somewhat constrained by the limited exploration of potential applications in various domains beyond the presented tasks. Reproducibility could be enhanced by providing more details on the experimental setup and conditions, as well as addressing how the model scales with increased complexity.\n\n# Summary Of The Review\nOverall, the paper presents a compelling approach to self-correction in sequence generation, with promising empirical results. However, it could significantly benefit from broader task evaluations, a more in-depth discussion of limitations and ethical considerations, and additional empirical evidence from real-world applications.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper presents a novel self-correction methodology that decouples a base generator from a corrector, allowing for iterative improvements in text generation tasks. The authors evaluate their approach across three main tasks: mathematical program synthesis, lexically-constrained generation, and toxicity control. They find that the self-correcting framework significantly enhances performance metrics, achieving up to 99% correctness in mathematical synthesis and notable reductions in toxicity scores. The methodology incorporates feedback mechanisms, which are shown to improve adherence to constraints and overall output quality.\n\n# Strength And Weaknesses\nStrengths of the paper include its comprehensive approach to self-correction, demonstrating statistically significant improvements over baseline models across multiple tasks. The use of a clear statistical framework and evaluation metrics enhances the robustness of the findings. Moreover, the ablation studies provide valuable insights into the contributions of different components of the methodology. However, a notable weakness is the lack of explicit statistical significance reporting, such as p-values or confidence intervals, which raises concerns about the reliability of the performance claims. Additionally, while the feedback mechanisms are beneficial, the exploration of alternative methods could have been more thoroughly addressed.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and well-organized, making it easy to follow the proposed methodology and results. The quality of the experiments is high, with a thorough evaluation of the self-correcting framework in diverse tasks. In terms of novelty, the approach of combining a corrector with a generator for iterative improvements is innovative, though the concept of self-correction in machine learning is not entirely new. The reproducibility of the findings could be enhanced by providing more detailed information about the experimental setup and data used, as well as including explicit statistical tests for the reported improvements.\n\n# Summary Of The Review\nThis paper introduces a promising self-correction methodology that demonstrates significant improvements in various generation tasks. While the contributions are substantial, the lack of rigorous statistical validation may undermine the strength of the findings. Overall, the work is a valuable addition to the literature, suggesting further exploration in feedback mechanisms and statistical robustness.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper presents a self-correction mechanism designed to enhance the performance of language models, particularly smaller ones like GPT-Neo 1.3B. The methodology involves a corrector that utilizes scalar value functions and feedback to refine the outputs of the primary model in specific tasks such as mathematical program synthesis, lexically-constrained generation, and toxicity control. The findings suggest that the self-corrector can improve model performance in these tasks; however, the evaluation is limited to a narrow range of tasks and lacks generalizability across diverse applications.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to self-correction and the potential it presents for improving language model outputs. However, there are notable weaknesses, including the limited scope of evaluation, as it primarily focuses on smaller models and a restricted set of tasks. The paper does not thoroughly investigate the robustness of the corrector across various domains or the impact of different types of feedback on performance. Additionally, the reliance on scalar value functions may hinder the approach's effectiveness in more complex scenarios, and the lack of qualitative analysis reduces the depth of understanding regarding the corrections made.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, but the methodology lacks depth in certain areas, such as the justification for example selection and potential biases in feedback. While the concept of a self-corrector is novel, the paper does not provide sufficient detail on the implementation or future work, which may hinder reproducibility. The empirical evaluations are primarily quantitative, missing a qualitative perspective that could enhance the overall understanding of the results.\n\n# Summary Of The Review\nOverall, the paper introduces an interesting self-correction approach for language models but suffers from significant limitations in terms of scope, evaluation, and depth of analysis. The findings are promising yet require more comprehensive validation across diverse tasks and model sizes to establish broader applicability and effectiveness.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"Generating Sequences by Learning to [Self]-Correct\" by Sean Welleck et al. proposes a two-module system consisting of a generator and a corrector to enhance sequence generation tasks. The authors claim that their self-correction framework allows for improved adherence to semantic constraints, which is a known challenge in language models. The methodology involves online training with feedback, and they present results from experiments on three tasks: mathematical program synthesis, lexically-constrained generation, and toxicity control. The findings suggest that incorporating a corrector leads to performance improvements, although the novelty of these contributions appears limited.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its systematic approach to addressing well-documented issues in sequence generation, such as adherence to constraints and the reduction of undesirable outputs like toxicity. The experiments conducted provide empirical support for the proposed method, and the use of ablation studies enhances the validity of their claims. However, the weaknesses are significant; much of the work presented lacks novelty, as the concepts of self-correction and feedback mechanisms are not new to the field. The authors do not sufficiently differentiate their approach from existing literature, making the contributions feel like a rehashing of established ideas.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, with logical flow and coherent presentation of the methodology and results. However, the novelty of the proposed framework is questionable, as it largely reiterates concepts that have been previously explored in the literature. The reproducibility of their results could be improved with more detailed descriptions of experimental setups and dataset specifications, as well as access to code or data to facilitate independent verification.\n\n# Summary Of The Review\nOverall, this paper presents a method that, while systematically addressing important issues in sequence generation, does not contribute significantly to the existing body of knowledge. The concepts employed are largely familiar, and the authors fail to provide a compelling case for the novelty of their approach.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel self-corrector framework designed to enhance output quality in sequence generation tasks. It proposes the use of scalar and natural language feedback mechanisms for self-correction, demonstrating that a smaller corrector model can significantly improve the generated outputs. The methodology includes experiments that showcase the effectiveness of this correction approach across various tasks, leading to findings that suggest promising avenues for further exploration in dynamic adaptation and multi-modal feedback integration.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to self-correction and the empirical results showing improved generation quality. The integration of feedback mechanisms is particularly noteworthy, as it opens up possibilities for more robust error correction. However, the work could benefit from a more extensive exploration of evaluation metrics, as the reliance on scalar values may limit the comprehensive understanding of the model's effectiveness. Additionally, the paper could expand on the potential of larger, task-specific corrector models and the implications of dynamic adaptation in real-time applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the motivation, methodology, and findings. The quality of writing is high, making complex ideas accessible. However, while the novelty of the self-corrector framework is significant, the paper would benefit from a more thorough discussion of reproducibility, particularly regarding the implementation details of the experiments and how they can be replicated in different contexts.\n\n# Summary Of The Review\nOverall, the paper introduces a promising self-corrector framework that demonstrates improvements in sequence generation tasks. While the contributions are significant, further exploration of evaluation metrics and the potential for larger corrector models would strengthen the work. \n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a novel self-corrector framework designed to enhance the performance of language generation models across various tasks, including mathematical program synthesis, lexically constrained generation, and toxicity control. The methodology involves an iterative feedback mechanism that refines initial outputs, leading to significant improvements in correctness rates and other performance metrics compared to baseline models like GPT-Neo and GPT-2. Notable findings include a correctness rate of 98.33% in mathematical synthesis and substantial gains in lexically constrained tasks, along with reduced toxicity in outputs, showcasing the self-corrector's versatility and effectiveness.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its comprehensive evaluation across multiple tasks and its ability to demonstrate significant performance improvements without the need for larger or fine-tuned models. The self-corrector's modularity and transferability across different model sizes further enhance its applicability. However, a potential weakness is the lack of detailed analysis regarding the computational cost and efficiency of the self-corrector compared to traditional methods, which could impact practical deployment.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and findings, making it accessible to a broad audience. The quality of the experiments is high, with robust performance metrics reported for each task. The novelty of the self-corrector approach is significant, particularly in its integration of explicit feedback mechanisms. However, the reproducibility of the results may be a concern if the implementation details and training processes are not adequately described.\n\n# Summary Of The Review\nOverall, the paper presents a compelling advancement in language generation through the introduction of a self-corrector framework that significantly improves benchmark performance across various tasks. While the contributions are noteworthy, further exploration of computational efficiency and detailed implementation guidelines would enhance the paper's impact.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper titled \"GENERATING SEQUENCES BY LEARNING TO SELF-CORRECT\" proposes a novel methodology for sequence generation that addresses the limitations of existing autoregressive models. The authors introduce a framework called Self-Correction, which enhances the generation process by incorporating a corrector mechanism that refines outputs iteratively. The main findings indicate that this approach significantly improves the quality of generated sequences across various tasks, demonstrating its effectiveness in both synthetic and real-world datasets.\n\n# Strength And Weaknesses\nThe paper's main strengths lie in its innovative approach to sequence generation and the thorough empirical evaluation of the proposed method. The introduction of the corrector mechanism is a valuable contribution that adds depth to the existing literature. However, the paper has weaknesses in clarity and organization, as certain sections are dense and could benefit from more concise language and better structural flow. Additionally, the terminology used could be more consistent, which might confuse readers unfamiliar with the concepts.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents an interesting and novel approach, the clarity and quality can be improved. The abstract is lengthy and could be more succinct, while the introduction lacks a smooth transition between discussing existing models and the proposed method. Moreover, some technical terms are not clearly defined, which may hinder understanding. Reproducibility is also a concern, as certain details in the methodology could be elaborated on for better comprehension.\n\n# Summary Of The Review\nOverall, the paper presents a compelling approach to improving sequence generation through self-correction, supported by empirical evidence. However, issues with clarity, organization, and terminology consistency detract from its overall impact. Addressing these concerns could significantly enhance the paper's accessibility and effectiveness.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.0463032923275577,
    -1.7628663996483833,
    -1.9286747466975807,
    -1.719657594291117,
    -1.976543594198701,
    -1.7119514283742796,
    -1.6039276931891033,
    -1.7944241379284074,
    -1.707091185193375,
    -1.6985749477100642,
    -1.70272209733242,
    -1.3909018524800023,
    -1.7339022822996846,
    -1.7951713567144638,
    -1.7055851119347845,
    -1.7181842873948,
    -1.945914393007926,
    -1.9534900266303823,
    -1.986306551206909,
    -1.8014333056753478,
    -2.1339462656807977,
    -1.7398774652534905,
    -1.843104051000859,
    -1.7619882912504101,
    -1.8216753437514048,
    -1.7879298896196831,
    -1.8315278310342265,
    -1.750311858410026,
    -1.580719833060488
  ],
  "logp_cond": [
    [
      0.0,
      -1.8660813360965507,
      -1.8662419428252557,
      -1.8413952369394762,
      -1.8665374852667729,
      -1.8796535484819998,
      -1.888370801239548,
      -1.8638981760037745,
      -1.8483838154161798,
      -1.8734290657122046,
      -1.8508278583010236,
      -1.9171533711947262,
      -1.8753018429984776,
      -1.8622590804361918,
      -1.8590049846990062,
      -1.8579675678016694,
      -1.8561915876536397,
      -1.8702292250690924,
      -1.8599383289584854,
      -1.8388493209610475,
      -1.8633627047208885,
      -1.8721493833494431,
      -1.865482335967313,
      -1.8458582747700338,
      -1.8572750851985764,
      -1.860938919424543,
      -1.8667897325904175,
      -1.8658700182282506,
      -1.8776151180121878
    ],
    [
      -1.4312007552807866,
      0.0,
      -1.2273861819135223,
      -1.2200829512589093,
      -1.2275165870059166,
      -1.3222973798443267,
      -1.3637821488402306,
      -1.2031251129022993,
      -1.173695650303816,
      -1.284114459005807,
      -1.1931477191098558,
      -1.4203327817932767,
      -1.1974849870970647,
      -1.1835529350054947,
      -1.1741817047284213,
      -1.242704643900126,
      -1.3201302938040325,
      -1.1989973383095116,
      -1.306525009415051,
      -1.2761333520890499,
      -1.2839666461418384,
      -1.3552544989407522,
      -1.3420343109195005,
      -1.1917705415619924,
      -1.2834027475710492,
      -1.2602658897035002,
      -1.327648695622991,
      -1.2559218885674488,
      -1.36110751597405
    ],
    [
      -1.568035050196387,
      -1.382479994941971,
      0.0,
      -1.3831441385858472,
      -1.3641847116558619,
      -1.540374275588622,
      -1.5072575514317355,
      -1.4643685507429223,
      -1.4054458729367627,
      -1.512073478991341,
      -1.3983909956462584,
      -1.6390420965314543,
      -1.3951603328059752,
      -1.3571949595073305,
      -1.403618706950355,
      -1.4196496147029127,
      -1.4898667625115916,
      -1.419515448692483,
      -1.4837044972826468,
      -1.4070387166014793,
      -1.4538013581957734,
      -1.5587614340966582,
      -1.5524746783231307,
      -1.3980357692778624,
      -1.4011549145836821,
      -1.4454599696216262,
      -1.5252192837235445,
      -1.4056146659761573,
      -1.5546484061646346
    ],
    [
      -1.370141812880314,
      -1.2511793673759977,
      -1.1654263710914081,
      0.0,
      -1.2163267755303073,
      -1.3461966791937499,
      -1.3867935954611874,
      -1.2440408024172895,
      -1.2029933678132236,
      -1.3663450436912399,
      -1.1639888409797994,
      -1.432143581704467,
      -1.1462663473105652,
      -1.1888413644471139,
      -1.23090053243169,
      -1.1889562157541909,
      -1.3471502246878024,
      -1.211616036382482,
      -1.3528867914270335,
      -1.2278748799602173,
      -1.299854315793679,
      -1.3190367819275954,
      -1.365444470779107,
      -1.2294628543435875,
      -1.2865189769202912,
      -1.23928038724799,
      -1.3326137422140867,
      -1.232030411295842,
      -1.3380331236764633
    ],
    [
      -1.6839176517464967,
      -1.5229528183337206,
      -1.5496618958304513,
      -1.5364295230606706,
      0.0,
      -1.6065868657189035,
      -1.6616741504487258,
      -1.5530664425225063,
      -1.5283629378250263,
      -1.6307307049955275,
      -1.5058117459989826,
      -1.7094637850744394,
      -1.4985928951629708,
      -1.5419193514723561,
      -1.4872535191395637,
      -1.54610096906806,
      -1.5800414649315289,
      -1.532245728262393,
      -1.636942232468684,
      -1.5030167233181615,
      -1.641289804451048,
      -1.6534837202463513,
      -1.686092334462536,
      -1.5457280584034787,
      -1.5800919746315856,
      -1.5063188177915916,
      -1.629836823671458,
      -1.5904738314118148,
      -1.683646244758893
    ],
    [
      -1.382635342705455,
      -1.25142025127324,
      -1.3167962349152198,
      -1.2784519792514013,
      -1.242328986587822,
      0.0,
      -1.3787003635091717,
      -1.2784763463405913,
      -1.294082172998221,
      -1.3105341123477197,
      -1.2671712061662845,
      -1.3916762222410575,
      -1.262493939110617,
      -1.232768919469712,
      -1.2836965540246437,
      -1.2947848506502126,
      -1.3506022599183687,
      -1.2653586871760663,
      -1.3244024975328315,
      -1.2965741815509308,
      -1.3647794875001713,
      -1.3678250813412884,
      -1.3579027478308934,
      -1.2932175842330547,
      -1.3044463541840416,
      -1.3047334480356017,
      -1.3509235263968136,
      -1.330694691376895,
      -1.3706606432251214
    ],
    [
      -1.2447936466670613,
      -1.1746683757825689,
      -1.162544410593385,
      -1.211839160146989,
      -1.1525891256039142,
      -1.2340018020542525,
      0.0,
      -1.2401660175228741,
      -1.1782833228368348,
      -1.1804994512029465,
      -1.1512478862467275,
      -1.3001851379697345,
      -1.160792895222511,
      -1.1547594447603338,
      -1.1963283122313946,
      -1.2246159949547515,
      -1.2029783803557221,
      -1.2139713041760791,
      -1.1652761273300691,
      -1.1195908215207528,
      -1.2287819826350783,
      -1.2546161111839793,
      -1.2626258070084013,
      -1.1957628949130932,
      -1.2194694695235169,
      -1.23206504676381,
      -1.2290928732454385,
      -1.2052207305000178,
      -1.2547875321345063
    ],
    [
      -1.5811295353892363,
      -1.3375189258173135,
      -1.381778947571841,
      -1.3505704607530593,
      -1.373042043585519,
      -1.4570309658437548,
      -1.4634267553430111,
      0.0,
      -1.3562810109815562,
      -1.4746689519731382,
      -1.3676602711193802,
      -1.528800913122094,
      -1.3606568126357261,
      -1.3716864149074706,
      -1.3503295330203344,
      -1.3861453841110487,
      -1.438947236903562,
      -1.3813493934132322,
      -1.505044374589377,
      -1.4199903694937388,
      -1.4160471509084844,
      -1.4805079987460064,
      -1.4746167127394565,
      -1.3725332567515913,
      -1.4017717401497711,
      -1.3198169575636833,
      -1.508079040157384,
      -1.4290247608380187,
      -1.4828405523223007
    ],
    [
      -1.3415018758860615,
      -1.1419638315260898,
      -1.2043551180824377,
      -1.132851811543959,
      -1.1726184922280156,
      -1.319224849538757,
      -1.322195544803602,
      -1.1653709127106984,
      0.0,
      -1.307420817026775,
      -1.1694181834821589,
      -1.409729401673755,
      -1.1612762894373032,
      -1.1318341639009242,
      -1.1446571302925845,
      -1.1681648088526941,
      -1.2538599544335771,
      -1.1714143008797682,
      -1.2268847509274232,
      -1.208057241653972,
      -1.2482631270594946,
      -1.3158959132501737,
      -1.3311569565305237,
      -1.1623636666538704,
      -1.2148518622713125,
      -1.165160009757682,
      -1.2669298387759396,
      -1.2204509661574099,
      -1.3372757841715592
    ],
    [
      -1.4094508015527785,
      -1.2985568878507259,
      -1.3448808025075696,
      -1.36666733653896,
      -1.3221555215184169,
      -1.3499763365416964,
      -1.400847370650689,
      -1.365471026634538,
      -1.3585455538163536,
      0.0,
      -1.3421171618413656,
      -1.4249229798864351,
      -1.317033752589931,
      -1.3576329710429904,
      -1.376486011139128,
      -1.3506864229449178,
      -1.2888509458291628,
      -1.3611376850468626,
      -1.3747964626978932,
      -1.342280598491009,
      -1.3484780420031777,
      -1.4306778389967065,
      -1.3810714862665239,
      -1.3079903544950777,
      -1.3687423342930582,
      -1.4290115127084324,
      -1.3194310189592255,
      -1.4076627361373102,
      -1.441149605577393
    ],
    [
      -1.3549239501691608,
      -1.1877874931556338,
      -1.2007663354825244,
      -1.1585175122377194,
      -1.1669529878378817,
      -1.2992688426715835,
      -1.3083654648792613,
      -1.2283000033291533,
      -1.173318075036317,
      -1.3441762417267988,
      0.0,
      -1.4344201583433172,
      -1.1177105542909451,
      -1.1296940108353508,
      -1.1999553080928476,
      -1.126216659221973,
      -1.2764759961874428,
      -1.2104159070680702,
      -1.260534445337371,
      -1.202428892294218,
      -1.2876991206260386,
      -1.3461061156198533,
      -1.3749366222517159,
      -1.1859876306168957,
      -1.1848769907162822,
      -1.1728863507111593,
      -1.3055321223500675,
      -1.236813424604856,
      -1.3347568211187333
    ],
    [
      -1.1947889659908764,
      -1.1391806017432162,
      -1.1840645277006177,
      -1.1532726776397126,
      -1.1569408419814828,
      -1.1121071820884598,
      -1.1647060679123773,
      -1.1467395465311023,
      -1.161828445873855,
      -1.1465457080340369,
      -1.1625681382916349,
      0.0,
      -1.1679324004868035,
      -1.1659935813150124,
      -1.1601639093852827,
      -1.1575403869015097,
      -1.1719355303604417,
      -1.1481703026335743,
      -1.1439914531859747,
      -1.1751513355036718,
      -1.159565525181037,
      -1.1278512788446802,
      -1.1021497806937164,
      -1.145639605396134,
      -1.1551940862175611,
      -1.164537840884429,
      -1.1429952779337162,
      -1.1508875663981881,
      -1.1579508025704746
    ],
    [
      -1.4494681455174419,
      -1.2621624128104336,
      -1.3021191281623425,
      -1.228504419563856,
      -1.2523041616735908,
      -1.3707718589868996,
      -1.4170126058705939,
      -1.294078516127462,
      -1.2735647667828849,
      -1.3772424873563875,
      -1.189135925070574,
      -1.4983847078712689,
      0.0,
      -1.2604794593173976,
      -1.2936669167062722,
      -1.2034557026082537,
      -1.3210501786869029,
      -1.2461732646897565,
      -1.3228252877647548,
      -1.2888172146863481,
      -1.3728613677263712,
      -1.4010320663022473,
      -1.4237995192678556,
      -1.2851029567183119,
      -1.2728413000551186,
      -1.2591421430519332,
      -1.3010304126636705,
      -1.3585786819677024,
      -1.389544452017378
    ],
    [
      -1.4334994150572797,
      -1.1797874174772116,
      -1.2051837967257266,
      -1.2015531034896803,
      -1.2595493687611794,
      -1.2819438486008632,
      -1.3852106236796218,
      -1.2627189886319177,
      -1.1994100996664163,
      -1.4170314994772377,
      -1.1688299928607109,
      -1.512245026750171,
      -1.2263063866875308,
      0.0,
      -1.227994467595312,
      -1.2576680892771723,
      -1.3384442443025875,
      -1.281442825155772,
      -1.359589541718714,
      -1.267005202892058,
      -1.29053145994186,
      -1.3940673720974326,
      -1.4302355471247095,
      -1.225117423021527,
      -1.3016042784180637,
      -1.2490277397388314,
      -1.3728798934471298,
      -1.2866567323828735,
      -1.3959466880237705
    ],
    [
      -1.341106342192192,
      -1.119594573310538,
      -1.134540062799377,
      -1.131063780933126,
      -1.030579125673739,
      -1.2704062770556324,
      -1.263792420363179,
      -1.1450204057108135,
      -1.1157674660786863,
      -1.2955384097627685,
      -1.147963732710979,
      -1.3843985839328496,
      -1.1501427021816217,
      -1.1031998965637229,
      0.0,
      -1.1560791459407025,
      -1.2265435219271106,
      -1.1776365139793186,
      -1.2431517853580318,
      -1.1127259340652977,
      -1.2024003401039358,
      -1.2144149090632257,
      -1.3031171433296223,
      -1.1425920434550447,
      -1.1691162743796693,
      -1.0450714064477862,
      -1.276180927738489,
      -1.2149504543333278,
      -1.257511755689426
    ],
    [
      -1.3159293945796817,
      -1.1235047667644735,
      -1.1119755100869853,
      -1.0932711296613975,
      -1.129109500768435,
      -1.241879306602347,
      -1.254900513275805,
      -1.1831187867183985,
      -1.0747782811932591,
      -1.290716516359128,
      -1.0592832573432238,
      -1.3539855897204924,
      -1.062492174619717,
      -1.1355173634225255,
      -1.130154071805735,
      0.0,
      -1.2482310496339395,
      -1.1592136716219468,
      -1.198792710449002,
      -1.1516381518219028,
      -1.2500155456976003,
      -1.2513149492389768,
      -1.308354815762004,
      -1.1639471686537608,
      -1.187376090577085,
      -1.1974559331856884,
      -1.189670876314575,
      -1.167438443048542,
      -1.2499083132153892
    ],
    [
      -1.6039560377404805,
      -1.5098867973015258,
      -1.4686181418970399,
      -1.4877451261613817,
      -1.4163339344147157,
      -1.5859318589859368,
      -1.5753578087430475,
      -1.5204175431007925,
      -1.4622637031115922,
      -1.540312858754915,
      -1.477851142234521,
      -1.6977937829582928,
      -1.445754445421181,
      -1.427482357513018,
      -1.5492844220321451,
      -1.5023338293457233,
      0.0,
      -1.5474738222345212,
      -1.5363319739074413,
      -1.4529798531479814,
      -1.5034511751237332,
      -1.5897207385062961,
      -1.5981134822356367,
      -1.5072316712399487,
      -1.4862490018419638,
      -1.4792418861273033,
      -1.516035992000034,
      -1.4599933315980849,
      -1.606158270958343
    ],
    [
      -1.6167366027325139,
      -1.391156633799794,
      -1.4297720629591446,
      -1.4628877873870085,
      -1.4100306389647759,
      -1.5275028431986033,
      -1.6025352802947612,
      -1.3732467757497873,
      -1.4172179651917765,
      -1.5210608270472326,
      -1.4452535637875437,
      -1.6077379686020048,
      -1.4073033031435247,
      -1.431894449689999,
      -1.4274316946499586,
      -1.4435004937399574,
      -1.5224330996609048,
      0.0,
      -1.4931251768891012,
      -1.520795337105839,
      -1.5094070276441414,
      -1.5479762334504081,
      -1.5267184381609877,
      -1.3614234986246572,
      -1.448973661678002,
      -1.4401544461989035,
      -1.5501119384094606,
      -1.3944941528838664,
      -1.5621535025937756
    ],
    [
      -1.670568639959521,
      -1.5877874330729016,
      -1.5695191162483852,
      -1.6066770427991728,
      -1.5769395958152765,
      -1.6190701830853693,
      -1.5637580354487588,
      -1.6356283363286437,
      -1.5578577179050095,
      -1.5938379052607308,
      -1.587729517025111,
      -1.7011929885686827,
      -1.5629694979597555,
      -1.5986228199943964,
      -1.6078407584015653,
      -1.5586255711285741,
      -1.6469354170333455,
      -1.622096570367017,
      0.0,
      -1.5998063200803754,
      -1.6302349131621903,
      -1.6167979686355685,
      -1.6241308478919823,
      -1.5989076194930414,
      -1.5885380803442408,
      -1.6618481675580419,
      -1.578708908215391,
      -1.6032022280727847,
      -1.6482537610999117
    ],
    [
      -1.4998621553286924,
      -1.431044705241414,
      -1.4299395619198754,
      -1.3851421139735645,
      -1.3474957800479639,
      -1.5039079122488521,
      -1.4411479229164912,
      -1.3987853736839355,
      -1.4366810932708498,
      -1.479131266330922,
      -1.4044581519655581,
      -1.5524050089861432,
      -1.4145384971160133,
      -1.4113403096459187,
      -1.3366071708129708,
      -1.392223940229826,
      -1.4426381350862472,
      -1.4449661226949506,
      -1.4965783836578168,
      0.0,
      -1.478019070187977,
      -1.4623906788311438,
      -1.5394624276470956,
      -1.4389568456575499,
      -1.3988896311591652,
      -1.345182156335783,
      -1.4687792729402176,
      -1.4788355365429457,
      -1.4869691107611167
    ],
    [
      -1.7224540571741191,
      -1.6543856966789305,
      -1.5854530548392116,
      -1.5742598045377216,
      -1.5709297829860314,
      -1.7493172661809124,
      -1.703086186559811,
      -1.670825699152224,
      -1.6081587315863115,
      -1.697401774668154,
      -1.6054405352419265,
      -1.794742217076331,
      -1.5996341982993094,
      -1.5694724209528919,
      -1.590496621681964,
      -1.610168279663021,
      -1.615191883315331,
      -1.665100478903669,
      -1.6843239002885688,
      -1.6223963575253975,
      0.0,
      -1.7397984713543908,
      -1.7405369380041693,
      -1.6424974959856358,
      -1.6149451700630642,
      -1.5878329868761403,
      -1.7022681335259575,
      -1.5927911642508448,
      -1.701559186989745
    ],
    [
      -1.4336445183973257,
      -1.4000795948044233,
      -1.4115018604541265,
      -1.368667828100395,
      -1.3150828203791323,
      -1.3921122565648119,
      -1.372346974881426,
      -1.362924399634063,
      -1.362484133543531,
      -1.4321150556596662,
      -1.4116925559903923,
      -1.432511582419161,
      -1.3991032504189977,
      -1.3855659208279203,
      -1.2793079268328182,
      -1.3858685109423798,
      -1.4367875038963571,
      -1.4118696615919561,
      -1.4079126740444028,
      -1.3181244342469125,
      -1.4366835261519146,
      0.0,
      -1.3840037247744994,
      -1.4007643824163454,
      -1.4002480662897059,
      -1.333159653960944,
      -1.3660268323177356,
      -1.3736382199623431,
      -1.2993043385833363
    ],
    [
      -1.523106469660957,
      -1.4804423206549422,
      -1.5633347378544489,
      -1.522334100581527,
      -1.4574136029539322,
      -1.4872861594689808,
      -1.5579217938672412,
      -1.4763354629977152,
      -1.5286040896192612,
      -1.4640708549363326,
      -1.5080754054280987,
      -1.493235514941454,
      -1.5025328254552768,
      -1.5219819614215488,
      -1.5158906565554378,
      -1.487746292428476,
      -1.4535421476799195,
      -1.4115727401193432,
      -1.4888963115913543,
      -1.489689659556924,
      -1.4998438798005824,
      -1.4488753637598606,
      0.0,
      -1.4804651836239953,
      -1.440100485336609,
      -1.5163950432543372,
      -1.4017683080221597,
      -1.4827055836367518,
      -1.5086212253265268
    ],
    [
      -1.4410344492742504,
      -1.3082849966414385,
      -1.3388260089242932,
      -1.3450111348169087,
      -1.3709088023411162,
      -1.4254093556697314,
      -1.4550941375544708,
      -1.2834106593194174,
      -1.3350952307872836,
      -1.388115315050369,
      -1.3506978979730704,
      -1.4932434723189592,
      -1.349157801044754,
      -1.3269033830284143,
      -1.3765351322749304,
      -1.3753814238620796,
      -1.3972157463911727,
      -1.3138864759027313,
      -1.430225500717101,
      -1.3999537218487004,
      -1.3922368518407646,
      -1.4697439390338864,
      -1.411590690663452,
      0.0,
      -1.3463551631282575,
      -1.3011185239389402,
      -1.4366469114758829,
      -1.3572399441293095,
      -1.483379360144229
    ],
    [
      -1.500819734709675,
      -1.4400494820329552,
      -1.4094236440401056,
      -1.4086863272615608,
      -1.3604462727321613,
      -1.5155921350614188,
      -1.5227482704433075,
      -1.420551666928466,
      -1.4149373202672195,
      -1.4606292774499545,
      -1.3798950626082584,
      -1.5855324000691056,
      -1.3714190340834271,
      -1.3862270979883942,
      -1.405198970175727,
      -1.3840003625501225,
      -1.3922347061361078,
      -1.437110838663181,
      -1.4762795370204809,
      -1.4153793592152224,
      -1.4381409010559867,
      -1.5216020874717893,
      -1.4990597292663947,
      -1.42847393623001,
      0.0,
      -1.3913301633299924,
      -1.4282182398742445,
      -1.3768691989405866,
      -1.543106855218473
    ],
    [
      -1.4839430620597727,
      -1.37520038299129,
      -1.351043083609235,
      -1.326155119973599,
      -1.2694822215883805,
      -1.4560078420854614,
      -1.464675380092732,
      -1.3118119404727313,
      -1.3335864529329,
      -1.4864952612141313,
      -1.3328405011491251,
      -1.5105473395921907,
      -1.3268491164319756,
      -1.3425482639433637,
      -1.2711111389900434,
      -1.3469788098768094,
      -1.3586709800741803,
      -1.3658685192919802,
      -1.4656237997995587,
      -1.3072509031952948,
      -1.4172285303279835,
      -1.4134263239453881,
      -1.4846361105444121,
      -1.3241312737356783,
      -1.3363109386846683,
      0.0,
      -1.432369303497285,
      -1.3948580085812952,
      -1.4357453278427674
    ],
    [
      -1.4675613302534674,
      -1.4033122775584945,
      -1.439189779586692,
      -1.3969148259933126,
      -1.3690090441838612,
      -1.4375630668903425,
      -1.4290564176487663,
      -1.4538033380397701,
      -1.4132290903091351,
      -1.4069862383311118,
      -1.3893298841152022,
      -1.4864548984560386,
      -1.3981187364633667,
      -1.4376610384035196,
      -1.4424855909812935,
      -1.3647690127138201,
      -1.3931859688591826,
      -1.4478893703183733,
      -1.3524360022335715,
      -1.4113064981801953,
      -1.3985202982174627,
      -1.4378741751789306,
      -1.3803034008366672,
      -1.452081617881122,
      -1.4042183565444097,
      -1.4220716186980185,
      0.0,
      -1.435469181120406,
      -1.4606383661058386
    ],
    [
      -1.420211136694013,
      -1.3015639164630854,
      -1.266883283278998,
      -1.2795548333200406,
      -1.2840776037917576,
      -1.344271405050471,
      -1.3394879727186633,
      -1.3170292514450466,
      -1.24731561318706,
      -1.4093708074414157,
      -1.2843086942889481,
      -1.4541321444417687,
      -1.2814282293800696,
      -1.2740380637191933,
      -1.3017076568065036,
      -1.3257571177348833,
      -1.3039274443603286,
      -1.241762096740067,
      -1.3661445249320845,
      -1.3377891979651755,
      -1.2961620959789113,
      -1.3920424979266433,
      -1.3830275024747838,
      -1.2145336252163788,
      -1.2456283350341333,
      -1.3179408330114142,
      -1.3314659289090778,
      0.0,
      -1.4105338407143828
    ],
    [
      -1.2102204776987338,
      -1.2320007166158558,
      -1.2545126782498277,
      -1.18193376499459,
      -1.1773007358915366,
      -1.2505630728080848,
      -1.1915390122248481,
      -1.166375451442552,
      -1.1860117823011567,
      -1.2322393618170755,
      -1.202358950766356,
      -1.2478570237662516,
      -1.2071568015341703,
      -1.1750864610856062,
      -1.1407680340154867,
      -1.1956338497977648,
      -1.2070400376068762,
      -1.2445573778415504,
      -1.1932534689926952,
      -1.1459714528664702,
      -1.202027819354098,
      -1.1272140441698149,
      -1.2409872387206582,
      -1.237395675207392,
      -1.2077239569517797,
      -1.1500972851041875,
      -1.216963516386982,
      -1.2559893729930518,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.180221956231007,
      0.18006134950230201,
      0.20490805538808154,
      0.17976580706078482,
      0.16664974384555786,
      0.15793249108800977,
      0.1824051163237832,
      0.1979194769113779,
      0.17287422661535312,
      0.1954754340265341,
      0.12914992113283152,
      0.17100144932908012,
      0.18404421189136588,
      0.18729830762855149,
      0.18833572452588832,
      0.19011170467391802,
      0.1760740672584653,
      0.18636496336907227,
      0.20745397136651023,
      0.1829405876066692,
      0.17415390897811456,
      0.18082095636024476,
      0.20044501755752386,
      0.18902820712898127,
      0.18536437290301477,
      0.17951355973714023,
      0.1804332740993071,
      0.16868817431536987
    ],
    [
      0.3316656443675967,
      0.0,
      0.535480217734861,
      0.542783448389474,
      0.5353498126424667,
      0.4405690198040566,
      0.3990842508081527,
      0.559741286746084,
      0.5891707493445673,
      0.4787519406425764,
      0.5697186805385275,
      0.3425336178551066,
      0.5653814125513186,
      0.5793134646428886,
      0.588684694919962,
      0.5201617557482574,
      0.44273610584435086,
      0.5638690613388717,
      0.4563413902333324,
      0.48673304755933344,
      0.4788997535065449,
      0.4076119007076311,
      0.4208320887288828,
      0.571095858086391,
      0.4794636520773341,
      0.5026005099448831,
      0.4352177040253924,
      0.5069445110809345,
      0.4017588836743333
    ],
    [
      0.36063969650119376,
      0.5461947517556096,
      0.0,
      0.5455306081117335,
      0.5644900350417188,
      0.3883004711089586,
      0.4214171952658452,
      0.4643061959546584,
      0.523228873760818,
      0.4166012677062396,
      0.5302837510513223,
      0.2896326501661264,
      0.5335144138916055,
      0.5714797871902502,
      0.5250560397472257,
      0.5090251319946679,
      0.4388079841859891,
      0.5091592980050976,
      0.4449702494149339,
      0.5216360300961014,
      0.47487338850180727,
      0.3699133126009224,
      0.37620006837444997,
      0.5306389774197182,
      0.5275198321138985,
      0.4832147770759545,
      0.4034554629740361,
      0.5230600807214234,
      0.37402634053294603
    ],
    [
      0.349515781410803,
      0.4684782269151193,
      0.5542312231997089,
      0.0,
      0.5033308187608097,
      0.3734609150973671,
      0.33286399882992956,
      0.47561679187382744,
      0.5166642264778933,
      0.3533125505998771,
      0.5556687533113176,
      0.28751401258665,
      0.5733912469805518,
      0.5308162298440031,
      0.488757061859427,
      0.5307013785369261,
      0.37250736960331454,
      0.508041557908635,
      0.3667708028640835,
      0.4917827143308997,
      0.4198032784974379,
      0.40062081236352154,
      0.35421312351201006,
      0.4901947399475295,
      0.4331386173708258,
      0.4803772070431269,
      0.3870438520770303,
      0.48762718299527497,
      0.38162447061465365
    ],
    [
      0.2926259424522044,
      0.4535907758649804,
      0.42688169836824974,
      0.44011407113803047,
      0.0,
      0.36995672847979755,
      0.3148694437499753,
      0.4234771516761948,
      0.44818065637367477,
      0.34581288920317355,
      0.4707318481997185,
      0.26707980912426166,
      0.4779506990357303,
      0.4346242427263449,
      0.48929007505913735,
      0.430442625130641,
      0.3965021292671722,
      0.44429786593630816,
      0.3396013617300171,
      0.4735268708805396,
      0.3352537897476531,
      0.3230598739523498,
      0.29045125973616504,
      0.43081553579522236,
      0.3964516195671155,
      0.47022477640710947,
      0.3467067705272431,
      0.3860697627868863,
      0.29289734943980816
    ],
    [
      0.32931608566882464,
      0.46053117710103963,
      0.3951551934590598,
      0.4334994491228783,
      0.4696224417864576,
      0.0,
      0.3332510648651079,
      0.43347508203368834,
      0.41786925537605857,
      0.40141731602655994,
      0.44478022220799507,
      0.32027520613322213,
      0.4494574892636627,
      0.4791825089045676,
      0.42825487434963594,
      0.41716657772406696,
      0.3613491684559109,
      0.44659274119821335,
      0.38754893084144815,
      0.41537724682334876,
      0.3471719408741083,
      0.34412634703299116,
      0.35404868054338623,
      0.41873384414122494,
      0.40750507419023796,
      0.40721798033867795,
      0.36102790197746604,
      0.3812567369973847,
      0.3412907851491582
    ],
    [
      0.35913404652204206,
      0.42925931740653445,
      0.44138328259571824,
      0.39208853304211444,
      0.4513385675851891,
      0.36992589113485086,
      0.0,
      0.3637616756662292,
      0.42564437035226854,
      0.4234282419861568,
      0.45267980694237586,
      0.3037425552193689,
      0.4431347979665923,
      0.44916824842876957,
      0.40759938095770876,
      0.37931169823435185,
      0.4009493128333812,
      0.3899563890130242,
      0.4386515658590342,
      0.4843368716683505,
      0.375145710554025,
      0.349311582005124,
      0.341301886180702,
      0.40816479827601015,
      0.38445822366558646,
      0.37186264642529343,
      0.37483481994366485,
      0.39870696268908556,
      0.349140161054597
    ],
    [
      0.2132946025391711,
      0.4569052121110939,
      0.41264519035656644,
      0.44385367717534807,
      0.4213820943428883,
      0.3373931720846526,
      0.33099738258539624,
      0.0,
      0.4381431269468512,
      0.3197551859552692,
      0.4267638668090272,
      0.2656232248063133,
      0.43376732529268125,
      0.4227377230209368,
      0.44409460490807295,
      0.4082787538173587,
      0.3554769010248453,
      0.41307474451517523,
      0.2893797633390305,
      0.3744337684346686,
      0.37837698701992295,
      0.313916139182401,
      0.3198074251889509,
      0.42189088117681606,
      0.39265239777863625,
      0.47460718036472405,
      0.28634509777102335,
      0.3653993770903887,
      0.31158358560610666
    ],
    [
      0.3655893093073135,
      0.5651273536672852,
      0.5027360671109373,
      0.574239373649416,
      0.5344726929653594,
      0.3878663356546179,
      0.384895640389773,
      0.5417202724826766,
      0.0,
      0.39967036816660007,
      0.5376730017112161,
      0.29736178351962006,
      0.5458148957560718,
      0.5752570212924508,
      0.5624340549007905,
      0.5389263763406809,
      0.4532312307597979,
      0.5356768843136068,
      0.4802064342659518,
      0.4990339435394029,
      0.4588280581338804,
      0.39119527194320125,
      0.3759342286628513,
      0.5447275185395046,
      0.4922393229220625,
      0.541931175435693,
      0.44016134641743543,
      0.4866402190359651,
      0.36981540102181576
    ],
    [
      0.28912414615728577,
      0.40001805985933836,
      0.35369414520249465,
      0.3319076111711041,
      0.37641942619164737,
      0.3485986111683679,
      0.29772757705937525,
      0.3331039210755262,
      0.3400293938937107,
      0.0,
      0.3564577858686986,
      0.2736519678236291,
      0.3815411951201333,
      0.3409419766670738,
      0.3220889365709363,
      0.3478885247651464,
      0.4097240018809014,
      0.3374372626632016,
      0.323778485012171,
      0.35629434921905534,
      0.35009690570688656,
      0.2678971087133577,
      0.31750346144354036,
      0.3905845932149865,
      0.329832613417006,
      0.2695634350016318,
      0.3791439287508387,
      0.29091221157275404,
      0.2574253421326713
    ],
    [
      0.3477981471632592,
      0.5149346041767862,
      0.5019557618498955,
      0.5442045850947006,
      0.5357691094945383,
      0.4034532546608365,
      0.39435663245315866,
      0.4744220940032666,
      0.529404022296103,
      0.35854585560562113,
      0.0,
      0.2683019389891028,
      0.5850115430414748,
      0.5730280864970692,
      0.5027667892395724,
      0.5765054381104471,
      0.4262461011449772,
      0.49230619026434974,
      0.44218765199504895,
      0.5002932050382021,
      0.41502297670638133,
      0.3566159817125667,
      0.3277854750807041,
      0.5167344667155243,
      0.5178451066161378,
      0.5298357466212607,
      0.3971899749823524,
      0.46590867272756387,
      0.3679652762136867
    ],
    [
      0.19611288648912595,
      0.2517212507367861,
      0.20683732477938466,
      0.23762917484028967,
      0.23396101049851947,
      0.2787946703915425,
      0.226195784567625,
      0.24416230594889998,
      0.22907340660614728,
      0.24435614444596543,
      0.22833371418836745,
      0.0,
      0.22296945199319884,
      0.2249082711649899,
      0.23073794309471962,
      0.23336146557849258,
      0.21896632211956057,
      0.24273154984642797,
      0.24691039929402758,
      0.21575051697633052,
      0.23133632729896525,
      0.26305057363532214,
      0.2887520717862859,
      0.24526224708386835,
      0.23570776626244117,
      0.2263640115955734,
      0.24790657454628606,
      0.2400142860818142,
      0.23295104990952775
    ],
    [
      0.2844341367822427,
      0.47173986948925095,
      0.43178315413734203,
      0.5053978627358287,
      0.48159812062609375,
      0.363130423312785,
      0.3168896764290907,
      0.43982376617222263,
      0.4603375155167997,
      0.356659794943297,
      0.5447663572291106,
      0.2355175744284157,
      0.0,
      0.473422822982287,
      0.44023536559341236,
      0.5304465796914308,
      0.4128521036127817,
      0.48772901760992804,
      0.41107699453492974,
      0.44508506761333644,
      0.36104091457331333,
      0.33287021599743727,
      0.31010276303182893,
      0.4487993255813727,
      0.46106098224456593,
      0.4747601392477514,
      0.4328718696360141,
      0.3753236003319822,
      0.3443578302823065
    ],
    [
      0.3616719416571841,
      0.6153839392372522,
      0.5899875599887372,
      0.5936182532247836,
      0.5356219879532844,
      0.5132275081136006,
      0.40996073303484204,
      0.5324523680825461,
      0.5957612570480475,
      0.3781398572372261,
      0.6263413638537529,
      0.2829263299642928,
      0.568864970026933,
      0.0,
      0.5671768891191518,
      0.5375032674372915,
      0.45672711241187636,
      0.5137285315586919,
      0.43558181499574977,
      0.5281661538224058,
      0.5046398967726038,
      0.40110398461703123,
      0.36493580958975436,
      0.5700539336929369,
      0.4935670782964001,
      0.5461436169756324,
      0.422291463267334,
      0.5085146243315903,
      0.3992246686906933
    ],
    [
      0.3644787697425924,
      0.5859905386242465,
      0.5710450491354075,
      0.5745213310016584,
      0.6750059862610454,
      0.4351788348791521,
      0.4417926915716055,
      0.5605647062239709,
      0.5898176458560982,
      0.410046702172016,
      0.5576213792238054,
      0.3211865280019348,
      0.5554424097531627,
      0.6023852153710616,
      0.0,
      0.549505965994082,
      0.4790415900076739,
      0.5279485979554659,
      0.4624333265767526,
      0.5928591778694867,
      0.5031847718308486,
      0.49117020287155877,
      0.4024679686051622,
      0.5629930684797397,
      0.5364688375551152,
      0.6605137054869983,
      0.42940418419629545,
      0.49063465760145664,
      0.4480733562453585
    ],
    [
      0.40225489281511817,
      0.5946795206303264,
      0.6062087773078146,
      0.6249131577334024,
      0.5890747866263648,
      0.47630498079245287,
      0.4632837741189948,
      0.5350655006764014,
      0.6434060062015408,
      0.4274677710356718,
      0.6589010300515761,
      0.36419869767430746,
      0.655692112775083,
      0.5826669239722744,
      0.5880302155890649,
      0.0,
      0.4699532377608604,
      0.5589706157728531,
      0.519391576945798,
      0.5665461355728971,
      0.4681687416971996,
      0.4668693381558231,
      0.4098294716327959,
      0.5542371187410391,
      0.530808196817715,
      0.5207283542091115,
      0.528513411080225,
      0.5507458443462578,
      0.4682759741794107
    ],
    [
      0.34195835526744545,
      0.43602759570640015,
      0.477296251110886,
      0.45816926684654424,
      0.5295804585932102,
      0.3599825340219891,
      0.37055658426487836,
      0.42549684990713343,
      0.48365068989633375,
      0.4056015342530108,
      0.4680632507734048,
      0.24812061004963315,
      0.5001599475867449,
      0.5184320354949079,
      0.3966299709757808,
      0.44358056366220255,
      0.0,
      0.39844057077340467,
      0.40958241910048465,
      0.4929345398599445,
      0.44246321788419274,
      0.35619365450162976,
      0.34780091077228925,
      0.4386827217679772,
      0.45966539116596206,
      0.46667250688062256,
      0.429878401007892,
      0.48592106140984104,
      0.33975612204958283
    ],
    [
      0.33675342389786844,
      0.5623333928305883,
      0.5237179636712377,
      0.49060223924337376,
      0.5434593876656064,
      0.425987183431779,
      0.35095474633562107,
      0.580243250880595,
      0.5362720614386058,
      0.43242919958314974,
      0.5082364628428386,
      0.3457520580283775,
      0.5461867234868576,
      0.5215955769403833,
      0.5260583319804237,
      0.5099895328904249,
      0.4310569269694775,
      0.0,
      0.4603648497412811,
      0.4326946895245434,
      0.44408299898624093,
      0.40551379317997416,
      0.42677158846939456,
      0.5920665280057251,
      0.5045163649523803,
      0.5133355804314788,
      0.4033780882209217,
      0.5589958737465159,
      0.3913365240366067
    ],
    [
      0.3157379112473879,
      0.3985191181340073,
      0.41678743495852366,
      0.3796295084077361,
      0.40936695539163237,
      0.3672363681215396,
      0.4225485157581501,
      0.3506782148782652,
      0.4284488333018994,
      0.39246864594617814,
      0.398577034181798,
      0.2851135626382262,
      0.4233370532471534,
      0.38768373121251254,
      0.37846579280534365,
      0.42768098007833477,
      0.33937113417356346,
      0.364209980839892,
      0.0,
      0.38650023112653353,
      0.35607163804471864,
      0.36950858257134045,
      0.36217570331492666,
      0.3873989317138675,
      0.3977684708626681,
      0.32445838364886703,
      0.407597642991518,
      0.38310432313412424,
      0.3380527901069972
    ],
    [
      0.3015711503466554,
      0.37038860043393385,
      0.3714937437554724,
      0.4162911917017833,
      0.4539375256273839,
      0.29752539342649564,
      0.3602853827588566,
      0.40264793199141224,
      0.36475221240449796,
      0.3223020393444258,
      0.39697515370978964,
      0.24902829668920456,
      0.38689480855933445,
      0.39009299602942904,
      0.464826134862377,
      0.4092093654455218,
      0.3587951705891006,
      0.35646718298039715,
      0.30485492201753095,
      0.0,
      0.3234142354873708,
      0.33904262684420394,
      0.26197087802825214,
      0.3624764600177979,
      0.40254367451618256,
      0.4562511493395647,
      0.33265403273513017,
      0.322597769132402,
      0.31446419491423105
    ],
    [
      0.41149220850667856,
      0.47956056900186717,
      0.5484932108415861,
      0.5596864611430761,
      0.5630164826947663,
      0.38462899949988527,
      0.43086007912098667,
      0.4631205665285738,
      0.5257875340944862,
      0.4365444910126437,
      0.5285057304388712,
      0.33920404860446673,
      0.5343120673814883,
      0.5644738447279058,
      0.5434496439988337,
      0.5237779860177767,
      0.5187543823654668,
      0.46884578677712874,
      0.4496223653922289,
      0.5115499081554002,
      0.0,
      0.3941477943264069,
      0.3934093276766284,
      0.49144876969516194,
      0.5190010956177336,
      0.5461132788046574,
      0.4316781321548402,
      0.5411551014299529,
      0.43238707869105264
    ],
    [
      0.30623294685616487,
      0.3397978704490672,
      0.328375604799364,
      0.3712096371530955,
      0.42479464487435825,
      0.34776520868867866,
      0.3675304903720644,
      0.37695306561942754,
      0.3773933317099596,
      0.3077624095938243,
      0.3281849092630982,
      0.30736588283432953,
      0.3407742148344928,
      0.3543115444255702,
      0.4605695384206723,
      0.3540089543111107,
      0.3030899613571334,
      0.32800780366153437,
      0.33196479120908773,
      0.421753031006578,
      0.3031939391015759,
      0.0,
      0.3558737404789911,
      0.33911308283714514,
      0.33962939896378463,
      0.40671781129254647,
      0.37385063293575493,
      0.3662392452911474,
      0.44057312667015425
    ],
    [
      0.31999758133990186,
      0.36266173034591676,
      0.27976931314641007,
      0.320769950419332,
      0.38569044804692676,
      0.35581789153187815,
      0.2851822571336178,
      0.3667685880031437,
      0.31449996138159775,
      0.37903319606452635,
      0.33502864557276024,
      0.34986853605940493,
      0.34057122554558217,
      0.3211220895793101,
      0.3272133944454212,
      0.35535775857238305,
      0.38956190332093943,
      0.43153131088151575,
      0.3542077394095047,
      0.35341439144393494,
      0.3432601712002765,
      0.39422868724099835,
      0.0,
      0.3626388673768637,
      0.4030035656642499,
      0.3267090077465218,
      0.44133574297869926,
      0.3603984673641072,
      0.3344828256743322
    ],
    [
      0.3209538419761597,
      0.45370329460897163,
      0.42316228232611697,
      0.4169771564335014,
      0.3910794889092939,
      0.33657893558067875,
      0.3068941536959393,
      0.4785776319309927,
      0.4268930604631265,
      0.37387297620004123,
      0.41129039327733974,
      0.26874481893145097,
      0.4128304902056561,
      0.43508490822199586,
      0.3854531589754797,
      0.3866068673883305,
      0.3647725448592374,
      0.4481018153476788,
      0.33176279053330915,
      0.36203456940170975,
      0.3697514394096455,
      0.2922443522165237,
      0.350397600586958,
      0.0,
      0.4156331281221526,
      0.4608697673114699,
      0.32534137977452726,
      0.40474834712110064,
      0.278608931106181
    ],
    [
      0.32085560904172983,
      0.3816258617184496,
      0.41225169971129927,
      0.412989016489844,
      0.4612290710192435,
      0.30608320868998606,
      0.2989270733080973,
      0.4011236768229389,
      0.4067380234841853,
      0.3610460663014503,
      0.4417802811431464,
      0.23614294368229927,
      0.4502563096679777,
      0.43544824576301067,
      0.4164763735756778,
      0.43767498120128234,
      0.42944063761529705,
      0.3845645050882238,
      0.34539580673092396,
      0.40629598453618243,
      0.38353444269541814,
      0.30007325627961556,
      0.3226156144850101,
      0.39320140752139476,
      0.0,
      0.43034518042141245,
      0.3934571038771604,
      0.44480614481081826,
      0.2785684885329318
    ],
    [
      0.30398682755991047,
      0.41272950662839314,
      0.43688680601044805,
      0.4617747696460841,
      0.5184476680313026,
      0.3319220475342217,
      0.32325450952695123,
      0.4761179491469518,
      0.4543434366867831,
      0.3014346284055518,
      0.455089388470558,
      0.27738255002749246,
      0.46108077318770757,
      0.44538162567631945,
      0.5168187506296398,
      0.44095107974287373,
      0.42925890954550283,
      0.42206137032770297,
      0.32230608982012443,
      0.48067898642438833,
      0.3707013592916997,
      0.374503565674295,
      0.303293779075271,
      0.46379861588400484,
      0.4516189509350148,
      0.0,
      0.35556058612239805,
      0.39307188103838797,
      0.3521845617769157
    ],
    [
      0.3639665007807591,
      0.4282155534757319,
      0.39233805144753453,
      0.4346130050409138,
      0.4625187868503653,
      0.3939647641438839,
      0.4024714133854601,
      0.3777244929944563,
      0.4182987407250913,
      0.42454159270311465,
      0.44219794691902425,
      0.34507293257818783,
      0.43340909457085974,
      0.3938667926307069,
      0.389042240052933,
      0.46675881832040633,
      0.4383418621750439,
      0.38363846071585317,
      0.47909182880065493,
      0.4202213328540312,
      0.43300753281676374,
      0.3936536558552959,
      0.4512244301975592,
      0.37944621315310445,
      0.4273094744898167,
      0.409456212336208,
      0.0,
      0.39605864991382056,
      0.3708894649283878
    ],
    [
      0.3301007217160128,
      0.44874794194694045,
      0.4834285751310279,
      0.4707570250899853,
      0.4662342546182683,
      0.40604045335955496,
      0.41082388569136263,
      0.43328260696497933,
      0.5029962452229659,
      0.34094105096861016,
      0.4660031641210778,
      0.29617971396825715,
      0.4688836290299563,
      0.47627379469083264,
      0.4486042016035223,
      0.42455474067514265,
      0.4463844140496973,
      0.5085497616699588,
      0.3841673334779414,
      0.4125226604448504,
      0.4541497624311146,
      0.35826936048338265,
      0.3672843559352421,
      0.5357782331936471,
      0.5046835233758926,
      0.4323710253986117,
      0.4188459295009481,
      0.0,
      0.3397780176956431
    ],
    [
      0.37049935536175416,
      0.34871911644463216,
      0.3262071548106602,
      0.3987860680658979,
      0.4034190971689513,
      0.33015676025240315,
      0.38918082083563976,
      0.41434438161793596,
      0.39470805075933124,
      0.3484804712434124,
      0.378360882294132,
      0.3328628092942363,
      0.37356303152631765,
      0.4056333719748817,
      0.43995179904500126,
      0.38508598326272314,
      0.37367979545361174,
      0.3361624552189375,
      0.38746636406779267,
      0.43474838019401774,
      0.37869201370638983,
      0.45350578889067306,
      0.3397325943398297,
      0.3433241578530959,
      0.3729958761087082,
      0.4306225479563004,
      0.36375631667350583,
      0.3247304600674361,
      0.0
    ]
  ],
  "row_avgs": [
    0.18140842988767283,
    0.49044623084086114,
    0.47025630968804466,
    0.4452881766218769,
    0.3932674150841323,
    0.3995179043780851,
    0.39851504800743387,
    0.3740206925444399,
    0.47797877078235634,
    0.3347638206186955,
    0.45951409601766385,
    0.23660208934858878,
    0.4155040658702556,
    0.49476131839291515,
    0.513634899967634,
    0.5294709344611565,
    0.4261177862708689,
    0.47516733362186686,
    0.3785177668870609,
    0.36049122227459784,
    0.4833938194535911,
    0.3572513149646683,
    0.3533616159817878,
    0.37974893303269885,
    0.3818909647933931,
    0.4048800347438176,
    0.41254785160199886,
    0.4298798708019795,
    0.3778348537317217
  ],
  "col_avgs": [
    0.3282772308383709,
    0.44349309662612707,
    0.43322478880175164,
    0.4493380174107147,
    0.4678563202617313,
    0.36773215388612757,
    0.35517815175016093,
    0.4325420515080993,
    0.4492654344475292,
    0.3683320862129122,
    0.45408893707932796,
    0.29034052074324107,
    0.458399813628836,
    0.45262061757014643,
    0.4452165916038741,
    0.4379571026856515,
    0.3967032149307636,
    0.42779197783716233,
    0.38542796469900875,
    0.4383806348493922,
    0.3888252421458448,
    0.3601561311619177,
    0.3470549022077882,
    0.4426694969096142,
    0.42878987295709303,
    0.44104400309445346,
    0.38317721110296693,
    0.41500069031963294,
    0.3471493134016236
  ],
  "combined_avgs": [
    0.25484283036302185,
    0.46696966373349413,
    0.45174054924489815,
    0.44731309701629585,
    0.4305618676729318,
    0.38362502913210633,
    0.37684659987879743,
    0.4032813720262696,
    0.46362210261494274,
    0.3515479534158038,
    0.4568015165484959,
    0.2634713050459149,
    0.4369519397495458,
    0.47369096798153076,
    0.47942574578575403,
    0.483714018573404,
    0.41141050060081624,
    0.4514796557295146,
    0.3819728657930348,
    0.39943592856199506,
    0.4361095307997179,
    0.358703723063293,
    0.350208259094788,
    0.41120921497115653,
    0.4053404188752431,
    0.42296201891913554,
    0.3978625313524829,
    0.4224402805608062,
    0.3624920835666726
  ],
  "gppm": [
    604.5202671404295,
    578.3077628170538,
    579.8344323590761,
    575.0313584807176,
    561.4686949473696,
    608.1296208959063,
    616.7970680175921,
    580.0623735391123,
    577.1339911209187,
    609.6088599995637,
    573.8672859007728,
    642.7809739612634,
    570.6189253922482,
    573.5997065670044,
    579.2413355407983,
    582.1453023976595,
    595.7294352511727,
    583.9507956826367,
    601.0706467059038,
    576.7957158093305,
    599.5391810079285,
    614.3542506552637,
    620.010456748674,
    576.001331544161,
    582.9812629181386,
    577.6060867188056,
    604.7593196538537,
    591.0417061458113,
    622.7203510402778
  ],
  "gppm_normalized": [
    1.4534514770533833,
    1.3483583574327405,
    1.3527049385767873,
    1.3440566082680552,
    1.3163638054203393,
    1.425937692003958,
    1.4423496846822523,
    1.358182340469339,
    1.3445779915561602,
    1.4258154911294665,
    1.3399105277765382,
    1.5147953814287831,
    1.3344860731924848,
    1.3380770880220754,
    1.348680622730479,
    1.355490141096558,
    1.3886108107938342,
    1.3572514895437766,
    1.398443483947054,
    1.352093429708512,
    1.3897733595547224,
    1.4325163562681962,
    1.4419309214456337,
    1.3492133181634667,
    1.3609612616695237,
    1.3499123263225816,
    1.4062220489778348,
    1.377299140212033,
    1.4512073751782404
  ],
  "token_counts": [
    675,
    403,
    416,
    436,
    480,
    456,
    430,
    452,
    399,
    429,
    422,
    532,
    453,
    418,
    384,
    385,
    398,
    367,
    383,
    466,
    347,
    394,
    358,
    460,
    422,
    432,
    368,
    403,
    379
  ],
  "response_lengths": [
    3472,
    2306,
    2402,
    2543,
    2898,
    2712,
    2505,
    2475,
    2305,
    2415,
    2369,
    3005,
    2631,
    2373,
    2241,
    2264,
    2370,
    2141,
    2206,
    2702,
    1992,
    2232,
    2025,
    2657,
    2339,
    2414,
    2122,
    2304,
    2137
  ]
}