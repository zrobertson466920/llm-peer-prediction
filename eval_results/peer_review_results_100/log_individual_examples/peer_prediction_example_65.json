{
  "example_idx": 65,
  "reference": "Under review as a conference paper at ICLR 2022\n\nRAINPROOF: AN UMBRELLA TO SHIELD TEXT GENERATORS FROM OUT-OF-DISTRIBUTION DATA\n\nAnonymous authors Paper under double-blind review\n\nABSTRACT\n\nAs more and more conversational and translation systems are deployed in production, it is essential to implement and to develop effective control mechanisms guaranteeing their proper functioning and security. An essential component to ensure safe system behavior is out-of-distribution (OOD) detection, which aims at detecting whether an input sample is statistically far from the training distribution. Although OOD detection is a widely covered topic in classification tasks, it has received much less attention in text generation. This paper addresses the problem of OOD detection for machine translation and dialog generation from an operational perspective. Our contributions include: (i) RAINPROOF a Relative informAItioN Projection ODD detection framework; and (ii) a more operational evaluation setting for OOD detection. Surprisingly, we find that OOD detection is not necessarily aligned with task-specific measures. The OOD detector may filter out samples that are well processed by the model and keep samples that are not, leading to weaker performance. Our results show that RAINPROOF breaks this curse and achieve good results in OOD detection while increasing performance.\n\n1\n\nINTRODUCTION\n\nSignificant progress have been made in Natural Language Generation (NLG) in recent years with the development of powerful generic (e.g., GPT (Radford et al., 2018; 2019; Brown et al., 2020)) and task-specific (e.g., Grover (Zellers et al., 2019), Pegasus (Zhang et al., 2020) and DialogGPT (Zhang et al., 2019)) text generators. Text generators power machine translation systems or chat bots that are by definition exposed to the public and whose reliability is therefore a prerequisite for adoption. Text generators are trained in the context of a so-called closed world (Antonucci et al., 2021; Fei & Liu, 2016), where training and test data are assumed to be drawn i.i.d. from a single distribution, known as the in-distribution. However, when deployed, these models operate in an open world (Parmar et al., 2021; Zhou, 2022) where the i.i.d. assumption is often violated. This change in data distribution is detrimental and induces a drop in performance as illustrated in Tab. 3 and Tab. 4. Thus, to ensure the trustworthiness and adoption, it is necessary to develop tools to protect them from harmful distribution shifts. For example, a trained translation model is not expected to be reliable when presented with another language (e.g. a Spanish model exposed to Catalan, or a Dutch model exposed to Afrikaans) or unexpected technical language (e.g., a colloquial translation model exposed to rare technical terms from the medical field).\n\nMost of the existing research, which aims to protect models from Out-Of-Distribution (OOD) data, focuses on classification. Despite their importance, (conditional) text generation has received much less attention even though it is among the most exposed applications. Existing solutions fall into two categories. The first one called training-aware methods (Zhu et al., 2022; Vernekar et al., 2019a;b) modifies the classifier training by exposing the neural network to OOD samples during training. The second one called plug-in methods aims at distinguishing regular samples in the in distribution (IN) from OOD samples based on the behavior of the model on a new input. Plug-in methods include Maximum Softmax Prediction (MSP) (Hendrycks & Gimpel, 2016) or Energy (Lee et al., 2018a) or feature-based anomaly detectors that compute a per-class anomaly score (Ming et al., 2022; Ryu et al., 2017; Huang et al., 2020; Ren et al., 2021a). Although plug-in methods seem attractive, their adaptation to text generation may not be straightforward. The sheer number of words present in the vocabulary prevents it to be used directly within the classification framework.\n\n1\n\nUnder review as a conference paper at ICLR 2022\n\nIn this work, we aim at developing new tools to build more reliable text generators, which can be used in practical systems. First, we work in the unsupervised detection setting where we do not assume that we have access to OOD samples as they are often not available. Second, we work in the black-box scenario, which is the most common in the Software as a Service framework Rudin & Radin (2019). In the black-box setting detection methods only have access to the output of the DNN architecture. Third, we want an easy-to-use and effective method to ensure adoptability. Last, we argue that OOD detection impacts on tasks specific performance of the whole system should be taken into account when choosing OOD detectors in an operational setting.\n\nOur contributions. Our main contributions can be summarized as follows:\n\n1. A more operational benchmark for text generation OOD detection. We present LOFTER the Language Out oF disTribution pErformance benchmaRk. Existing works on OOD detection for language modeling (Arora et al., 2021) focus on (i) english language only, (ii) the GLUE benchmark and (iii) measure performance solely in terms of OOD detection. LOFTER is, in our view, a more operational setting with a strong focus on neural machine translation (NMT) and dialog generation. First, it introduces more realistic data shifts that go beyond English Fan et al. (2021): language shifts induced by closely related language pairs (e.g., Spanish and Catalan or Dutch and Afrikaans1) and domain change (e.g., medical vs news data or different types of dialogs). In addition, LOFTER comes with an updated evaluation setting: detectors’ performance are jointly evaluated w.r.t the overall system’s performance on the end task.\n\n2. Novel information theoretic-based detectors. We present RAINPROOF: a Relative informAItioN Projection Out OF distribution detector. RAINPROOF is fully unsupervised. It is flexible and can be applied both when no reference samples (IN) are available (corresponding to scenario s0) and when they are (corresponding to scenario s1). RAINPROOF tackles s0 by computing the models’ predictions negentropy (Brillouin, 1953). For s1, it relies its natural extension: the Information Projection (Kullback, 1954; Csisz ́ar, 1967), an information-theoretic tool that remains overlooked by the machine learning community.\n\n3. New insights on the operational value of OOD detectors Our extensive experiments on LOFTER show that OOD detectors may filter out samples that are well processed by the model and keep samples that are not, leading to weaker performance. Our results show that RAINPROOF breaks this curse and achieve good results in OOD detection while increasing performance.\n\n4. Code and reproductibility. After acceptance, we will publish the open-source code on github. com and the data to facilitate future research, ensure reproducibility and reduce computational costs.\n\n2 PROBLEM STATEMENT & RELATED WORKS\n\n2.1 NOTATIONS & CONDITIONAL TEXT GENERATION\n\n(cid:110)\n\nLet us denote Ω a vocabulary of size |Ω| and Ω∗ its Kleene closure (Fletcher et al., 1990)2. We\n\np ∈ [0, 1]|Ω| : (cid:80)|Ω|\n\ni=1 pi = 1 the set of probability distributions defined over Ω. denote P(Ω) = Let Dtrain be the training set, composed of N ⩾ 1 i.i.d. samples {(xi, yi)}N i=1 ∈ (X × Y)N with probability law pXY . We denote pX and pY the associated marginal laws of pXY . Each xi is a sequence of tokens and we denote xi t} ∈ Ω∗ denotes the prefix of length t. The same notations hold for y.\n\nj ∈ Ω the jth token of the ith sequence. xi\n\n⩽t = {xi\n\n1, · · · , xi\n\n(cid:111)\n\nConditional textual generation. In conditional textual generation, the goal is to model a probability distribution p⋆(x, y) over variable-length text sequences (x, y) by finding pθ ≈ p⋆(x, y) for any (x, y). In this work, we assume to have access to a pretrained conditional language model fθ : X × Y → R|Ω| where the output is the (unormalized) logits scores. fθ parameterized pθ, i.e., for any (x, y), pθ(x, y) = softmax(fθ(x, y)/T ) where T ∈ R denotes the temperature. Given an input sequence x, the pretrained language fθ can recursively generate an output sequence ˆy by\n\n1Afrikaans is a daughter language of Dutch (Jansen et al., 2007). The Dutch sentence: Appelen zijn\n\ngewoonlijk groen, geel of rood can be translated in ”Appels is gewoonlik groen, geel of rooi.”\n\n2The Kleene closure corresponds to sequences of arbitrary size written with words in Ω. Formally: Ω∗ =\n\nΩi.\n\n∞ (cid:83)\n\ni=0\n\n2\n\nUnder review as a conference paper at ICLR 2022\n\nsampling yt+1 ∼ pT θ (·|x, ˆy⩽t), for t ∈ [1, |y|]. Note that ˆy0 is the start of sentence (< SOS > token). We denote by S(x), the set of normalized logits scores generated by the model when the initial input is x i.e., S(x) = {softmax(fθ(x, ˆy⩽t))}|ˆy| t=1. Note that elements of S(x) are discrete probability distributions on Ω.\n\n2.2 PROBLEM STATEMENT\n\nIn OOD detection the goal is to find an anomaly score a : X → R+ that quantifies how much a sample is far from the IN distribution. x is classified as IN or OUT according to the score a(x). Following previous work (Hendrycks & Gimpel, 2016), one fixes a threshold γ and classifies the test sample IN if a(x) ⩽ γ or OOT if a(x) > γ. Formally, let us denote g(·, γ) the decision function, we\n\ntake: g(x, γ) =\n\n(cid:26) 1 0\n\nif a (x) > γ if a (x) ⩽ γ\n\nRemark 1. In our setting, OOD examples are not available. In our experiments, we take γ such that at least 80% of the train set is classified as IN data. This assumption is reasonable since, in practice, even a well tailored dataset might contains significant shares of outliers (Mishra et al., 2020).\n\n2.3 REVIEW OF OOD DETECTORS\n\nOOD detection for classification. Most works on OOD detection have focused on detectors for classifiers and relies either on internal representations (features-based detectors) or on the final soft probabilities produced by the classifier (softmax based detectors).\n\nFeatures-based detectors. They leverage latent representations to derive anomaly scores (Kirichenko et al., 2020; Zisselman & Tamar, 2020). The most well-known is the Mahanalobis distance (Lee et al., 2018b; Ren et al., 2021b) but there are other methods employing Grams matrices (Sastry & Oore, 2020), Fisher Rao distance (Gomes et al., 2022) or other statistical tests (Haroush et al., 2021). Other methods rely on the gradient space (Huang et al., 2021) or the moment of the features (Quintanilha et al., 2019; Sun et al., 2021). These methods require access to the latent representations of the models, which does not fit the black-box scenario. Moreover, they often rely on a per-class decision, which is fine for classifiers but the sheer number of words in Ω makes it impossible to use for text generation.\n\nSoftmax-based detectors. These detectors rely on the soft probabilities produced by the model. The maximum softmax probability (Hendrycks & Gimpel, 2017; Hein et al., 2019; Liang et al., 2018; Hsu et al., 2020) uses the probability of the mode while others take into account the entire distribution, such as the Energy-based OOD detection scores (Liu et al., 2020). Due to the large vocabulary size, it is unclear how these methods generalize to sequence generation tasks.\n\nOOD detection for text generation. Little work has been done on OOD detection for text generation. Therefore, we will follow Arora et al. (2021) and will rely on their baselines but also generalize common OOD scores such as MSP or Energy to the context of text generation.\n\nGeneralization to sequence generation. We generalize common OOD detectors for classification tasks by computing the average OOD score along the sequence at each step of the text generation. We refer the reader to Sec. A.6 for more details. Remark 2. Note that features-based detectors assume a white-box framework where the internal representations of an input are accessible. By contrast to softmax-based detectors which only rely on the final output. Following Arora et al. (2021), we work in a black-box framework (Chen et al., 2020). We also compare our results to the Mahalanobis distance (Lee et al., 2018b), as it is known to be a strong baseline.\n\n3 RAINPROOF AN INFORMATION THEORETIC OOD DETECTORS\n\n3.1\n\nINFORMATION THEORETICAL BACKGROUND\n\nAn information measure I : P(Ω) × P(Ω) → R quantifies the similarity between any pair of discrete distributions p, q ∈ P(Ω). Since Ω is a finite set, we will adopt the following notations p = [p1, · · · , p|Ω|] and q = [q1, · · · , q|Ω|]. The development of new information measures for\n\n3\n\nUnder review as a conference paper at ICLR 2022\n\nspecific applications has received much attention over the years (Fujisawa & Eguchi, 2008; Cichocki et al., 2011) (we refer the reader to Basseville (2013) for a complete review). While there exist information distances, it is, in general, difficult to build metrics that satisfy all the properties of a distance, thus we often rely on divergences which drop the symmetry property and the triangular inequality. In what follows, we motivate the information measures we will use in this work.\n\nFirst, we rely on the R ́enyi divergences (Csisz ́ar, 1967). R ́enyi divergences belong to the f -divergences family and are parametrized by a parameter α ∈ R+ − {1}. They are flexible and include well-known divergences such as the Kullback-Leiber divergence (KL) Kullback (1959) (when α → 1) or the Hellinger distance (Hellinger, 1909) (when α = 0.5). The R ́enyi divergence between p and q is defined as follows:\n\nDα(p∥q) =\n\n1 α − 1\n\n\n\n\n\nlog\n\n\n\n|Ω| (cid:88)\n\ni=1\n\npα i\nqα−1\n\ni\n\n .\n\n(1)\n\nThe Renyi divergence is widely used in machine learning (Peters et al., 2019) because α allows weighting the relative influence of the distributions’ tail.\n\nSecond, we investigate the Fisher-Rao distance (FR). FR is a distance on the Riemannian space formed by the parametric distributions, using Fisher information matrix as its metric (Amari, 2012). It computes the geodesic distance between two discrete distributions (Rao, 1992; Pinele et al., 2020) and is defined as follows:\n\nFR(p∥q) =\n\n2 π\n\narccos\n\n|Ω| (cid:88)\n\ni=1\n\n√\n\npi × qi.\n\n(2)\n\nIt has recently found many applications (Picot et al., 2022; Colombo et al., 2022b;a) and is known to be more accurate than popular divergence measures (Costa et al., 2015).\n\n3.2 RAINPROOF FOR THE NO-REFERENCE SCENARIO (s0)\n\nAt inference time, the no-reference scenario (s0) does not assume the existence of a reference set of IN samples to decide whether a new input sample is OOD. Softmax-based detectors such as MSP (Hendrycks & Gimpel, 2016), Energy (Liu et al., 2020) or the sequence likelihood3 (Arora et al., 2021) are examples of OOD scores operating under s0.\n\nUnder these assumptions, our OOD detector RAINPROOF is composed of three steps. For a given input x with generated sentence ˆy:\n\n1. We first use fθ to extract the step-by-step sequence of soft distributions S(x). 2. We then compute an anomaly score (aI(x)) by averaging a step-by-step score provided by I. This step-by-step score is obtained by measuring the similarity between a reference distribution u ∈ P(Ω) and one element of S(x). Formally:\n\naI(x) =\n\n1 |S(x)|\n\n(cid:88)\n\np∈S(x)\n\nI (p∥u) ,\n\n(3)\n\nwhere |S(x)| = |ˆy|.\n\n3. The last step consists in thresholding the previous anomaly score aI(x). If aI(x) is over a given threshold γ, we classify x as an OOD example.\n\nInterpretation of Eq. 3. aI(x) measures the average dissimilarity of the probability distribution of the next token to normality (as defined by u). aI(x) also corresponds to the token average uncertainty of the model fθ to generate ˆy when the input is x. The intuition behind Eq. 3 is that the distributions produced by fθ, when exposed to an OOD sample, should be far from normality and thus should have a high score.\n\nChoice of u and I. The uncertainty definition of Eq. 3 depends on the choice of both the reference distribution u and the information measure I. A natural choice for u is the uniform distribution,\n\n3The likelyhood of the sequence is the same as the perplexity. In our work we report the log-likelyhood for\n\nnumerical stability reasons: i.e., aL(x) = − (cid:80)|ˆy|−1\n\nt=0\n\nlog pθ(ˆyt+1|x, ˆy⩽t)\n\n4\n\nUnder review as a conference paper at ICLR 2022\n\n|Ω| , · · · , 1\n\ni.e., u = [ 1 |Ω| ] which we will use in this work. It is worth pointing out that I(·||u) yields the negentropy of a distribution. Other possible choices for u include one hot or tf-idf distribution (Colombo et al., 2022b). For I, we rely on the R ́enyi divergence to obtain aDα and the Fisher-Rao distance to obtain aFR.\n\n3.3 RAINPROOF FOR THE REFERENCE SCENARIO (s1)\n\nIn the with reference scenario (s1), we assume that one has access to a reference set of IN samples R = {xi : (xi, yi) ∈ Dtrain}|R| i=1 where |R| is the size of the reference set. For example, the Mahalanobis distance works under this assumption. One of the weakness of Eq. 3 is that it imposes is to imposes an ad-hoc choice when using u (the uniform distribution). In s1, we can leverage R, to obtain a data-driven notion normality.\n\nUnder s1, our OOD detector RAINPROOF follows these four steps:\n\n1. (Offline) For each xi ∈ R, we generate ˆyi and the associated sequence of probability distributions (S(xi)). Overall we thus generate (cid:80) x∈R |ˆyi| probability distributions which could explode for long sequences4. To overcome this limitation, we rely on the bag of distributions of each sequence (Colombo et al., 2022b). We form the set of these bags of distributions\n\n ̄S ∗ =\n\n(cid:91)\n\nxi∈R\n\n \n\n\n\n1 |S(xi)|\n\n \n\np\n\n\n\n.\n\n(cid:88)\n\np∈S(xi)\n\n(4)\n\n2. (Online) For a given input x with generated sentence ˆy, we compute its bag of distributions representation\n\n ̄p(x) =\n\n1 |S(x)|\n\n(cid:88)\n\np.\n\np∈S(x)\n\n(5)\n\n3. (Online) For x, we then compute an anomaly score a⋆ Formally, a⋆\n\nI(x) is defined as:\n\nI(x) by projecting ̄p(x) on the set ̄S ∗.\n\na⋆\n\nI(x) = min p∈ ̄S ⋆\n\nI(p∥ ̄p(x)).\n\n(6)\n\nWe denote p⋆(x) = arg min\n\np∈ ̄S ∗\n\nI(p∥ ̄p(x)).\n\n4. The last step consists of thresholding the previous anomaly score aI(x). If aI(x) is over a given threshold γ, we classify x as an OOD example.\n\nInterpretation of Eq. 6. aI(x) relies on a Generalized Information Projection (Kullback, 1954; Csisz ́ar, 1975; 1984)5 which measures the similarity between ̄p(x) and the set ̄S ∗. Note that the closest element of ̄S ∗ in the sens of I can give insights on the decision of the detector. It allows to interpret the decision of the detector as we will see in Tab. 5.\n\nChoice of I. Similarly to Sec. 3.2, we will rely on the R ́enyi divergence to define a⋆ Fisher-Rao distance a⋆\n\nRα\n\nFR(x).\n\n(x) and the\n\n4 RESULTS ON LOFTER\n\n4.1 LOFTER: LANGUAGE OUT OF DISTRIBUTION PERFORMANCE BENCHMARK\n\nLOFTER for NMT. We consider two main types of changes: language changes and domain changes, which both can occur in real-world situations. For each shift, we rely on pretrained generators from the HuggingFace Hub. Further experiemental details are relegated to Ap. A. Language shifts can\n\n4It is also worth pointing that doing a projection at each timestep would require a per-step reference set in addition to the computational time required to actually compute the projections, therefore we decided to aggregate the probability distributions over the sequence.\n\n5The minimization problem of Eq. 6 finds numerous connections in the theory of large deviation (Sanov,\n\n1958) or in statistical physics (Jaynes, 1957).\n\n5\n\nUnder review as a conference paper at ICLR 2022\n\nTable 1: Summary of the performance and computational cost of every detector.\n\n(a) Summary of the performance of our detectors (Ours) compared to commonly used strong baselines (Bas.). We report in bold the best detector for each scenario and we underline the best overall.\n\nLanguage shifts\n\nDomain shifts\n\nDialog shifts\n\nAUROC\n\nFPR\n\nF1\n\nAUROC\n\nFPR\n\nF1\n\nAUROC\n\nFPR\n\nF1\n\ns0\n\ns1\n\nOurs\n\nBas.\n\nOurs\n\nBas.\n\naDα aFR aE aMSP aL aD∗ aFR∗ aM aC\n\nα\n\n0.95 0.93 0.89 0.87 0.78 0.88 0.88 0.92 0.71\n\n0.25 0.28 0.44 0.44 0.79 0.34 0.35 0.26 0.80\n\n0.84 0.83 0.77 0.75 0.50 0.78 0.77 0.73 0.62\n\n0.85 0.74 0.76 0.78 0.72 0.86 0.81 0.78 0.68\n\n0.62 0.87 0.78 0.77 0.89 0.50 0.69 0.59 0.76\n\n0.75 0.60 0.71 0.71 0.65 0.70 0.69 0.40 0.67\n\n0.79 0.72 0.65 0.66 0.65 0.86 0.76 0.84 0.72\n\n0.64 0.70 0.76 0.72 0.95 0.52 0.75 0.55 0.61\n\n0.66 0.64 0.57 0.21 0.62 0.59 0.38 0.56 0.48\n\n(b) Computation time (in seconds) for the different detectors. Off. (Onl.) stands online) for offline (resp. time.\n\nScore Off.\n\naDα aMSP aM aD∗\n\nα\n\n40s\n\nOnl. 2.10−3 s 1.10−4 s 3.10−3 s 9.10−2 s\n\nappear when a translation system is exposed to a language that is extremely similar to the language the system has been trained on (e.g., Afrikaans for a system trained on Dutch) and, therefore, can lead to significant translation errors (see Tab. 7)). For language shifts, we focus on closely related language pairs coming from the Tatoeba dataset (Tiedemann, 2012b) (see Tab. 6). We study the shifts induced by Catalan-Spanish, Portugese-Spanish and Afrikaans-Dutch. Domain shifts, which occur when the model is exposed to a specific topic that was not seen during training, can also affect the quality of the translation (see Tab. 4). To simulate domain shifts, we use the language Tatoeba MT dataset (Tiedemann, 2020) and the news commentary dataset (Tiedemann, 2012b) as base datasets and the shifts are induced by the EuroParl dataset (Tiedemann, 2012a) and EMEA (Tiedemann, 2012b) dataset.\n\nLOFTER for dialogs. For conversational agents, an interesting scenario is when a goal-oriented agent designed to handle a specific type of conversations (e.g., customer conversations, daily dialogue) is exposed to an unexpected conversation. In this case, it is crucial to interrupt the agent so it does not damage the user’s trust with misplaced responses (Perez et al., 2022). We rely on the Multi WOZ dataset (Zang et al., 2020), a human to human dataset collected in the Wizard-of-Oz set-up (Kelley, 1984), for IN distribution data. This choice is mostly motivated by the availability of pretrained models on Multi WOZ. For dialog shifts, we use spoken datasets coming from various sources which are part of the SILICONE benchmark (Chapuis et al., 2020). Specifically, we use a goaloriented dataset (i.e., Switchboard Dialog Act Corpus (SwDA) (Stolcke et al., 2000)), a multi-party meetings dataset (i.e., MRDA (Shriberg et al., 2004) and Multimodal EmotionLines Dataset MELD (Poria et al., 2018)), daily communication dialogs ( i.e., DailyDialog DyDA Li et al. (2017)), and scripted scenarii (i.e., IEMOCAP Tripathi et al. (2018)). We refer the curious reader to Sec. A.4 for more details on each dataset.\n\nMetrics. OOD detection is usually framed as an unbalanced binary classification problem where the class of interest is OUT. We can assess the performance of our OOD detectors focusing on the False alarm rate (FPR) and on the True detection rate (TPR). To evaluate the performance on the OOD task we report the AUROC and the FPR. Area Under the Receiver Operating Characteristic curve (AUROC) (Bradley, 1997). The AUROC can be interpreted as the probability that an IN-distribution example has an higher anomaly score than an OOD sample. For this metric, higher is better. False Positive Rate at r% True Positive Rate (FPR). In many practical application, we have to detect at least r% of the the OOD samples. This corresponds to pre-defined safety level. FPR quantifies the share of IN samples we wrongly detect under this constraint. It leads to select a threshold γr such that the corresponding TPR equals r. In our work r is set to 95%. Additional details on these metrics can be found in Sec. A.1. F1, precision and recall. In addition we report the F1 scores of the detectors with a threshold designed such that 80% of the IN dataset is actually classified as IN.\n\n4.2 EXPERIMENTS IN MACHINE TRANSLATION AND RESULTS\n\nResults on language shifts. We assess, for each language pair, the OOD detection performance of RAINPROOF and report the average AUROC and FPR in Tab. 1a. We provide the detailed results in Tab. 8. We find that our no-reference methods (aDα and aFR) achieve better performance that\n\n6\n\nUnder review as a conference paper at ICLR 2022\n\ncommon no-reference baselines but also outperform the reference-based baseline. In particular, aDα , by achieving an AUROC of 0.95 and FPR of 0.25, outperforms all considered methods. Moreover, while no-reference baselines only capture up to 62% of the OOD samples on average, ours detect up to 83.5%, achieving even better results than the with-reference baseline (75.3%).\n\nScenario\n\nTable 2: Correlation between OOD scores and translation metrics BLEU and BERT-S on domain shifts datasets.\n\nResults on domain shifts. We evaluate the OOD detection performance of RAINPROOF on domain shifts in Spanish and German with technical medical data and parliamentary data. We report the average OOD detecIn s0, tion performance in Tab. 1a. we observe that aDα and aFR outperform the strongest baselines (i.e., Energy, MSP and sequence likelihood) by several AUROC points. Interestingly enough even our no-reference detectors outperform the referencebased baseline (i.e., aM ). However, we find that relying on a reference set is a must-have in terms of FPR. While aDα achieves similar AUROC performance to its information projection counterpart aD∗\n\nα , the latter achieve much better FPR.\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\n-0.29 -0.36 -0.19 -0.47 -0.15 -0.12 -0.11 -0.02 0.02\n\n-0.22 -0.26 -0.19 -0.45 -0.16 0.00 0.00 -0.05 0.00\n\n-0.09 -0.19 -0.39 -0.49 -0.37 -0.09 -0.10 -0.08 0.07\n\n-0.26 -0.30 -0.24 -0.51 -0.19 0.00 0.00 -0.04 0.00\n\n-0.17 -0.24 -0.26 -0.49 -0.24 -0.19 -0.17 -0.13 -0.06\n\n-0.18 -0.27 -0.33 -0.48 -0.29 -0.09 -0.12 0.01 0.06\n\nBertscore f1\n\nBleu score\n\nBaselines\n\nBaselines\n\nScore\n\nOUT\n\nOUT\n\nALL\n\nOurs\n\nALL\n\nOurs\n\nIN\n\nIN\n\ns1\n\ns0\n\nα\n\n4.3 EXPERIMENTS IN DIALOG GENERATION AND RESULTS\n\nResults on Dialog shifts. The dialog shifts benchmark is more difficult than NMT benchmark as all detectors achieve lower performances. It is the only case where our no-reference detectors do not outperform the Mahalanobis baseline and achieve only 0.79 in AUROC. The best baseline is the Mahalanobis distance and achieves better performance on dialog task than on NMT domain shifts reaching an AUROC of 0.84. However, our reference based detector based on the R ́enyi information projection secures better AUROC (0.86) and better FPR (0.52). Even though RAINPROOF outperforms all the baselines, shifts in dialog are hard to detect and will require further investigations. Non-aggregated results for dialog are provided in Ap. C. They show that RAINPROOF consistently outperforms baselines on all datasets.\n\nImportance of distribution tails. Our results show that, when it comes to domain shift (domain shifts in translation or dialog shifts), reference-based detectors are required to obtain good results. They also show that, the more these detectors take into account the tail of the distributions, the better they are, as displayed in Sec. B.1. We find that low values of α (near 0) yields better results with the R ́enyi Information projection aD∗ α . It suggests that the tail of the distributions used during text generation carries context information and insights on the processed texts. Such results are consistent with findings of recent works in the context of automatic evaluation of text generation (Colombo et al., 2022b). Comparison to the Mahalanobis distance. Our reference-based detector work with a small reference set. In our experiments, we use reference sets of size 10 to 2000. The Mahalanobis distance requires to approximate the covariance matrix of the reference set. In our simulations, the embeddings of dimension 512 make the estimation unreliable. On the contrary, RAINPROOF, which rely on information projections, remains numerically sound with small reference set.\n\nFigure 1: Impact of α on the performance of the R ́enyi information projection for dialog shifts detection. A smaller α increases the weight of the tail of the distribution. An α of 0 would consist in counting the number of the common non zero elements.\n\n7\n\n0.050.20.50.81.11.31.61.90.50.60.70.80.9AUROC||400800120016002000Under review as a conference paper at ICLR 2022\n\nTable 3: Average impact of different OOD detectors on the BLEU score for different type of dataset: IN data only, OOD data and the combination of both ALL. For each we report the absolute average BLEU score (Abs.), the average gains in BLEU (G.s) compared to a setting without OOD filtering (fθ only) and the share of the subset removed by the detector (R.Sh.). These results are achieved by setting γ such that we remove 20% of the IN dataset.\n\nOOD Absolute Gains Removed shares Absolute Gains Removed shares Absolute Gains Removed shares\n\nALL\n\nIN\n\ns0\n\ns1\n\nOurs\n\nBas.\n\nOurs\n\nBas.\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\n53.6 57.2 56.6 56.3 58.1 52.4 54.0 54.0 54.2 53.6\n\n+0.0 +3.6 +3.1 +2.7 +4.5 -1.2 +0.4 +0.4 +0.7 +0.1\n\n0.0% 19.7% 19.0% 20.0% 19.2% 18.5% 19.2% 19.4% 14.6% 20.0%\n\n30.8 40.9 39.9 31.9 34.6 26.7 31.6 31.6 31.3 31.6\n\n+0.0 +10.1 +9.1 +1.1 +3.8 -4.1 +0.8 +0.8 +0.5 +0.9\n\n0.0% 57.1% 60.8% 31.9% 43.7% 38.2% 61.3% 61.4% 17.9% 59.0%\n\n44.4 55.6 54.6 48.3 52.4 43.2 48.9 49.0 46.1 47.4\n\n+0.0 +11.2 +10.1 +3.9 +8.0 -1.2 +4.5 +4.5 +1.6 +3.0\n\n0.0% 35.1% 36.7% 24.1% 28.9% 28.1% 38.0% 38.1% 15.5% 37.9%\n\n5 TOWARDS A PRACTICAL EVALUATION OF OOD DETECTORS\n\nFollowing previous work, we measure the performance of the detectors on the OOD detection task based on AUROC and FPR. However, this evaluation framework neglects the impact of the detector on the overall system’s performance. We identify three main evaluation criteria that are important in practice: execution time, overall system performance in terms of quality of the generated sentences, and interpretability of the decision. Our study is conducted on NMT because due to the existence of relevant and widely adopted metrics for assessing the quality of a generated sentence (i.e., BLEU (Papineni et al., 2002) and BERTSCORE (BERT-S) (Unanue et al., 2021)).\n\n5.1 COMPLEXITY STUDY\n\nRuntime and memory costs. We report in Tab. 1b the runtime of all methods. Detectors for s0 are faster than the ones for s1. Contrarily to detectors using references, the no-reference detectors do not require additional memory. They can be setup easily in a plug&play manner at the output of any model.\n\nNumerical stability. The Mahalanobis distance requires to estimate both μ and Σ−1 (see Sec. A.6). The dimension of the latent space of the considered pre-trained model is either 768 or 512. In this setting, when the size of the reference set is small, the estimation of the Mahalanobis parameters is numerically unstable. For s1, RAINPROOF relies on information projection and does not involve numerically unstable computations but requires a larger memory footprint (0.5 GB) to store the reference set (2000 probability distributions of dimension 50K).\n\n5.2\n\nIMPACT OF OOD FILTERING ON TRANSLATION QUALITY\n\nThe main objective of OOD filtering is to remove samples that are far from the training distribution. On these samples, the user has no guarantee that the model will produce a good quality translation. In this experiment, we compare the performance of the system with and without the different detectors in terms of the quality of the generated sentence.\n\nGlobal performance. In Tab. 3, we report the global performance of the systems (fθ) without and with OOD detectors on IN samples, OOD samples and all samples (ALL). From the first row of Tab. 3, we notice that OOD samples are harmful to the model. We observe that, in most of the cases, adding detectors increases the model performance on IN, OOD and all samples. Exceptions include aM SP (for OOD, IN and ALL) and aM (for OOD). Results indicate that no-reference RAINPROOF outperforms the reference-based version of RAINPROOF. Thus, OOD detector evaluation should consider the final task performance. Overall, it is worth noting that directly adapting classical OOD detection methods (e.g., MSP or Energy) to the sequence generation problem leads to poor results in terms of performance gains (i.e., as measured by BLEU or BERT-S). In others words, the final task does not benefit from adding classical OOD detectors.\n\nFiner performance analysis. In Tab. 4, we report the per-shift-types performance of fθ with and without OOD detector. In Tab. 4, we observe a decrease in performance in the case of language and\n\n8\n\nUnder review as a conference paper at ICLR 2022\n\nTable 4: Detailed impacts on NMT performance results per tasks (Domain- or Language-shifts) of the different OOD detectors. We present results on the different part of the data: IN data, OOD data and the combination of both, ALL. For each we report the absolute average BLEU score (Abs.), the average gains in BLEU (G.s.) compared to a setting without OOD filtering (fθ only) and the share of the subset removed by the detector (R.Sh.). We provide more detailed results on each dataset in Ap. D\n\nAbs.\n\n46.9 50.5 49.7 49.3 50.7 45.8 47.1 47.1 47.6 46.9\n\nIN G.\n\n+0.0 +3.6 +2.8 +2.4 +3.8 -1.1 +0.2 +0.2 +0.7 -0.0\n\nDomain shifts OOD G.\n\nRh. Abs.\n\nRh. Abs.\n\n0.0% 43.3 19.6% 48.5 19.3% 47.6 20.0% 45.5 19.2% 47.5 19.2% 33.4 18.9% 37.8 18.9% 37.7 13.6% 43.5 20.0% 43.0\n\n+0.0 +5.2 +4.4 +2.2 +4.3 -9.9 -5.4 -5.5 +0.3 -0.3\n\n0.0% 45.1 29.8% 50.5 40.6% 49.2 17.8% 47.6 24.2% 49.9 45.7% 40.8 62.7% 45.9 62.6% 46.0 3.6% 45.4 61.9% 44.4\n\nALL G.\n\n+0.0 +5.4 +4.1 +2.5 +4.8 -4.3 +0.9 +0.9 +0.3 -0.7\n\nRh. Abs.\n\n0.0% 60.2 24.7% 63.8 29.9% 63.5 18.9% 63.3 21.7% 65.4 32.5% 59.0 40.8% 60.9 40.7% 60.9 8.6% 60.9 41.0% 60.4\n\nIN G.\n\n+0.0 +3.6 +3.3 +3.1 +5.2 -1.3 +0.6 +0.7 +0.7 +0.1\n\nLanguage shifts OOD G.\n\nRh. Abs.\n\nRh. Abs.\n\n0.0% 18.3 19.8% 33.3 18.7% 32.1 20.0% 18.4 19.2% 21.6 17.7% 20.1 19.5% 25.4 19.9% 25.5 15.6% 19.1 20.0% 20.3\n\n+0.0 +15.0 +13.8 +0.1 +3.3 +1.8 +7.1 +7.2 +0.8 +2.0\n\n0.0% 43.8 84.3% 60.7 81.0% 60.0 46.0% 49.1 63.2% 54.9 30.8% 45.7 60.0% 51.9 60.2% 52.0 32.2% 46.7 56.0% 50.4\n\nALL G.\n\n+0.0 +17.0 +16.2 +5.3 +11.1 +1.9 +8.2 +8.2 +2.9 +6.6\n\nRh.\n\n0.0% 45.4% 43.5% 29.4% 36.1% 23.7% 35.2% 35.5% 22.5% 34.9%\n\ns0\n\ns1\n\nOurs\n\nBas.\n\nOurs\n\nBas.\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\ndomain shifts, the latter being more harmful. On domain shifts, we observe that reference-based detectors decrease system’s performance on OOD samples. This means that the detectors tend to filter out samples that are well-handled by the model and ignore sentences that are not. It is worth noting that reference-based detectors remove, in proportion, twice as many samples as their no-reference counterparts, while the threshold selection procedure remains the same. This observation also holds when removing less samples (i.e., calibrating γ that we remove 10%, 5% or even 1% of the IN dataset) (Tab. 15).\n\nThreshold free analysis. In Tab. 2, we report the correlation between OOD scores and final task performance for the case of domain shifts. We refer the reader to Tab. 14 for the results on language shifts. We observe that the likelihood score is the most correlated with the final sentence quality, as measured by BLEU or BERT-S. This finding illustrates that higher correlation with sentence quality does not necessarily translate into higher performance gains when filtering OOD samples. This result suggests that Quality Estimation (Specia et al., 2010; Blatz et al., 2004), while closely related, is a different problem.\n\n5.3 TOWARDS AN INTERPRETABLE DECISION\n\nAn important dimension fostering adoption is the ability to verify the decision taken by the automatic system (Montavon et al., 2018). RAINPROOF offers a step in this direction when used with references: for each input sample, RAINPROOF finds the closest sample (in the sens of the Information Projection) in the reference set to take its decision. We present in Tab. 5 some OOD samples along with their translation scores, projection scores, and their projection on the reference set. We notice that, in general, sentences that are close to the reference set, and whose projection has a close meaning, are better handled by fθ. Therefore, one can visually interpret the prediction of RAINPROOF, and validate it. This observation further validate our method.\n\n6 CONCLUSIONS\n\nTable 5: OOD inputs, their translations and projections onto the reference set. The first 2 are far from the reference set and not well translated whereas the next 2 are very close to the reference set and well translated. We can, for that matter, notice that the projection is quite close to the input sentence grammatically speaking.\n\nSource\n\nAhir a la nit v`arem treballar fins a les deu.\n\nGround truth\n\nLast night we worked until 10 p.m.\n\nGenerated p⋆(x)\n\nAhir a la nit v`arem treballar fins a les deu.\n\nDar gato por liebre.\n\nSource\n\nAquesta cola s’ha esbravat i no t ́e bon gust.\n\nGround-truth\n\nThis cola has lost its fizz and doesn’t taste any good.\n\nGenerated p⋆(x)\n\nThis tail s’ha esbravat i no tea bon gust.\n\nEsta cuchara es de t ́e.\n\nsource\n\nAquesta ́es una carta molt estranya.\n\nGround-truth\n\nThis is a very strange letter.\n\nGenerated p⋆(x)\n\nThis is a molt estranya card.\n\nEste carro es chiquito.\n\nBLEU 3.75\n\nScore 1.23\n\nBLEU 4.09\n\nScore 1.14\n\nBLEU 26.27\n\nScore 0.74\n\nIn this work, we introduced both a detection framework called RAINPROOF as well as a new benchmark called LOFTER for detecting OOD samples when using textual generators in the black-box scenario. Our work adopts an operational perspective by not only considering OOD performance but also task-specific metrics. Our results show that, despite the good results obtained in\n\nAustr`alia no ́es `Austria.\n\nGenerated p⋆(x)\n\nAustr`alia is not Austria.\n\nAustralia isn’t Austria.\n\nLa vida no es f ́acil.\n\nGround-truth\n\nBLEU 21.86\n\nScore 0.82\n\nsource\n\n9\n\nUnder review as a conference paper at ICLR 2022\n\npure OOD detection, OOD filtering can harm the performance of the final system, as it is the case for MSP or Mahanalobis. We found that, RAINPROOF breaks this curse and induces significant gains in translation performance both on OOD samples and in general. In conclusion, this work paves the way to the development of detectors tailored for text generators and calls for a global evaluation when benchmarking future OOD detectors.\n\n10\n\nUnder review as a conference paper at ICLR 2022\n\nREFERENCES\n\nShun-ichi Amari. Differential-geometrical methods in statistics, volume 28. Springer Science &\n\nBusiness Media, 2012.\n\nAlessandro Antonucci, Alessandro Facchini, and Lilith Mattei. Structural learning of probabilistic sentential decision diagrams under partial closed-world assumption. 2021. doi: 10.48550/ARXIV. 2107.12130. URL https://arxiv.org/abs/2107.12130.\n\nUdit Arora, William Huang, and He He. Types of out-of-distribution texts and how to detect them.\n\narXiv preprint arXiv:2109.06827, 2021.\n\nMich ́ele Basseville. Divergence measures for statistical data processing—an annotated bibliography.\n\nSignal Processing, 93(4):621–633, 2013.\n\nJohn Blatz, Erin Fitzgerald, George Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and Nicola Ueffing. Confidence estimation for machine translation. In Coling 2004: Proceedings of the 20th international conference on computational linguistics, pp. 315–321, 2004.\n\nAndrew P Bradley. The use of the area under the roc curve in the evaluation of machine learning\n\nalgorithms. Pattern recognition, 30(7):1145–1159, 1997.\n\nL. Brillouin. The negentropy principle of information. Journal of Applied Physics, 24(9):1152– 1163, September 1953. doi: 10.1063/1.1721463. URL https://doi.org/10.1063/1. 1721463.\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.\n\nEmile Chapuis, Pierre Colombo, Matteo Manica, Matthieu Labeau, and Chlo ́e Clavel. HierarIn Findings of the Association chical pre-training for sequence labelling in spoken dialog. for Computational Linguistics: EMNLP 2020, pp. 2636–2648, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.findings-emnlp.239. URL https://www.aclweb.org/anthology/2020.findings-emnlp.239.\n\nJianbo Chen, Michael I Jordan, and Martin J Wainwright. Hopskipjumpattack: A query-efficient decision-based attack. In 2020 ieee symposium on security and privacy (sp), pp. 1277–1294. IEEE, 2020.\n\nAndrzej Cichocki, Sergio Cruces, and Shun-ichi Amari. Generalized alpha-beta divergences and their\n\napplication to robust nonnegative matrix factorization. Entropy, 13(1):134–170, 2011.\n\nPierre Colombo, Guillaume Staerman, Nathan Noiry, and Pablo Piantanida. Learning disentangled textual representations via statistical measures of similarity. arXiv preprint arXiv:2205.03589, 2022a.\n\nPierre Jean A Colombo, Chlo ́e Clavel, and Pablo Piantanida. Infolm: A new metric to evaluate summarization & data2text generation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pp. 10554–10562, 2022b.\n\nSueli IR Costa, Sandra A Santos, and Joao E Strapasson. Fisher information distance: A geometrical\n\nreading. Discrete Applied Mathematics, 197:59–69, 2015.\n\nImre Csisz ́ar.\n\nInformation-type measures of difference of probability distributions and indirect\n\nobservation. studia scientiarum Mathematicarum Hungarica, 2:229–318, 1967.\n\nImre Csisz ́ar. I-divergence geometry of probability distributions and minimization problems. The\n\nannals of probability, pp. 146–158, 1975.\n\nImre Csisz ́ar. Sanov property, generalized i-projection and a conditional limit theorem. The Annals\n\nof Probability, pp. 768–793, 1984.\n\nJesse Davis and Mark Goadrich. The relationship between precision-recall and roc curves. Proceedings of the 23rd international conference on Machine learning, pp. 233–240, 2006.\n\nIn\n\n11\n\nUnder review as a conference paper at ICLR 2022\n\nAngela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep Baines, Onur Celebi, Guillaume Wenzek, Vishrav Chaudhary, et al. Beyond englishcentric multilingual machine translation. J. Mach. Learn. Res., 22(107):1–48, 2021.\n\nGeli Fei and Bing Liu. Breaking the closed world assumption in text classification. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 506–514, 2016.\n\nPeter Fletcher, Hughes Hoyle, and C Wayne Patty. Foundations of discrete mathematics. Brooks/Cole,\n\nFlorence, KY, November 1990.\n\nHironori Fujisawa and Shinto Eguchi. Robust parameter estimation with a small bias against heavy\n\ncontamination. Journal of Multivariate Analysis, 99(9):2053–2081, 2008.\n\nEduardo Dadalto Camara Gomes, Florence Alberge, Pierre Duhamel, and Pablo Piantanida. Igeood: An information geometry approach to out-of-distribution detection. arXiv preprint arXiv:2203.07798, 2022.\n\nMatan Haroush, Tzviel Frostig, Ruth Heller, and Daniel Soudry. A statistical framework for efficient\n\nout of distribution detection in deep neural networks, 2021.\n\nMatthias Hein, Maksym Andriushchenko, and Julian Bitterwolf. Why relu networks yield highconfidence predictions far away from the training data and how to mitigate the problem. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 41–50, 2019.\n\nErnst Hellinger. Neue begr ̈undung der theorie quadratischer formen von unendlichvielen ver ̈anderlichen. Journal f ̈ur die reine und angewandte Mathematik, 1909(136):210–271, 1909.\n\nDan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution\n\nexamples in neural networks. arXiv preprint arXiv:1610.02136, 2016.\n\nDan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. In International Conference on Learning Representations, 2017.\n\nYen-Chang Hsu, Yilin Shen, Hongxia Jin, and Zsolt Kira. Generalized odin: Detecting out-ofdistribution image without learning from out-of-distribution data. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 10951–10960, 2020.\n\nHaiwen Huang, Zhihan Li, Lulu Wang, Sishuo Chen, Bin Dong, and Xinyu Zhou. Feature space\n\nsingularity for out-of-distribution detection. arXiv preprint arXiv:2011.14654, 2020.\n\nRui Huang, Andrew Geng, and Yixuan Li. On the importance of gradients for detecting distributional\n\nshifts in the wild. ArXiv, abs/2110.00218, 2021.\n\nCarel Jansen, Robert Schreuder, and Anneke Neijt. The influence of spelling conventions on perceived plurality in compounds: A comparison of afrikaans and dutch. Written language & literacy, 10(2): 185–194, 2007.\n\nEdwin T Jaynes. Information theory and statistical mechanics. Physical review, 106(4):620, 1957.\n\nJohn F Kelley. An iterative design methodology for user-friendly natural language office information\n\napplications. ACM Transactions on Information Systems (TOIS), 2(1):26–41, 1984.\n\nPolina Kirichenko, Pavel Izmailov, and Andrew G Wilson. Why normalizing flows fail to detect out-of-distribution data. In H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 20578–20589. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/ ecb9fe2fbb99c31f567e9823e884dbec-Paper.pdf.\n\nSolomon Kullback. Information theory and statistics. Courier Corporation, 1954.\n\nSolomon Kullback. Information Theory and Statistics. John Wiley, 1959.\n\n12\n\nUnder review as a conference paper at ICLR 2022\n\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. Advances in neural information processing systems, 31, 2018a.\n\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems 31, pp. 7167–7177. Curran Associates, Inc., 2018b.\n\nKimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting out-of-distribution samples and adversarial attacks, 2018c. URL https://arxiv.org/abs/ 1807.03888.\n\nYanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. Dailydialog: A manually labelled multi-turn dialogue dataset. In Proceedings of The 8th International Joint Conference on Natural Language Processing (IJCNLP 2017), 2017.\n\nShiyu Liang, Yixuan Li, and R. Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum?id=H1VGkIxRZ.\n\nWeitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection.\n\nAdvances in Neural Information Processing Systems, 2020.\n\nYifei Ming, Yiyou Sun, Ousmane Dia, and Yixuan Li. Cider: Exploiting hyperspherical embeddings\n\nfor out-of-distribution detection. arXiv preprint arXiv:2203.04450, 2022.\n\nSwaroop Mishra, Anjana Arunkumar, Bhavdeep Sachdeva, Chris Bryan, and Chitta Baral. Dqi:\n\nMeasuring data quality in nlp, 2020. URL https://arxiv.org/abs/2005.00816.\n\nGr ́egoire Montavon, Wojciech Samek, and Klaus-Robert M ̈uller. Methods for interpreting and\n\nunderstanding deep neural networks. Digital signal processing, 73:1–15, 2018.\n\nKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for autoIn Proceedings of the 40th Annual Meeting of the matic evaluation of machine translation. Association for Computational Linguistics, pp. 311–318, Philadelphia, Pennsylvania, USA, July 2002. Association for Computational Linguistics. doi: 10.3115/1073083.1073135. URL https://aclanthology.org/P02-1040.\n\nJitendra Parmar, Satyendra Singh Chouhan, Vaskar Raychoudhury, and Santosh Singh Rathore. Open-world machine learning: Applications, challenges, and opportunities, 2021. URL https: //arxiv.org/abs/2105.13448.\n\nEthan Perez, Saffron Huang, Francis Song, Trevor Cai, Roman Ring, John Aslanides, Amelia Glaese, Nat McAleese, and Geoffrey Irving. Red teaming language models with language models. arXiv preprint arXiv:2202.03286, 2022.\n\nBen Peters, Vlad Niculae, and Andr ́e FT Martins. Sparse sequence-to-sequence models. arXiv\n\npreprint arXiv:1905.05702, 2019.\n\nMarine Picot, Francisco Messina, Malik Boudiaf, Fabrice Labeau, Ismail Ben Ayed, and Pablo Piantanida. Adversarial robustness via fisher-rao regularization. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.\n\nJulianna Pinele, Jo ̃ao E. Strapasson, and Sueli I. R. Costa. The fisher–rao distance between multivariate normal distributions: Special cases, bounds and applications. Entropy, 22(4), 2020. ISSN 10994300. doi: 10.3390/e22040404. URL https://www.mdpi.com/1099-4300/22/4/404.\n\nSoujanya Poria, Devamanyu Hazarika, Navonil Majumder, Gautam Naik, Erik Cambria, and Rada Mihalcea. Meld: A multimodal multi-party dataset for emotion recognition in conversations. arXiv preprint arXiv:1810.02508, 2018.\n\n13\n\nUnder review as a conference paper at ICLR 2022\n\nIgor M. Quintanilha, Roberto de M. E. Filho, Jos ́e Lezama, Mauricio Delbracio, and Leonardo O. Nunes. Detecting out-of-distribution samples using low-order deep features statistics, 2019. URL https://openreview.net/forum?id=rkgpCoRctm.\n\nAlec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al.\n\nImproving language\n\nunderstanding by generative pre-training. 2018.\n\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language\n\nmodels are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n\nC Radhakrishna Rao. Information and the accuracy attainable in the estimation of statistical parame-\n\nters. In Breakthroughs in statistics, pp. 235–247. Springer, 1992.\n\nJie Ren, Stanislav Fort, Jeremiah Liu, Abhijit Guha Roy, Shreyas Padhy, and Balaji Lakshminarayanan. A simple fix to mahalanobis distance for improving near-ood detection. arXiv preprint arXiv:2106.09022, 2021a.\n\nJie Ren, Stanislav Fort, Jeremiah Liu, Abhijit Guha Roy, Shreyas Padhy, and Balaji Lakshminarayanan.\n\nA simple fix to mahalanobis distance for improving near-ood detection, 2021b.\n\nCynthia Rudin and Joanna Radin. Why are we using black box models in ai when we don’t need to?\n\na lesson from an explainable ai competition. 2019.\n\nSeonghan Ryu, Seokhwan Kim, Junhwi Choi, Hwanjo Yu, and Gary Geunbae Lee. Neural sentence embedding using only in-domain sentences for out-of-domain sentence detection in dialog systems. Pattern Recognition Letters, 88:26–32, 2017.\n\nIvan N Sanov. On the probability of large deviations of random variables. United States Air Force,\n\nOffice of Scientific Research, 1958.\n\nChandramouli Shama Sastry and Sageev Oore. Detecting out-of-distribution examples with Gram matrices. In Hal Daum ́e III and Aarti Singh (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 8491–8501. PMLR, 13–18 Jul 2020. URL https://proceedings.mlr.press/v119/sastry20a. html.\n\nElizabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy Ang, and Hannah Carvey. The icsi meeting recorder dialog act (mrda) corpus. Technical report, INTERNATIONAL COMPUTER SCIENCE INST BERKELEY CA, 2004.\n\nLucia Specia, Dhwaj Raj, and Marco Turchi. Machine translation evaluation versus quality estimation.\n\nMachine translation, 24(1):39–50, 2010.\n\nAndreas Stolcke, Klaus Ries, Noah Coccaro, Elizabeth Shriberg, Rebecca Bates, Daniel Jurafsky, Paul Taylor, Rachel Martin, Marie Meteer, and Carol Van Ess-Dykema. Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational Linguistics, 26(3): 339–371, 2000.\n\nYiyou Sun, Chuan Guo, and Yixuan Li. React: Out-of-distribution detection with rectified activations.\n\nArXiv, abs/2111.12797, 2021.\n\nJorg Tiedemann. Parallel data, tools and interfaces in opus. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis (eds.), Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may 2012a. European Language Resources Association (ELRA). ISBN 978-2-9517408-7-7.\n\nJ ̈org Tiedemann. The Tatoeba Translation Challenge – Realistic data sets for low resource and multilingual MT. In Proceedings of the Fifth Conference on Machine Translation, pp. 1174– 1182, Online, November 2020. Association for Computational Linguistics. URL https://www. aclweb.org/anthology/2020.wmt-1.139.\n\n14\n\nUnder review as a conference paper at ICLR 2022\n\nJ ̈org Tiedemann and Santhosh Thottingal. OPUS-MT — Building open translation services for the World. In Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT), Lisbon, Portugal, 2020.\n\nJ ̈org Tiedemann. Parallel data, tools and interfaces in opus. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Ugur Dogan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis (eds.), Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may 2012b. European Language Resources Association (ELRA). ISBN 978-2-9517408-7-7.\n\nSamarth Tripathi, Sarthak Tripathi, and Homayoon Beigi. Multi-modal emotion recognition on\n\niemocap dataset using deep learning. arXiv preprint arXiv:1804.05788, 2018.\n\nInigo Jauregi Unanue, Jacob Parnell, and Massimo Piccardi. Berttune: Fine-tuning neural machine\n\ntranslation with bertscore, 2021. URL https://arxiv.org/abs/2106.02208.\n\nSachin Vernekar, Ashish Gaurav, Vahdat Abdelzad, Taylor Denouden, Rick Salay, and Krzysztof Czarnecki. Out-of-distribution detection in classifiers via generation, 2019a. URL https: //arxiv.org/abs/1910.04241.\n\nSachin Vernekar, Ashish Gaurav, Taylor Denouden, Buu Phan, Vahdat Abdelzad, Rick Salay, and Krzysztof Czarnecki. Analysis of confident-classifiers for out-of-distribution detection. arXiv preprint arXiv:1904.12220, 2019b.\n\nWeizhe Yuan, Graham Neubig, and Pengfei Liu. Bartscore: Evaluating generated text as text\n\ngeneration, 2021. URL https://arxiv.org/abs/2106.11520.\n\nXiaoxue Zang, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. Multiwoz 2.2: A dialogue dataset with additional annotation corrections and state tracking baselines. In Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, ACL 2020, pp. 109–117, 2020.\n\nRowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. Defending against neural fake news. Advances in neural information processing systems, 32, 2019.\n\nJingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. Pegasus: Pre-training with extracted gap-sentences for abstractive summarization. In International Conference on Machine Learning, pp. 11328–11339. PMLR, 2020.\n\nYizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen, Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing Liu, and Bill Dolan. Dialogpt: Large-scale generative pre-training for conversational response generation. arXiv preprint arXiv:1911.00536, 2019.\n\nZhi-Hua Zhou. Open-environment machine learning. National Science Review, 9(8):nwac123, 2022.\n\nQiuyu Zhu, Guohui Zheng, and Yingying Yan. Effective out-of-distribution detection in classifier\n\nbased on pedcc-loss, 2022. URL https://arxiv.org/abs/2204.04665.\n\nEv Zisselman and Aviv Tamar. Deep residual flow for out of distribution detection. In The IEEE\n\nConference on Computer Vision and Pattern Recognition (CVPR), June 2020.\n\n15\n\nUnder review as a conference paper at ICLR 2022\n\n7 APPENDIX\n\nA Experimental setting\n\nA.1 Additionnal Details on Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nA.2 Language pairs\n\nA.3 Samples .\n\n.\n\n.\n\n.\n\nA.4 Dialog datasets\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\nA.5 Choices of models .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nA.6 Generalization of existing OOD detectors to Sequence Generation . . . . . . . . .\n\nB Parameters tuning\n\nB.1 Impact of α .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n. .\n\n. . .\n\n. . . . .\n\n. . . . . . . . . . . . . . . . . . . . .\n\nC Performance of our detectors in OOD detection\n\nC.1 Summary of our results .\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nC.2 Detailed results of OOD detection performances . . . . . . . . . . . . . . . . . . .\n\nC.3 ROC AUC curves .\n\n.\n\n.\n\n.\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nD NTM performance\n\nD.1 Absolute performances .\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nD.2 Gains\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nD.3 Effect of a Larger threshold on NMT performance . . . . . . . . . . . . . . . . . .\n\nE Negative results\n\nE.1 Different aggregation of OOD metrics . . . . . . . . . . . . . . . . . . . . . . . .\n\nE.2 Negentropy of bag of distributions . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nE.3 Different reference distributions\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nE.4 Impact of additional finetuning on IN data . . . . . . . . . . . . . . . . . . . . . .\n\n17\n\n17\n\n17\n\n18\n\n18\n\n18\n\n18\n\n19\n\n19\n\n20\n\n20\n\n20\n\n21\n\n24\n\n24\n\n27\n\n27\n\n27\n\n27\n\n27\n\n28\n\n28\n\n16\n\nUnder review as a conference paper at ICLR 2022\n\nA EXPERIMENTAL SETTING\n\nIn this section we dive into the details and definitions of our experimental setting. First we present our OOD detection performance metrics (Sec. A.1), then we provide a couple samples for one of the small language shifts (Sec. A.3). We also discusse the choices of pretrained model (Sec. A.5) and how we adapted common OOD detectors to the text generation case (Sec. A.6).\n\nA.1 ADDITIONNAL DETAILS ON METRICS\n\nOOD Detection is usually an unbalanced binary classification problem where the class of interest is OUT. Let us denote Z the random variable corresponding to actually being out of distribution. We can assess the performance of our OOD detectors focusing on the False alarm rate and on the True detection rate. The False alarm rate or False positive rate (FPR) is the proportion of samples missclassified as OUT. For a score threshold γ, we have FPR = Pr (cid:0)a(x) > γ | Z = 0(cid:1). The True detection rate or True positive rate (TPR) is the proportion of OOD samples that are detected by the method. It is given by TPR = Pr (cid:0)a(x) > γ | Z = 1(cid:1).\n\nIn order to evaluate the performance of our methods we will focus and report mainly the AUROC and the FPR, we provide more detailed metrics and experiments in Sec. A.1.\n\nArea Under the Receiver Operating Characteristic curve (AUROC) Bradley (1997). The Receiver Operating Characteristic curve is curve obtained by plotting the True positive rate against the False positive rate. The area under this curve is the probability that an in-distribution example Xin has a anomaly score higher than an OOD sample xout: AUROC= Pr(a(xin) > a(xout)). It is given by γ (cid:55)→ (Pr (cid:0)a(x) > γ | Z = 0(cid:1), Pr (cid:0)a(x) > γ | Z = 1(cid:1)).\n\nFalse Positive Rate at 95% True Positive Rate (FPR). We accept to allow only a given false positive rate r corresponding to a defined level of safety and we want to know what share of positive samples we actually catch under this constraint. It leads to select a threshold γr such that the corresponding TPR equals r. At this threshold, one then computes: Pr(a(x) > γr | Z = 0) with γr s.t. TPR(γr) = r. r is chosen depending of the difficulty of task at hand and the required level of safety.\n\nFor the sake of brevity we present only AUROCand FPRmetrics in our aggregated results but we also used Detection error and Area Under the Precision-Recall curve metrics and those are presented in our full results section (Ap. C).\n\nDetection error. It is simply the probability of miss-classification for a given True positive rate.\n\nArea Under the Precision-Recall curve (AUPR-IN/AUPR-OUT) Davis & Goadrich (2006). The Precision-Recall curve plots the recall (true detection rate) against the precision (actual proportion of OOD amongst the predicted OOD). The area under this curve γ (cid:55)→ (Pr (cid:0)Z = 1 | s(X) ⩽ γ(cid:1), Pr (cid:0)s(X) ⩽ γ | Z = 1(cid:1)) captures the trade-off between precision and recall made by the model. A high value represents a high precision and a high recall i.e. the detector captures most of the positive samples while having few False positive.\n\nA.2 LANGUAGE PAIRS\n\nModel\n\nIN data Language shift\n\nOUT data\n\nTatoeba DE DE-EN Tatoeba DE DE-EN Tatoeba ES ES-EN Tatoeba ES ES-EN Tatoeba ES ES-EN NLD-EN Tatoeba ES\n\nNews FR Tatoeba NLD News FR Tatoeba CAT Tatoeba POR AFR\n\nDE-EN DE-EN ES-EN ES-EN\n\nDomain shift\n\nTatoeba DE Tatoeba DE Tatoeba ES Tatoeba ES\n\nEMEA DE Eurparl DE EMEA DE Eurparl DE\n\nTable 6: Summary of models and studied shifts.\n\n17\n\nUnder review as a conference paper at ICLR 2022\n\nA.3 SAMPLES\n\nSource sentence\n\nExpected translation\n\nTranslation\n\nA en Tom li agrada la tecnologia. Ac ́ı est`a la teua bossa. Aix`o et posar`a en perill. A Londres hi han molts parcs bonics. Aquest pa ́es molt delici ́os. A tots els meus amics els agraden els videojocs. Ac ̧ `o ́es un peix. Moltes felicitats! Bon any nou! Aquell que menteix, robar`a. Jo s ́oc qui t ́e la clau. En Tom surt a treballar cada mat ́ı a dos quarts de set. Tom leaves for work at 6:30 every morning. Ell m’ha dit que la seva casa era embruixada. Aquest ́es el lloc on va n`eixer el meu pare.\n\nTom likes technology. Here is your bag. That’ll put you in danger. There are many beautiful parks in London. This bread is very delicious. All my friends like playing videogames. This is a fish. Congratulations! Happy New Year! He that will lie, will steal. I’m the one who has the key.\n\nTom li likes technology. Ac ́ı est ́a la teua bossa. Aix`o et posar`a en perill. To London hi han molts parcs bonics. Aquest pa ́es molt delici ́os. A tots els meus amics els agrade els videojocs. Aaaaaaaaaaaaaaaaaaaa ... aaaaaaaaaaaaaaaaaaaaaaaaaa Moltes congrats! Bon any nou! The one who’s mindless, he’ll steal. Jo soc qui te la clau. In Tom surt to pull each mat ́ı to two quarts of set. Ell m’ha dit that the seva house was haunted.\n\nHe told me that his house was haunted. This is the place where my father was born. Aquest is the lloc on va n`eixer el meu pare.\n\nBLEU\n\n42.73 8.12 8.12 6.57 8.12 4.20 0.00 27.52 15.97 12.22 5.69 3.67 27.78 8.30\n\nTable 7: Example of behavior of a language model trained to handle Spanish inputs on Catalan inputs.\n\nA.4 DIALOG DATASETS\n\nSwitchboard Dialog Act Corpus (SwDA) is a corpus of telephonic conversations. The corpus provides labels, topic and speaker information (Stolcke et al., 2000).\n\nICSI MRDA Corpus (MRDA) contains transcript 75h of naturally occuring meetings involving more than 50 people (Shriberg et al., 2004).\n\nDaylyDialog Act Corpus (DyDA) contains daily common communications between people, covering topic such as small talk, meteo or daily activities (Li et al., 2017).\n\nInteractive Emotional Dyadic Motion Capture IEMOCAP)(Tripathi et al., 2018) consists of transcripts of improvisations or scripted scenarii supposed to outline the expression of emotions.\n\nA.5 CHOICES OF MODELS\n\nA lot of pretrained model for conditional text generation are available. To perform our experiments we needed models that were already well installed and deployed and that would also support OOD settings. For translation tasks we needed specialized models for a notion of OOD to be easily defined. It would be indeed more hazardous to define a notion of OOD language when working with a multilingual model. The same is true for conversational models.\n\nNeural Machine Translation model. We benchmark our OOD method on translation models provided by Helsinky NLP Tiedemann & Thottingal (2020) on several pairs of languages with large and small shifts. We extended the experiment to detect domain shifts. These models are indeed specialized in each language pairs and are widely recognize in the neural machine translation field. For our experiments we used the testing set provided along these models, so we can consider that they have been fine tuned over the same distribution.\n\nConversational model. We used a dialogGPT Zhang et al. (2019) model fine-tuned on the Multi WOZ dataset as chat bot model. The finetuning on daily dialogue type tasks ensure that the model is specialized, thus allowing us to get a good definition of samples not being in its range of expertise. Moreover, the choice of the architure, DialogGPT, guarantee that our results are valid on a very common architecture.\n\nAdditional finetuning. We further finetuned the models on the reference set to check whether additional finetuning on the distribution would affect the results. It did not change significantly the results Tab. 17. It is not surprising considering that the models we used were already trained on a very similar distribution.\n\nA.6 GENERALIZATION OF EXISTING OOD DETECTORS TO SEQUENCE GENERATION\n\nIn this section, we extend classical OOD detection score to the conditional text generation settting. Common OOD detectors were built for classification tasks and we need to adapt them to conditional text generation. Our task can be viewed as a sequence of classification problems with a very large number of classes (the size of the vocabulary). We chose the most naive approach which consists of\n\n18\n\nUnder review as a conference paper at ICLR 2022\n\naveraging the OOD scores over the sequence. We experimented with other aggregation such as the min/max or the standard deviation without getting interesting results.\n\nLikelihood Score The most naive approach to build a OOD score is to rely solely on the loglikelihood of the sequence. For a conditioning x we define the log-likelyhood score by aL(x) = − (cid:80)|ˆy|−1\n\nlog pθ(ˆyt+1|x, ˆy⩽t). The likelihood is the same as the perplexity.\n\nt=0\n\nAverage Maximum Softmax Probability score The maximum softmax probability Hendrycks & Gimpel (2017) takes the probability of the mode of the categorical distribution as score of OOD. We extend thise definition in the case of sequence of probability distribution by averaging this score along the sequence. For a given conditioning x, we define the average MSP score aMSP(x) = 1 θ (i|x, ˆy⩽t)). While it is closely linked to uncertainty measures it\n\nt=1 max\n\n(cid:80)|ˆy|\n\npT\n\n|ˆy|\n\ni∈[|0,K|]\n\ndiscards most of the information contained in the probability distribution. It discards the whole probability distribution. We claim that much more information can be retrieve by studying the whole distribution.\n\nAverage Energy score We extend the definition of the energy score described in Liu et al. (2020) to a sequence of probability distributions by averaging the score along the sequence. For a given conditioning x and a temperature T we define the average energy of the sequence:aE(x) ≜ − T efθ(x,ˆy⩽t)i/T . It corresponds to the normalization term of the softmax function |ˆy| applied on the logits. While it takes into account the whole distribution, it only takes into account the amount of unormalized mass before normalization without attention to how this mass is distributed along the features.\n\nt=1 log (cid:80)|Ω|\n\n(cid:80)|ˆy|\n\ni\n\nMahalanobis distance Following Lee et al. (2018c) compute the Mahalanobis matrice based on the samples of a given reference set R. In our case we are using encoder-decoder models we use the output of the last hidden layer of the encoder as embedding. Let’s denote φ(x) this embedding for a conditionning x. Let’s μ and Σ be respectively the mean and the covariance of these embedding on the reference set. We define aM(x) = (cid:0)1 + (φ(x) − μ)⊤Σ−1(φ(x) − μ)(cid:1)−1\n\n.\n\nB PARAMETERS TUNING\n\nDetectors depend on their anomaly score to make decision and these scores can be parametric. First of all, soft probability based scores depend on the soft probability distribution and its scaling, therefore the temperature is a crucial parameter to tune to get the most performance. While a small temperature tend to make the distribution more picky, higher value spread the probability mass along the classes. Moreover, the renyi divergence and its related informaiton projection depend on a factor α. We provide here further results and analysis of those parameters on our results.\n\nB.1\n\nIMPACT OF α\n\nIndeed, in Fig. 1 we present the impact of the size of the reference set and of the paramet α on Renyi information projection to distinguish dialog shifts, as expected, the larger the reference set, the better. However, we see that smaller values of α yield better results.\n\nWe recall that the Renyi divergence is defined as Dα(p∥q) = 1 R+ − {1}. Smaller values of α distribute the weight of each feature more equally in the final divergence, more specifically they tend to give an equal weight to the very likely outcome as well as to the less likely ones, therefore giving more weight to the tail of the distribution. When α tends to 0 the Renyi divergence actually counts the number of nonzero common probabilities. That makes sens in terms of topic detection, it counts the common tokens considered during text generation.\n\n, where α ∈\n\nα−1 log\n\ni=1\n\ni\n\ni\n\n(cid:16)(cid:80)|Ω|\n\n(cid:17)\n\npα qα−1\n\n19\n\nUnder review as a conference paper at ICLR 2022\n\nFigure 2: Trade-offs between AUROCand FPRfor each tasks and metrics\n\nFigure 3: ROCAUC curves for our uncertainty based metrics compared to common baselines for language shifts detection. Baselines are represented in dashed lines.\n\nC PERFORMANCE OF OUR DETECTORS IN OOD DETECTION\n\nC.1 SUMMARY OF OUR RESULTS\n\nIn Fig. 2 we present the different level of performance of all the detectors we studied. We can see that in every task our detectors outperform the baselines but also that in dialog shift, while the Mahalanobis distance outperform clearly our detectors for s0, they still outperform baselines for their scenario by far.\n\nC.2 DETAILED RESULTS OF OOD DETECTION PERFORMANCES\n\nIn this section we present the performances of our OOD detectors on each detailed tasks, i.e. for each pair of IN and OOD data with all the considered metrics. We show that our metrics outperform other OOD detectors baselines in almost all scenarios.\n\n20\n\n0.30.40.50.60.70.80.9FPR0.650.700.750.800.850.900.95AUROCTask = Language shifts0.30.40.50.60.70.80.9FPRTask = Domain shifts0.30.40.50.60.70.80.9FPRTask = Dialog shifts OursBaselinesScoreaDaFRaEaMSPaLaD*aFR*aD*KLaM0.00.20.40.60.81.0deu-frdeu-nlnld-afr0.00.20.40.60.81.00.00.20.40.60.81.0spa-cat0.00.20.40.60.81.0spa-fr0.00.20.40.60.81.0spa-poraEaFRaMaMSPaDaLUnder review as a conference paper at ICLR 2022\n\nTable 8: Detailed results of the performances of our OOD detectors on different language shifts. The first language of the pair is the reference language of the model and the second one is the studied shift.\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n1.00 0.98 0.98 0.80 0.99 1.00 0.99 0.99 0.99 1.00 1.00 1.00 0.57 0.99 0.76 0.79\n\n0.99 0.99 0.95 0.71 0.98 1.00 1.00 0.98 0.98 1.00 0.99 1.00 0.58 0.97 0.82 0.86\n\n1.00 0.99 0.98 0.78 0.99 1.00 1.00 0.99 0.98 1.00 1.00 1.00 0.59 0.99 0.81 0.82\n\n0.03 0.05 0.04 0.44 0.04 0.03 0.03 0.06 0.06 0.02 0.02 0.03 0.47 0.03 0.34 0.25\n\n0.91 0.91 0.90 0.69 0.90 0.91 0.91 0.90 0.90 0.91 0.91 0.91 0.38 0.90 0.42 0.68\n\n0.01 0.05 0.04 0.84 0.03 0.00 0.01 0.06 0.07 0.00 0.00 0.00 0.90 0.00 0.64 0.44\n\ns0\n\ns1\n\n0.83 0.83 0.83 0.75 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.59 0.83 0.56 0.75\n\n1.00 0.99 1.00 0.63 1.00 1.00 1.00 0.99 0.98 1.00 0.99 1.00 0.28 0.99 0.34 0.62\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.94 0.95 0.82 0.80 0.77 0.81 0.77 0.80 0.71 0.86 0.77 0.79 0.51 0.60 0.67 0.74\n\n0.94 0.94 0.75 0.71 0.76 0.72 0.70 0.74 0.59 0.77 0.58 0.72 0.51 0.44 0.67 0.84\n\n0.94 0.95 0.79 0.77 0.74 0.77 0.75 0.78 0.67 0.83 0.70 0.77 0.51 0.48 0.70 0.82\n\n0.17 0.16 0.45 0.46 0.45 0.44 0.46 0.43 0.50 0.42 0.52 0.45 0.50 0.52 0.44 0.30\n\n0.87 0.87 0.71 0.67 0.67 0.70 0.68 0.69 0.58 0.76 0.66 0.69 0.31 0.00 0.63 0.76\n\n0.29 0.28 0.85 0.88 0.85 0.84 0.88 0.81 0.95 0.80 0.99 0.84 0.95 1.00 0.85 0.56\n\n0.82 0.82 0.77 0.50 0.70 0.76 0.75 0.76 0.71 0.78 0.75 0.75 0.52 0.00 0.71 0.79\n\n1.00 0.92 1.00 1.00 1.00 0.65 0.62 0.64 0.50 0.73 0.59 0.63 0.22 0.00 0.60 0.74\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\n(a) deu-fr\n\n(b) spa-por\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.86 0.86 0.70 0.68 0.68 0.58 0.52 0.59 0.48 0.68 0.56 0.55 0.35 0.51 0.55 0.52\n\n0.94 0.93 0.82 0.79 0.83 0.78 0.74 0.77 0.69 0.80 0.67 0.76 0.65 0.63 0.77 0.82\n\n0.91 0.90 0.77 0.75 0.73 0.69 0.66 0.70 0.60 0.76 0.62 0.68 0.50 0.55 0.67 0.71\n\n0.29 0.32 0.59 0.59 0.59 0.60 0.61 0.59 0.64 0.60 0.66 0.60 0.63 0.66 0.57 0.53\n\n0.77 0.77 0.63 0.52 0.52 0.54 0.49 0.54 0.43 0.62 0.51 0.52 0.27 0.00 0.53 0.53\n\n0.42 0.47 0.88 0.88 0.88 0.89 0.92 0.89 0.96 0.90 0.99 0.89 0.95 0.99 0.85 0.79\n\ns0\n\ns1\n\n0.70 0.70 0.63 0.35 0.52 0.58 0.54 0.58 0.50 0.62 0.56 0.56 0.37 0.00 0.55 0.57\n\n1.00 0.86 1.00 1.00 1.00 0.51 0.45 0.50 0.37 0.61 0.47 0.49 0.21 0.00 0.57 0.49\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n1.00 1.00 0.99 0.69 0.98 1.00 0.94 0.97 0.97 1.00 1.00 0.99 0.57 0.99 0.67 0.88\n\n1.00 1.00 0.96 0.72 0.98 0.99 0.97 0.98 0.97 1.00 0.99 0.99 0.56 0.97 0.72 0.95\n\n1.00 1.00 0.98 0.73 0.98 0.99 0.96 0.98 0.97 1.00 0.99 0.99 0.58 0.99 0.72 0.92\n\n0.03 0.03 0.04 0.41 0.05 0.03 0.07 0.08 0.09 0.02 0.03 0.03 0.48 0.04 0.43 0.12\n\n0.91 0.91 0.90 0.60 0.90 0.91 0.90 0.90 0.90 0.91 0.91 0.90 0.39 0.90 0.00 0.89\n\n0.00 0.01 0.03 0.76 0.04 0.01 0.09 0.11 0.14 0.00 0.01 0.02 0.92 0.02 0.82 0.19\n\n0.83 0.83 0.83 0.71 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.59 0.83 0.00 0.83\n\n1.00 1.00 1.00 0.52 1.00 1.00 0.99 0.98 0.97 1.00 0.99 1.00 0.29 0.98 0.00 0.96\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\n(c) spa-cat\n\n(d) spa-fr\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.76 0.71 0.74 0.72 0.70 0.71 0.66 0.41 0.34 0.75 0.43 0.70 0.34 0.65 0.44 0.47\n\n0.90 0.88 0.88 0.88 0.88 0.94 0.94 0.74 0.70 0.88 0.70 0.95 0.71 0.84 0.79 0.85\n\n0.85 0.80 0.82 0.82 0.81 0.87 0.86 0.59 0.53 0.83 0.56 0.87 0.53 0.76 0.65 0.71\n\n0.51 0.53 0.55 0.58 0.55 0.22 0.23 0.64 0.67 0.57 0.68 0.22 0.65 0.61 0.62 0.55\n\n0.65 0.63 0.67 0.48 0.48 0.69 0.65 0.37 0.00 0.46 0.00 0.67 0.00 0.00 0.40 0.49\n\n0.72 0.75 0.78 0.82 0.78 0.30 0.32 0.91 0.96 0.81 0.96 0.30 0.93 0.87 0.89 0.78\n\ns0\n\ns1\n\n0.61 0.60 0.62 0.31 0.31 0.64 0.61 0.43 0.00 0.50 0.00 0.62 0.00 0.00 0.40 0.52\n\n1.00 0.66 1.00 1.00 1.00 0.75 0.69 0.32 0.00 0.43 0.00 0.72 0.00 0.00 0.40 0.47\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n1.00 0.99 0.98 0.76 0.98 1.00 0.98 0.98 0.98 1.00 0.99 1.00 0.57 0.99 0.71 0.76\n\n0.99 0.99 0.93 0.74 0.97 1.00 0.99 0.98 0.96 0.99 0.97 1.00 0.57 0.94 0.74 0.84\n\n0.99 0.99 0.97 0.78 0.98 1.00 0.99 0.98 0.97 1.00 0.99 1.00 0.58 0.98 0.75 0.80\n\n0.03 0.04 0.05 0.40 0.05 0.03 0.03 0.06 0.07 0.02 0.03 0.03 0.48 0.03 0.41 0.27\n\n0.91 0.91 0.90 0.70 0.90 0.91 0.90 0.90 0.90 0.91 0.90 0.91 0.38 0.90 0.49 0.65\n\n0.01 0.03 0.06 0.75 0.06 0.00 0.02 0.07 0.10 0.00 0.00 0.00 0.92 0.02 0.78 0.50\n\n0.83 0.83 0.83 0.75 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.83 0.58 0.83 0.61 0.74\n\n1.00 1.00 1.00 0.65 1.00 1.00 0.99 0.98 0.97 0.99 0.99 1.00 0.28 0.98 0.41 0.58\n\n(e) nld-afr\n\n(f) deu-nl\n\nC.3 ROC AUC CURVES\n\nC.3.1 LANGUAGE SHIFTS\n\nFigure 4: ROC-AUC curves for our reference based metrics compared to common baselines for language shifts detection. Baselines are represented in dashed lines.\n\n21\n\n0.00.20.40.60.81.0deu-frdeu-nlnld-afr0.00.20.40.60.81.00.00.20.40.60.81.0spa-cat0.00.20.40.60.81.0spa-fr0.00.20.40.60.81.0spa-poraFR*aD*KLaD*aD*aD*aD*aMUnder review as a conference paper at ICLR 2022\n\nTable 9: Detailed results of the performances of our OOD detectors on different domain shifts. For Spanish (spa) and German (de), we present two domains shifts: Technical medical (EMEA) data and legal parlementary texts (parl) against common language emboddied by the Tatoeba dataset (tat).\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.90 0.87 0.88 0.86 0.89 0.90 0.89 0.79 0.79 0.88 0.87 0.85 0.52 0.86 0.88 0.87\n\n0.76 0.73 0.75 0.73 0.76 0.88 0.83 0.68 0.68 0.73 0.73 0.70 0.53 0.67 0.89 0.90\n\n0.86 0.81 0.83 0.82 0.85 0.90 0.88 0.76 0.75 0.84 0.83 0.80 0.53 0.80 0.90 0.89\n\n0.43 0.46 0.49 0.48 0.44 0.25 0.33 0.46 0.47 0.47 0.48 0.50 0.49 0.52 0.25 0.22\n\n0.81 0.77 0.78 0.76 0.79 0.82 0.82 0.68 0.66 0.78 0.77 0.74 0.32 0.75 0.00 0.81\n\n0.82 0.86 0.93 0.91 0.84 0.45 0.62 0.88 0.89 0.89 0.91 0.94 0.93 0.98 0.46 0.39\n\ns0\n\ns1\n\n0.80 0.79 0.79 0.77 0.80 0.81 0.80 0.75 0.75 0.79 0.79 0.77 0.53 0.78 0.00 0.80\n\n1.00 0.75 1.00 0.74 1.00 0.86 0.83 0.61 0.59 0.77 0.75 0.72 0.22 0.72 0.00 0.81\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.75 0.66 0.75 0.68 0.75 0.66 0.67 0.60 0.60 0.67 0.66 0.62 0.51 0.65 0.57 0.62\n\n0.75 0.67 0.75 0.61 0.75 0.65 0.63 0.59 0.59 0.67 0.65 0.64 0.52 0.67 0.61 0.66\n\n0.76 0.70 0.71 0.68 0.71 0.68 0.67 0.61 0.61 0.70 0.69 0.65 0.51 0.69 0.60 0.66\n\n0.41 0.44 0.44 0.49 0.45 0.44 0.48 0.48 0.48 0.44 0.45 0.45 0.49 0.43 0.46 0.44\n\n0.67 0.45 0.67 0.67 0.67 0.00 0.00 0.15 0.00 0.00 0.00 0.00 0.00 0.00 0.27 0.00\n\n0.76 0.84 0.83 0.94 0.86 0.84 0.90 0.90 0.91 0.82 0.85 0.85 0.94 0.80 0.87 0.83\n\n0.67 0.64 0.69 0.50 0.50 0.83 0.00 0.83 0.00 0.00 0.00 0.00 0.00 0.00 0.47 0.00\n\n1.00 0.35 1.00 1.00 1.00 0.00 0.00 0.08 0.00 0.00 0.00 0.00 0.00 0.00 0.19 0.00\n\n(a) de:news-EMEA\n\n(b) es:news-parl\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.75 0.61 0.75 0.63 0.75 0.69 0.66 0.61 0.59 0.65 0.65 0.63 0.51 0.64 0.52 0.58\n\n0.75 0.65 0.75 0.58 0.75 0.66 0.64 0.59 0.58 0.65 0.65 0.64 0.52 0.64 0.66 0.61\n\n0.71 0.65 0.68 0.64 0.68 0.68 0.68 0.62 0.60 0.68 0.68 0.66 0.51 0.67 0.59 0.62\n\n0.41 0.45 0.45 0.51 0.46 0.43 0.46 0.48 0.48 0.45 0.45 0.45 0.49 0.45 0.41 0.47\n\n0.67 0.42 0.67 0.67 0.67 0.30 0.00 0.28 0.00 0.00 0.00 0.00 0.00 0.00 0.40 0.00\n\n0.78 0.84 0.85 0.96 0.86 0.81 0.88 0.90 0.90 0.86 0.85 0.86 0.93 0.86 0.78 0.89\n\ns0\n\ns1\n\n0.66 0.61 0.66 0.50 0.51 0.80 0.00 0.51 0.00 0.00 0.00 0.00 0.00 0.00 0.52 0.00\n\n1.00 0.32 1.00 1.00 1.00 0.22 0.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.33 0.00\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.92 0.89 0.90 0.86 0.90 0.88 0.89 0.79 0.79 0.90 0.88 0.81 0.52 0.87 0.67 0.81\n\n0.81 0.75 0.77 0.73 0.80 0.85 0.83 0.70 0.68 0.77 0.75 0.66 0.51 0.70 0.59 0.83\n\n0.89 0.85 0.86 0.82 0.87 0.88 0.88 0.76 0.75 0.86 0.84 0.76 0.52 0.81 0.64 0.83\n\n0.37 0.44 0.44 0.47 0.41 0.29 0.32 0.45 0.47 0.44 0.45 0.50 0.50 0.49 0.49 0.31\n\n0.83 0.79 0.80 0.76 0.81 0.81 0.81 0.67 0.66 0.79 0.77 0.70 0.33 0.75 0.00 0.75\n\n0.70 0.82 0.83 0.89 0.77 0.54 0.59 0.85 0.89 0.83 0.85 0.94 0.95 0.94 0.94 0.58\n\n0.81 0.80 0.80 0.77 0.80 0.80 0.80 0.75 0.75 0.80 0.79 0.76 0.54 0.78 0.00 0.78\n\n1.00 0.78 1.00 0.74 1.00 0.82 0.82 0.60 0.58 0.79 0.75 0.65 0.24 0.72 0.00 0.72\n\n(c) de:news-parl\n\n(d) es:news-EMEA\n\nC.3.2 DOMAIN SHIFTS\n\nFigure 5: ROC-AUC curves for our uncertainty based metrics compared to common baselines for domain shifts detection. baselines are represented in dashed lines.\n\n22\n\n0.00.20.40.60.81.0de:news-EMEAde:news-parl0.00.20.40.60.81.00.00.20.40.60.81.0spa:tat-EMEA0.00.20.40.60.81.0spa:tat-parlaEaFRaMSPaDaLUnder review as a conference paper at ICLR 2022\n\nTable 10: Detailed performance results of our OOD detectors on dialog shift against the Multi WOZ dataset as reference set.\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.87 0.73 0.75 0.81 0.53 0.69 0.66 0.61 0.62 0.62 0.64 0.69 0.54 0.55 0.88 0.87\n\n0.87 0.81 0.75 0.79 0.64 0.69 0.68 0.64 0.63 0.65 0.65 0.69 0.55 0.57 0.89 0.84\n\n0.87 0.79 0.62 0.82 0.57 0.72 0.70 0.64 0.65 0.65 0.67 0.72 0.55 0.57 0.90 0.87\n\n0.31 0.34 0.40 0.39 0.42 0.43 0.44 0.45 0.46 0.44 0.46 0.43 0.49 0.48 0.25 0.33\n\n0.78 0.67 0.67 0.76 0.32 0.60 0.56 0.45 0.47 0.47 0.51 0.60 0.34 0.37 0.75 0.80\n\n0.56 0.63 0.75 0.72 0.78 0.81 0.82 0.85 0.87 0.83 0.86 0.82 0.93 0.91 0.46 0.61\n\ns0\n\ns1\n\n0.79 0.75 0.53 0.75 0.53 0.72 0.70 0.64 0.65 0.65 0.67 0.71 0.55 0.58 0.86 0.80\n\n0.77 0.60 1.00 0.77 0.22 0.52 0.47 0.35 0.37 0.37 0.41 0.51 0.25 0.27 0.67 0.80\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.52 0.41 0.63 0.40 0.36 0.69 0.42 0.38 0.36 0.39 0.39 0.53 0.31 0.31 0.54 0.53\n\n0.87 0.86 0.87 0.66 0.86 0.93 0.84 0.81 0.80 0.82 0.81 0.88 0.78 0.80 0.89 0.87\n\n0.72 0.69 0.63 0.47 0.67 0.85 0.67 0.63 0.62 0.64 0.64 0.75 0.57 0.58 0.70 0.74\n\n0.52 0.55 0.56 0.73 0.52 0.40 0.63 0.64 0.66 0.63 0.67 0.58 0.68 0.66 0.74 0.73\n\n0.52 0.37 0.43 0.43 0.31 0.63 0.43 0.37 0.36 0.38 0.40 0.54 0.29 0.29 0.59 0.56\n\n0.69 0.73 0.74 1.00 0.69 0.53 0.85 0.85 0.89 0.85 0.90 0.77 0.91 0.88 0.91 0.99\n\n0.50 0.39 0.28 0.27 0.34 0.56 0.44 0.39 0.39 0.40 0.41 0.51 0.32 0.33 0.55 0.53\n\n0.54 0.35 1.00 1.00 0.28 0.75 0.43 0.35 0.34 0.36 0.38 0.59 0.26 0.26 0.64 0.60\n\n(a) dailydialog-default\n\n(b) silicone-melds\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.52 0.41 0.63 0.40 0.36 0.69 0.42 0.38 0.38 0.39 0.40 0.53 0.31 0.32 0.54 0.53\n\n0.87 0.86 0.87 0.66 0.86 0.93 0.84 0.82 0.81 0.83 0.82 0.88 0.77 0.79 0.89 0.87\n\n0.72 0.69 0.63 0.47 0.67 0.85 0.67 0.64 0.63 0.65 0.65 0.75 0.57 0.59 0.70 0.74\n\n0.52 0.55 0.56 0.73 0.52 0.40 0.63 0.64 0.65 0.63 0.65 0.58 0.69 0.68 0.74 0.73\n\n0.52 0.37 0.43 0.43 0.31 0.63 0.43 0.38 0.37 0.39 0.40 0.54 0.30 0.32 0.59 0.56\n\n0.69 0.73 0.74 1.00 0.69 0.53 0.85 0.86 0.87 0.84 0.88 0.77 0.93 0.91 0.91 0.99\n\ns0\n\ns1\n\n0.50 0.39 0.28 0.27 0.34 0.56 0.44 0.40 0.39 0.41 0.41 0.51 0.34 0.35 0.55 0.53\n\n0.54 0.35 1.00 1.00 0.28 0.75 0.43 0.36 0.35 0.38 0.38 0.59 0.28 0.29 0.64 0.60\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines Baselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.79 0.68 0.75 0.91 0.70 0.92 0.60 0.58 0.58 0.59 0.59 0.75 0.55 0.56 0.87 0.85\n\n0.80 0.73 0.75 0.73 0.65 0.91 0.60 0.58 0.57 0.59 0.58 0.74 0.55 0.59 0.87 0.93\n\n0.81 0.70 0.64 0.85 0.64 0.91 0.61 0.59 0.59 0.60 0.59 0.75 0.56 0.59 0.88 0.91\n\n0.36 0.39 0.45 0.49 0.43 0.23 0.47 0.48 0.48 0.47 0.48 0.41 0.49 0.47 0.15 0.10\n\n0.73 0.49 0.67 0.78 0.54 0.83 0.44 0.39 0.41 0.41 0.41 0.65 0.37 0.39 0.80 0.83\n\n0.68 0.74 0.84 0.94 0.80 0.42 0.89 0.90 0.91 0.90 0.90 0.77 0.92 0.89 0.21 0.21\n\n0.78 0.66 0.61 0.76 0.69 1.00 0.63 0.59 0.61 0.61 0.61 0.74 0.58 0.59 0.80 0.81\n\n0.69 0.39 1.00 0.81 0.45 0.87 0.34 0.29 0.31 0.31 0.31 0.58 0.27 0.29 0.84 0.85\n\n(c) silicone-melde\n\n(d) silicone-dydae\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines Baselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.71 0.68 0.75 0.69 0.61 0.88 0.68 0.63 0.63 0.64 0.65 0.79 0.55 0.57 0.87 0.87\n\n0.74 0.73 0.75 0.48 0.74 0.89 0.70 0.65 0.64 0.67 0.66 0.80 0.56 0.59 0.87 0.95\n\n0.72 0.72 0.66 0.57 0.71 0.88 0.70 0.65 0.65 0.67 0.67 0.80 0.56 0.59 0.88 0.93\n\n0.36 0.36 0.39 0.50 0.36 0.24 0.42 0.45 0.45 0.43 0.44 0.36 0.48 0.47 0.15 0.10\n\n0.63 0.57 0.67 0.67 0.00 0.80 0.56 0.48 0.48 0.49 0.51 0.71 0.36 0.38 0.80 0.86\n\n0.67 0.67 0.74 1.00 0.66 0.44 0.80 0.85 0.85 0.82 0.84 0.68 0.92 0.89 0.21 0.21\n\ns0\n\ns1\n\n0.73 0.70 0.53 0.50 0.00 0.79 0.70 0.66 0.65 0.66 0.67 0.76 0.57 0.58 0.80 0.82\n\n0.55 0.48 1.00 1.00 0.00 0.82 0.47 0.38 0.38 0.39 0.41 0.66 0.26 0.28 0.84 0.90\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines Baselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.79 0.68 0.75 0.91 0.70 0.92 0.60 0.58 0.57 0.59 0.58 0.75 0.54 0.55 0.84 0.85\n\n0.80 0.73 0.75 0.73 0.65 0.91 0.60 0.58 0.56 0.59 0.57 0.74 0.56 0.58 0.87 0.93\n\n0.81 0.70 0.64 0.85 0.64 0.91 0.61 0.59 0.58 0.60 0.59 0.75 0.56 0.58 0.87 0.91\n\n0.36 0.39 0.45 0.49 0.43 0.23 0.47 0.48 0.48 0.47 0.49 0.41 0.49 0.47 0.13 0.10\n\n0.73 0.49 0.67 0.78 0.54 0.83 0.44 0.40 0.40 0.41 0.41 0.65 0.35 0.38 0.81 0.83\n\n0.68 0.74 0.84 0.94 0.80 0.42 0.89 0.90 0.92 0.90 0.92 0.77 0.92 0.89 0.22 0.21\n\n0.78 0.66 0.61 0.76 0.69 1.00 0.63 0.60 0.60 0.61 0.61 0.74 0.56 0.58 0.81 0.81\n\n0.69 0.39 1.00 0.81 0.45 0.87 0.34 0.30 0.30 0.31 0.31 0.58 0.26 0.28 0.84 0.85\n\n(e) silicone-swda\n\n(f) silicone-dydada\n\nScenario\n\nScore\n\nScenario\n\nScore\n\nAUPR-IN AUPR-OUT AUROC ERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\nAUPR-IN\n\nAUPR-OUT\n\nAUROC\n\nERR\n\nf1\n\nFPR\n\nprecision\n\nrecall\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines Baselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.42 0.41 0.61 0.53 0.35 0.67 0.29 0.27 0.27 0.27 0.28 0.41 0.23 0.24 0.45 0.42\n\n0.91 0.90 0.89 0.76 0.90 0.95 0.85 0.84 0.84 0.85 0.85 0.90 0.82 0.83 0.92 0.89\n\n0.72 0.72 0.63 0.58 0.68 0.86 0.63 0.60 0.59 0.61 0.61 0.73 0.54 0.56 0.75 0.70\n\n0.57 0.57 0.61 0.80 0.56 0.44 0.72 0.72 0.70 0.72 0.71 0.61 0.74 0.73 0.78 0.78\n\n0.45 0.38 0.35 0.40 0.33 0.58 0.34 0.30 0.29 0.30 0.30 0.46 0.23 0.24 0.53 0.47\n\n0.70 0.71 0.76 1.00 0.70 0.55 0.90 0.90 0.88 0.89 0.89 0.77 0.92 0.91 0.97 0.99\n\ns0\n\ns1\n\n0.40 0.35 0.23 0.34 0.32 0.48 0.32 0.29 0.28 0.29 0.29 0.41 0.23 0.25 0.50 0.42\n\n0.50 0.41 1.00 0.48 0.35 0.77 0.36 0.31 0.29 0.31 0.31 0.52 0.22 0.24 0.56 0.54\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines Baselines\n\nα\n\nKL\n\naDα aFR aE aL aMSP aD∗ aD∗ aDidf aDidf aDmean aDmean aFR∗ aFRidf aFRmean aC aM\n\nKL\n\nKL\n\nα\n\nα\n\n0.71 0.69 0.75 0.72 0.62 0.86 0.66 0.61 0.62 0.63 0.63 0.77 0.55 0.57 0.87 0.88\n\n0.77 0.74 0.75 0.48 0.76 0.88 0.71 0.66 0.64 0.68 0.65 0.80 0.57 0.59 0.92 0.96\n\n0.75 0.74 0.70 0.57 0.73 0.87 0.70 0.64 0.64 0.66 0.66 0.79 0.57 0.59 0.94 0.94\n\n0.33 0.36 0.37 0.50 0.32 0.23 0.41 0.43 0.44 0.42 0.44 0.36 0.48 0.47 0.13 0.10\n\n0.60 0.58 0.67 0.67 0.00 0.79 0.52 0.45 0.46 0.45 0.48 0.69 0.36 0.40 0.89 0.88\n\n0.60 0.67 0.68 1.00 0.59 0.42 0.77 0.82 0.84 0.79 0.84 0.66 0.91 0.90 0.22 0.21\n\n0.72 0.71 0.60 0.50 0.00 0.79 0.68 0.63 0.64 0.64 0.66 0.75 0.57 0.60 0.82 0.82\n\n0.52 0.49 1.00 1.00 0.00 0.80 0.42 0.34 0.36 0.35 0.38 0.63 0.27 0.30 0.65 0.94\n\n(g) silicone-iemocap\n\n(h) silicone-mrda\n\n23\n\nFigure 6: ROC-AUC curves for our reference based metrics compared to common baselines for\n\ndomain shift detection. baselines are represented in dashed lines.\n\n0.00.20.40.60.81.0de:news-EMEAde:news-parl0.00.20.40.60.81.00.00.20.40.60.81.0spa:tat-EMEA0.00.20.40.60.81.0spa:tat-parlaFR*aD*KLaD*aD*aD*aD*aMUnder review as a conference paper at ICLR 2022\n\nC.3.3 DIALOG SHIFTS\n\nFigure 7: ROC-AUC curves for our uncertainty based metrics compared to common baselines for dialog shifts detection. baselines are represented in dashed lines.\n\nFigure 8: Rocauc curves for our reference based metrics compared to common baselines for dialog shift detection. baselines are represented in dashed lines.\n\nD NTM PERFORMANCE\n\nSurprisingly we show that common OOD detectors tend to exclude samples that are well handled by the model and keep some that are not leading to decreasing overall performance in terms of translation metrics. Moreoever it seems this phenomenon is more dominant in reference based detectors. We show that our uncertainty based detectors mostly avoir that downfall and provide good OOD detection and improved translation performances.\n\nD.1 ABSOLUTE PERFORMANCES\n\nIt is clear (somewhat expected) that NMT models do not perform as well on OOD data as we can see in Tab. 11b. However, we find that our OOD detectors are able to remove most of the worst case samples and keep enough well translated samples so that with correct filtering our method actually allow the model to achieve somewhat acceptable BLEU scores.\n\n24\n\n0.00.20.40.60.81.0daily_dialog-defaultdyda_daiemocap0.00.20.40.60.81.00.00.20.40.60.81.0meld_s0.00.20.40.60.81.0mrda0.00.20.40.60.81.0swdaaDaFRaMSPaEaL0.00.20.40.60.81.0daily_dialog-defaultdyda_daiemocap0.00.20.40.60.81.00.00.20.40.60.81.0meld_s0.00.20.40.60.81.0mrda0.00.20.40.60.81.0swdaaMaD*KLaD*aFR*aD*aD*aD*Under review as a conference paper at ICLR 2022\n\nFigure 9: Gain in translation performances when filtering OOD samples with our method on different datasets and language pairs.\n\nScenario\n\ns0\n\ns1\n\nScenario\n\ns0\n\ns1\n\nScenario\n\ns0\n\ns1\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA de:news-EMEA\n\n59.73 62.48 62.84 62.66 64.77 58.63 60.43 60.47 60.78 59.87\n\n59.73 62.48 62.84 62.66 64.77 58.63 60.43 60.47 60.78 59.87\n\n61.19 66.43 64.89 64.53 66.60 59.59 61.74 61.73 61.04 61.36\n\n59.73 64.92 63.75 62.66 64.77 58.63 60.43 60.47 60.78 59.87\n\n(a) IN\n\n34.07 36.68 36.10 35.87 36.72 33.00 33.82 33.78 34.48 33.85\n\n59.73 63.86 62.84 62.66 64.77 58.63 60.43 60.47 60.78 59.87\n\n34.07 36.69 36.19 35.87 36.72 33.00 33.82 33.78 34.48 33.85\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA de:news-EMEA\n\n15.73 27.22 26.26 14.43 16.62 17.36 19.66 19.72 16.84 16.55\n\n15.40 36.88 36.99 12.98 14.70 18.97 22.81 22.89 16.72 19.30\n\n23.79 35.80 33.00 27.71 33.59 23.91 33.72 33.82 23.67 25.15\n\n33.17 41.70 38.17 35.07 40.23 30.81 34.05 34.12 33.32 30.75\n\n(b) OOD\n\n28.36 33.64 32.10 31.97 34.18 26.46 27.38 27.39 29.11 27.22\n\n59.38 64.11 65.24 60.50 61.32 41.51 46.25 45.82 59.55 59.15\n\n52.16 54.60 55.02 54.48 54.41 34.64 43.62 43.61 52.19 54.71\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA de:news-EMEA\n\n44.24 59.52 59.50 48.75 54.37 46.62 49.72 49.81 47.98 48.70\n\n37.57 60.15 60.50 40.58 48.54 42.62 48.34 48.40 42.07 49.44\n\n49.45 62.53 59.87 57.89 61.70 47.75 57.76 57.72 50.03 52.91\n\n46.45 56.42 52.82 48.77 54.76 44.21 56.97 57.03 45.97 49.61\n\n(c) ALL\n\n31.21 35.35 34.34 34.19 35.64 29.50 30.37 30.37 31.77 30.42\n\n59.55 63.98 63.39 61.48 62.92 56.16 59.52 59.53 60.12 59.84\n\n43.12 46.32 46.11 45.78 46.22 33.37 36.91 36.89 43.84 37.86\n\nTable 11: Absolue translation performances in terms of BLEU on the different subset (IN, OOD, ALL) of each dataset of our translation OOD performance benchmark.\n\n25\n\nALLINOODDataset0102030405060BLEUspa-catspa-pornld-afrUnder review as a conference paper at ICLR 2022\n\nScenario\n\ns0\n\ns1\n\nScenario\n\ns0\n\ns1\n\nScenario\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA de:news-EMEA\n\n+2.75 +3.11 +2.93 +5.03 -1.10 +0.70 +0.74 +1.05 +0.14\n\n+2.75 +3.11 +2.93 +5.03 -1.10 +0.70 +0.74 +1.05 +0.14\n\n+5.24 +3.70 +3.34 +5.41 -1.60 +0.55 +0.54 -0.15 +0.17\n\n+5.19 +4.02 +2.93 +5.03 -1.10 +0.70 +0.74 +1.05 +0.14\n\n(a) IN\n\n+2.61 +2.03 +1.79 +2.65 -1.07 -0.26 -0.29 +0.40 -0.22\n\n+4.13 +3.11 +2.93 +5.03 -1.10 +0.70 +0.74 +1.05 +0.14\n\n+2.62 +2.11 +1.79 +2.65 -1.07 -0.26 -0.29 +0.40 -0.22\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA de:news-EMEA\n\n+11.49 +10.53 -1.30 +0.89 +1.63 +3.94 +3.99 +1.11 +0.82\n\n+21.48 +21.59 -2.42 -0.70 +3.57 +7.41 +7.49 +1.32 +3.90\n\n+12.02 +9.22 +3.92 +9.80 +0.12 +9.93 +10.03 -0.12 +1.36\n\n+8.52 +5.00 +1.89 +7.06 -2.36 +0.88 +0.95 +0.14 -2.43\n\n(b) OOD\n\n+5.28 +3.75 +3.61 +5.82 -1.90 -0.98 -0.97 +0.75 -1.14\n\n+4.74 +5.87 +1.12 +1.94 -17.87 -13.13 -13.56 +0.17 -0.22\n\n+2.44 +2.85 +2.31 +2.24 -17.52 -8.54 -8.56 +0.02 +2.55\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA de:news-EMEA\n\n+15.28 +15.26 +4.51 +10.13 +2.38 +5.48 +5.57 +3.74 +4.46\n\n+22.58 +22.93 +3.01 +10.98 +5.06 +10.78 +10.83 +4.51 +11.87\n\n+13.09 +10.42 +8.44 +12.26 -1.70 +8.31 +8.27 +0.58 +3.46\n\n+9.97 +6.37 +2.32 +8.31 -2.24 +10.52 +10.58 -0.49 +3.16\n\n(c) ALL\n\n+4.14 +3.13 +2.98 +4.42 -1.72 -0.85 -0.85 +0.56 -0.79\n\n+4.43 +3.84 +1.92 +3.36 -3.40 -0.04 -0.02 +0.57 +0.28\n\n+3.20 +2.99 +2.66 +3.10 -9.74 -6.20 -6.23 +0.72 -5.26\n\nScenario\n\nDataset ALL Score\n\nspa-cat\n\nspa-por\n\nnld-afr\n\nspa:tat-parl\n\nde:news-parl\n\nspa:tat-EMEA\n\nde:news-EMEA\n\nIN OOD ALL\n\nIN OOD ALL\n\nIN OOD ALL\n\nIN OOD ALL\n\nIN OOD ALL\n\nIN OOD ALL\n\nIN OOD\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\n43% 20% 86% 56% 20% 92% 37% 20% 75% 37% 20% 54% 29% 20% 38% 20% 19% 20% 14% 20% 7% 43% 20% 85% 56% 20% 92% 32% 16% 66% 28% 18% 39% 28% 20% 37% 48% 20% 76% 15% 19% 10% 9% 27% 20% 40% 28% 20% 36% 33% 20% 62% 19% 20% 19% 30% 20% 40% 12% 20% 33% 19% 59% 40% 19% 61% 35% 19% 69% 32% 19% 44% 30% 19% 40% 13% 19% 6% 8% 52% 19% 86% 48% 20% 76% 26% 19% 38% 32% 19% 45% 14% 16% 9% 15% 19% 12% 14% 20% 6% 57% 19% 94% 40% 19% 62% 29% 19% 47% 41% 19% 62% 36% 20% 71% 54% 19% 88% 12% 19% 6% 57% 20% 94% 40% 18% 62% 30% 20% 48% 41% 20% 62% 36% 20% 71% 54% 20% 88% 12% 18% 23% 16% 37% 27% 16% 38% 17% 15% 22% 0% 2% 30% 20% 49% 46% 20% 72% 28% 20% 47% 38% 20% 56% 17% 20% 14% 58% 20% 96% 50% 20% 81%\n\n4% 14% 20% 6% 13% 19%\n\n2% 10% 11% 10%\n\n9% 16%\n\n6% 11%\n\n9% 16%\n\nTable 13: Share of the datasets removed when taking γ so that we keep 80% of the IN distribution.\n\n26\n\nUnder review as a conference paper at ICLR 2022\n\nD.2 GAINS\n\nD.3 EFFECT OF A LARGER THRESHOLD ON NMT PERFORMANCE\n\nTable 15: Detailed impacts on NMT performance results per tasks (Domain- or Language-shifts) of the different OOD detectors with a threshold defined to keep 99% of the IN data. We present results on the different part of the data: IN data, OOD data and the combination of both, ALL. For each we report the absolute average BLEU score (Abs.), the average gains in BLEU (G.s.) compared to a setting without OOD filtering (fθ only) and the share of the subset removed by the detector (R.Sh.).\n\nAbs.\n\n47.1 47.3 47.3 47.3 47.3 47.0 47.0 47.0 47.0\n\nIN G.s\n\n+0.0 +0.2 +0.2 +0.2 +0.2 -0.1 -0.1 -0.1 -0.1\n\nR.Sh Abs.\n\n0.0% 43.4 1.0% 44.2 1.0% 44.1 1.0% 44.0 0.9% 44.0 1.0% 40.3 0.9% 40.3 0.9% 40.3 1.0% 41.6\n\nDomain shifts OOD G.s\n\nR.Sh Abs.\n\n+0.0 +0.8 +0.7 +0.5 +0.6 -3.1 -3.1 -3.1 -1.8\n\n0.0% 45.3 5.5% 45.8 7.2% 45.7 1.9% 45.6 1.9% 45.6 14.7% 43.5 26.5% 43.9 26.6% 43.9 18.1% 44.6\n\nALL G.s\n\n+0.0 +0.5 +0.4 +0.4 +0.4 -1.8 -1.4 -1.3 -0.7\n\nR.Sh Abs.\n\n0.0% 60.5 3.2% 60.7 4.1% 60.7 1.4% 60.9 1.4% 60.8 7.8% 60.4 13.7% 60.5 13.8% 60.5 9.6% 60.5\n\nIN G.s\n\n+0.0 +0.2 +0.2 +0.4 +0.3 -0.1 -0.0 -0.0 -0.0\n\nOurs\n\nBas.\n\nOurs\n\nBas.\n\naDα aFR aE aL aMSP aD∗ aFR∗ aM\n\nα\n\ns0\n\ns1\n\nE NEGATIVE RESULTS\n\nE.1 DIFFERENT AGGREGATION OF OOD METRICS\n\nLanguage shifts OOD G.s\n\nR.Sh Abs.\n\nR.Sh Abs.\n\n0.0% 18.1 1.0% 21.8 1.0% 22.3 1.0% 18.7 0.9% 19.1 1.0% 18.5 0.9% 19.3 0.9% 19.3 1.0% 18.4\n\n+0.0 +3.7 +4.2 +0.6 +0.9 +0.3 +1.1 +1.1 +0.3\n\n0.0% 43.9 34.5% 49.2 37.0% 49.7 17.6% 46.0 18.4% 46.2 4.3% 44.3 10.5% 45.3 10.5% 45.3 12.1% 45.3\n\nALL G.s\n\n+0.0 +5.4 +5.9 +2.1 +2.3 +0.5 +1.4 +1.4 +1.4\n\nR.Sh\n\n0.0% 14.6% 15.8% 7.3% 7.6% 2.5% 4.8% 4.8% 5.9%\n\nMost of our detectors are initially classification OOD detectors that we adapted for text generation by averaging them over the generated sequences and using this aggregated score as a score for the whole sequence. We experimented with other aggregations such as the standard deviation or the min/max along the sequence. If the standard deviation gave relatively good results they were still less interesting that the naive average.\n\nE.2 NEGENTROPY OF BAG OF DISTRIBUTIONS\n\nTable 14: Correlation between OOD scores and translation metrics BLEU and BERT-S\n\nScenario\n\ns0\n\ns1\n\nOurs\n\nBaselines\n\nOurs\n\nBaselines\n\nScore\n\naDα aFR aE aL aMSP aD∗ aFR∗ aC aM\n\nα\n\nBertscore f1\n\nBleu score\n\nALL\n\nIN\n\nOUT\n\nALL\n\nIN\n\nOUT\n\n-0.49 -0.47 -0.19 -0.22 -0.28 -0.35 -0.34 -0.12 -0.23\n\n-0.33 -0.33 -0.30 -0.26 -0.15 -0.22 -0.22 -0.07 -0.14\n\n-0.53 -0.45 0.00 0.23 -0.43 -0.65 -0.64 -0.05 -0.29\n\n-0.37 -0.38 -0.16 -0.30 -0.14 -0.24 -0.24 -0.11 -0.11\n\n-0.27 -0.28 -0.21 -0.29 -0.09 -0.18 -0.18 -0.06 -0.06\n\n-0.38 -0.37 0.00 -0.06 -0.14 -0.35 -0.37 -0.12 -0.05\n\nWe introduced in Sec. 3.3 the bag of distributions as a way to aggregate a sequence of probability distribution and compare it to a set of reference using information projections Sec. 3.3. A natural idea would be to apply the Negentropy methods (Sec. 3.2) to these aggregated distributions.\n\nMore formally given a sequence of probability distribution Sθ(x) = {pT compute its bag of distributions:\n\nθ (x, ˆy⩽t)}n\n\nt=1 we would\n\nAnd then compute as novelty score:\n\n ̄pθ(x) ≜ 1\n\n|y|\n\n|y| (cid:88)\n\nt=1\n\npθ(x, y⩽t)\n\nJD(p) = D(p∥U)\n\n(7)\n\n(8)\n\nFurther experiments have shown that this process was unable to discriminate OOD samples or improve performance translation. We suspect that the uncertainty at each step is key to capture the behavior of the language model and that this uncertainty information is lost when averaging probability distribution along the sequence.\n\n27\n\nUnder review as a conference paper at ICLR 2022\n\nE.3 DIFFERENT REFERENCE DISTRIBUTIONS\n\nIn the no-reference scenario we used the uniform distribution as reference distribution to compare against. However, we can obviously use other reference distributions. We tried two natural options: the tf-idf Yuan et al. (2021) distribution and the average distribution on the reference set. The latter effectively replacing the projection onto the reference set by the distance to the average element of it.\n\nIt is worth signaling that these methods falls into the reference scenario since we need it to compute these statistics. They would be interesting though if they could maintain performance while being less computationally expensive than the projection.\n\nWe found out that these references were not as efficient as the projection onto the reference set and did not achieve better performance than their no reference counterparts.\n\ns0\n\ns1\n\nOurs\n\nBas.\n\nOurs\n\nBas.\n\nα\n\naDα aFR aE aMSP aL aD∗ aFR∗ aDmean aDidf aFRmean aFRidf aM aC\n\nα\n\nα\n\nLanguage shifts\n\nDomain shifts\n\nDialog shifts\n\nAUROC FPR\n\nF1\n\nAUROC\n\nFPR\n\nF1\n\nAUROC\n\nFPR\n\nF1\n\n0.95 0.93 0.89 0.87 0.78 0.88 0.88 0.84 0.82 0.72 0.67 0.92 0.71\n\n0.25 0.28 0.44 0.44 0.79 0.34 0.35 0.41 0.48 0.72 0.81 0.26 0.80\n\n0.84 0.83 0.77 0.75 0.50 0.71 0.69 0.62 0.62 0.62 0.61 0.73 0.62\n\n0.85 0.74 0.76 0.78 0.72 0.86 0.81 0.68 0.66 0.53 0.52 0.78 0.68\n\n0.62 0.87 0.78 0.77 0.89 0.50 0.69 0.84 0.87 0.94 0.94 0.59 0.76\n\n0.75 0.60 0.71 0.71 0.65 0.70 0.69 0.67 0.67 0.66 0.66 0.40 0.67\n\n0.79 0.72 0.65 0.66 0.65 0.86 0.76 0.64 0.63 0.58 0.56 0.84 0.72\n\n0.64 0.70 0.76 0.72 0.95 0.52 0.75 0.86 0.87 0.90 0.92 0.55 0.61\n\n0.66 0.64 0.57 0.21 0.62 0.59 0.38 0.57 0.57 0.57 0.57 0.56 0.48\n\nTable 16: Summary of the results including different custom reference distributions.\n\nE.4\n\nIMPACT OF ADDITIONAL FINETUNING ON IN DATA\n\nLanguage shifts\n\nDomain shifts\n\nDialog shifts\n\nAUROC\n\nFPR\n\nF1\n\nAUROC\n\nFPR\n\nF1\n\nAUROC\n\nFPR\n\nF1\n\n0.94 0.92 0.89 0.87 0.78 0.89 0.86 0.84 0.82 0.72 0.62 0.91 0.70\n\n0.26 0.24 0.44 0.44 0.79 0.34 0.37 0.41 0.48 0.72 0.85 0.28 0.80\n\n0.80 0.78 0.72 0.73 0.61 0.60 0.61 0.61 0.61 0.62 0.67 0.60 0.63\n\n0.86 0.72 0.76 0.78 0.74 0.87 0.65 0.68 0.66 0.53 0.55 0.71 0.65\n\n0.65 0.88 0.85 0.83 0.92 0.51 0.93 0.84 0.87 0.94 0.96 0.76 0.76\n\n0.70 0.67 0.67 0.67 0.66 0.71 0.64 0.69 0.69 0.66 0.58 0.57 0.64\n\n0.79 0.72 0.65 0.66 0.65 0.85 0.77 0.64 0.63 0.58 0.56 0.78 0.71\n\n0.70 0.70 0.76 0.72 0.95 0.52 0.77 0.86 0.87 0.94 0.93 0.55 0.61\n\n0.67 0.65 0.59 0.56 0.51 0.59 0.58 0.55 0.55 0.57 0.57 0.57 0.48\n\ns0\n\ns1\n\nOurs\n\nBas.\n\nOurs\n\nBas.\n\nα\n\naDα aFR aE aMSP aL aD∗ aFR∗ aDmean aDidf aFRmean aFRidf aM aC\n\nα\n\nα\n\nTable 17: Summary of the results with additional finetuning of the models on the reference set. The results are similar to the results without finetuning as expected since the models had been trained initially on similar distributions.\n\n28",
  "translations": [
    "# Summary Of The Paper\n\nThe paper explored OOD detection in text. Different from previous OOD work, this paper more focuses on realistic data shifts and domain change. To measure the out-of-domain score, the authors introduce renting divergence and fisher-ran distance.\n\n# Strength And Weaknesses\n\nLack of baselines\nI think the experiment lacks an important baseline, the perplexity (PPL), since this work is based on large pretrained language model. The language model is originally designed to maximize the $p(x) = p(x_1)p(x_2)...p(x_n)$, which is a great anomaly detector itself. \n\nExperiments\n- Have you ever test your model on some other classical OOD tasks?\n\nProblem\n- Could the author give more explanation on no-referene scenario? Take mutual information, a special case of Renyi divergence as an example, I(P, U) = H(P) + H(U) because U and P are independent variables. H(U) is a constant variable for any distribution.  As the results, the entropy is used as the novelty score. \n- Did you fine-tune the language-model with in-domain data?\n\nPerformance\n- From the reviewers' experience on OOD in text, the performance could be much better using a simple plug-in structure. (The reviewer understood that the authors want to avoid the extra plug-in structure, just curious if better results can be achieved)\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThe motivation is clear. \nThe quality could be further improved. \nNovelty is limited.\n\nSuggestion:\n- In section 4.2, it's unnecessary to add an arrow after every AUROC and FPR. \n- The notation part is distributed in two places, 2.1/2.2. Similarly, the related work is also appeared in two places 2.3/3.1. It will be easier to read if related work are together and important notations are gathered.\n\n# Summary Of The Review\n\nI have some doubts on the methods. The experiment part should compare with more baselines on some common OOD datasets. Currently, nearly all the datasets are synthesized by authors and there is no demo in supplementary.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.\n\n# Empirical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, a Relative informAtion Projection OOD detection framework tailored for text generation tasks, addressing the critical issue of out-of-distribution (OOD) detection in natural language generation systems. The authors introduce LOFTER, a novel benchmark for evaluating OOD detection under realistic domain shifts, and demonstrate that existing OOD detection methods may misalign with task-specific performance measures. RAINPROOF effectively mitigates these misalignments, showing superior detection capabilities and enhancing overall performance in machine translation and dialog generation tasks.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative contributions to the field of OOD detection for text generation, including the introduction of the LOFTER benchmark and the RAINPROOF framework, which operates effectively in both reference and no-reference scenarios. The empirical results are compelling, demonstrating RAINPROOF's robust performance compared to existing methods. However, the paper could benefit from a more detailed discussion on the potential limitations of the framework and the implications of its findings in practical applications. Additionally, the evaluation metrics, while insightful, could be expanded to include more diverse performance indicators.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured, presenting its contributions clearly and systematically. The methodology is described with sufficient detail to allow for reproducibility, and the authors' commitment to releasing code and data further enhances the paper's quality. The novelty of the proposed framework and benchmark is significant, given the limited prior work on OOD detection in text generation contexts. Overall, the clarity and quality of the writing facilitate a good understanding of the concepts and findings.\n\n# Summary Of The Review\nRAINPROOF provides a significant advancement in OOD detection for text generation tasks, offering both a novel framework and a comprehensive benchmark for evaluation. The results indicate that the proposed method effectively improves OOD detection performance, which is crucial for enhancing the reliability of conversational and translation systems.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces two key contributions to the field of Out-Of-Distribution (OOD) detection in text generation: the RAINPROOF framework and the LOFTER benchmark. RAINPROOF is an unsupervised OOD detection framework that operates in both black-box settings and scenarios with reference in-distribution (IN) samples, utilizing information-theoretic measures like Rényi divergences and Fisher-Rao distance to compute anomaly scores. LOFTER serves as an operational benchmark for evaluating OOD detection performance in realistic settings that extend beyond English. Experimental results demonstrate that RAINPROOF significantly outperforms existing OOD detection methods, achieving high AUROC scores and revealing that traditional OOD detectors may filter out useful samples, adversely affecting task performance.\n\n# Strength And Weaknesses\nThe strengths of the paper include the introduction of an innovative and comprehensive framework that addresses a crucial gap in OOD detection for text generation, an area that has been less explored compared to traditional classification tasks. The experimental evaluation is robust, showcasing RAINPROOF's superior performance across various datasets and scenarios. However, the paper also presents several weaknesses, including the potential complexity and resource demands of implementing the information-theoretic measures, which may hinder accessibility for practitioners. Additionally, the generalizability of the findings across diverse languages and domains remains untested, and the reliance on specific reference sets raises concerns about overfitting.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and well-structured, making it easy to follow the presented methodologies and results. The quality of the experiments is commendable, providing a thorough evaluation of RAINPROOF against established baselines. The novelty of the proposed framework and benchmark is high, contributing significantly to the field. However, reproducibility could be a concern due to the complexity of the employed methodologies and lack of extensive discussion on implementation details.\n\n# Summary Of The Review\nOverall, this paper makes a notable contribution to OOD detection in text generation through the introduction of RAINPROOF and LOFTER, addressing existing gaps in the field. While the proposed methods show strong empirical performance, challenges related to implementation complexity and generalizability should be further investigated.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"RAINPROOF: An Umbrella to Shield Text Generators from Out-of-Distribution Data\" presents a novel framework for Out-of-Distribution (OOD) detection specifically tailored for text generation tasks, such as machine translation and dialog generation. Key contributions include the development of RAINPROOF, an information-theoretic OOD detection method, and the introduction of LOFTER, a benchmark for evaluating OOD detection in text generation. The authors demonstrate that OOD detection can significantly enhance translation quality and system robustness, with evaluations showing RAINPROOF outperforms existing methods on various language and domain shifts.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to applying OOD detection in text generation, an area often overlooked in existing literature. The introduction of LOFTER as an operational benchmark is a significant contribution, providing a standardized way to evaluate different OOD detectors. Additionally, the authors' commitment to open-source code and data promotes reproducibility. However, the paper could benefit from a more detailed discussion on the limitations of RAINPROOF, particularly regarding its performance under different scenarios and potential trade-offs in computational efficiency.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodologies clearly, making it accessible to readers familiar with OOD detection and natural language generation. The quality of the experiments is commendable, and the use of established metrics (AUROC, FPR, F1) aids in the evaluation of detector performance. The novelty of the information-theoretic approach to OOD detection in text generation is noteworthy, although the theoretical underpinnings could be further elaborated. Reproducibility is addressed through the authors' commitment to sharing code and data, which is a strength of the work.\n\n# Summary Of The Review\nOverall, the paper presents a strong contribution to the field of natural language generation by addressing a critical gap in OOD detection. RAINPROOF offers a robust solution for enhancing system performance in the presence of distribution shifts, and the establishment of LOFTER as a benchmark is a valuable addition. While the paper is clear and well-executed, further exploration of the limitations and practical implications of RAINPROOF would enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces RAINPROOF, a novel out-of-distribution (OOD) detection framework specifically designed for text generation tasks. The authors propose a new benchmark, LOFTER, which serves as a more practical evaluation setting for OOD detection in text generation, addressing the limitations of previous benchmarks. The findings demonstrate that RAINPROOF not only enhances OOD detection capabilities but also improves overall performance in text generation, showing promising results across various scenarios, albeit with some inconsistencies, particularly in dialog generation tasks.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Novel Framework**: RAINPROOF presents an innovative approach to OOD detection in text generation, which is a significant contribution to the field. However, the complexity of its implementation might pose challenges for practitioners lacking a deep understanding of its theoretical foundations.\n2. **Operational Evaluation Setting**: The introduction of LOFTER as an operational benchmark enhances the practical relevance of the evaluation, although its reliance on specific datasets may limit generalizability across diverse languages or domains.\n3. **Performance Improvement**: The results indicate an improvement in OOD detection and performance for text generators, countering the traditional performance drop associated with similar methods. Nonetheless, the observed weaknesses in dialog generation tasks suggest a need for further refinement.\n4. **Black-box Scenario Compatibility**: The framework’s effectiveness in black-box settings increases its applicability in real-world environments, though this may compromise transparency and interpretability.\n5. **Promoting Reproducibility**: The authors commit to publishing their code and data, which supports transparency and facilitates validation of their findings by other researchers. However, the specific implementations and hyperparameters may affect reproducibility across different environments.\n\n**Weaknesses:**\n1. **Limited Exploration of OOD Types**: The focus on language and domain shifts does not fully address the variety of OOD scenarios, suggesting the need for broader exploration in future work.\n2. **Narrow Performance Metrics**: The heavy reliance on AUROC and FPR metrics may not provide a comprehensive view of model efficacy, indicating that additional metrics like precision and recall could enrich the evaluation.\n3. **Dependency on Reference Samples**: RAINPROOF’s performance hinges on the quality and quantity of available reference samples, which may not be feasible in low-resource contexts.\n4. **Increased Computational Costs**: The implementation of an information-theoretic approach may elevate computational demands, potentially limiting practicality in resource-constrained or real-time settings.\n5. **Interpretability Issues**: While RAINPROOF offers some interpretability, its decision-making process lacks transparency in numerous cases, which may hinder trust in sensitive applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its contributions clearly, making it accessible to readers. The novelty of the framework is evident, although the complexity may challenge practical application. The authors’ commitment to reproducibility through the release of code and data is commendable, yet the dependency on specific implementations raises concerns about consistency across different research environments.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in OOD detection for text generation through the introduction of RAINPROOF and the LOFTER benchmark. While it demonstrates promising results and addresses key challenges, certain limitations in scope, performance metrics, and interpretability need to be addressed to enhance its applicability and impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces RAINPROOF (Relative informAtion Projection OOD detection framework), a novel approach for out-of-distribution (OOD) detection specifically designed for text generation tasks. The authors propose an operational benchmark, LOFTER, which enhances the evaluation of OOD detection performance by addressing language and domain shifts. RAINPROOF utilizes an information-theoretic methodology, incorporating measures such as Renyi divergence and Fisher-Rao distance to compute anomaly scores, effectively balancing the detection of OOD samples while preserving the integrity of in-distribution instances. The experimental results demonstrate that RAINPROOF outperforms traditional OOD detection methods, leading to improvements in translation performance on in-distribution samples.\n\n# Strength And Weaknesses\nThe major strength of the paper lies in its innovative methodological framework that effectively merges information theory with practical applications in OOD detection for text generation. The introduction of LOFTER as an evaluation benchmark is a notable contribution, providing a more realistic assessment environment that reflects real-world challenges. However, a potential weakness is that the paper could benefit from a more detailed discussion of the limitations and scenarios where RAINPROOF may not perform as effectively, as well as a comparative analysis with more varied existing methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its methodologies and findings, making it accessible to readers. The novelty of the approach is evident, particularly in the use of information-theoretic measures for OOD detection, which distinguishes it from existing methodologies. The authors' commitment to releasing their code and datasets upon acceptance enhances the reproducibility of their work, promoting transparency in the research community.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in OOD detection for text generation tasks through the innovative RAINPROOF framework and the introduction of the LOFTER benchmark. The findings are compelling, and the authors’ dedication to reproducibility strengthens the impact of their contributions.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces \"RAINPROOF,\" a novel framework designed to enhance the robustness of text generation systems against adversarial attacks. The authors propose a Relative Information Projection method for adversarial training, which allows for improved resilience without requiring extensive labeled datasets. They evaluate the effectiveness of RAINPROOF against traditional methods and present a new benchmark for assessing adversarial training in text generation. The findings indicate that RAINPROOF significantly outperforms existing approaches in both robustness and output quality, while also addressing the issue of filtering beneficial samples during adversarial training.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to adversarial training in the context of text generation, which is a less-explored area compared to image classification. The introduction of a practical evaluation benchmark is a notable contribution, as it provides a clearer understanding of model robustness. Additionally, the authors' commitment to open-sourcing their code and datasets promotes reproducibility and further research. However, the paper could improve by providing a more thorough analysis of the trade-offs between robustness and generation quality and by including experiments across a broader range of text generation tasks to validate the generalizability of their findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions, methodology, and findings. The writing quality is high, and the logical flow makes it easy to follow the authors' arguments. The novelty of the approach is significant, as it addresses a gap in adversarial training for text generation. The commitment to reproducibility through open-source code and datasets further enhances the paper's quality, allowing other researchers to build upon the work.\n\n# Summary Of The Review\nOverall, the paper presents a substantial contribution to the field of adversarial training for text generation, offering a novel framework that effectively enhances model robustness. The findings are well-supported by experiments, and the authors provide a clear path for future research in the area. Despite some areas for improvement, the work is impactful and timely.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"RAINPROOF: An Umbrella to Shield Text Generators from Out-of-Distribution Data\" proposes a new framework for out-of-distribution (OOD) detection in text generation systems. The authors present RAINPROOF as a groundbreaking approach, introducing a novel detection method called Relative Information Projection and a benchmark named LOFTER, which aims to redefine performance standards in the field. Findings indicate that RAINPROOF significantly outperforms existing methods in OOD detection, and the authors argue that their work will catalyze a transformational shift in the application of OOD detection techniques across various domains.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its ambitious claims regarding the framework's transformative potential and the introduction of a new benchmark LOFTER, which could help standardize the evaluation of OOD detection techniques. The methodology presented is framed as innovative, promising improvements not only in performance but also in the interpretability of OOD detection. However, the weaknesses include an overestimation of the contributions, as the advancements appear to be incremental rather than revolutionary. The paper lacks comprehensive comparisons with existing methodologies, which could provide a more balanced perspective on the significance of its contributions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the presentation is generally good, with a logical flow of ideas, although some technical details regarding the implementation of the Relative Information Projection method could be elaborated further. The quality of the writing is high, and the paper is well-structured. While the novelty of the proposed method is highlighted, the claims regarding its significance should be supported by more rigorous empirical validation. Reproducibility could be enhanced by providing additional experimental details and code availability.\n\n# Summary Of The Review\nOverall, the paper presents a well-structured proposal for a new OOD detection framework in text generation, with promising results and a new benchmark. However, the claims of revolutionary impact are overstated, and a more measured assessment of the contributions would strengthen the paper's credibility.\n\n# Correctness\nRating: 4/5  \nThe methodology and findings are generally sound, but the claims of revolutionary advances require more empirical support.\n\n# Technical Novelty And Significance\nRating: 3/5  \nWhile the proposed method is novel, its significance appears to be more incremental in nature compared to existing approaches.\n\n# Empirical Novelty And Significance\nRating: 3/5  \nThe empirical results show promise, but a more comprehensive evaluation against a broader set of benchmarks would enhance the assessment of its significance.",
    "# Summary Of The Paper\nThe paper introduces RAINPROOF, a novel out-of-distribution (OOD) detection framework specifically designed for text generation tasks, such as machine translation and dialog generation. The authors present LOFTER, a new benchmark for evaluating OOD detection in practical scenarios, emphasizing the importance of reliable text generation in open-world settings. RAINPROOF employs a fully unsupervised approach that utilizes information-theoretic measures to enhance OOD detection capabilities, achieving notable improvements in detection rates and overall model performance across various language and domain shifts.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative contributions, including the introduction of the LOFTER benchmark and the RAINPROOF framework, both of which address the gap in OOD detection for text generation tasks. The methodology is robust, and the empirical results demonstrate significant improvements over traditional methods, particularly in the context of language and dialog shifts. However, a potential weakness is the performance drop observed in domain shifts, which, while still superior to classical methods, suggests that further refinements may be necessary to handle such scenarios more effectively.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and findings. The novelty of the RAINPROOF framework and LOFTER benchmark is apparent, as they address an under-explored area in the literature. The authors commit to releasing code post-acceptance, which enhances the reproducibility of their work, although the lack of immediate availability may hinder some aspects of validation for the community.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in OOD detection for text generation, showcasing a novel framework and benchmark that fill an important gap in existing research. While the results are promising, particularly in enhancing model performance alongside detection capabilities, there remains room for improvement in handling domain shifts.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper \"RAINPROOF: An Umbrella to Shield Text Generators from Out-of-Distribution Data\" proposes a novel framework for detecting and handling out-of-distribution (OOD) data in text generation tasks. The authors introduce specific statistical distance metrics, such as Renyi divergence and Fisher-Rao distance, to measure distribution shifts, emphasizing task-specific performance metrics rather than traditional OOD detection metrics. The framework aims to filter out detrimental OOD samples while maintaining the potential value of certain outliers, and it claims to generalize existing OOD detection methods across various modalities. The findings suggest improvements in model performance in the presence of filtered OOD samples, although several fundamental assumptions underpin the methodology that warrant scrutiny.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to OOD detection, particularly the emphasis on task-specific metrics, which could provide a more nuanced understanding of language generation quality. The proposed filtering mechanisms show promise in improving model performance. However, the paper's weaknesses are pronounced; many assumptions, such as the dichotomy between closed and open world scenarios, the adequacy of statistical distance metrics, and the generalizability of existing OOD methods, are not sufficiently justified. Additionally, the reliance on a black-box framework may overlook critical interpretability aspects, and the evaluation metrics used may not accurately reflect real-world performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, yet some sections lack depth in discussing the implications of the assumptions made. The novelty is commendable, particularly in the context of applying OOD detection to language generation, but it is undermined by insufficient empirical validation of the proposed methodologies. Reproducibility is a concern, as the paper does not provide detailed information on the implementation of the proposed metrics and filtering techniques, which could hinder replication efforts by other researchers.\n\n# Summary Of The Review\nOverall, the paper presents a promising framework for addressing OOD data in text generation but is hindered by several unexamined assumptions and insufficient empirical validation. While the contributions to the field are noteworthy, the clarity and robustness of the methodology could be significantly improved.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, a novel framework designed for out-of-distribution (OOD) detection specifically in text generation tasks, such as machine translation and dialog generation. The authors introduce the LOFTER benchmark for evaluating OOD detection methods in this domain and propose a methodology that leverages information-theoretic measures for scoring OOD samples. The findings indicate that RAINPROOF outperforms existing baseline methods, enhancing both OOD detection capabilities and translation performance, while also advocating for a dual evaluation approach that considers both detection metrics and overall system performance.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its clear identification of a gap in OOD detection methodologies tailored for text generation, the introduction of the LOFTER benchmark, and the innovative application of information theory in the RAINPROOF framework. The results convincingly demonstrate the framework's efficacy, providing solid empirical support for its contributions. However, one potential weakness lies in the limited exploration of practical scenarios where the model may be applied, as well as the need for further validation across diverse datasets and contexts beyond those presented in the experiments.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured, with a clear progression from problem statement to methodology and results. The quality of the writing is high, making complex ideas accessible. The novelty of the approach is notable, especially given the lack of prior focus on OOD detection in text generation. The authors emphasize reproducibility by committing to code availability, which is a significant positive aspect.\n\n# Summary Of The Review\nOverall, RAINPROOF makes a valuable contribution to the field of OOD detection in text generation, demonstrating both innovative methodology and impressive empirical results. While the paper presents a strong case for its approach, further exploration of real-world applicability would enhance its impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper addresses a significant issue in the domain of machine learning: the challenge of out-of-distribution (OOD) detection. The authors propose a novel framework that combines uncertainty estimation with a new loss function to enhance the robustness of models in identifying OOD samples. Through extensive experiments on standard benchmarks, the proposed method demonstrates superior performance compared to existing techniques, highlighting its effectiveness in practical applications such as image classification and anomaly detection.\n\n# Strengths And Weaknesses\n**Strengths**  \n1. **Novelty**: The integration of uncertainty estimation with a customized loss function presents a fresh approach to OOD detection, which has potential implications for improving model reliability.\n2. **Relevance**: The focus on OOD detection is crucial given the increasing deployment of machine learning models in safety-critical applications, ensuring that the paper addresses a timely and significant problem.\n3. **Clarity**: The paper is well-structured and clearly written, making complex ideas accessible to a broad audience while maintaining a rigorous scientific tone.\n4. **Comprehensive Evaluation**: The authors provide a thorough evaluation on multiple datasets, showcasing the advantages of their approach through both quantitative metrics and visualizations.\n\n**Weaknesses**  \n1. **Limited Baselines**: While the authors compare their method against a few existing techniques, the inclusion of a wider array of baselines would better contextualize their claims of superiority.\n2. **Generalizability**: The discussion surrounding the method’s applicability to various domains or different types of data is somewhat limited, raising questions about its robustness across diverse settings.\n3. **Complexity**: The proposed method introduces additional complexity, which could pose challenges in real-world implementations. A detailed analysis of the trade-offs between complexity and performance would be beneficial.\n4. **Interpretability**: The paper lacks a deeper exploration of how the model's decisions are made, which could enhance the understanding of its operational mechanics and increase user trust.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper demonstrates a high level of clarity and quality, with well-defined objectives and a coherent structure. The novelty of the approach is evident, particularly in its combination of uncertainty estimation with a new loss function. However, the reproducibility of the results could be improved by providing more details on the implementation and hyperparameter settings used in the experiments.\n\n# Summary Of The Review\nThis paper presents a valuable contribution to the field of OOD detection through a novel framework that effectively combines uncertainty estimation with a specialized loss function. While the methodology and findings are promising, addressing the limitations related to baseline comparisons and generalizability could significantly enhance the paper's impact. \n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper \"RAINPROOF: An Umbrella to Shield Text Generators from Out-of-Distribution Data\" presents a novel framework for out-of-distribution (OOD) detection in natural language generation (NLG) systems, specifically targeting machine translation and dialog generation. The authors highlight a significant gap in existing research, noting that while OOD detection has been extensively explored in classification tasks, it remains under-addressed in the context of text generation. RAINPROOF not only focuses on detecting OOD samples but also assesses the impact of OOD detection on overall system performance. The findings reveal that traditional OOD detection methods can degrade translation quality by filtering out relevant samples, while RAINPROOF improves both detection accuracy and task-specific performance.\n\n# Strength And Weaknesses\nThe paper makes substantial contributions by filling a critical gap in OOD detection for NLG systems, emphasizing the need for tailored methods that consider the unique challenges of text generation. The methodology is well-articulated, incorporating unsupervised detection techniques that enhance usability in real-world scenarios. However, a potential weakness lies in the lack of extensive empirical validation across diverse datasets and languages, which could strengthen the generalizability of the proposed framework. Additionally, the paper could benefit from a more detailed discussion on how the framework scales with increasing complexity in language and context.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and presents its ideas in a structured manner, making it accessible to a wide audience. The quality of the methodology is high, and the novelty of focusing on OOD detection in text generation is significant. However, while the authors advocate for comprehensive evaluation metrics, the reproducibility of the results may be hindered by the absence of detailed implementation specifics and benchmark comparisons with existing methods. Including these aspects could enhance the paper's impact and encourage further research.\n\n# Summary Of The Review\nOverall, the paper presents a timely and significant contribution to the field of natural language generation by addressing the critical issue of OOD detection. While the proposed RAINPROOF framework demonstrates promising results and emphasizes the importance of considering task-specific performance, further empirical validation and detailed implementation guidance would strengthen its applicability and reproducibility.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper introduces RAINPROOF, a framework designed for out-of-distribution (OOD) detection in text generation systems, addressing a significant gap in the literature where most existing OOD detection research focuses on classification tasks. The authors propose the LOFTER benchmark for evaluating OOD detection in neural machine translation and dialog generation, which incorporates realistic data shifts. The findings reveal that OOD detection can detrimentally impact task-specific performance and that RAINPROOF is effective at both improving OOD detection and enhancing overall model performance.\n\n# Strength And Weaknesses\nStrengths of the paper include its novel contributions to the field of OOD detection in natural language generation, particularly through the introduction of the LOFTER benchmark and the RAINPROOF framework, which leverages information theory for unsupervised detection. Additionally, the paper provides insights into the adverse effects of OOD detection on task performance, emphasizing the need for task-specific metrics. However, a potential weakness is the limited scope of empirical evaluation across various text generation tasks; while the performance improvements are noted, a broader evaluation would strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The novelty of RAINPROOF and the LOFTER benchmark is significant, filling an important research gap in OOD detection for text generation. The authors have made their code and datasets open-source, promoting reproducibility and encouraging further research, which is commendable. However, the paper could benefit from additional clarity regarding the specific implementation details of RAINPROOF.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of OOD detection in text generation, addressing critical challenges and proposing a robust framework. With strong methodological foundations and an emphasis on reproducibility, it sets the stage for future research in this area. However, expanding the empirical evaluation could further substantiate the claims made.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"RAINPROOF: An Umbrella to Shield Text Generators from Out-of-Distribution Data\" introduces a novel framework aimed at enhancing out-of-distribution (OOD) detection specifically for text generation tasks. The main contributions include the development of the LOFTER benchmark for evaluating OOD detection in text generation, the RAINPROOF framework which utilizes information-theoretic principles for OOD detection, and a detailed analysis of how OOD detection affects task-specific performance. The authors present experimental results demonstrating that RAINPROOF outperforms existing methods in terms of both OOD detection efficacy and overall translation quality.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its clear identification of a pressing issue in natural language generation (NLG) and the introduction of a comprehensive new benchmark (LOFTER) that fills a significant gap in the evaluation of OOD detection methods. The methodology is well-structured, employing rigorous techniques for both no-reference and reference scenarios. However, the paper could benefit from a more thorough discussion of the limitations of the proposed methods and the potential challenges in real-world applications. Additionally, while the findings are compelling, they may require more contextualization regarding their practical implications for practitioners in the field.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with clear contributions and a logical flow of ideas. However, certain sections contain technical jargon that may pose accessibility challenges for readers not deeply familiar with the domain. The novelty of the proposed RAINPROOF framework and the LOFTER benchmark is significant, as they address a critical gap in the existing literature on OOD detection in text generation. The authors have committed to making their code publicly available, enhancing the reproducibility of their results.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of natural language generation by addressing OOD detection through a novel framework and benchmark. While the findings are promising and the methodology robust, the paper could improve its accessibility and provide more insights into practical applications and limitations.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, a novel framework for out-of-distribution (OOD) detection in the context of text generation, particularly focusing on machine translation and dialog systems. The authors identify the limitations of existing OOD detection methods which primarily cater to classification tasks, highlighting the challenges posed by distributional shifts in text generation. RAINPROOF employs information-theoretic principles, particularly Rényi divergences, to compute anomaly scores, effectively distinguishing between in-distribution and out-of-distribution samples. Empirical evaluations demonstrate that RAINPROOF significantly outperforms traditional methods in both OOD detection and task-specific performance metrics, while also introducing a comprehensive evaluation framework for assessing OOD detection systems.\n\n# Strength And Weaknesses\nThe major strength of the paper lies in its innovative approach to OOD detection, bridging a gap in the literature that has largely overlooked text generation contexts. By employing an information-theoretic framework, the authors provide a robust mechanism for quantifying distributional divergences. The empirical results are compelling, showing marked improvements over existing techniques. However, the paper could benefit from a more extensive discussion on the practical implementation of RAINPROOF in real-world systems, as well as potential limitations and edge cases that may not have been fully explored in the experiments.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates both the theoretical foundations and practical implementations of RAINPROOF. The methodology is detailed, allowing for reproducibility, though the description of the experimental setup could be expanded to aid researchers seeking to replicate the results. The novelty of the approach is significant, as it introduces a new perspective on OOD detection tailored specifically for text generation, an area that has received insufficient attention in prior research.\n\n# Summary Of The Review\nOverall, this paper makes a notable contribution to the field of NLP by addressing the critical issue of OOD detection in text generation. The proposed RAINPROOF framework is innovative and shows promising empirical results that highlight its effectiveness. While the paper is clear and well-written, further elaboration on practical implications and limitations could enhance its impact.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a new framework called RAINPROOF aimed at improving out-of-distribution (OOD) detection in text generation tasks. The authors claim that RAINPROOF leverages information theory concepts to enhance detection performance and introduce a new benchmark, LOFTER, intended to facilitate operational evaluations in this domain. However, the paper lacks a strong motivation for the importance of OOD detection in text generation and does not provide compelling evidence that RAINPROOF offers substantial improvements over existing methods.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address a pertinent issue within text generation, namely OOD detection. However, the contributions appear to be largely reiterative of existing methods, lacking true innovation. The operational evaluation setting does not convincingly demonstrate improvements over established benchmarks, and the necessity of the LOFTER benchmark is poorly justified. Furthermore, the performance metrics employed may oversimplify real-world complexities, raising concerns about the reliability of the conclusions drawn from the experiments. Notably, the authors fail to adequately discuss the limitations of their framework, particularly concerning computational efficiency and scalability, which are critical for practical implementation.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is undermined by a superficial introduction that does not effectively communicate the significance of the research problem. The quality of the methodology is questionable due to the lack of rigorous statistical validation of the results, as well as insufficient discussion of the experiments conducted, particularly regarding dialog shifts. While the authors promise open-source code availability, the lack of transparency in experimental design raises concerns about reproducibility and the reliability of the reported findings.\n\n# Summary Of The Review\nOverall, the paper presents a seemingly innovative framework for OOD detection in text generation but ultimately falls short in its contributions and empirical validation. The claims of novelty and performance improvement are not sufficiently supported, leading to doubts about the practical applicability of the proposed methods.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, a novel framework for out-of-distribution (OOD) detection tailored for text generation tasks. RAINPROOF introduces a Relative informAtion Projection methodology, which significantly enhances OOD sample detection while improving the overall performance of text generation systems. The development of the Language Out oF disTribution pErformance benchmark (LOFTER) establishes a new standard for evaluating text generators under realistic data shifts. Notably, RAINPROOF operates effectively in unsupervised settings and black-box scenarios, utilizing advanced information-theoretic tools such as Rényi divergence and Fisher-Rao distance to achieve its results.\n\n# Strength And Weaknesses\nStrengths of this paper include its innovative approach to OOD detection in text generation, the dual improvement in detection and generation performance, and the practical applicability in unsupervised and black-box environments. The introduction of LOFTER as a benchmark is a significant contribution that aligns evaluation practices with real-world applications. However, the paper could benefit from a more extensive empirical evaluation across diverse datasets and languages to fully validate its claims. Some sections may require clearer explanations of the technical aspects to enhance understanding for a broader audience.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its ideas clearly, although some advanced concepts may pose challenges for readers without a strong background in information theory. The quality of the writing is high, reinforcing the significance of the contributions. The novelty of RAINPROOF is substantial, addressing a key gap in OOD detection for text generation. The authors' commitment to open-sourcing their code and data enhances the reproducibility of their results, fostering trust and collaboration in the research community.\n\n# Summary Of The Review\nRAINPROOF represents a significant advancement in OOD detection for text generation, combining innovative methodology with practical applications in real-world scenarios. While the framework shows great promise and is grounded in solid theoretical foundations, further empirical validation across diverse contexts would strengthen its impact.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces the RAINPROOF framework (Relative informAtion Projection OOD detection) for enhancing out-of-distribution (OOD) detection in Natural Language Generation (NLG). By leveraging principles from information theory, the framework employs measures such as Rényi divergence and Fisher-Rao distance to analyze distributional similarities. The authors propose a novel methodological approach that incorporates a bag of distributions and emphasizes the importance of reference sets to establish norms for OOD detection, ultimately advancing theoretical discourse in the field and suggesting a need for holistic performance metrics that consider both detection efficacy and downstream task performance.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its theoretical grounding and innovative use of information theory to address the challenges of OOD detection in generative text contexts. The introduction of a bag of distributions and the emphasis on reference sets provide a fresh perspective that enhances the robustness of existing methods. However, the paper could benefit from clearer empirical validation of the proposed framework and a more detailed discussion on practical implementation challenges, which might limit its immediate applicability in real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its ideas clearly, making the theoretical contributions accessible to readers. The quality of the writing is high, with careful attention to the nuances of the theoretical framework. In terms of novelty, the integration of information theory into OOD detection for NLG is significant. However, the reproducibility of the proposed methods could be improved by providing more detailed descriptions of the implementation and evaluation processes, as well as sharing code or datasets for practical use.\n\n# Summary Of The Review\nOverall, the paper presents a theoretically robust and novel approach to OOD detection in text generation, contributing significantly to the discourse on this critical topic. While the framework is conceptually strong, the authors should aim to enhance empirical validation and clarity on practical applications to bolster its impact in the field.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, a Relative informAItioN Projection framework designed for out-of-distribution (OOD) detection in text generation tasks. The methodology is fully unsupervised and applicable in scenarios where no reference samples are available, utilizing predictions negentropy and Information Projection for effective OOD detection. The authors introduce a new benchmark dataset, LOFTER, which simulates realistic data shifts and evaluates the performance of various OOD detection methods, including Maximum Softmax Probability and Energy-based scores. The findings suggest that while RAINPROOF offers robust OOD detection capabilities, common detectors often misclassify samples that the model can handle well.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to OOD detection without requiring reference samples, which is a significant advancement in the field. The introduction of the LOFTER dataset is also commendable, as it provides a challenging benchmark for future research. However, a notable weakness lies in the lack of clear advantages for using alternative reference distributions over a uniform distribution, suggesting a potential limitation in the proposed framework's flexibility. Additionally, the paper could benefit from more extensive discussions on the implications of parameter tuning on performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its ideas clearly, though some sections could be more concise to enhance readability. The quality of the experiments and results is satisfactory, with comprehensive metrics provided for evaluation. The novelty of the approach is significant, particularly in the context of unsupervised OOD detection in text generation. The authors have committed to publishing their code and data on GitHub, which is a positive step towards ensuring reproducibility.\n\n# Summary Of The Review\nOverall, the paper presents an innovative framework for OOD detection in text generation, supported by a new benchmark dataset. While the contributions are notable, particularly in the unsupervised context, some aspects of the methodology could be further clarified and enhanced. The results suggest practical implications for balancing detection performance with task performance.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled RAINPROOF aims to address the challenge of out-of-distribution (OOD) detection in text generation. The authors propose a framework that reportedly operates effectively in black-box scenarios, introducing a new operational benchmark named LOFTER. They claim that RAINPROOF outperforms existing no-reference baselines and provides a filtering mechanism for well-processed samples. However, the paper lacks comprehensive comparative analysis against established OOD detection methodologies and relies heavily on theoretical constructs from information theory.\n\n# Strength And Weaknesses\nThe primary strengths of the paper are its focus on operational evaluations and the attempt to innovate in the OOD detection space for text generation. However, several weaknesses undermine the paper's contributions. Firstly, the novelty of their framework is questionable, as many existing methods have addressed similar issues more effectively. The introduction of LOFTER appears to add unnecessary complexity without justifiable improvements. Additionally, the lack of substantial evidence for their claims of improved performance against common baselines raises concerns about the validity of their results. The reliance on reference distributions further contradicts their black-box premise, and the experiments indicate underperformance compared to established benchmarks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper presents its ideas in a clear manner, but the quality of the contributions is diminished due to the lack of rigorous validation and comparative analysis. The novelty of the proposed methods is questionable, as they do not significantly advance the field beyond what has already been established. Reproducibility may be hindered by the reliance on theoretical concepts that do not translate well into practical improvements, coupled with inadequate details on the experimental setup.\n\n# Summary Of The Review\nOverall, RAINPROOF attempts to innovate in the realm of OOD detection for text generation, but it falls short in providing substantial evidence to support its claims and lacks rigorous comparisons to established methods. While the focus on operational evaluations is commendable, the paper does not convincingly demonstrate how its framework offers tangible benefits over existing approaches.\n\n# Correctness\nRating: 2/5\n\n# Technical Novelty And Significance\nRating: 2/5\n\n# Empirical Novelty And Significance\nRating: 1/5",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, a detection framework designed to shield text generators from out-of-distribution (OOD) data. It introduces LOFTER, a benchmark for assessing language performance under OOD conditions. The methodology focuses on a black-box scenario typical in Software as a Service (SaaS) contexts, where the authors explore the discrepancies between OOD detection and task-specific performance measures. The findings reveal that existing OOD detection methods do not necessarily align with performance metrics specific to the tasks, suggesting that improvements can be made in the evaluation of these models.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its novel contribution to the field of OOD detection by highlighting the misalignment between OOD detection capabilities and task-specific performance. The introduction of LOFTER provides a valuable resource for future research. However, the paper suffers from several clarity issues and minor errors in grammar and notation, which may hinder readers' understanding. The methodology could also benefit from a clearer articulation of how the proposed framework can be applied in practical settings.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a novel approach to OOD detection, its clarity is somewhat compromised by inconsistent terminology, vague phrasing, and typographical errors. The methodology section, although rich in detail, could be better structured for improved comprehension. The reproducibility of the results may be affected by the lack of consistent notation and definitions throughout the paper. Overall, the paper's quality is high in terms of contributions but is marred by issues that could impact clarity and reproducibility.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the understanding of OOD detection in text generation, introducing both a novel framework and benchmark. However, clarity and consistency issues detract from the paper's overall impact and may complicate the reader's ability to fully grasp the methodologies employed.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper focuses on out-of-distribution (OOD) detection in text generation systems, proposing a new framework aimed at enhancing the reliability of generated texts by identifying instances that deviate from the training data distribution. The authors employ a specific methodology, leveraging existing OOD detection techniques to analyze their effectiveness in the context of text generation. Key findings suggest that the proposed framework can improve detection accuracy, although the evaluation is limited to a narrow set of benchmarks and metrics.\n\n# Strength And Weaknesses\nWhile the paper presents a relevant contribution to OOD detection in text generation, it has notable limitations. A primary strength is its innovative approach to integrating OOD detection into text generation models, which is timely given the growing reliance on such models in various applications. However, the paper's weaknesses include a lack of exploration into other NLP tasks where OOD detection is equally critical, such as summarization and sentiment analysis. Furthermore, the absence of a comparative analysis with state-of-the-art methods and the limited evaluation metrics constrain the robustness of the findings. The implications of OOD detection on interpretability and model transparency are underexplored, and the paper does not address potential scalability issues for real-time applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is reasonable, though it could benefit from a more detailed discussion of the methodology and results. The quality of the writing is adequate, but some sections lack depth, particularly in discussing the implications of OOD detection. The novelty of the proposed framework is notable, yet the paper does not sufficiently establish its significance relative to existing approaches. Reproducibility is hindered by the limited evaluation metrics and the lack of comprehensive benchmarks, which would aid in validating the findings.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to OOD detection in text generation but falls short in addressing several critical aspects, including broader applicability, interpretability, and robustness. The lack of comparative analysis and comprehensive evaluation metrics limits the impact of the findings. Additional exploration of ethical implications and user feedback integration could enhance the framework's relevance and applicability.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a comprehensive evaluation framework for Out-of-Distribution (OOD) detection in text generation tasks, underscoring the necessity for robust statistical methodologies. It introduces key metrics such as True Positive Rate (TPR), False Positive Rate (FPR), and Area Under the Receiver Operating Characteristic curve (AUROC) to assess OOD detectors' performance. The authors employ statistical significance testing and information theory metrics, including Renyi Divergence and Fisher-Rao Distance, to enhance the detection capabilities. Empirical results demonstrate that the proposed method, RAINPROOF, significantly outperforms baseline models across multiple scenarios, validating the effectiveness of OOD filtering.\n\n# Strength And Weaknesses\nStrengths of the paper include its thorough exploration of statistical methods for OOD detection and the introduction of innovative metrics that address the unique challenges of text generation. The experimental design, which incorporates parameter tuning and cross-validation, enhances the robustness of the findings. However, the paper could benefit from a more detailed discussion regarding the potential negative impacts of inappropriate OOD filtering, as well as clearer explanations of the statistical significance tests employed, which may hinder the understanding for readers less familiar with the methodology.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodology clearly, yet some sections may be overly technical for a broader audience. The quality of the empirical results is commendable, with a rigorous approach to statistical validation. The novelty lies in the integration of advanced statistical measures tailored for OOD detection; however, the reproducibility of results could be improved by providing more extensive details on the datasets used and the experimental setup.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of OOD detection in text generation, offering an innovative framework and validating its approach through empirical results. While it excels in methodological rigor and contributions to statistical evaluation, it could enhance clarity and reproducibility to better serve the research community.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a framework for out-of-distribution (OOD) detection in text generation tasks, focusing on unsupervised methods. The authors aim to extend traditional OOD detection techniques to sequence generation, proposing a novel approach that leverages reference distributions for anomaly detection. The findings indicate that while the proposed methods can filter out OOD samples, they may also inadvertently exclude well-processed samples, raising concerns about the calibration of detection thresholds.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative application of OOD detection within the context of text generation and its focus on unsupervised methods, which can be advantageous in scenarios lacking labeled data. However, significant weaknesses include the limited exploration of the implications of the operational setting for OOD detection, particularly in varying real-world contexts. The reliance on a black-box approach restricts interpretability, and the generalization of traditional OOD detectors may not adequately capture the complexities of text data. Additionally, the evaluation metrics may not fully represent practical effectiveness, and there is insufficient discussion regarding computational costs and scalability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, but some sections lack clarity, particularly regarding the implications of the chosen methodologies and the discussion of results. The novelty of applying OOD detection to text generation is evident, yet the reproducibility is hindered by a lack of extensive comparisons with state-of-the-art methods and limited exploration of alternative techniques. The authors do not provide sufficient detail on how the proposed methods could be adapted to different languages or domains.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to OOD detection in text generation, but it falls short in several critical areas, including interpretability, scalability, and thorough evaluation against existing methods. Further exploration is needed to address the limitations identified, especially in terms of practical applicability and computational efficiency.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"RAINPROOF\" presents a framework aimed at enhancing out-of-distribution (OOD) detection for text generation models. The authors assert that existing research predominantly focuses on classification tasks, neglecting the unique challenges posed by text generation. Their contributions include a new benchmark for evaluating OOD detection methods, the introduction of the RAINPROOF framework, and a mechanism for filtering out good samples to improve model performance. They provide empirical results showcasing improvements in AUROC and false positive rates compared to existing baselines, although these improvements appear marginal. The paper also includes a complexity study reporting runtime and memory costs associated with their approach.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its attempt to address OOD detection in text generation, which is indeed a relevant and necessary area of research. However, the contributions feel somewhat superficial; the introduction of a benchmark and a new framework does not significantly advance the field as these aspects are already well-established in machine learning. Additionally, the authors' claims of novelty are undermined by the fact that their observations and methodologies are largely reflective of standard practices in the field. The performance improvements reported, while positive, are minimal and do not convincingly demonstrate the superiority of their approach.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, making it accessible to readers. However, the novelty of the contributions is questionable, as many of the ideas presented are already part of the broader machine learning discourse. The reproducibility of the results is supported by the authors' decision to release their code, which is commendable and aligns with current best practices in research. Nonetheless, the paper lacks a detailed discussion on the limitations of their approach, which would have enhanced the clarity and quality of the findings.\n\n# Summary Of The Review\nOverall, the paper attempts to tackle a relevant issue in the domain of text generation by focusing on OOD detection. However, the contributions are largely derivative and do not offer substantial advancements over existing methodologies. While the paper is clear and well-organized, it ultimately falls short of providing novel insights that would significantly impact the field.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper presents RAINPROOF, an innovative approach to out-of-distribution (OOD) detection in text generation, emphasizing the role of information-theoretic measures. The methodology involves evaluating various reference distributions for OOD detection and assessing the impact of distribution tails. The findings indicate that while RAINPROOF offers promising results, there are limitations in performance due to the reliance on traditional metrics and the effects of OOD filtering.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its introduction of information-theoretic measures, which provide a fresh perspective on OOD detection. However, the paper falls short by not adequately exploring modern methodologies, such as self-supervised learning or generative adversarial networks, which could enhance its findings. Furthermore, the operational evaluation could benefit from broader application scenarios and a more comprehensive set of evaluation metrics to validate the robustness of the proposed method.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its ideas clearly. However, the novelty of the approach is somewhat limited by the lack of engagement with contemporary techniques in anomaly detection. While the results are reproducible, the paper would benefit from more detailed explanations of the methodologies employed, particularly in relation to the evaluation metrics and the dynamics of OOD filtering.\n\n# Summary Of The Review\nOverall, RAINPROOF contributes valuable insights into OOD detection through information-theoretic measures, yet it overlooks the potential of modern deep learning methods. Future research directions could significantly enhance the framework by integrating more advanced techniques and user-centered design approaches.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a new out-of-distribution (OOD) detection framework called RAINPROOF, specifically evaluated on the LOFTER benchmark in the context of machine translation and dialog generation. RAINPROOF demonstrates significant improvements over existing baseline methods across various scenarios, including language shifts (AUROC of 0.95), domain shifts (AUROC generally above 0.80), and dialog shifts (AUROC of 0.86). The authors emphasize the dual importance of OOD detection metrics and task-specific performance metrics, reporting that RAINPROOF not only enhances OOD detection but also improves translation quality, evidenced by enhanced BLEU scores. The framework effectively filters harmful OOD samples while retaining well-handled samples, underscoring its adaptability and real-world applicability.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its empirical results, which showcase RAINPROOF's robustness and effectiveness across multiple OOD scenarios, significantly outperforming traditional OOD detectors. The detailed presentation of performance metrics through tables and figures adds clarity and reinforces the claims made regarding RAINPROOF's efficacy. However, a notable weakness is the relatively limited emphasis on methodological innovation, which may leave some readers seeking a deeper understanding of the underlying mechanisms that contribute to RAINPROOF's success.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its findings, with sufficient detail provided in the results section to facilitate reproducibility. The novelty of RAINPROOF is evident in its application to OOD detection within text generation tasks, although the methodological aspects could benefit from further elaboration to enhance understanding. Overall, the quality of the writing is high, and the presentation of results is clear and accessible.\n\n# Summary Of The Review\nRAINPROOF represents a significant advancement in OOD detection for text generation, demonstrating superior performance across various scenarios compared to existing methods. While the empirical results are strong and well-supported, the paper could benefit from a greater emphasis on the methodological innovations driving these results.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel approach to out-of-distribution (OOD) detection in machine learning models, proposing an information-theoretic tool that leverages negentropy to enhance detection performance across various datasets. The methodology involves a comprehensive evaluation of existing OOD detection methods, followed by the introduction of the proposed model, which is tested against benchmarks and recent state-of-the-art techniques. The findings indicate that the proposed method significantly improves detection accuracy while maintaining robustness against distribution shifts.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative application of information theory to OOD detection, which is a relevant and timely topic given the growing concerns about model reliability in real-world applications. Additionally, the empirical results demonstrate the effectiveness of the proposed method, suggesting a potential for broader application in the field. However, the paper suffers from clarity issues, particularly in the abstract and introduction, where complex language and dense information hinder accessibility. Furthermore, the presentation of results lacks sufficient contextual discussion, which could diminish their perceived significance.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper introduces a novel concept and presents valuable findings, the clarity and quality of writing could be significantly improved. The abstract is convoluted, and the frequent use of acronyms without initial definitions may alienate readers unfamiliar with the terminology. The overall structure is somewhat erratic, leading to a lack of smooth transitions between sections. Reproducibility is not adequately addressed, as the methodology section could benefit from more detailed descriptions of experimental setups and data sources.\n\n# Summary Of The Review\nOverall, the paper contributes an innovative approach to OOD detection, demonstrating empirical improvements over existing methods. However, it requires substantial revisions to enhance clarity, structure, and presentation of results to fully engage its audience and convey its significance effectively.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.7137445472860335,
    -1.7999582056582857,
    -1.7483127159318461,
    -1.6096514262090305,
    -1.7120157465349384,
    -1.802333314933142,
    -1.5424903199595337,
    -1.7560585697614557,
    -1.785101501503474,
    -1.9161027137079938,
    -1.7333672712026764,
    -1.3812928872560388,
    -1.5590610781485479,
    -1.6958561283062359,
    -1.6709108967663775,
    -1.5103846648311419,
    -2.011575914033088,
    -1.9116462582666496,
    -1.9137589216494206,
    -1.9890816081512617,
    -1.9645834244665297,
    -1.8143114740759652,
    -1.6243169170201759,
    -1.7930009505746722,
    -1.7907410418724325,
    -1.68711744713219,
    -1.8526155824771566,
    -1.8121594344069654,
    -1.7318456753037055
  ],
  "logp_cond": [
    [
      0.0,
      -2.494340302826856,
      -2.4327991420395225,
      -2.4874135634941736,
      -2.477491040501074,
      -2.44987366142086,
      -2.5094810167918955,
      -2.49853662114418,
      -2.505068809424903,
      -2.4705014752986254,
      -2.5099544367088518,
      -2.5262839978258134,
      -2.514078613642153,
      -2.4979345342117116,
      -2.4838746885654683,
      -2.4998070213920336,
      -2.5050464632277767,
      -2.4586654540942856,
      -2.4737138393925973,
      -2.4955205453126235,
      -2.4855797295475655,
      -2.5276752887398577,
      -2.5201992934735573,
      -2.45992101800787,
      -2.5110148403582713,
      -2.5150372018844265,
      -2.5109073916712363,
      -2.499963450775953,
      -2.524602150423336
    ],
    [
      -1.4682370165878558,
      0.0,
      -1.291013421612296,
      -1.2964669980021173,
      -1.2851211347299938,
      -1.2251068697882697,
      -1.3663584368668766,
      -1.36171028806479,
      -1.2666563776851891,
      -1.4092202886370688,
      -1.2345071776937953,
      -1.504053213394684,
      -1.3661927654273236,
      -1.2646346505479378,
      -1.2328542330650403,
      -1.3481963440084495,
      -1.347803280129775,
      -1.2123804588122096,
      -1.316990451458524,
      -1.2274883533443064,
      -1.3588950470719459,
      -1.3235137275862456,
      -1.4513950352762617,
      -1.4025066545287725,
      -1.4434325377965638,
      -1.3679710084919843,
      -1.4130194930738416,
      -1.309365055770367,
      -1.4532002492346319
    ],
    [
      -1.4368764010965898,
      -1.3413770393282178,
      0.0,
      -1.3166839371928614,
      -1.25028256345863,
      -1.2500577144688068,
      -1.4148157130920889,
      -1.3937650208566599,
      -1.3357908744026976,
      -1.3644387081532483,
      -1.3532205563863935,
      -1.5261068180058444,
      -1.3698058885928979,
      -1.3217611295498861,
      -1.339106551226246,
      -1.3473079528516965,
      -1.3305566744787194,
      -1.2916106460729684,
      -1.3834683737250848,
      -1.345111489998335,
      -1.3126223646793327,
      -1.3606013337372078,
      -1.459330820294114,
      -1.3460380050878924,
      -1.4107848078322416,
      -1.3806980035291188,
      -1.3853183562544693,
      -1.3415661384470356,
      -1.4973517077959078
    ],
    [
      -1.326745815726761,
      -1.1630069138521684,
      -1.1175411691293007,
      0.0,
      -1.0647114017985884,
      -1.124254813591427,
      -1.2458089211191914,
      -1.1794784681346213,
      -1.1283008038942333,
      -1.1901561244998267,
      -1.1109201953751846,
      -1.3636478640308916,
      -1.1514583694206626,
      -1.1355103115354084,
      -1.0890338079361752,
      -1.1906471650229369,
      -1.135758936214524,
      -1.1670579255042721,
      -1.2505263574553291,
      -1.1813935873211845,
      -1.1926445419943084,
      -1.192550497204896,
      -1.2969494330777873,
      -1.1813211220445494,
      -1.2696804988160986,
      -1.2192495893788502,
      -1.2275184278192446,
      -1.153083846174243,
      -1.3108902706895338
    ],
    [
      -1.5367177904683924,
      -1.4416256623184875,
      -1.4282464330309312,
      -1.3784264526300443,
      0.0,
      -1.3981601784957634,
      -1.4769029335367372,
      -1.4614688887459848,
      -1.392309210120472,
      -1.4824680428042476,
      -1.3949677328733825,
      -1.5260474379638358,
      -1.481998409268102,
      -1.4098236133589617,
      -1.4343596512263146,
      -1.4576285108460332,
      -1.4025571970513417,
      -1.4166783084802845,
      -1.4927994601026628,
      -1.4544576224762622,
      -1.4367596573216461,
      -1.4477307114422826,
      -1.509367173111491,
      -1.4784958753777462,
      -1.4877440577737062,
      -1.4580164801880524,
      -1.4641031668211195,
      -1.4329440685694015,
      -1.5187815175055768
    ],
    [
      -1.4488460359215494,
      -1.1988848790520712,
      -1.1982390880547633,
      -1.2483886670139779,
      -1.2344304197277882,
      0.0,
      -1.3431522612735856,
      -1.3273336770790483,
      -1.2070013521679077,
      -1.3560315987661453,
      -1.2356778189601918,
      -1.5282375006624795,
      -1.3725209306994255,
      -1.2655162805979259,
      -1.252660471255511,
      -1.3216857338212147,
      -1.2634116055741327,
      -1.1562961854050384,
      -1.2945213966118054,
      -1.2743941154174474,
      -1.3438976691376956,
      -1.3581299457044893,
      -1.500744440449203,
      -1.346303874428393,
      -1.440972714792128,
      -1.385708793143126,
      -1.3839185236722127,
      -1.3105857797954892,
      -1.4834847156087394
    ],
    [
      -1.285123521729556,
      -1.103036830653524,
      -1.1461028513580265,
      -1.1409774199053848,
      -1.1412300963796689,
      -1.107256556466574,
      0.0,
      -1.1502093910224511,
      -1.17508420353072,
      -1.1902245875486848,
      -1.1416218850450846,
      -1.288925429338708,
      -1.176386266065493,
      -1.1108286067750113,
      -1.1590882383127141,
      -1.1788976583579387,
      -1.1696853753707563,
      -1.1030371970550403,
      -1.175528825903953,
      -1.0982553948318052,
      -1.1745733483944076,
      -1.2172202377938608,
      -1.2255966010146169,
      -1.1809062056759962,
      -1.2504864665152033,
      -1.1774913550495176,
      -1.1715695894240408,
      -1.1865063862341958,
      -1.2486224797570356
    ],
    [
      -1.4879816832217978,
      -1.3298979713432701,
      -1.3736789464463357,
      -1.3160117916749745,
      -1.3399847329940588,
      -1.3538894339580445,
      -1.4000898837947104,
      0.0,
      -1.3561038553880729,
      -1.3184587053605081,
      -1.3407056584935781,
      -1.4964056151444425,
      -1.3319765206792142,
      -1.3639417631688782,
      -1.3107281999878433,
      -1.4165757549431075,
      -1.3219701014666925,
      -1.3262021438812062,
      -1.3757602743559827,
      -1.340755472104734,
      -1.3344037560544908,
      -1.329037614239046,
      -1.4145225767264107,
      -1.401614459893823,
      -1.449102037609936,
      -1.400250341697727,
      -1.3801171578116957,
      -1.3762409824103312,
      -1.4558778002638595
    ],
    [
      -1.4965155930828973,
      -1.2481156274114693,
      -1.3038432782584817,
      -1.285130889839239,
      -1.1739718190243509,
      -1.241549621383942,
      -1.378425953948684,
      -1.356571285662807,
      0.0,
      -1.3700610183530653,
      -1.1689797379198796,
      -1.5253612634328417,
      -1.289388513974342,
      -1.229351290513775,
      -1.2695752638400897,
      -1.3563625482617083,
      -1.2651531219868999,
      -1.2645631224501446,
      -1.3968402623852922,
      -1.2610505315957417,
      -1.3294442804708801,
      -1.3201646064001609,
      -1.482088261193455,
      -1.4115285417794612,
      -1.481119180137144,
      -1.3231814896115213,
      -1.4005334575113175,
      -1.231849805224071,
      -1.479016451024301
    ],
    [
      -1.6580521249901021,
      -1.5515430534561823,
      -1.520209720120239,
      -1.51381200552805,
      -1.559640876565964,
      -1.5352210493592156,
      -1.5890720067455488,
      -1.5321122411891386,
      -1.5213688214332197,
      0.0,
      -1.5273398058037673,
      -1.6915322145040723,
      -1.4387736546592114,
      -1.5562032179167637,
      -1.509471448305735,
      -1.5692786188992176,
      -1.5668709541852792,
      -1.5382610631599924,
      -1.5338763412313017,
      -1.515769886632123,
      -1.5472496377946803,
      -1.4606966616046337,
      -1.6323802860550278,
      -1.5389619203383018,
      -1.5912838157696274,
      -1.503524870436192,
      -1.575644511617348,
      -1.5502440029635824,
      -1.6592994677938189
    ],
    [
      -1.4253441372469757,
      -1.1260007832207708,
      -1.2218888863697916,
      -1.1625194989419478,
      -1.1517250738968698,
      -1.1356791572747575,
      -1.2849595570509578,
      -1.2403518185562,
      -1.1058294696212045,
      -1.2672669712524918,
      0.0,
      -1.4358527012409892,
      -1.2072232412891275,
      -1.157988848219547,
      -1.089733946364871,
      -1.24409103980586,
      -1.1938148804578943,
      -1.1828438804781738,
      -1.2730096305632383,
      -1.1630454504890715,
      -1.244664246143788,
      -1.2383900438481221,
      -1.4013564906889144,
      -1.2889813247589854,
      -1.38190112214074,
      -1.206360741581755,
      -1.3288946659263414,
      -1.2228597335979237,
      -1.37738991470464
    ],
    [
      -1.1821555555023433,
      -1.1848395725961491,
      -1.16442365589132,
      -1.1875302928112135,
      -1.1326577027433733,
      -1.1856821557093287,
      -1.191350960387923,
      -1.1660964112203736,
      -1.1767652901564258,
      -1.1898006991451453,
      -1.1744660124860278,
      0.0,
      -1.1684983136192397,
      -1.180165177380244,
      -1.1655938968064896,
      -1.189766923365372,
      -1.1786567024209051,
      -1.1833620614554536,
      -1.1937494451332082,
      -1.1950941717492427,
      -1.200588123129279,
      -1.1767923168326464,
      -1.1538564144219603,
      -1.1879668532366212,
      -1.1678827750770906,
      -1.1757368624940772,
      -1.1732814437265209,
      -1.185134398068981,
      -1.1545062960556016
    ],
    [
      -1.305665866550134,
      -1.2325316583966794,
      -1.1723065448010455,
      -1.170557874293721,
      -1.1893342932332631,
      -1.2224652213967127,
      -1.256601777248695,
      -1.1376707512397701,
      -1.170182978797994,
      -1.0967775555418509,
      -1.1380441095405123,
      -1.34016327641434,
      0.0,
      -1.1544470906368438,
      -1.136523222302797,
      -1.2169278521233815,
      -1.200471257691011,
      -1.2047364871032231,
      -1.1684857251480416,
      -1.1970009011789862,
      -1.207491797110928,
      -1.144223726069643,
      -1.273533879459279,
      -1.2200751056713752,
      -1.2802143146922285,
      -1.1858660662688987,
      -1.2226644672404041,
      -1.1796239035974894,
      -1.3171400768254062
    ],
    [
      -1.3763687537090936,
      -1.1789894943948434,
      -1.2457017702127013,
      -1.19514674163091,
      -1.1959833417562156,
      -1.1960976718872223,
      -1.2505159094197027,
      -1.3005622503559406,
      -1.171956388858448,
      -1.3062459418488446,
      -1.1999051335200142,
      -1.4315626059999909,
      -1.2233986071514273,
      0.0,
      -1.1517650850728594,
      -1.2788433609833716,
      -1.2332820792302703,
      -1.2231552928078124,
      -1.3294436985047722,
      -1.2277253742464824,
      -1.304271925204757,
      -1.27174436545404,
      -1.3832844814514067,
      -1.2854549183407076,
      -1.3554847045777487,
      -1.2692451441480481,
      -1.3188759867171633,
      -1.2038981105013746,
      -1.3798542370969884
    ],
    [
      -1.3685459339311714,
      -1.125144745116884,
      -1.2272636514791713,
      -1.1039313635969086,
      -1.144654757696034,
      -1.1807187586753993,
      -1.2870720562104188,
      -1.210721688324038,
      -1.1726105981027068,
      -1.2287171541738264,
      -1.1331689730823113,
      -1.4256666983252484,
      -1.1840371289248066,
      -1.1272247988051414,
      0.0,
      -1.27584741064927,
      -1.1651043870845947,
      -1.1919381285682082,
      -1.2909274755686653,
      -1.2234850383388705,
      -1.2049179691063627,
      -1.1676396282492991,
      -1.3594675052767407,
      -1.2651922189359457,
      -1.331534738767509,
      -1.260083721755773,
      -1.2857394708423278,
      -1.2158038900980888,
      -1.3493482352777306
    ],
    [
      -1.2200075056294326,
      -1.0987009127045482,
      -1.1023749248715045,
      -1.1177492398927547,
      -1.1514944242727534,
      -1.0977048007499643,
      -1.1692207666192698,
      -1.2140807675951448,
      -1.1343801162671832,
      -1.1753863952782933,
      -1.0950428291505099,
      -1.251821577444175,
      -1.119677541918626,
      -1.1107743589098988,
      -1.1004240205679858,
      0.0,
      -1.1487178463489502,
      -1.144163988879798,
      -1.1447115644987207,
      -1.188912038461335,
      -1.1699396128096198,
      -1.1572331664221043,
      -1.1967731061894318,
      -1.1186980633552275,
      -1.1980089275083103,
      -1.115123365620672,
      -1.143835113389869,
      -1.1198000915922979,
      -1.208943645828261
    ],
    [
      -1.656910801040576,
      -1.4643500797874587,
      -1.4974771242436067,
      -1.4582398188020684,
      -1.3979698811143972,
      -1.4535813354636573,
      -1.5590697190186946,
      -1.514869319645082,
      -1.4494216518550533,
      -1.585693963816055,
      -1.4925413069076443,
      -1.7227060679151078,
      -1.6382902344386212,
      -1.4752626534162931,
      -1.4398843636437761,
      -1.5644413440379104,
      0.0,
      -1.442535552317239,
      -1.5985296654985002,
      -1.5095493476132746,
      -1.4700747749732928,
      -1.5571245469474901,
      -1.6410069702542016,
      -1.5438472543287394,
      -1.6186142142644366,
      -1.48213213580296,
      -1.5405167497747727,
      -1.5028588154763598,
      -1.655366970556022
    ],
    [
      -1.5779070926535892,
      -1.3548482709865997,
      -1.3683904605859925,
      -1.4325461629286642,
      -1.346034225896599,
      -1.2764650741241848,
      -1.427173092099318,
      -1.4590419825133094,
      -1.4232221354387116,
      -1.4450590641445389,
      -1.388633082066739,
      -1.6144167802271427,
      -1.5108931734970208,
      -1.389144028618891,
      -1.4158784477785522,
      -1.4859528077726412,
      -1.4274557995239316,
      0.0,
      -1.4040173736332668,
      -1.396825237565304,
      -1.439844064324431,
      -1.4446478849822424,
      -1.5730607468129345,
      -1.4856509069797577,
      -1.5628657039022014,
      -1.5055933594237345,
      -1.525171657298468,
      -1.4792383635525608,
      -1.5877075774625056
    ],
    [
      -1.6113253464776283,
      -1.4403171717448595,
      -1.4698591800193221,
      -1.5376710464307668,
      -1.5482038560376108,
      -1.405500937750374,
      -1.5449119447277828,
      -1.4819966570981347,
      -1.5126428304800499,
      -1.4197016866674657,
      -1.5019996999302798,
      -1.64429019480409,
      -1.4975365299168495,
      -1.535826778628308,
      -1.5224007827833448,
      -1.5135748212866065,
      -1.5285778059151771,
      -1.4498906518793033,
      0.0,
      -1.4741551290205608,
      -1.5079163570058682,
      -1.4781197621828561,
      -1.6071623618112667,
      -1.4746942075591278,
      -1.5802278521993285,
      -1.4883593793542222,
      -1.5207144475800318,
      -1.5433835556134519,
      -1.6296623190311745
    ],
    [
      -1.658205139643246,
      -1.4415164927809019,
      -1.4999414190359635,
      -1.5310575168402596,
      -1.5104226319396803,
      -1.4836471704377447,
      -1.5595392403172954,
      -1.5228426795988286,
      -1.5020153550427786,
      -1.5688381082076968,
      -1.4763932490198484,
      -1.7381645713217033,
      -1.5683731792596856,
      -1.4919756624203315,
      -1.5220197326783067,
      -1.6324715344416307,
      -1.525055419319138,
      -1.4793318913082305,
      -1.5280278385375716,
      0.0,
      -1.5544589349501496,
      -1.5164574720448527,
      -1.6834405074548218,
      -1.5991234717288587,
      -1.6395537372855997,
      -1.5482852497350876,
      -1.5974192308347284,
      -1.5524660927709124,
      -1.6904760637519929
    ],
    [
      -1.6733607001124156,
      -1.55657685511034,
      -1.504232992972036,
      -1.5666374273470627,
      -1.4988181538961591,
      -1.5528439796955646,
      -1.6423085451291994,
      -1.558788503740169,
      -1.550229777890632,
      -1.5848603939964272,
      -1.550872492180276,
      -1.736940778963909,
      -1.5973899331681054,
      -1.5689684972868654,
      -1.563677717565924,
      -1.610896872218738,
      -1.4720215949835902,
      -1.5477215245008011,
      -1.5929269030818387,
      -1.5417532840626507,
      0.0,
      -1.566463713520215,
      -1.7085710716884832,
      -1.6094852806144815,
      -1.6537441019042336,
      -1.5320441354681478,
      -1.5871042494252572,
      -1.5559127180900032,
      -1.7557861538692432
    ],
    [
      -1.5566097366300764,
      -1.3622854715059343,
      -1.4149093630973248,
      -1.3926230051341075,
      -1.3974788426464462,
      -1.4202261934881233,
      -1.4867642576419602,
      -1.4119914565642664,
      -1.3673655280278507,
      -1.388759914279101,
      -1.3733365419702175,
      -1.5691525723729733,
      -1.3858943052355586,
      -1.4214123903457192,
      -1.3881610355792793,
      -1.4651294435756759,
      -1.4102984547963777,
      -1.4458628715523885,
      -1.435861220783314,
      -1.4087564373953667,
      -1.4041749580911078,
      0.0,
      -1.523812319097684,
      -1.470690339822849,
      -1.5333533372157697,
      -1.4453683288183916,
      -1.4561078560937588,
      -1.4087914777110138,
      -1.5136247536831786
    ],
    [
      -1.3450561676676753,
      -1.2959134150753886,
      -1.357535732171329,
      -1.3143799888461603,
      -1.2704544959897976,
      -1.3303203989354935,
      -1.3288010324686041,
      -1.345156880934116,
      -1.3385435918576922,
      -1.3594434807838789,
      -1.3571245298227266,
      -1.3553720167401495,
      -1.3409458040099067,
      -1.3103640392385814,
      -1.3302699628117733,
      -1.3324008774308214,
      -1.3069454364990303,
      -1.3430531771175112,
      -1.3821496934526574,
      -1.3665299215960465,
      -1.3552785118023207,
      -1.3653371611526623,
      0.0,
      -1.3291495930848531,
      -1.286561077151298,
      -1.3657111447614496,
      -1.307703229295116,
      -1.3271491560808557,
      -1.319054655650044
    ],
    [
      -1.4809401778555693,
      -1.4025040781511597,
      -1.3447666810041878,
      -1.3792086226849611,
      -1.3884368668570868,
      -1.3578572091843022,
      -1.4256185500317489,
      -1.4215227011087765,
      -1.4087791069935958,
      -1.3852594527455122,
      -1.3923878342104787,
      -1.5502361603071253,
      -1.4115000007689689,
      -1.3723676727877654,
      -1.396611387157177,
      -1.404824502719207,
      -1.358742023089089,
      -1.3535786298163661,
      -1.3955497757729454,
      -1.3843482502967377,
      -1.388774180142533,
      -1.4098426566844355,
      -1.4367204553239679,
      0.0,
      -1.4128153195208233,
      -1.394675045515567,
      -1.3700815642822177,
      -1.3631004737614554,
      -1.4848683875573012
    ],
    [
      -1.478056154283821,
      -1.4722623030616422,
      -1.3870977510658877,
      -1.4021314099143554,
      -1.3936010508351353,
      -1.4453311165507032,
      -1.4788042476067886,
      -1.5311810273776785,
      -1.4729271732453224,
      -1.3792998807826684,
      -1.4618900932691576,
      -1.5366673332442593,
      -1.482896708189976,
      -1.4527838900414527,
      -1.4458203570275363,
      -1.4526658711395313,
      -1.42211937921142,
      -1.4462430218662836,
      -1.5224810794023638,
      -1.4449886680941302,
      -1.4417734755523046,
      -1.4955488731576925,
      -1.4090821794583375,
      -1.4458112830567447,
      0.0,
      -1.4950967336486596,
      -1.4197319732512623,
      -1.4285558465179287,
      -1.4980132906597445
    ],
    [
      -1.432609079440209,
      -1.3684544220048027,
      -1.3557764017420235,
      -1.3556808938539289,
      -1.3239092260878922,
      -1.3699083026760923,
      -1.3484257456866846,
      -1.4065208046150177,
      -1.317955713844125,
      -1.3236467535292025,
      -1.3251508976196822,
      -1.4507946875157183,
      -1.3078977329210506,
      -1.3388858230403253,
      -1.3326917325816394,
      -1.3648722878995279,
      -1.3268065680115455,
      -1.377481681129325,
      -1.318836331473318,
      -1.353782727802981,
      -1.322690792687953,
      -1.3266531016876173,
      -1.4172243926762071,
      -1.345676274195247,
      -1.420531801950746,
      0.0,
      -1.3512407039535241,
      -1.3561447042840213,
      -1.4262645850007354
    ],
    [
      -1.4937540513018064,
      -1.4158245966245488,
      -1.4024513939740206,
      -1.454158528918395,
      -1.416297612296566,
      -1.4329207611470134,
      -1.410760085650809,
      -1.461374925808903,
      -1.4158740231544085,
      -1.4123450217244689,
      -1.4283921643395838,
      -1.5694285328623496,
      -1.4285273081351344,
      -1.4149024585383916,
      -1.4537183422061164,
      -1.4355627717423611,
      -1.3504042498934035,
      -1.4256011293617028,
      -1.4651162990639646,
      -1.4343155923948143,
      -1.38892551105015,
      -1.408469552683124,
      -1.4559321107427599,
      -1.4108115371989125,
      -1.4361849562810656,
      -1.4100140317385566,
      0.0,
      -1.4004532157120542,
      -1.4776409384146576
    ],
    [
      -1.5156279541629178,
      -1.3178133894393664,
      -1.3502716576482947,
      -1.3285968227353324,
      -1.3259186666296963,
      -1.354413807633617,
      -1.4339673324057935,
      -1.4083076773745942,
      -1.2995506113843152,
      -1.4141573470040918,
      -1.332216798473036,
      -1.5798461853104047,
      -1.3848647095438535,
      -1.3347166703973168,
      -1.3600962926339837,
      -1.382127612258734,
      -1.385332860870046,
      -1.3527658232357844,
      -1.4705143964536014,
      -1.3603010524057424,
      -1.4057490283195906,
      -1.372562014818045,
      -1.495710481185309,
      -1.4074451333733784,
      -1.4683724895231796,
      -1.407927351516605,
      -1.4467019577469673,
      0.0,
      -1.5256905168752735
    ],
    [
      -1.4116550089301296,
      -1.37659290684791,
      -1.3762327703826884,
      -1.377495459642923,
      -1.3463360653052265,
      -1.3689370575397828,
      -1.4045395531222882,
      -1.442600747047225,
      -1.3634309579527069,
      -1.4269556200521054,
      -1.3690944649057306,
      -1.4164900941955774,
      -1.4243823972204352,
      -1.3709820930293766,
      -1.3633500018857159,
      -1.3775233502674105,
      -1.389370911035872,
      -1.3674154556605533,
      -1.4046066929704297,
      -1.3684990103561165,
      -1.4132666079616485,
      -1.3884305654605977,
      -1.427589846195199,
      -1.3937609547486218,
      -1.4047850426865114,
      -1.4356091248953875,
      -1.3734439477452203,
      -1.3934588737699336,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.21940424445917772,
      0.280945405246511,
      0.2263309837918599,
      0.23625350678495938,
      0.2638708858651735,
      0.20426353049413803,
      0.21520792614185336,
      0.20867573786113036,
      0.24324307198740813,
      0.20379011057718177,
      0.18746054946022017,
      0.1996659336438804,
      0.2158100130743219,
      0.2298698587205652,
      0.21393752589399995,
      0.20869808405825685,
      0.25507909319174793,
      0.24003070789343628,
      0.21822400197341008,
      0.22816481773846808,
      0.18606925854617584,
      0.19354525381247623,
      0.25382352927816365,
      0.20272970692776227,
      0.19870734540160706,
      0.2028371556147972,
      0.21378109651008037,
      0.18914239686269774
    ],
    [
      0.3317211890704299,
      0.0,
      0.5089447840459898,
      0.5034912076561684,
      0.5148370709282919,
      0.574851335870016,
      0.43359976879140905,
      0.4382479175934957,
      0.5333018279730966,
      0.39073791702121685,
      0.5654510279644904,
      0.2959049922636017,
      0.4337654402309621,
      0.5353235551103479,
      0.5671039725932454,
      0.4517618616498362,
      0.45215492552851066,
      0.5875777468460761,
      0.4829677541997617,
      0.5724698523139793,
      0.4410631585863398,
      0.47644447807204005,
      0.348563170382024,
      0.39745155112951314,
      0.3565256678617219,
      0.4319871971663014,
      0.3869387125844441,
      0.4905931498879186,
      0.3467579564236538
    ],
    [
      0.31143631483525636,
      0.4069356766036283,
      0.0,
      0.43162877873898475,
      0.498030152473216,
      0.49825500146303936,
      0.33349700283975725,
      0.35454769507518624,
      0.4125218415291485,
      0.3838740077785978,
      0.3950921595454526,
      0.22220589792600176,
      0.37850682733894825,
      0.42655158638196,
      0.40920616470560023,
      0.40100476308014965,
      0.4177560414531267,
      0.45670206985887773,
      0.3648443422067613,
      0.40320122593351115,
      0.43569035125251343,
      0.3877113821946383,
      0.28898189563773213,
      0.4022747108439537,
      0.33752790809960453,
      0.36761471240272736,
      0.3629943596773768,
      0.40674657748481047,
      0.25096100813593836
    ],
    [
      0.28290561048226937,
      0.4466445123568621,
      0.4921102570797298,
      0.0,
      0.5449400244104421,
      0.4853966126176035,
      0.36384250508983906,
      0.43017295807440914,
      0.4813506223147972,
      0.4194953017092038,
      0.49873123083384585,
      0.2460035621781389,
      0.45819305678836786,
      0.4741411146736221,
      0.5206176182728552,
      0.4190042611860936,
      0.4738924899945065,
      0.44259350070475834,
      0.3591250687537013,
      0.42825783888784597,
      0.4170068842147221,
      0.41710092900413454,
      0.31270199313124314,
      0.42833030416448103,
      0.3399709273929319,
      0.39040183683018026,
      0.38213299838978587,
      0.4565675800347875,
      0.29876115551949667
    ],
    [
      0.17529795606654597,
      0.27039008421645083,
      0.28376931350400714,
      0.3335892939048941,
      0.0,
      0.313855568039175,
      0.2351128129982012,
      0.2505468577889536,
      0.31970653641446645,
      0.22954770373069078,
      0.3170480136615559,
      0.18596830857110258,
      0.23001733726683637,
      0.3021921331759767,
      0.2776560953086238,
      0.2543872356889052,
      0.30945854948359663,
      0.29533743805465384,
      0.21921628643227553,
      0.2575581240586762,
      0.27525608921329225,
      0.2642850350926558,
      0.20264857342344733,
      0.2335198711571922,
      0.22427168876123216,
      0.25399926634688597,
      0.24791257971381886,
      0.2790716779655369,
      0.1932342290293616
    ],
    [
      0.3534872790115926,
      0.6034484358810708,
      0.6040942268783787,
      0.5539446479191641,
      0.5679028952053538,
      0.0,
      0.4591810536595564,
      0.4749996378540937,
      0.5953319627652343,
      0.44630171616699665,
      0.5666554959729502,
      0.27409581427066243,
      0.4298123842337165,
      0.5368170343352161,
      0.549672843677631,
      0.4806475811119273,
      0.5389217093590093,
      0.6460371295281035,
      0.5078119183213365,
      0.5279391995156946,
      0.4584356457954464,
      0.44420336922865267,
      0.301588874483939,
      0.4560294405047489,
      0.3613606001410139,
      0.41662452179001597,
      0.4184147912609293,
      0.4917475351376528,
      0.31884859932440257
    ],
    [
      0.25736679822997766,
      0.4394534893060096,
      0.3963874686015072,
      0.40151290005414886,
      0.4012602235798648,
      0.4352337634929597,
      0.0,
      0.39228092893708255,
      0.3674061164288136,
      0.3522657324108489,
      0.4008684349144491,
      0.25356489062082566,
      0.36610405389404077,
      0.4316617131845224,
      0.38340208164681955,
      0.363592661601595,
      0.37280494458877733,
      0.43945312290449334,
      0.36696149405558076,
      0.44423492512772844,
      0.36791697156512604,
      0.3252700821656729,
      0.3168937189449168,
      0.36158411428353743,
      0.29200385344433033,
      0.36499896491001604,
      0.3709207305354929,
      0.3559839337253379,
      0.2938678402024981
    ],
    [
      0.2680768865396579,
      0.42616059841818554,
      0.38237962331512,
      0.4400467780864812,
      0.41607383676739684,
      0.4021691358034112,
      0.35596868596674525,
      0.0,
      0.3999547143733828,
      0.43759986440094756,
      0.41535291126787754,
      0.2596529546170132,
      0.42408204908224145,
      0.3921168065925775,
      0.4453303697736124,
      0.3394828148183482,
      0.4340884682947632,
      0.4298564258802495,
      0.380298295405473,
      0.4153030976567218,
      0.4216548137069649,
      0.4270209555224096,
      0.341535993035045,
      0.35444410986763275,
      0.30695653215151975,
      0.3558082280637287,
      0.37594141194975994,
      0.3798175873511245,
      0.3001807694975962
    ],
    [
      0.28858590842057663,
      0.5369858740920046,
      0.48125822324499223,
      0.49997061166423484,
      0.611129682479123,
      0.5435518801195318,
      0.40667554755478985,
      0.428530215840667,
      0.0,
      0.41504048315040865,
      0.6161217635835943,
      0.2597402380706322,
      0.49571298752913195,
      0.555750210989699,
      0.5155262376633842,
      0.4287389532417656,
      0.519948379516574,
      0.5205383790533293,
      0.38826123911818167,
      0.5240509699077323,
      0.45565722103259376,
      0.46493689510331304,
      0.30301324031001897,
      0.3735729597240127,
      0.30398232136632997,
      0.46192001189195264,
      0.3845680439921564,
      0.553251696279403,
      0.306085050479173
    ],
    [
      0.25805058871789166,
      0.3645596602518115,
      0.39589299358775487,
      0.40229070817994383,
      0.35646183714202984,
      0.38088166434877824,
      0.32703070696244496,
      0.3839904725188552,
      0.39473389227477407,
      0.0,
      0.3887629079042265,
      0.22457049920392147,
      0.4773290590487824,
      0.35989949579123004,
      0.4066312654022588,
      0.3468240948087762,
      0.34923175952271457,
      0.37784165054800134,
      0.3822263724766921,
      0.4003328270758708,
      0.3688530759133135,
      0.45540605210336005,
      0.28372242765296596,
      0.377140793369692,
      0.3248188979383664,
      0.4125778432718017,
      0.3404582020906457,
      0.36585871074441134,
      0.2568032459141749
    ],
    [
      0.3080231339557007,
      0.6073664879819056,
      0.5114783848328848,
      0.5708477722607286,
      0.5816421973058066,
      0.5976881139279189,
      0.44840771415171865,
      0.4930154526464765,
      0.6275378015814719,
      0.46610029995018465,
      0.0,
      0.29751456996168724,
      0.5261440299135489,
      0.5753784229831294,
      0.6436333248378054,
      0.4892762313968164,
      0.5395523907447821,
      0.5505233907245026,
      0.46035764063943807,
      0.5703218207136049,
      0.4887030250588884,
      0.4949772273545543,
      0.332010780513762,
      0.444385946443691,
      0.3514661490619364,
      0.5270065296209214,
      0.404472605276335,
      0.5105075376047528,
      0.3559773564980364
    ],
    [
      0.19913733175369552,
      0.1964533146598897,
      0.21686923136471892,
      0.19376259444482535,
      0.24863518451266553,
      0.19561073154671016,
      0.18994192686811573,
      0.21519647603566527,
      0.204527597099613,
      0.19149218811089352,
      0.20682687477001105,
      0.0,
      0.2127945736367991,
      0.20112770987579487,
      0.2156989904495492,
      0.19152596389066678,
      0.20263618483513368,
      0.1979308258005852,
      0.18754344212283058,
      0.18619871550679612,
      0.18070476412675984,
      0.20450057042339242,
      0.22743647283407853,
      0.19332603401941761,
      0.21341011217894823,
      0.20555602476196166,
      0.20801144352951795,
      0.1961584891870578,
      0.2267865912004372
    ],
    [
      0.25339521159841394,
      0.32652941975186844,
      0.3867545333475024,
      0.38850320385482684,
      0.36972678491528477,
      0.33659585675183523,
      0.30245930089985285,
      0.42139032690877776,
      0.38887809935055384,
      0.46228352260669703,
      0.4210169686080356,
      0.2188978017342078,
      0.0,
      0.4046139875117041,
      0.4225378558457509,
      0.3421332260251664,
      0.35858982045753685,
      0.35432459104532477,
      0.3905753530005063,
      0.3620601769695617,
      0.35156928103761986,
      0.4148373520789048,
      0.2855271986892689,
      0.33898597247717266,
      0.2788467634563194,
      0.3731950118796492,
      0.33639661090814377,
      0.3794371745510585,
      0.24192100132314165
    ],
    [
      0.31948737459714227,
      0.5168666339113925,
      0.45015435809353455,
      0.5007093866753258,
      0.4998727865500203,
      0.4997584564190136,
      0.4453402188865332,
      0.39529387795029525,
      0.5238997394477878,
      0.3896101864573913,
      0.49595099478622173,
      0.26429352230624503,
      0.47245752115480855,
      0.0,
      0.5440910432333765,
      0.4170127673228643,
      0.46257404907596555,
      0.47270083549842346,
      0.3664124298014637,
      0.46813075405975346,
      0.3915842031014789,
      0.424111762852196,
      0.3125716468548292,
      0.4104012099655283,
      0.34037142372848717,
      0.42661098415818777,
      0.37698014158907256,
      0.49195801780486126,
      0.3160018912092475
    ],
    [
      0.3023649628352061,
      0.5457661516494936,
      0.4436472452872062,
      0.5669795331694689,
      0.5262561390703435,
      0.49019213809097817,
      0.38383884055595874,
      0.46018920844233957,
      0.49830029866367065,
      0.44219374259255106,
      0.5377419236840661,
      0.2452441984411291,
      0.4868737678415709,
      0.5436860979612361,
      0.0,
      0.3950634861171074,
      0.5058065096817828,
      0.47897276819816925,
      0.3799834211977122,
      0.44742585842750704,
      0.46599292766001477,
      0.5032712685170784,
      0.31144339148963684,
      0.4057186778304318,
      0.33937615799886856,
      0.4108271750106045,
      0.38517142592404974,
      0.45510700666828874,
      0.3215626614886469
    ],
    [
      0.29037715920170926,
      0.4116837521265937,
      0.4080097399596374,
      0.3926354249383872,
      0.3588902405583885,
      0.4126798640811775,
      0.3411638982118721,
      0.29630389723599704,
      0.3760045485639587,
      0.3349982695528486,
      0.415341835680632,
      0.25856308738696687,
      0.39070712291251586,
      0.399610305921243,
      0.40996064426315604,
      0.0,
      0.3616668184821916,
      0.3662206759513438,
      0.3656731003324212,
      0.3214726263698069,
      0.3404450520215221,
      0.3531514984090376,
      0.3136115586417101,
      0.3916866014759144,
      0.3123757373228315,
      0.3952612992104698,
      0.3665495514412729,
      0.390584573238844,
      0.3014410190028809
    ],
    [
      0.354665112992512,
      0.5472258342456293,
      0.5140987897894813,
      0.5533360952310196,
      0.6136060329186908,
      0.5579945785694307,
      0.4525061950143934,
      0.496706594388006,
      0.5621542621780347,
      0.425881950217033,
      0.5190346071254437,
      0.28886984611798017,
      0.3732856795944668,
      0.5363132606167949,
      0.5716915503893119,
      0.44713456999517764,
      0.0,
      0.569040361715849,
      0.4130462485345878,
      0.5020265664198134,
      0.5415011390597952,
      0.45445136708559786,
      0.3705689437788864,
      0.4677286597043486,
      0.39296169976865136,
      0.529443778230128,
      0.4710591642583153,
      0.5087170985567282,
      0.3562089434770659
    ],
    [
      0.3337391656130604,
      0.5567979872800499,
      0.5432557976806571,
      0.47910009533798537,
      0.5656120323700506,
      0.6351811841424648,
      0.4844731661673316,
      0.45260427575334017,
      0.488424122827938,
      0.4665871941221107,
      0.5230131761999106,
      0.29722947803950683,
      0.4007530847696288,
      0.5225022296477586,
      0.49576781048809737,
      0.4256934504940084,
      0.48419045874271793,
      0.0,
      0.5076288846333827,
      0.5148210207013455,
      0.47180219394221856,
      0.4669983732844072,
      0.33858551145371507,
      0.4259953512868919,
      0.3487805543644482,
      0.40605289884291507,
      0.38647460096818165,
      0.4324078947140888,
      0.323938680804144
    ],
    [
      0.30243357517179237,
      0.4734417499045611,
      0.4438997416300985,
      0.37608787521865383,
      0.36555506561180984,
      0.5082579838990466,
      0.3688469769216378,
      0.43176226455128597,
      0.40111609116937075,
      0.494057234981955,
      0.4117592217191408,
      0.26946872684533063,
      0.41622239173257114,
      0.37793214302111267,
      0.39135813886607584,
      0.40018410036281415,
      0.3851811157342435,
      0.4638682697701173,
      0.0,
      0.43960379262885985,
      0.4058425646435524,
      0.4356391594665645,
      0.3065965598381539,
      0.4390647140902928,
      0.33353106945009214,
      0.4253995422951984,
      0.3930444740693888,
      0.37037536603596877,
      0.2840966026182461
    ],
    [
      0.33087646850801566,
      0.5475651153703598,
      0.4891401891152982,
      0.4580240913110021,
      0.4786589762115814,
      0.5054344377135169,
      0.42954236783396627,
      0.4662389285524331,
      0.48706625310848306,
      0.4202434999435649,
      0.5126883591314133,
      0.25091703682955835,
      0.4207084288915761,
      0.49710594573093014,
      0.46706187547295497,
      0.35661007370963094,
      0.46402618883212376,
      0.5097497168430312,
      0.46105376961369005,
      0.0,
      0.43462267320111203,
      0.47262413610640897,
      0.3056411006964399,
      0.38995813642240296,
      0.34952787086566195,
      0.44079635841617404,
      0.3916623773165333,
      0.43661551538034926,
      0.2986055443992688
    ],
    [
      0.2912227243541141,
      0.4080065693561896,
      0.46035043149449373,
      0.397945997119467,
      0.46576527057037054,
      0.411739444770965,
      0.32227487933733023,
      0.4057949207263607,
      0.4143536465758977,
      0.3797230304701025,
      0.4137109322862538,
      0.2276426455026206,
      0.36719349129842427,
      0.3956149271796643,
      0.4009057069006057,
      0.35368655224779166,
      0.4925618294829395,
      0.41686189996572853,
      0.37165652138469096,
      0.422830140403879,
      0.0,
      0.3981197109463146,
      0.25601235277804646,
      0.3550981438520482,
      0.31083932256229607,
      0.4325392889983819,
      0.3774791750412725,
      0.40867070637652647,
      0.20879727059728648
    ],
    [
      0.25770173744588876,
      0.4520260025700309,
      0.3994021109786403,
      0.42168846894185763,
      0.416832631429519,
      0.39408528058784187,
      0.327547216434005,
      0.40232001751169877,
      0.44694594604811444,
      0.4255515597968642,
      0.4409749321057477,
      0.24515890170299182,
      0.4284171688404066,
      0.39289908373024596,
      0.4261504384966859,
      0.3491820305002893,
      0.40401301927958744,
      0.3684486025235767,
      0.37845025329265125,
      0.40555503668059845,
      0.41013651598485734,
      0.0,
      0.29049915497828116,
      0.34362113425311613,
      0.28095813686019544,
      0.36894314525757355,
      0.35820361798220635,
      0.4055199963649514,
      0.30068672039278654
    ],
    [
      0.27926074935250056,
      0.3284035019447873,
      0.26678118484884683,
      0.30993692817401564,
      0.35386242103037824,
      0.2939965180846824,
      0.29551588455157174,
      0.27916003608606,
      0.28577332516248366,
      0.264873436236297,
      0.2671923871974493,
      0.2689449002800264,
      0.2833711130102692,
      0.31395287778159453,
      0.29404695420840254,
      0.2919160395893545,
      0.3173714805211456,
      0.28126373990266473,
      0.24216722356751852,
      0.2577869954241294,
      0.26903840521785516,
      0.25897975586751354,
      0.0,
      0.29516732393532275,
      0.3377558398688778,
      0.2586057722587263,
      0.3166136877250598,
      0.2971677609393202,
      0.3052622613701319
    ],
    [
      0.31206077271910293,
      0.3904968724235125,
      0.4482342695704844,
      0.4137923278897111,
      0.40456408371758545,
      0.43514374139037004,
      0.36738240054292337,
      0.3714782494658957,
      0.38422184358107647,
      0.40774149782916,
      0.4006131163641935,
      0.24276479026754694,
      0.38150094980570337,
      0.42063327778690685,
      0.3963895634174952,
      0.38817644785546523,
      0.43425892748558326,
      0.4394223207583061,
      0.39745117480172687,
      0.40865270027793454,
      0.40422677043213917,
      0.3831582938902367,
      0.3562804952507044,
      0.0,
      0.38018563105384895,
      0.39832590505910526,
      0.4229193862924545,
      0.42990047681321686,
      0.308132563017371
    ],
    [
      0.31268488758861146,
      0.31847873881079036,
      0.4036432908065448,
      0.3886096319580772,
      0.39713999103729725,
      0.3454099253217293,
      0.3119367942656439,
      0.2595600144947541,
      0.31781386862711014,
      0.41144116108976414,
      0.3288509486032749,
      0.25407370862817324,
      0.30784433368245656,
      0.33795715183097985,
      0.34492068484489624,
      0.3380751707329013,
      0.3686216626610126,
      0.34449802000614893,
      0.2682599624700688,
      0.34575237377830237,
      0.34896756632012793,
      0.2951921687147401,
      0.3816588624140951,
      0.3449297588156879,
      0.0,
      0.29564430822377297,
      0.3710090686211702,
      0.3621851953545039,
      0.292727751212688
    ],
    [
      0.2545083676919808,
      0.3186630251273872,
      0.3313410453901664,
      0.33143655327826105,
      0.36320822104429773,
      0.3172091444560976,
      0.3386917014455053,
      0.2805966425171722,
      0.369161733288065,
      0.36347069360298745,
      0.36196654951250773,
      0.23632275961647164,
      0.3792197142111393,
      0.3482316240918646,
      0.3544257145505505,
      0.32224515923266206,
      0.3603108791206444,
      0.309635766002865,
      0.3682811156588719,
      0.3333347193292089,
      0.36442665444423694,
      0.3604643454445726,
      0.2698930544559828,
      0.34144117293694287,
      0.2665856451814439,
      0.0,
      0.3358767431786658,
      0.3309727428481686,
      0.26085286213145453
    ],
    [
      0.35886153117535025,
      0.4367909858526078,
      0.450164188503136,
      0.3984570535587617,
      0.4363179701805906,
      0.41969482133014324,
      0.4418554968263477,
      0.3912406566682536,
      0.43674155932274816,
      0.4402705607526878,
      0.4242234181375728,
      0.283187049614807,
      0.42408827434202223,
      0.43771312393876505,
      0.39889724027104023,
      0.4170528107347955,
      0.5022113325837532,
      0.42701445311545383,
      0.38749928341319206,
      0.4182999900823423,
      0.4636900714270067,
      0.4441460297940327,
      0.3966834717343968,
      0.44180404527824413,
      0.41643062619609106,
      0.4426015507386001,
      0.0,
      0.45216236676510246,
      0.37497464406249903
    ],
    [
      0.2965314802440475,
      0.49434604496759893,
      0.46188777675867065,
      0.48356261167163295,
      0.4862407677772691,
      0.4577456267733484,
      0.3781921020011718,
      0.4038517570323712,
      0.5126088230226502,
      0.39800208740287357,
      0.4799426359339294,
      0.2323132490965607,
      0.4272947248631118,
      0.4774427640096486,
      0.4520631417729817,
      0.4300318221482313,
      0.42682657353691944,
      0.45939361117118094,
      0.341645037953364,
      0.45185838200122297,
      0.4064104060873748,
      0.4395974195889203,
      0.31644895322165634,
      0.40471430103358697,
      0.3437869448837858,
      0.4042320828903603,
      0.36545747665999806,
      0.0,
      0.2864689175316919
    ],
    [
      0.32019066637357585,
      0.35525276845579556,
      0.35561290492101705,
      0.3543502156607825,
      0.38550960999847894,
      0.3629086177639227,
      0.3273061221814173,
      0.2892449282564804,
      0.3684147173509986,
      0.30489005525160007,
      0.36275121039797487,
      0.3153555811081281,
      0.30746327808327023,
      0.3608635822743289,
      0.3684956734179896,
      0.354322325036295,
      0.3424747642678334,
      0.36443021964315214,
      0.32723898233327575,
      0.36334666494758894,
      0.318579067342057,
      0.34341510984310775,
      0.30425582910850646,
      0.33808472055508365,
      0.3270606326171941,
      0.296236550408318,
      0.3584017275584852,
      0.3383868015337719,
      0.0
    ]
  ],
  "row_avgs": [
    0.2192700618504093,
    0.4589478282051743,
    0.3837964448391607,
    0.4182283126818091,
    0.25838766639532185,
    0.4780127265476604,
    0.36840199833417764,
    0.3831198113644995,
    0.45153947233640385,
    0.36297077517019616,
    0.49193986921224964,
    0.2039214414123761,
    0.3539993716994531,
    0.42840029348183745,
    0.4385356065891114,
    0.3598953536605475,
    0.478259247499042,
    0.456371809809727,
    0.3969509468659977,
    0.4311701941259815,
    0.37740705473500225,
    0.3764971021775431,
    0.2897917322906066,
    0.3902896017771343,
    0.3356388214612616,
    0.32759908392107767,
    0.4201098073714408,
    0.4113891972155771,
    0.3398158330960868
  ],
  "col_avgs": [
    0.29301610516237925,
    0.42664798328484455,
    0.4218038396384647,
    0.42044899181038103,
    0.4451709155921824,
    0.43126401118717433,
    0.35987124348050636,
    0.3778740405374378,
    0.42167598317517385,
    0.3859827846187102,
    0.4246955053024787,
    0.25378319859507353,
    0.38926888491575706,
    0.42049436354297054,
    0.4251111735532615,
    0.3717394278740512,
    0.4103510484759191,
    0.4223327366145256,
    0.3680952615576641,
    0.4075375141847652,
    0.39028365393312126,
    0.3927172852393084,
    0.3060328742694985,
    0.3717958317392519,
    0.3205142293394568,
    0.38185421908343803,
    0.36067508086247607,
    0.3996519380663794,
    0.28996734049021494
  ],
  "combined_avgs": [
    0.25614308350639425,
    0.44279790574500943,
    0.40280014223881266,
    0.41933865224609507,
    0.35177929099375216,
    0.4546383688674174,
    0.364136620907342,
    0.3804969259509686,
    0.4366077277557888,
    0.37447677989445316,
    0.45831768725736416,
    0.2288523200037248,
    0.3716341283076051,
    0.42444732851240397,
    0.4318233900711864,
    0.36581739076729936,
    0.44430514798748055,
    0.43935227321212633,
    0.3825231042118309,
    0.41935385415537335,
    0.38384535433406175,
    0.3846071937084258,
    0.2979123032800526,
    0.3810427167581931,
    0.3280765254003592,
    0.35472665150225785,
    0.39039244411695845,
    0.4055205676409782,
    0.3148915867931509
  ],
  "gppm": [
    665.8536430479883,
    629.3526999468932,
    629.1331889351333,
    631.211340022276,
    607.3496874204081,
    626.264409195804,
    662.4287998237149,
    646.5156429231362,
    631.6129434748236,
    642.5385248508206,
    631.1551603738268,
    707.0752490315823,
    646.6810264680031,
    632.9886043863866,
    630.3445578234545,
    656.2579383920956,
    633.085895876637,
    628.2777222994854,
    653.2075086890067,
    633.9041420406468,
    641.4322331149029,
    643.9319955193624,
    684.177198931375,
    653.22431305617,
    677.2787067384824,
    648.5963615196737,
    661.3337257016059,
    639.6235201139564,
    692.9684564373246
  ],
  "gppm_normalized": [
    1.4803628203855947,
    1.470972994737734,
    1.47758029779823,
    1.4725883692989914,
    1.422614301014679,
    1.4608408525396526,
    1.5454345004920333,
    1.4977900545982814,
    1.4708497377952658,
    1.4938253696614834,
    1.4663200987587446,
    1.640520808979436,
    1.507759401654414,
    1.4739531125507572,
    1.4672058058668627,
    1.5222109172968377,
    1.4729039282616092,
    1.466176361339319,
    1.5158939938258738,
    1.48172900185804,
    1.4872765740516514,
    1.492866240981972,
    1.581911763974617,
    1.5145636222360717,
    1.5717994496431094,
    1.5031759996602219,
    1.534933699666974,
    1.4885358436365426,
    1.599819636795494
  ],
  "token_counts": [
    277,
    515,
    611,
    479,
    483,
    468,
    529,
    403,
    449,
    451,
    404,
    473,
    494,
    442,
    447,
    417,
    443,
    473,
    430,
    500,
    413,
    401,
    405,
    424,
    448,
    408,
    436,
    450,
    391,
    303,
    497,
    433,
    459,
    752,
    459,
    495,
    438,
    433,
    410,
    431,
    387,
    410,
    444,
    431,
    438,
    393,
    372,
    470,
    373,
    439,
    420,
    389,
    490,
    384,
    410,
    374,
    372,
    394,
    324,
    414,
    458,
    484,
    436,
    428,
    501,
    399,
    399,
    381,
    466,
    408,
    398,
    376,
    425,
    390,
    398,
    422,
    389,
    407,
    452,
    424,
    401,
    424,
    397,
    379,
    413,
    401,
    344,
    781,
    392,
    394,
    392,
    352,
    525,
    360,
    385,
    392,
    397,
    413,
    380,
    455,
    358,
    381,
    399,
    424,
    396,
    397,
    404,
    410,
    394,
    346,
    390,
    420,
    367,
    398,
    386,
    349,
    693,
    449,
    447,
    450,
    437,
    450,
    518,
    423,
    431,
    416,
    460,
    437,
    476,
    460,
    444,
    463,
    451,
    458,
    421,
    440,
    470,
    414,
    457,
    429,
    431,
    416,
    443,
    439,
    406,
    1366,
    431,
    451,
    431,
    382,
    435,
    379,
    402,
    392,
    554,
    420,
    469,
    441,
    450,
    466,
    420,
    414,
    410,
    438,
    442,
    378,
    440,
    388,
    437,
    397,
    387,
    391,
    431,
    399,
    1428,
    431,
    434,
    454,
    409,
    434,
    388,
    406,
    484,
    448,
    357,
    618,
    424,
    397,
    365,
    453,
    437,
    439,
    452,
    382,
    412,
    347,
    390,
    420,
    459,
    322,
    408,
    451,
    409,
    557,
    395,
    451,
    431,
    438,
    437,
    417,
    383,
    398,
    374,
    428,
    387,
    416,
    435,
    406,
    409,
    457,
    395,
    425,
    379,
    415,
    441,
    340,
    408,
    417,
    426,
    414,
    438,
    335,
    468,
    442,
    473,
    474,
    383,
    401,
    465,
    446,
    413,
    388,
    399,
    481,
    480,
    453,
    411,
    415,
    389,
    446,
    406,
    459,
    411,
    398,
    367,
    435,
    415,
    350,
    346,
    429,
    364,
    533,
    424,
    479,
    491,
    712,
    431,
    444,
    521,
    415,
    476,
    408,
    564,
    485,
    428,
    449,
    470,
    420,
    441,
    430,
    446,
    447,
    421,
    459,
    433,
    414,
    473,
    353,
    452,
    397
  ],
  "response_lengths": [
    2363,
    2384,
    2633,
    2575,
    3995,
    2382,
    2446,
    2848,
    2244,
    2645,
    2208,
    3166,
    2693,
    2334,
    2464,
    2591,
    2435,
    2426,
    2401,
    2456,
    2489,
    2240,
    2589,
    2415,
    2355,
    2609,
    1955,
    2405,
    2329
  ]
}