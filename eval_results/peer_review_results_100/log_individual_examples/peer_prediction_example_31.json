{
  "example_idx": 31,
  "reference": "Published as a conference paper at ICLR 2023\n\nCOMPOSITIONAL TASK REPRESENTATIONS FOR LARGE LANGUAGE MODELS\n\nNan Shao∗1, Zefan Cai∗2, Hanwei Xu1, Chonghua Liao3, Yanan Zheng3, Zhilin Yang†3451 1Recurrent AI, 2Beijing Jiaotong University, 3Tsinghua University 4Shanghai Artificial Intelligence Laboratory, 5Shanghai Qi Zhi Institute {windoker,zefncai}@gmail.com {zyanan, zhiliny}@tsinghua.edu.cn\n\nABSTRACT\n\nLarge language models have shown a remarkable cross-task generalization ability. Most prior works assumed that prompts effectively extract knowledge from language models to facilitate generalization to new tasks. This perspective led to numerous studies on improving prompts. In contrast, we introduce a new perspective, compositional generalization, that views each task as a composition of latent codes and generalizes to test tasks by a new composition of seen codes. To this end, we propose a novel prompt-free approach, Compositional Task Representations (CTR), that employs multi-task training to learn a discrete, compositional codebook. Empirically, our CTR substantially outperforms prompt-based methods in zero-label learning on average. According to our analysis, some of the learned CTR codes are interpretable to humans and demonstrate a certain degree of controllability.\n\n1\n\nINTRODUCTION\n\nLarge language models (LLMs) have shown remarkable performance in cross-task generalization. Without using any labeled data for the target task, GPT-3 (Brown et al., 2020) obtains reasonable performance on a wide range of tasks. Later extensions such as FLAN (Wei et al., 2022) and T0 (Sanh et al., 2022) continue training the LLMs on a large number of supervised tasks, which further improves cross-task generalization performance. The aforementioned studies have used an important assumption that natural language prompts extract knowledge from LLMs to facilitate generalization to new tasks. In this direction, numerous studies have focused on different aspects of improving prompt-based learning, such as designing better prompts (Xu et al., 2022), increasing the number of prompts (Wang et al., 2022; Aribandi et al., 2022), and improving the training efficiency of prompts (Lester et al., 2021).\n\nIn contrast, we explore an alternative perspective for cross-task generalization, i.e., compositional generalization. Specifically, we explore whether it is possible to represent tasks using discrete compositions of latent codes. This perspective enjoys several potential benefits. First, since the latent codes have been trained for seen tasks, we expect the LLMs to have strong cross-task generalization abilities because new tasks can also be represented as a composition of these trained codes. Second, it provides a way to analyze and understand cross-task generalization by investigating the association between tasks and the learned representations. Third, it has the potential of being more controllable than prompts for task generalization due to its built-in compositionality.\n\nMotivated by the aforementioned potentials, we propose a new method, Compositional Task Representations (CTR), that employs multi-task training to learn a discrete, compositional codebook. Specifically, given a large number of training tasks, we use an encoder to map each randomlyinitialized task embedding to a fixed-length sequence of query vectors. Each query vector is used to retrieve a code from a codebook, which is formulated as an embedding lookup table. This produces\n\n*Equal contribution. †Corresponding author. ‡The code will be available at https://github.com/shaonan1993/CTR.\n\n1\n\nPublished as a conference paper at ICLR 2023\n\nFigure 1: An illustration of how CTR generalizes to zero-label tasks. In this real example produced by our model, CTR combines the abilities of reasoning-based QA, sentence generation, and multichoice selection from training tasks to perform a new task COPA.\n\na sequence of codes, a compositional representation of the current task. These compositional codes are fed as the input to an LLM in place of prompts to make predictions. At test time, given a new task, we use unlabeled data to search for a high-performing composition of codes, which enables zero-label cross-task generalization. CTR is also applicable to the few-shot setting where the few labeled examples are used for code search.\n\nEmpirically, we demonstrate improved performance under both the settings of zero-label learning and few-shot learning, outperforming strong baselines including prompt tuning, model tuning, and genetic prompt search (Xu et al., 2022). Importantly, we analyze the learned task representations and show that they demonstrate a certain degree of interpretability and controllability. For example, as shown in Figure 1, CTR learns to generalize to a new task by a new composition of existing codes.\n\n2 RELATED WORK\n\nLanguage Model Prompting. Brown et al. (2020) showed that GPT-3 performs well in the fewshot setting if properly handcrafted prompts are provided. Other works (Shoeybi et al., 2019; Rae et al., 2021; Schick & Sch ̈utze, 2021) also report promising zero-shot or few-shot performances of LLMs. Besides, Wei et al. (2022) and Sanh et al. (2022) collect a set of labeled datasets and use manual templates to transform them into a sequence-to-sequence style. Such a formulation makes it possible to continue training LLMs on these labeled datasets and improves cross-task generalization. Wang et al. (2022); Mishra et al. (2022) introduced a benchmark of over 1600 tasks and their expertwritten instructions Gao et al. (2021); Shin et al. (2020) studied automating the search process of discrete prompts. Li & Liang (2021); Liu et al. (2021) propose continuous soft prompts with gradient-based optimization. Compared to these approaches, we study a different approach that learns compositional task representations, which benefits cross-task generalization.\n\nCompositional Architecture for LLMs. Previous work has explored designing compositional architectures. Sparsely Gated Mixture of Expert (MoE) (Lepikhin et al., 2021) activates a subset of a network given the input data. Artetxe et al. (2021) trained an MoE model with 1.1T parameters, which is shown to outperform a dense model with similar computational cost. SkillNet-NLU (Tang et al., 2022) and SkillNet-NLG (Liao et al., 2022b) employed a similar sparsely activated mechanism to handle different NLU or NLG tasks. Different from these approaches, our approach focuses on learning compositional task representations using a discrete codebook.\n\n2\n\nI watched the first McCainObama debate last night . It was full of moments I had to pause the DVR because I had to discuss what they were saying with my husband . I learned a lot about the Iraq war and Afghanistan , and I saw both McCain and Obama make some going points , and I saw them both make some blunders .How would this person be classified ?-Moderate -Liberal -Conservative -None of the above choices .CosmosQA(Code 69 is shared bytasks that are multiple-choice/reasoning-based QA): Document: National Archives Yes, it2019s that time again, folks. It2019s the first Friday of the month, when for one ever-so-brief moment the interests of Wall Street, Washington and Main Street are all aligned on one thing: Jobs. A fresh update on the U.S. employment situation for January hits the wires at 8:30 a.m. ......CTR+LLMModerateThe unemployment rate dropped to 8.2% last month, but the economy only added 120,000 jobs, when 203,000 new jobs had been predicted, according to today's jobs report. Reaction on the Wall Street Journal's MarketBeat Blog was swift: \"Woah!!! Bad number. \" The unemployment rate, however, is better news; it had been expected to hold steady at 8.3%. But the AP notes that the dip is mostly due to more Americans giving up on seeking employment.\"Compositional Task CodeGenerated OutputsThe woman retired. so... -She received her pension. -She paid off her mortgage.COPA(sentence completion)She received her pension.Training PhaseZero-Label Inference PhaseRand falls on shock SA rate cut Interest rates are trimmed to 7.5 by the South African central bank, but the lack of warning hits the rand and surprises markets. world politics, sports, business, or science and technology?Business[23, 90, 69, 15, 2, 79, 25, 103, 120, 44][54, 14, 58, 28, 117, 33, 16, 53, 109, 111][111,7,69,15,2,79,39,1,119,19][23, 90, 76, 15, 2, 79, 39, 1, 119, 19]TaskInputsThe girl found a bug in her cereal. so... -She poured milk in the bowl. -She lost her appetite.AGNews(Code [15,2,79,39,1,119,19] occurs in tasks that select from multiple options):MultiNews(Code 111 exists in most long-sentence-generationtasks):She lost her appetite.Published as a conference paper at ICLR 2023\n\nFigure 2: An overview of the architecture of our proposed CTR . The left part illustrates the training phase, while the right part shows how CTR works during the inference phrase.\n\n3 COMPOSITIONAL TASK REPRESENTATIONS\n\nThe motivation of CTR is to explore the cross-task generalization ability of LLMs from a brandnew perspective—compositional generalization, and to further improve the performance of crosstask generalization. Specifically, our main hypothesis is that being trained on a variety of natural language tasks, LLMs will be able to learn to represent each task as a composition of discrete latent codes, where each latent code is associated with certain aspects of a task. As a result, CTR potentially enjoys the advantages of better cross-task generalization since it could represent new tasks by forming new compositions.\n\nThis section introduces the overall architecture of CTR and how it is trained to overcome optimization challenges. As Figure 2 shows, CTR consists of the CTR learning module and an LLM, where the CTR learning module contains an encoder, a decoder, task embeddings, and a codebook.\n\n3.1 DISCRETE LATENT TASK CODEBOOK\n\nWe define a latent task codebook embedding space C ∈ RS×D where S is the size of the latent codebook embedding space (i.e., each task code can take either of the S categorical values), and D is the dimension of each latent code embedding Ci ∈ RD, i ∈ [1, 2, · · · , S]. This is analogous to the idea of VQ-VAE (van den Oord et al., 2017) where a discrete latent codebook is also employed.\n\nAs Figure 2 shows, given a training task as the input (assuming the task id is k), CTR first obtains its task embedding Ek ∈ RD by retrieving from a randomly-initialized task embedding lookup table RN ×D where N is the number of training tasks. The task embedding Ek is then passed to the encoder module and is mapped into a fixed-length sequence of query vectors Q ∈ RL×D where L is the length of the sequence. For each query vector Ql, l ∈ [1, 2, · · · , L], it is used to retrieve a task code embedding from the codebook embedding space. Specifically, it calculates the l2 distance with each of the latent code embedding Ci ∈ RD, i ∈ [1, 2, · · · , S], and find the nearest neighbor,\n\nCTRl = Czl, where zl = arg min\n\ni\n\n||Ql − Ci||2\n\n(1)\n\nIn this way, all query vectors together produce a L-length sequence of code embeddings, denoted as the compositional task representations (CTR). They are then passed through a decoder, followed by being used as the input to an LLM in place of prompts to make predictions.\n\nLet z be a vector of L latent codes z1, z2, . . . , zL. We consider each latent code as describing an attribute or a necessary skill of a certain task, such as task type, output space, etc. Intuitively, we need multiple codes to fully describe a task, and each task is formulated as a composition of codes.\n\n3.2 TRAINING\n\nTraining can be challenging due to the existence of discrete latent variables. Moreover, during the initial training phase, the CTR learning module is randomly initialized. As a result, the codebook embeddings C will have a very different distribution to the query vectors Q, which increases the\n\n3\n\nInference Phase of CTRTraining Phase of CTRPublished as a conference paper at ICLR 2023\n\ndifficulty of optimization. We decouple training into two phases. In the first phase, we freeze the LLM and only update the CTR learning module. This is followed by tuning all parameters.\n\nIn terms of the loss function, following van den Oord et al. (2017), we employ two separate losses, an embedding loss and a commitment loss, to match the query vectors with the compositional task representations. These losses are used in combination with a standard language modeling loss,\n\nL = LLM +\n\nL (cid:88)\n\nl=1\n\n(||sg[Ql] − CTRl||2\n\n2 + β||Ql − sg[CTRl]||2 2)\n\n(2)\n\nwhere LLM is a standard language modeling loss for solving the target task, sg denotes stopping the gradients, and β is a hyperparameter.\n\n3.3\n\nINFERENCE\n\nWe consider two settings: zero-label learning and few-shot learning, and describe how we apply CTR in these settings.\n\nCode Ensemble for Zero-Label Learning. In the zero-label setting, we are given a new task along with a set of unlabeled data. * The question is how to decide the code for this new task without labeled data. Our main idea is to select one of the training tasks (319 in total in our experiments) and use its learned code for this new task. We first obtain a set of candidate codes by examining how much a code gives predictions that deviate from a uniform distribution on the unlabeled data (Zhao et al., 2021). The candidate set is formed by N (set to 60 in our experiments) codes with the lowest deviations. We then ensemble the candidate set of codes to predict pseudo labels on unlabeled data, and select the code with the highest pseudo-label accuracy.\n\nBitwise Search for Few-Shot Learning. In the few-shot setting, we are given a new task along with a set of labeled data. We use this set of labeled data as our validation set to search for a high-performing code. Our preliminary study shows that one can control the output of CTR by changing one bit in the code vector z. Inspired by this, we first examine the validation-set accuracy for codes of training tasks, and select the code with the best accuracy as an initialization. Then we iteratively change a single bit of the selected code and evaluate the validation-set performance. At each iteration, we keep the updated code with higher performance. Finally, the code vector that obtains the best result on the validation set is taken as the test-task code. Our preliminary study shows that a certain code value usually occurs in a specific position of the code vector, and each position usually only has a small set of code values. Motivated by this, we only changes a small set of valid code candidates for each position.\n\nIn both the zero-label and few-shot settings, after we obtain a code vector z for the new task, we use the vector to obtain a composition task representation by indexing z in the codebook C. The task representations are then passed through the decoder and the LLM to perform the new task, similar to training time. This is also illustrated in the right part of Figure 2.\n\n4 EXPERIMENTS\n\n4.1 EXPERIMENTAL SETUP\n\nWe conduct extensive quantitative experiments to validate the performance of cross-task generalization of CTR. We mainly consider two settings, the zero-label setting and the few-shot setting. Aside from quantitative experiments, we perform qualitative analysis to understand the cross-task generalization ability by investigating the association between the discrete latent codes and the tasks.\n\n4.1.1 DATASETS\n\nCTR requires a large multi-task set for training, and a held-out set of tasks whose types are never seen during training for evaluation. We follow the T0 benchmark. The training part consists of\n\n*To clarify, for the zero-label setting, the unlabeled data equals the inputs of the test task. Note that the\n\ninputs naturally exist as long as we perform the evaluation. So it requires no extra effort to acquire data.\n\n4\n\nPublished as a conference paper at ICLR 2023\n\n39 tasks of 8 task types, including closed-book question answering (QA), multiple-choice QA, extractive QA, sentiment analysis, paraphrase identification, topic classification, summarization, and structure to text. The test part consists of 11 tasks of 4 task types, including natural language inference (RTE (Dagan et al., 2006), CB (De Marneffe et al., 2019), ANLI/R1-R3 (Nie et al., 2020)), coreference resolution (WSC (Levesque et al., 2012), Winogrande (Sakaguchi et al., 2020)), sentence completion (COPA (Roemmele et al., 2011), StoryCloze (Mostafazadeh et al., 2017), Hellaswag (Zellers et al., 2019)), and word sense disambiguation (WiC (Pilehvar & Camacho-Collados, 2019)). Both the training and test parts are disjoint in task types, ensuring the zero-label setting. We follow T0 to use the accuracy on the validation split of test tasks as the metric.\n\n4.1.2 BASELINES\n\nFor the zero-label setting, we primarily compare CTR with the following baselines. It is noteworthy that all baselines share a similar model size as CTR (i.e., about 770M), thus are comparable. We provide implementation details of baselines in Appendix A.7.\n\n• T0 (Sanh et al., 2022) shares similar goals as CTR, which uses prompted multi-task training to improve the generalization performance. T0 reports the average results over multiple prompts.†.\n\n• Self-Training Since unlabeled data are accessed, we consider the self-training (Schick & Sch ̈utze, 2020) method as one of the baselines. Starting from T0, it uses T0 to label the unlabeled data, and further finetunes T0 with the pseudo-labeled data. It also reports average performance over prompts.\n\n• Manual-Code uses artificial feature vectors in place of CTR vector. Specifically, we manually label a set of artificially-designed features for each task, including the number of input fields of the task, whether it requires reasoning, and whether it is a classification task, etc. Each task can be represented as an discrete feature vector, each dimension associated with one of the aspects.\n\n• ZPS (Liao et al., 2022a) is method for zero-label prompt selection. It first labels a set of unlabeled data through prompt ensemble, and use the pseudo-labeled data to select the best natural language prompt for the test task. We apply ZPS to multi-task T0 as a baseline.\n\nFor the few-shot setting where there are 32 test-set labeled examples, based on the multi-task T0, we experimented the following five baseline methods.\n\n• Model Tuning directly finetunes the pretrained model using the test-set labeled data. Specifically, we follow the few-shot setting in Zheng et al. (2021) to use 16 labeled data for finetuning and another 16 labeled samples for model selection.\n\n• Prompt Tuning (Lester et al., 2021) introduces additional continuous prompts to the backbone model (i.e., T0) and trains the continuous prompts using the few labeled data.\n\n• GPS (Xu et al., 2022) is a genetic prompt search method. Based on T0, GPS gradually mutates the prompts with a generative model and uses the few labeled data to selects prompt candidates.\n\n• GRIPS (Prasad et al., 2022) is a gradient-free edit-based method for optimal prompt search.\n\n• Black-Box Tuning (BBT) (Sun et al., 2022) is a gradient-free few-shot prompt selection method. Unlike GPS and GRIPS, it searches for the best soft prompt embedding in a continuous space.\n\n4.1.3 TRAINING DETAILS\n\nWe instantiate our CTR with T5-Large (Raffel et al., 2019) being the LLM. We implement both the encoder and the decoder in our CTR model as two linear networks. We have experimented with various architectures (see Appendix A.4 for more details). For the first stage of training where the LLM is frozen, we use the Adam optimizer with a learning rate of 1e-2, a decay rate of 0.1, and a batch size of 2048. We use a codebook embedding dimension of 1024, which is the same as the hidden dimension. The CTR length is set at 10 and each position can be assigned values ranging from 0 to 127; i.e., the codebook size is 128. The hyperparameter β is set at 0.1. We experimented with different codebook sizes and CTR lengths, and detailed results are provided in Appendix A.5. For the second training phase where all parameters are updated, we use the Adam optimizer with a learning rate of 1e-4 and a batch size of 1024. We follow the training recipe as T0 (Sanh et al., 2022) for the rest of the hyperparameters.\n\n†T0 uses natural language prompts from PromptSource (Bach et al., 2022).\n\n5\n\nPublished as a conference paper at ICLR 2023\n\nMethod\n\nT0-Large Self-Training Manual-Code ZPS Our CTR\n\nModel Tuning Prompt Tuning GPS GRIPS BBT Our CTR\n\nRTE\n\nCB\n\n72.67 73.57 75.19 79.06 80.51\n\n75.31 77.08 77.68 71.56 71.19 80.51\n\n56.55 76.14 56.89 67.86 87.50\n\n80.95 76.90 79.64 70.89 57.26 83.93\n\nNatural Language Inference\n\nSentence Completion Co-reference WSD ANLI1 ANLI2 ANLI3 COPA Hella. Story. WSC Wino. WiC\n\nZero-Label Setting (unlabeled data of each test task)\n\n32.77 34.42 33.12 31.20 33.40\n\n32.15 32.90 32.49 31.10 34.40\n\n34.38 37.44 33.48 34.25 33.80\n\n85.36 87.45 75.76 88.00 92.00\n\n27.18 30.33 30.84 29.16 27.50\n\n93.04 94.54 93.10 93.43 90.10\n\nFew-Shot Setting (32 labeled data of each test task)\n\n35.73 31.89 32.71 32.14 33.79 34.40\n\n31.31 31.86 31.49 32.26 32.00 34.20\n\n35.93 35.53 37.56 34.77 35.30 36.60\n\n82.05 81.70 81.08 77.56 76.49 89.00\n\n41.86 31.18 28.11 26.44 28.95 35.07\n\n92.04 94.10 93.40 93.40 93.11 91.70\n\n63.94 57.08 61.16 65.38 56.58\n\n55.96 62.88 64.23 62.12 62.12 68.18\n\n54.35 56.56 54.10 53.43 49.40\n\n56.74 55.42 52.72 52.96 53.40 55.00\n\n50.33 50.75 51.45 49.84 62.50\n\n52.15 51.22 52.52 52.12 52.93 58.62\n\nAvg.\n\n54.79 57.38 54.33 56.61 58.88\n\n58.18 57.25 57.38 55.11 54.23 60.66\n\nTable 1: Main results of CTR and baselines on 11 test tasks under the zero-label setting and the fewshot setting. The zero-label setting allows using unlabeled data of the test task while the few-shot setting uses 32 labeled data of the test task. All methods share a similar model size (i.e., 770M).\n\n4.2 MAIN RESULTS AND ANALYSIS\n\nThe performance of cross-task generalization, respectively under the zero-label setting and the fewshot setting, are shown in Table 1. Our CTR outperforms all baseline methods on average under both settings. Comparing CTR with T0-Large and its variant (i.e., self-training), CTR outperforms them respectively by more than 4 points and by almost 1.5 points on average. The improvements potentially originate from two aspects—(a) the learned compositional task representations benefit from better generalization abilities than the discrete manual prompts used by T0/self-training; (b) our CTR can select a high-performing compositional task representation for the unseen task. Compared with Manual-Code, our CTR demonstrate significant advantages of more than 4.5 points, proving that artificially-designed features of tasks are unreliable, and CTR provides an effective way of automatically training such data-driven compositional task representations using multi-tasks.\n\nCompared with Model Tuning, Prompt Tuning, and BBT, where they require parameter updates over the test-task data, CTR shows better performance of cross-task generalization on average. Compared with baselines that do not tune parameters (i.e., GPS, GRIPS), CTR shows even larger and more consistent advantages on most of the test tasks; i.e., on 9/11 tasks CTR shows dominating performance.\n\nOn co-reference tasks , CTR performs worse under the zero-label setting and better under the fewshot setting. The zero-label setting uses pseudo-labeled data to select test codes while the few-shot setting uses real-labeled data to select codes. The reason for the decreased performance lies in that the pseudo data of the co-reference task were of low quality and did not select effective task codes.\n\nPlease refer to Appendix A.3 for generated zero-label cases from CTR .\n\n4.3 ABLATION STUDY\n\n4.3.1 ARE MANUAL PROMPTS NECESSARY?\n\nWe are interested in whether CTR will be further improved when combined with discrete manual prompts. We conduct comparative experiments of CTR respectively with and without manual prompts. Specifically, for CTR without manual prompts, the inputs are a direct concatenation of multiple text fields, with compositional task representations appended in front of it. For CTR with manual prompts, the inputs are constructed by leveraging T0 prompts , with CTR placed in front.\n\nThe results are presented in Table 2. We report both the CTR results as well as its “upper-bound” results. It is noteworthy that the “upper-bound” results are post-hoc, which are obtained by the best code/prompt with observing the test task performance, and are merely given for estimating the potential of the two methods. We shall observe that adding additional discrete manual prompts does not improve the CTR performance as well as the “upper-bound”. From the results, we shall conclude that (1) our CTR does not rely on manual prompts to obtain optimal performance. CTR can work as an alternative to the prompt-based methods. (2) By comparing the CTR performance and the CTR\n\n6\n\nPublished as a conference paper at ICLR 2023\n\nupper-bound, there is still room to optimize the code-searching algorithm, and as a result to further improve the generalization performance.\n\nOur CTR\n\nupper-bound\n\nw/ Manual Prompt upper-bound\n\nRTE\n\nCB\n\n80.51 81.95\n\n72.56 80.87\n\n87.50 89.29\n\n82.14 85.71\n\nNatural Language Inference\n\nSentence Completion Co-reference WSD ANLI1 ANLI2 ANLI3 COPA Hella. Story. WSC Wino. WiC\n\n33.40 38.77\n\n35.00 41.50\n\n34.40 39.00\n\n35.20 39.80\n\n33.80 40.60\n\n38.90 44.60\n\n92.00 94.23\n\n90.00 93.00\n\n27.50 42.81\n\n30.30 38.76\n\n90.10 94.20\n\n92.70 95.60\n\n56.58 73.86\n\n55.68 71.59\n\n49.40 60.00\n\n52.00 59.90\n\n62.50 61.76\n\n55.33 60.97\n\nAvg.\n\n58.88 65.13\n\n58.17 64.75\n\nTable 2: Ablation study on manual prompts. It shows the results of our CTR respectively without and with manual prompts. The experiments are under the zero-label setting. The “upper-bound” results of each method are obtained by using the best code/prompt after observing test task performance and are merely given for estimating the potential of the method. Results show that additionally adding manual prompts does not necessarily improve performance, and the codebook learned by CTR can act as an alternative to previous manual prompts.\n\n4.3.2 TRAINING OBJECTIVES\n\nOur CTR consists of three training loss items. Intuitively, the LM loss is optimized to predict the correct answer of the tasks. The embedding loss and the commitment loss are optimized to minimize the distance between the query embeddings and the CTR that are lookup from the codebook embeddings. To study the effectiveness of each loss item, we conduct an ablation study on them, and the results are shown in Table 3. Results show that removing either of the loss items will drastically hurt the zero-label performance , proving that either loss item is indispensable for the training of CTR .\n\nLoss Function\n\nOur CTR Loss\n\nNatural Language Inference\n\nSentence Completion Co-reference WSD ANLI1 ANLI2 ANLI3 COPA Hella. Story. WSC Wino. WiC\n\nRTE\n\nCB\n\nAvg.\n\n80.51\n\n87.50\n\n33.40\n\nwo/ Commitment Loss wo/ Embedding Loss wo/ Commitment+Embedding\n\n76.53 74.01 79.06\n\n76.79 75.00 76.79\n\n33.30 33.70 30.90\n\n34.40\n\n32.60 33.20 33.70\n\n33.80\n\n38.00 34.30 35.70\n\n92.00\n\n27.50\n\n90.10\n\n56.58\n\n49.40\n\n62.50\n\n58.88\n\n85.00 75.00 84.00\n\n33.50 25.40 30.50\n\n74.70 86.00 85.90\n\n64.77 61.36 57.95\n\n49.90 54.30 55.60\n\n54.39 50.00 50.00\n\n56.32 54.75 56.37\n\nTable 3: Ablation study on CTR loss function. Results show that by removing either of the loss items, i.e., commitment loss, embedding loss or both, the performance decreases to varying degrees.\n\n4.4\n\nIN-DEPTH ANALYSIS\n\n4.4.1\n\nINTERPRETABILITY\n\nSince CTR is trained to represent tasks with compositional codes, each code associated with one of the key aspects of tasks, CTR demonstrates a certain degree of interpretability. Table 4 presents examples of CTR that shows how each compositional task code is possibly interpreted.\n\nInterestingly, it frequently occurred that tasks that share similar features indeed have the same compositional code. For example, the code 52 occurs in tasks that require extracting information from the given contexts, including samsum * (summarization task), wiki bio * (structured data to text task), and paws labeled final paraphrase task (paraphrase generation) etc. Another example is that code 111 exists in most of the tasks that require generating long setences, including multi news * and samsum * (both are summarization tasks).\n\nWe also validate these explanations on unseen test tasks. Results show that these possible explanations still hold. For example, the COPA task generates long answers given two candidate choices, and its compositional code has the code 111 (indicating sentence generation).\n\n4.4.2 CONTROLLABILITY\n\nCTR also demonstrates a certain degree of controllability. Specifically, by modifying one bit of the compositional task code, our CTR will exhibit a different task behavior. Table 5 shows several examples of controlling CTR. We shall observe that, given the same inputs, by simply changing one\n\n7\n\nPublished as a conference paper at ICLR 2023\n\nCode: 41\n\nExplain: generate key words based on passages\n\nTASKS: wiki hop original choose best object interrogative 2 wiki hop original choose best object affirmative 3 common gen topics from the sentence\n\nwiki hop original generate subject and object common gen sentence to concepts\n\nCode: 52\n\nExplain: extract the main information of the article\n\nTASKS: samsum Sum up the following dialogue samsum To sum up this dialog samsum Given the above dialogue write a summary wiki bio key content wiki bio comprehension paws labeled final paraphrase task\n\nwiki bio what content\n\nsamsum Summarize this dialogue samsum Generate a summary for this dialogue\n\nCode: 69\n\nExplain: generate the answers given candidate choices\n\nTASKS: qasc qa with separated facts 1 qasc qa with separated facts 4 cosmos qa context description question answer text cosmos qa context question description answer text social i qa Show choices and generate answer trec fine grained LOC\n\nqasc qa with separated facts 2 qasc qa with combined facts 1 cosmos qa description context question answer text cosmos qa no prompt text trec fine grained LOC context first super glue copa best option\n\nCode: 111\n\nExplain: Generate long sentence\n\nTASKS: multi news summary scenario multi news distill samsum Write a dialogue that match this summary\n\nmulti news summarize multi news expand (reverse task) super glue copa best option\n\nTable 4: Examples of how compositional task codes can be possibly interpreted. We use a codebook size of 128. It shows the co-occurrence of tasks and codes. By analyzing common features shared by multiple tasks, we shall find that CTR embraces the advantage of interpretability.\n\nbit of the compositional task code, the task behavior of CTR turns from DIALOGUE GENERATION to TOPIC CLASSIFICATION, from REVIEW RATING to SUMMARIZATION, from SENTIMENT ANALYSIS to TOPIC CLASSIFICATION, etc.\n\nWe shall conclude— (1) Since the inputs are randomly sampled from all tasks, some of which are quite different in data distribution, CTR performs well on them, proving that CTR indeed learns the ability to perform different tasks, instead of simply memorizing/overfitting to a certain dataset. (2) CTR is capable of switching between different tasks by simply changing one bit of the compositional code, proving that CTR effectively encodes the “task behavior” factor into the bits of the compositional code while disentangling other factors.\n\n4.4.3 HOW CTR GENERALIZES TO NEW TASKS\n\nTo reveal how CTR essentially works, we use Figure 1 to explain how CTR generalizes from training tasks to unseen tasks such as COPA. During the training phase, CTR learns the compositional task code for each task, each code associated with certain features of the task. For example, code 69 is associated with many of the multiple-choice/reasoning-based QA tasks; code 111 is associated with most of the long-sentence-generation tasks, etc. For a new task, its task code is a re-arranged composition of the code existing in training tasks. If the new task shares the same code snippet as the training tasks, it inherits corresponding task features as well. In the example of Figure 1, a real case produced by our model, the new task COPA is performed by combining the abilities of reasoning-based QA, sentence generation, and multi-choice selection from training tasks. These observations are consistent with our motivation of learning CTR for cross-task generalization.\n\n4.4.4 GENERALIZING TO NEW UNSEEN DOMAINS/CLASSES\n\nAnother interesting finding is that, for tasks with limited categorical classes, e.g., topic classification tasks, CTR is capable of generalizing to new unseen classes/domains. Table 6 shows several examples. Given different inputs that are randomly sampled from a large set of tasks and the compositional task code of AGNews, CTR not only predicts topic classes that are originally defined\n\n8\n\nPublished as a conference paper at ICLR 2023\n\nINPUT: If Jim moves some particles of matter farther apart, what will happen to the rate at which they can pass vibrations on to nearby particles decrease or increase? Assuming that: When particles of matter are closer together, they can more quickly pass the energy of vibrations to nearby particles.\n\nTASK CODE: [61, 96, 127, 113, 55, 107, 5, 87,\n\n, 5]\n\nFILL 52 → DIALOGUE: W: Hi, Jim. I’m Jim. I’m a physicist at the University of California, Berkeley. FILL 37 → TOPIC CLASSIFICATION: Science and Technology\n\nINPUT: A historic victory for the separatist Parti Quebecois was marred by an attack on a victory rally for premier-elect Pauline Marois. A man opened fire during her victory speech, killing one person and critically wounding another, reports CTV. ... “I have convictions and I am going to defend them.” Marois said during her victory speech. “There will be a referendum when the Quebec population wants a referendum.”\n\nTASK CODE: [31,\n\n, 4, 113, 55, 107, 18, 87, 12, 63]\n\nFILL 68 → REVIEW RATING: 1 star FILL 93 → SUMMARIZATION : One person was killed and another critically injured in a shooting at a victory rally for the separatist Parti Quebecois in Quebec City on Sunday.\n\nINPUT: Paragraph: I’ve been here a few times and I like that it’s right up the street. On Tuesday and Wednesday they have specials on manicures and pedicures which is $5 cheaper then the original price.\n\nTASK CODE: [23, 90, 76, 15, 2, 79,\n\n, 1, 119, 19]\n\nFILL 13 → SENTIMENT ANALYSIS: Positive FILL 5 → TOPIC CLASSIFICATION : Business.\n\nTable 5: Examples of controlling the compositional codes. Given the input and a compositional task code, each time we modify one bit of the code, CTR begins to perform a different task.\n\nPredict with the code for AGNews (topic classification): [23, 90, 76, 15, 2, 79, 39, 1, 119, 19] Original AGNews classes: {World, Sports, Business, Science and technology}\n\nINPUT: Fears for T N pension after talks Unions representing workers at Turner Newall say they are ‘disappointed’ after talks with stricken parent firm Federal Mogul. OUTPUT: Business\n\nINPUT: There are 10 apples on an apple tree. Three fall off. Now there are X apples.\n\nOUTPUT: Math problem\n\nINPUT: Stuning even for the non-gamer This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate game music! It would impress anyone who cares to listen! OUTPUT: Music\n\nINPUT: Slack (2003) compares three groups that conducted biological research at Yale during overlapping periods between 1910 and 1970. Yale proved important as a site for this research. ... Hutchinson’s example shows that new models for research groups are needed, especially for those that include extensive field research. OUTPUT: Ecology\n\nTable 6: Examples of CTR generalizing to new unseen classes/domains. The inputs are randomly selected from all tasks other than AGNews. The first case predict the same classes as AGNews defines, while the latter three cases predict new classes that are never seen within AGNews. It shows the codebook of CTR can generalize to new unseen classes/domains.\n\nby AGNews, but also predicts new topic classes that never occur in AGNews. Please refer to Appendix A.1 and Appendix A.2 for more cases.\n\n5 CONCLUSIONS\n\nIn this paper, we explore cross-task generalization from a new perspective—compositional generalization. We propose the Compositional Task Representations (CTR) method that learns a discrete compositional codebook for tasks and generalizes to new unseen tasks by forming new compositions of the task codes. For the inference of CTR , we propose two algorithms — Code Ensemble and Bitwise Search, respectively for zero-label and few-shot settings. Experiments demonstrate that our CTR significantly outperforms existing prompted-based methods on both zero-label and few-shot settings. Analysis of the learned compositional task codes proves that some of the CTR codes show certain degrees of interpretability and controllability.\n\n9\n\nPublished as a conference paper at ICLR 2023\n\nREFERENCES\n\nVamsi Aribandi, Yi Tay, Tal Schuster, Jinfeng Rao, Huaixiu Steven Zheng, Sanket Vaibhav Mehta, Honglei Zhuang, Vinh Q. Tran, Dara Bahri, Jianmo Ni, Jai Gupta, Kai Hui, Sebastian Ruder, and Donald Metzler. Ext5: Towards extreme multi-task scaling for transfer learning. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum? id=Vzh1BFUCiIX.\n\nMikel Artetxe, Shruti Bhosale, Naman Goyal, Todor Mihaylov, Myle Ott, Sam Shleifer, Xi Victoria Lin, Jingfei Du, Srinivasan Iyer, Ramakanth Pasunuru, et al. Efficient large scale language modeling with mixtures of experts. arXiv preprint arXiv:2112.10684, 2021.\n\nStephen Bach, Victor Sanh, Zheng Xin Yong, Albert Webson, Colin Raffel, Nihal V. Nayak, Abheesht Sharma, Taewoon Kim, M Saiful Bari, Thibault Fevry, Zaid Alyafeai, Manan Dey, Andrea Santilli, Zhiqing Sun, Srulik Ben-david, Canwen Xu, Gunjan Chhablani, Han Wang, Jason Fries, Maged Al-shaibani, Shanya Sharma, Urmish Thakker, Khalid Almubarak, Xiangru Tang, Dragomir Radev, Mike Tian-jian Jiang, and Alexander Rush. PromptSource: An integrated development environment and repository for natural language prompts. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pp. 93–104, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/ v1/2022.acl-demo.9. URL https://aclanthology.org/2022.acl-demo.9.\n\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCanLanguage models are few-shot dlish, Alec Radford, Ilya Sutskever, and Dario Amodei. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Adlearners. vances in Neural Information Processing Systems, volume 33, pp. 1877–1901. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\n\nIdo Dagan, Oren Glickman, and Bernardo Magnini. The pascal recognising textual entailment challenge. In Joaquin Qui ̃nonero-Candela, Ido Dagan, Bernardo Magnini, and Florence d’Alch ́e Buc (eds.), Machine Learning Challenges. Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment, pp. 177–190, Berlin, Heidelberg, 2006. Springer Berlin Heidelberg. ISBN 978-3-540-33428-6.\n\nMarie-Catherine De Marneffe, Mandy Simons, and Judith Tonhauser. The commitmentbank: Investigating projection in naturally occurring discourse. In proceedings of Sinn und Bedeutung, volume 23, pp. 107–124, 2019.\n\nTianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 3816–3830, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.295. URL https://aclanthology.org/2021. acl-long.295.\n\nDmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. {GS}hard: Scaling giant models with conditional computation and automatic sharding. In International Conference on Learning Representations, 2021. URL https://openreview.net/forum?id=qrwe7XHTmYb.\n\nBrian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 3045–3059, Online and Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.243. URL https://aclanthology.org/2021.emnlp-main.243.\n\n10\n\nPublished as a conference paper at ICLR 2023\n\nHector Levesque, Ernest Davis, and Leora Morgenstern. The winograd schema challenge. In Thirteenth International Conference on the Principles of Knowledge Representation and Reasoning. Citeseer, 2012.\n\nXiang Lisa Li and Percy Liang. Prefix-tuning: Optimizing continuous prompts for generation. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 4582–4597, Online, August 2021. Association for Computational Linguistics. doi: 10.18653/ v1/2021.acl-long.353. URL https://aclanthology.org/2021.acl-long.353.\n\nChonghua Liao, Yanan Zheng, and Zhilin Yang. Zero-label prompt selection. arXiv preprint\n\narXiv:2211.04668, 2022a.\n\nJunwei Liao, Duyu Tang, Fan Zhang, and Shuming Shi. Skillnet-nlg: General-purpose natural language generation with a sparsely activated approach. arXiv preprint arXiv:2204.12184, 2022b.\n\nXiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, and Jie Tang. Gpt\n\nunderstands, too. arXiv preprint arXiv:2103.10385, 2021.\n\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. Cross-task generalization via natural language crowdsourcing instructions. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 3470–3487, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.acl-long. 244. URL https://aclanthology.org/2022.acl-long.244.\n\nNasrin Mostafazadeh, Michael Roth, Annie Louis, Nathanael Chambers, and James Allen. LSIn Proceedings of the 2nd Workshop on LinkDSem 2017 shared task: The story cloze test. ing Models of Lexical, Sentential and Discourse-level Semantics, pp. 46–51, Valencia, Spain, April 2017. Association for Computational Linguistics. doi: 10.18653/v1/W17-0906. URL https://aclanthology.org/W17-0906.\n\nYixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adversarial NLI: A new benchmark for natural language understanding. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 4885–4901, Online, July 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.acl-main.441. URL https://aclanthology.org/2020.acl-main.441.\n\nMohammad Taher Pilehvar and Jose Camacho-Collados. WiC: the word-in-context dataset for In Proceedings of the 2019 Conference evaluating context-sensitive meaning representations. of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 1267–1273, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1128. URL https://aclanthology.org/N19-1128.\n\nArchiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal. Grips: Gradient-free, edit-based instruction search for prompting large language models. arXiv preprint arXiv:2203.07281, 2022.\n\nJack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et al. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446, 2021.\n\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer. CoRR, abs/1910.10683, 2019.\n\nMelissa Roemmele, Cosmin Adrian Bejan, and Andrew S Gordon. Choice of plausible alternaIn AAAI Spring Symposium: Logical\n\ntives: An evaluation of commonsense causal reasoning. Formalizations of Commonsense Reasoning, pp. 90–95, 2011.\n\nKeisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adver-\n\nsarial winograd schema challenge at scale. In AAAI, pp. 8732–8740. AAAI Press, 2020.\n\n11\n\nPublished as a conference paper at ICLR 2023\n\nVictor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. Multitask prompted training enables zero-shot task generalization. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=9Vrb9D0WI4.\n\nTimo Schick and Hinrich Sch ̈utze. It’s not just size that matters: Small language models are also\n\nfew-shot learners. CoRR, abs/2009.07118, 2020.\n\nTimo Schick and Hinrich Sch ̈utze. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 255–269, Online, April 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.eacl-main.20. URL https: //aclanthology.org/2021.eacl-main.20.\n\nTaylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4222–4235, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.346. URL https://aclanthology.org/2020. emnlp-main.346.\n\nMohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. Megatron-lm: Training multi-billion parameter language models using model parallelism. arXiv preprint arXiv:1909.08053, 2019.\n\nTianxiang Sun, Yunfan Shao, Hong Qian, Xuanjing Huang, and Xipeng Qiu. Black-box tuning for\n\nlanguage-model-as-a-service. arXiv preprint arXiv:2201.03514, 2022.\n\nDuyu Tang, Fan Zhang, Yong Dai, Cong Zhou, Shuangzhi Wu, and Shuming Shi. One model, multiple tasks: Pathways for natural language understanding. arXiv preprint arXiv:2203.03312, 2022.\n\nAaron van den Oord, Oriol Vinyals, and koray kavukcuoglu. Neural discrete representation learnIn I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and ing. R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL https://proceedings.neurips.cc/paper/2017/file/ 7a98af17e63a0ac09ce2e96d03992fbc-Paper.pdf.\n\nYizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. Benchmarking generalization via in-context instructions on 1,600+ language tasks. arXiv preprint arXiv:2204.07705, 2022.\n\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2022. URL https://openreview.net/ forum?id=gEZrGCozdqR.\n\nHanwei Xu, Yujun Chen, Yulun Du, Nan Shao, Yanggang Wang, Haiyu Li, and Zhilin Yang. Zeroprompt: Scaling prompt-based pretraining to 1,000 tasks improves zero-shot generalization. arXiv preprint arXiv:2201.06910, 2022.\n\nRowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. HellaSwag: Can a machine really finish your sentence? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 4791–4800, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1472. URL https://aclanthology.org/ P19-1472.\n\n12\n\nPublished as a conference paper at ICLR 2023\n\nTony Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. Calibrate before use: Improving\n\nfew-shot performance of language models. ArXiv, abs/2102.09690, 2021.\n\nYanan Zheng, Jing Zhou, Yujie Qian, Ming Ding, Jian Li, Ruslan Salakhutdinov, Jie Tang, Sebastian Ruder, and Zhilin Yang. Fewnlu: Benchmarking state-of-the-art methods for few-shot natural language understanding. CoRR, abs/2109.12742, 2021.\n\n13\n\nPublished as a conference paper at ICLR 2023\n\nA APPENDIX\n\nA.1 EXAMPLES OF AGNEWS\n\nQUESTION: Fears for T N pension after talks Unions representing workers at Turner Newall say they are ’disappointed’ after talks with stricken parent firm Federal Mogul. MODEL ANSWER (WITHIN THE ORIGINAL CLASSES): Business\n\nQUESTION: Prediction Unit Helps Forecast Wildfires (AP) AP - It’s barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar. MODEL ANSWER (WITHIN THE ORIGINAL CLASSES): Science and technology\n\nINPUT: How did serfdom develop in and then leave Russia? MODEL OUTPUT (OUT OF ORIGINAL CLASSES): History\n\nINPUT: There are 10 apples on an apple tree. Three fall off. Now there are X apples. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Math problem\n\nINPUT: the rock is destined to be the 21st century’s new “conan” and that he’s going to make a splash even greater than arnold schwarzenegger, jean-claud van damme or steven segal. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Film\n\nINPUT: E. D. Abbott Ltd - Abbott of Farnham E D Abbott Limited was a British coachbuilding business based in Farnham Surrey trading under that name from 1929. A major part of their output was under sub-contract to motor vehicle manufacturers. Their business closed in 1972. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Company\n\nINPUT: Stuning even for the non-gamer This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Music\n\nINPUT: E. D. Abbott Ltd - Abbott of Farnham E D Abbott Limited was a British coachbuilding business based in Farnham Surrey trading under that name from 1929. A major part of their output was under sub-contract to motor vehicle manufacturers. Their business closed in 1972. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Company\n\nQUESTION: Slack (2003) compares three groups that conducted biological research at Yale during overlapping periods between 1910 and 1970. Yale proved important as a site for this research. The leaders of these groups were Ross Granville Harrison, Grace E. Pickford, and G. Evelyn Hutchinson, and their members included both graduate students and more experienced scientists. All produced innovative research, including the opening of new subfields in embryology, endocrinology, and ecology, respectively, over a long period of time. Harrison’s group is shown to have been a classic research school; Pickford’s and Hutchinson’s were not. Pickford’s group was successful in spite of her lack of departmental or institutional position or power. Hutchinson and his graduate and postgraduate students were extremely productive, but in diverse areas of ecology rather than one focused area of research or the use of one set of research tools. Hutchinson’s example shows that new models for research groups are needed, especially for those that include extensive field research. MODEL ANSWER (OUT OF ORIGINAL CLASSES): Ecology\n\nTable 7: Examples of CTR by the compositional code of AG News. Given different inputs that are randomly sampled from a large set of tasks, and the compositional task code of AGNews, CTR not only predicts topic classes that are originally defined by AGNews, but also predicts new topic classes that never occur in AGNews .\n\n14\n\nPublished as a conference paper at ICLR 2023\n\nA.2 EXAMPLES OF DBPEDIA 14\n\nQUESTION: Federation of International Trade Associations - The Federation of International Trade Associations (FITA) based in Reston Virginia and New York New York USA was founded in 1984. It fosters international trade by seeking to strengthen the role of associations in the United States Mexico and Canada. FITA is the strategic partner of the United States Commercial Service for ecommerce. company, educational institution, artist, athlete, office holder, mean of transportation, building, natural place, village, animal, plant, album, film or written work MODEL ANSWER (WITHIN THE ORIGINAL CLASSES): Company\n\nQUESTION: Furian knife In this movie sequel, Vin Diesel returns as Riddick, an escaped convict with a price on his head. Riddick has been hiding on a snow planet for the last five years, when a group of mercenaries try to capture him. Riddick returns to the planet Helion, and finds out that his friend Jack, is in prison on Crematoria, a very hot planet. While on Helion, the planet is invaded by the Necromongers, led by Lord Marshal (Colm Feore), who wants to rule the universe. Riddick is captured by the mercs and flown to the same unsavoury and possibly illegal prison Kyra is in. Turns out Jack is now known as Kyra (Alexa Davalos) and is tough as nails. MODEL ANSWER (WITHIN THE ORIGINAL CLASSES): Film\n\nQUESTION: lila abu-lughod’s: - name - alma mater - website - known for - birth date - employer - nationality - occupation Bio: lila abu-lughod -lrb- born 1952 -rrb- is an american with palestinian and jewish ancestry who is professor of anthropology and women’s and gender studies at columbia university in new york city. a specialist of the arab world, her seven books, most based on long term ethnographic research, cover topics from sentiment and poetry to nationalism and media, from gender politics to the politics of memory. MODEL ANSWER (WITHIN THE ORIGINAL CLASSES): Educational Institution\n\nINPUT: when he dug his massive body into the batter’s box tuesday night at legends field during an exhibition game against the new york yankees, adam dunn not only wasn’t hitting his weight, he wasn’t hitting the weight of an UNK bag of baseballs. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Sports\n\nINPUT: We know that, thanks to our DNA, each of us is a little bit different. Some of those differences are obvious, like eye and hair color. Others are not so obvious, like how our bodies react to medication. Researchers are beginning to look at how to tailor medical treatments to our genetic profiles, in a relatively new field called pharmacogenomics. Some of the biggest breakthroughs have been in cancer treatment. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Science\n\nINPUT: how did athenians make money? Other Greek cities set up democracies, and even though most followed an Athenian model, none were as powerful, stable, nor as well-documented as that of Athens. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): City\n\nINPUT: Great food, portions could be smaller. A little pricey for Middleton. Would try somewhere else next time but would also not hesitate to return MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Restaurant\n\nINPUT: Facts: - name: mr. marcus - spelling: us - caption: mr. october 2007 marcus at a porn star karaoke event, - height: 5 8 - alias: mister marcus, mr. marquis - image: mr marcus, 2007.jpg - birth date: 4 september 1970 - birth name: jesse spencer - weight: 200 lb kg on - ethnicity: black - birth place: pomona, california, usa - hair color: black - number of films: 1,782 -lrb- per iafd -rrb- as a performer & 36 as a director - eye color: brown mr. marcus. MODEL OUTPUT (OUT OF ORIGINAL CLASSES): Actor\n\nTable 8: Examples of CTR by the compositional code of DBpedia 14. Given different inputs that are randomly sampled from a large set of tasks, and the compositional task code of DBpedia 14, CTR not only predicts topic classes that are originally defined by DBpedia 14, but also predicts new topic classes that never occur in DBpedia 14 .\n\n15\n\nPublished as a conference paper at ICLR 2023\n\nA.3 EXAMPLES OF ZERO-LABEL TASKS\n\nCOPA Task Code: [111,7,69,15,2,79,39,1,119,19]\n\nINPUT: The woman retired. so... - She received her pension. - She paid off her mortgage. OUTPUT: She received her pension.\n\nINPUT: The girl found a bug in her cereal. so... - She poured milk in the bowl. - She lost her appetite. OUTPUT: She lost her appetite.\n\nWinogrande Task Code: [5,21,76,15,2,79,25,1,119,19]\n\nINPUT: Sarah was a much better surgeon than Maria so always got the easier cases. Sarah or Maria? OUTPUT: Sarah\n\nINPUT: Terry tried to bake the eggplant in the toaster oven but the was too big. eggplant or toaster? OUTPUT: eggplant\n\nStoryCloze/2016 Task Code: [23,68,54,10,2,79,25,103,120,44]\n\nINPUT: Sam loved his old belt. He matched it with everything. Unfortunately he gained too much weight. It became too small. - Sam went on a diet.- Sam was happy. OUTPUT: Sam went on a diet.\n\nINPUT: Larry bought a new motorcycle. He was excited to look cool. The first time he tried riding it he dropped it. He hurt his leg and had to go to the hospital. - Larry loved going to the hospital.- Larry became careful. OUTPUT: Larry became careful.\n\nWinograd Schema Challenge Task Code: [5, 68, 4, 10, 8, 22, 18, 124, 12, 97]\n\nINPUT: Jane gave Joan candy because she was hungry. Jane was hungry. Yes or no? OUTPUT: No\n\nINPUT: Joe Joe’s uncle can still beat him at tennis, even though he is 30 years older. Joe is 30 years older. Yes or no? OUTPUT: No\n\nTable 9: Examples of generalizing to tasks of unseen types. It shows cases of the CTR code for zero-label test tasks, and corresponding generated examples.\n\nA.4 COMPONENT ARCHITECTURE\n\nEncoder-Decoder\n\nNatural Language Inference\n\nSentence Completion Co-reference WSD CB ANLI1 ANLI2 ANLI3 COPA Hella. Story. WSC Wino. WiC\n\nRTE\n\nAvg.\n\nCTR: Linear - Linear\n\n80.51 87.50\n\n33.40\n\nLinear - None Linear - MLP Linear - Transformer Linear - RNN MLP - Linear MLP - None MLP - MLP MLP - Transformer MLP - RNN\n\n77.98 82.14 77.26 80.36 77.98 80.36 78.70 80.36 79.06 71.43 78.34 76.79 76.53 76.79 78.70 75.00 79.78 73.21\n\n32.40 32.40 32.70 33.80 32.40 32.90 33.20 32.40 33.20\n\n34.40\n\n33.30 34.00 31.80 32.50 33.40 33.30 33.30 33.00 33.70\n\n33.80\n\n33.60 35.60 35.70 36.30 35.20 33.80 34.30 33.90 34.50\n\n92.00\n\n27.50\n\n90.10\n\n56.58\n\n49.40\n\n62.50\n\n58.88\n\n86.00 84.00 88.00 87.00 88.00 87.00 84.00 82.00 85.00\n\n29.43 26.86 27.72 30.70 30.25 30.08 28.14 28.70 28.64\n\n89.30 84.10 89.10 87.30 89.70 90.60 90.90 91.00 90.90\n\n55.68 54.55 54.55 55.68 60.23 52.27 52.27 56.82 57.95\n\n57.70 55.70 58.00 57.20 55.70 56.60 55.00 55.70 56.90\n\n50.00 50.31 49.84 56.11 49.84 50.31 50.47 50.16 50.00\n\n57.05 55.92 56.89 57.79 56.84 56.54 55.90 56.12 56.71\n\nTable 10: Ablation study on different architectures of the CTR encoder and decoder. All experiments are conducted under the zero-label setting. We experiment two of the encoder, respectively the linear net and the multi-layer perceptron (MLP), and five alternatives of the decoder, including the linear net, bidirectional RNN, Transformer, MLP and removing the decoder (None). Results show that the simple “Linear - Linear” combination achieves the best performance.\n\nTable 10 shows the zero-label results when using different architecture of the encoder and the decoder. We experiment two of the encoder, respectively the linear net and the multi-layer perceptron (MLP), and five alternatives of the decoder, including the linear net, bidirectional RNN, Transformer, MLP and removing the decoder (None). Results show that simply using a linear network for both the encoder and the decoder performs best, while complicated architectures, e.g., Transformer and MLP, yield poor performance. This could because that the learning of codebook embeddings\n\n16\n\nPublished as a conference paper at ICLR 2023\n\nas well as the code mapping does not necessarily need complicated transformation. When using complicated architectures, it instead increases the difficulties of the learning process.\n\nA.5 CODEBOOK SIZE AND CTR LENGTH\n\nThere are two critical hyper-parameters for CTR —the codebook size and the CTR length. We conduct experiments of different selection of the two hyper-parameters, and see how it influence the performance of zero-label generalization. Table 11 presents the results. We shall observe that when the codebook size decreases below 64, the performance decreases to a large degree. We conjecture that it is due to the capacity of a codebook size below 64 is not sufficient for representing the multiple aspects of the tasks. In addition, experimenting with a CTR length of 10 generally outperforms those with larger CTR length.\n\nCodebook Size\n\nCTR Length\n\nNatural Language Inference\n\nSentence Completion Co-reference WSD CB ANLI1 ANLI2 ANLI3 COPA Hella. Story. WSC Wino. WiC\n\nRTE\n\nAvg.\n\n128\n\n128 64 64 48 48\n\n10\n\n20 10 20 10 20\n\n80.51 87.50\n\n33.40\n\n77.62 80.36 75.81 73.21 79.06 82.14 77.26 78.57 79.42 60.71\n\n33.10 31.90 36.80 35.30 33.80\n\n34.40\n\n34.40 31.70 31.70 33.30 32.50\n\n33.80\n\n38.50 36.70 38.50 38.80 33.20\n\n92.00\n\n27.50\n\n90.10\n\n62.50\n\n49.40\n\n56.58\n\n58.88\n\n87.00 89.00 85.00 88.00 81.00\n\n31.60 26.90 30.86 33.54 29.00\n\n90.90 65.40 92.00 66.10 92.50\n\n54.55 48.86 56.82 60.23 50.00\n\n50.90 52.50 53.20 50.00 48.00\n\n55.80 54.70 50.47 53.45 53.92\n\n57.70 53.34 57.87 55.87 54.01\n\nTable 11: Ablation study on different codebook size and CTR length. All experiments are conducted under the zero-label setting. We experiment three of the codebook size, respectively 128, 64 and 48, and two of the CTR length, including 10 and 20. Results show that ”128 - 10” combination achieves the best performance.\n\nA.6 PERFORMANCE SENSITIVITY TO DIFFERENT SELECTION OF CODES\n\nWe want to verify whether different selections of codes will affect the performance of the model. Intuitively, if a code is merely noise that gets ignored by the model eventually, the model will not sensitive to different selections of codes and vice versa. Therefore, we randomly sampled several codes of training tasks and evaluate their performance on different test tasks. The results are shown in Table 12. As shown in the table, the model is highly sensitive to a different selection of codes. For example, the code of task amazon polarity user satisfied can perform well on RTE and significantly better than the performance of code of task cnn dailymail 3.0.0 news card view.\n\nTest Task\n\nCode of Train Task\n\nResults Min./Max.\n\nCB\n\nRTE\n\nWSC\n\nCOPA\n\nxsum read below DOC write abstract quoref Guess Title For Context imdb Writer Expressed Sentiment gigaword write a title for this sentence\n\namazon polarity user satisfied kilt tasks hotpotqa final exam cnn dailymail 3.0.0 news card view wiki hop original explain relation\n\ncosmos qa context description question answer text yelp review full format score cos e v1.11 question description option text xsum DOC write summary of above\n\ncos e v1.11 rationale quarel logic test wiki hop original choose best object interrogative 2 adversarial qa dbert based on\n\n35.83 41.79 52.74 42.50\n\n75.13 72.74 49.60 49.36\n\n52.74 63.51 57.90 53.19\n\n55.95 81.92 59.05 81.40\n\n35.83/52.74\n\n49.36/72.74\n\n52.74/63.51\n\n59.05/81.92\n\nTable 12: Performance sensitivity to different selections of codes.\n\n17\n\nPublished as a conference paper at ICLR 2023\n\nA.7 EXPERIMENTAL DETAILS\n\nFor the data preprocessing of all experiments, to balance the number of data for different tasks, we restrict the maximum data examples for each training task to be 50,000, which empirically yields better results.\n\nTraining details of each baseline method under the zero-label setting are illustrated as follows.\n\nT0-Large Based on T5-Large-LM-Adapted, it performs multi-task training for 10000 steps. We set the maximum length of input and target sequences to 384 and 32 respectively. We use the Adam optimizer with a learning rate of 1e-4, a dropout rate of 0.1, and a batch size of 1024. Following T0 Sanh et al. (2022), we use the same task prompts from PromptSource(Bach et al., 2022). We report the average accuracy of multiple prompts for each test task. Note that our reproduced T0Large results are much better than those reported in the original paper Sanh et al. (2022), which sets a much stronger baseline for comparison. We report the average accuracy of prompts for each test task. We believe our baseline is well-optimized. Because the performance on test tasks is comparable to the results of T0-3B reported in Sanh et al. (2022), even our baseline only contains 770M parameters.\n\nSelf-Training For a fair comparison, we randomly sample 32 unlabeled data for self-training, which is the same as CTR. The Self-Training method trains from the T0-Large with these pseudo-labeled examples for 5 epochs and reports average performance over prompts. For the training, we use a batch size of 32 and the Adam optimizer with a learning rate of 1e-4.\n\nManual-Code In practice, we manually label a set of artificially-designed features for each task, including the number of input fields of the task, whether it requires reasoning, whether it includes options into inputs, and whether it is a classification task, etc. Each task can be represented as an artificially-defined discrete feature vector, each dimension associated with one of the aspects. Manual-Code follows exact the same training recipe as the second training phase of our CTR. Training details are presented in Section 4.1.3.\n\nZero-Label Prompt Selection (ZPS) for producing pseudo-labeled data. Finally, we report the accuracy of the selected prompt.\n\n(Liao et al., 2022a) For each task, we use 32 unlabeled data\n\nFor the few-shot setting, we consider the following five baseline methods. All few-shot baselines are based on our reproduced T0-Large.\n\nModel Tuning We use the Adam optimizer with a batch size of 256 and a learning rate of 1e-4. We combine all training data of the test tasks for training. The maximum training step is 100. We use a validation set for model selection. Finally, we report the average accuracy of the selected best checkpoint.\n\nPrompt Tuning (Lester et al., 2021) We use the Adam optimizer with a batch size of 128 and a learning rate of 0.05. We combine all training data of the test tasks for training. The maximum training step is 100. The length of continuous prompts for each task is 20. We use a validation set for model selection. Finally, we report the average accuracy of the selected best checkpoint.\n\nGPS (Xu et al., 2022) We follow hyper-parameters reported in the original paper. Specifically, we run the GPS for 6 steps. At each step, new prompts are generated by a T5-xxl-lm-adapted model.\n\nGRIPS In our experiments, we set max patience P = 2, candidate l = 5, and step m = 5. For the rest of the hyper-parameters, we follow the original GRIPS paper(Prasad et al., 2022).\n\nBlack-Box Tuning (BBT) (Sun et al., 2022) In practice, we use the Adam optimizer with a learning rate of 0.05. For each test task, we train the soft prompt for 200 steps. We set the prompt length L = 10, subspace dimension d = 500, and cma budget 1000. For the rest of the hyper-parameters, we follow the original BBT(Sun et al., 2022).\n\n18",
  "translations": [
    "# Summary Of The Paper\n\nThis paper studies learning composable task codes for soft-prompting of language models. The authors propose an approach similar to VQ-VAE where each task is associated with a set of discrete codes and embedding of these codes from a codebook lookup table is stacked as a soft-prompt for a language model. First, a 2D embedding for each training task is learned via another lookup table. Next, each row of this embedding matrix is used to search for the nearest code embedding in codebook lookup table. The model is trained with typical language model loss in addition to commitment and embedding losses for learning codebook embeddings. By sharing codes across tasks, this approach presents a natural task compositionality. The authors propose code ensembling for zero-shot learning and bitwise searching for few-shot learning. On a set of benchmark tasks, the model compares favorably to previous models; achieving on-par or better on average. The authors also experiment with interpretability -- similar tasks share codes -- and controllability -- bitwise perturbation exhibits different behaviors.\n\n# Strength And Weaknesses\n\n**Strengths** The paper studies a very important and interesting problem -- learning composable task codes for generalization to unseen tasks. I find the formulation of the problem using VQ-VAE natural and inference methods convincing. It is interesting to see that empirical results, especially zero-shot learning, improves compared to self-training or T0 models.\n\n**Weaknesses** There are a few points that require clarification and improvement.\n1. Does sharing a code necessarily mean that two tasks are similar in some sense? I found no evidence as to how important a code is for a task; hence, I can't say if a code is merely noise that gets ignored by the model eventually. For example, if you increase the number of codes, *L*, the model might be given more codes but not all of them would be used. There is not loss that encourages the LLM to utilize all codes as well.\n\n2. What is the effective number of codes that discrete compositional task code, *z*, has? Are all codes in z unique or are they frequently reused?\n\n3. Comparison to previous work needs clarification.\n- Are baselines multi-task learners or are they initialized with some pretrained embedding? Like, prompts can be initialized or they can be trained in mutli-task fashion.\n- What are the architectural details of other models, including model size, are they comparable?\n- What is the performance of model tuning if you use all 32 examples for training? I think it is a bit unfair to use all examples for CTR while using only half of them for others.\n- You mention that other methods update extra parameters as a weakness but this is not true. Prompt tuning only updates an additional prompt while the LLM is fixed. On the other hand, CTR updates a codebook and LLM is also fine-tuned. I think this is less scalable overall compared to parameter efficient updates.\n\n4. How do you choose hyperparameters? Like, \"CTR length\", \"codebook size\", or *N=60*. I don't see a clear pattern on final performance and no training/dev results are given.\n\n5. Could you clarify:\n- How do you combine with manual prompts? Are they appended as additional soft-prompt vectors?\n- What is the performance if you haven't updated the LLM? This would be a fairer comparison to parameter efficient models.\n- What is the performance w.r.t. increasing data size for few-shot learning?\n- Why does the model perform worse on co-reference?\n\n# Clarity, Quality, Novelty And Reproducibility\n\nI find the composable task codes novel and the paper is well written. I believe results can't be reproducible without proper details on hyper parameters.\n\n# Summary Of The Review\n\nI think composable task codes, VQ-VAE style training for LLM fine-tuning, and generalization to novel tasks during inference are strong points of the paper. But, there are still pieces that are unclear and needs improvement.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\n\n# Empirical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
    "# Summary Of The Paper\nThe paper presents a novel approach to compositional generalization in large language models (LLMs) through a method called Compositional Task Representations (CTR). CTR utilizes multi-task training to learn a discrete codebook of task representations without relying on prompts, demonstrating superior performance in zero-label and few-shot learning scenarios. The findings reveal that CTR not only outperforms traditional prompt-based methods but also enhances interpretability and controllability of task representations.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative approach to task representation and the empirical results that validate its effectiveness. The methodology effectively combines the advantages of compositional generalization with the capabilities of LLMs. However, one potential weakness is the reliance on the training setup, which may limit the applicability of CTR to tasks outside the studied benchmarks. Additionally, while the interpretability of task codes is highlighted, the paper could benefit from more extensive analysis on how these codes influence specific task performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions and findings. The methodology is detailed, allowing for reproducibility of results, particularly with the outlined training phases and loss functions. The novelty of CTR lies in its departure from prompt-based methods and its focus on compositional representations, which is a significant contribution to the field. However, the discussion on interpretability could be expanded to improve understanding of the implications of the findings.\n\n# Summary Of The Review\nOverall, this paper introduces a compelling method that enhances compositional generalization in LLMs through CTR, demonstrating significant empirical advantages over existing methods. Its contributions to task representation, interpretability, and controllability mark it as a noteworthy advancement in the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Compositional Task Representations for Large Language Models\" introduces a novel framework for representing tasks in large language models (LLMs) through compositional task representations (CTR). The authors propose a prompt-free methodology that leverages multi-task training to create a discrete codebook of task representations, allowing for effective zero-label and few-shot learning. The experimental results demonstrate that CTR outperforms traditional methods, particularly in cross-task generalization, and provides interpretability and controllability in task behavior.\n\n# Strength And Weaknesses\nThe main strength of this paper lies in its innovative approach to task representation, moving away from traditional prompt-based methods to a more structured codebook system that enhances model generalization. Empirical results validate the effectiveness of CTR, showcasing superior performance across multiple tasks and settings. However, the approach has limitations, including the complexity involved in the code search process and its dependency on the quality and diversity of training tasks, which may affect generalization to new domains. Additionally, the variability in performance across different types of tasks indicates potential areas for improvement.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology, making it accessible to readers. The quality of the experiments is high, with a thorough evaluation against multiple baseline methods. The novelty of the compositional task representation approach is significant, offering fresh insights into task generalization in LLMs. However, the reproducibility could be challenged by the specific hyperparameters and configurations used, which might not be straightforward for researchers to replicate without additional details.\n\n# Summary Of The Review\nOverall, the paper presents a compelling advancement in the representation of tasks for LLMs through compositional generalization. While the method exhibits strong empirical results and interpretability, there are areas for improvement regarding code selection efficiency and task performance variability.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces **Compositional Task Representations (CTR)** for improving the cross-task generalization capabilities of Large Language Models (LLMs) such as GPT-3. It posits that LLMs can effectively learn to represent tasks using discrete latent codes, facilitating better generalization through the composition of these codes. The proposed methodology employs a prompt-free approach with multi-task training, utilizing an encoder-decoder architecture that maps task embeddings to discrete codes. Experimental results demonstrate that CTR outperforms existing methods in both zero-label and few-shot learning settings, showing significant improvements in task generalization and interpretability.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to task representations, moving beyond traditional prompt-based methods to a compositional framework that enhances generalization and interpretability. The experimental results are robust, showcasing CTR's superiority over various baselines in different settings, which strengthens the claims made. However, a potential weakness is the reliance on a specific architecture (T5-Large) for the implementation, which may limit the generalizability of the findings to other models or architectures. Additionally, while the paper provides valuable insights, it could benefit from discussing the practical implications and potential limitations of the proposed method in real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its contributions and findings. The methodology is detailed, with key equations effectively illustrating the model's workings. The novelty of the compositional generalization perspective is evident, presenting a fresh approach to understanding task representations in LLMs. The reproducibility of the results is supported by comprehensive training details, although sharing code and data could further enhance transparency and enable independent verification of the results.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in the field of large language models by introducing Compositional Task Representations, which enhance task generalization and interpretability. While the methodology is robust and the results are compelling, further exploration of practical applications and broader architectural implications would strengthen the contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper titled \"Compositional Task Representations for Large Language Models\" presents a novel approach to cross-task generalization by introducing Compositional Task Representations (CTR). The authors shift focus from traditional prompt-based methods to discrete task representations, demonstrating that CTR outperforms existing methods in zero-label and few-shot learning scenarios. The methodology involves multi-task training to create a discrete codebook for various tasks, which enhances interpretability and controllability while providing thorough empirical validation through quantitative metrics and qualitative analyses of learned codes.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative perspective on compositional generalization and the performance improvements observed with CTR in specific experimental setups. However, its limitations include a lack of empirical validation across diverse tasks and the potential variability in interpretability across different contexts. While the multi-task training approach is a significant contribution, it may introduce challenges related to computational resources and the risk of negative transfer. The thorough empirical validation and ablation studies conducted provide a solid foundation, though the analysis could benefit from broader evaluations and additional insights into model performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear and well-structured, presenting its contributions and findings effectively. The novelty of the compositional approach is evident, though its reproducibility may be hindered by the need for more detailed implementation guidelines and strategies for optimizing code selection. The quality of empirical validation is commendable, yet the scope of evaluation could be expanded to enhance the robustness of the results.\n\n# Summary Of The Review\nOverall, the paper offers a compelling contribution to the field by introducing Compositional Task Representations, which demonstrate significant performance improvements in specific settings. However, further empirical validation across a wider range of tasks and clearer implementation guidelines are necessary to fully establish the approach's generalizability and usability.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel methodology aimed at enhancing the cross-task generalization capabilities of large language models (LLMs). CTR departs from traditional prompt-based methods by encoding tasks as combinations of discrete latent representations, allowing LLMs to generalize from previously learned tasks. The authors present empirical results indicating that CTR significantly outperforms conventional methods in zero-label and few-shot learning scenarios, demonstrating both improved performance and interpretability of task representations.\n\n# Strength And Weaknesses\nOne of the key strengths of this paper is the introduction of a fresh perspective on task representation that emphasizes compositionality, which is a notable shift from existing prompt-based approaches. The elimination of manual prompt engineering through a learned codebook enhances the approach's practicality and adaptability. However, a potential weakness lies in the complexity of the proposed methodology, which may make it challenging for practitioners to implement without substantial background knowledge. Additionally, while the empirical results are promising, further validation across a wider range of tasks and domains could strengthen the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology, key contributions, and experimental results. The quality of writing is high, with sufficient details provided to understand the CTR framework and its implications for LLMs. The novelty of the approach is significant, as it redefines task representation in a way that could influence future research. However, reproducibility may be a concern if the implementation details are not thoroughly documented or if the code is not made publicly available.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to task representation for large language models, offering significant improvements in generalization capabilities. While the methodological complexity could pose challenges for adoption, the results indicate a meaningful advancement in the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel method for adversarial training utilizing Compositional Task Representations (CTR). The authors argue that traditional adversarial training approaches, which typically depend on perturbations of input data, can be improved by structuring tasks as combinations of latent codes. By adopting this compositional framework, the authors aim to generate adversarial examples that are more aligned with the underlying task structure, thereby enhancing model robustness and generalization. Their extensive experimental results demonstrate that models trained with CTR surpass conventional adversarial training techniques, particularly in zero-label and few-shot learning settings, while also providing interpretable adversarial behaviors.\n\n# Strength And Weaknesses\nThe main strengths of the paper include the innovative approach to adversarial training through compositionality, which offers a fresh perspective on the generation of adversarial examples. The empirical validation across various tasks and the demonstration of improved robustness and performance in scarce data scenarios substantiate the claims made. However, a potential weakness lies in the scalability of the proposed framework; while the results are promising, additional experiments on larger and more complex datasets could strengthen the findings. Furthermore, the interpretability aspect, although highlighted, could benefit from more detailed exploration and examples to illustrate its practical implications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodology. The presentation of results is coherent, and the comparisons with baseline methods are thorough, enhancing the quality of the research. The novelty of the compositional task representation in adversarial settings is evident, positioning the work as a significant advance in the field. Reproducibility is supported by the detailed experimental setup, though the authors could improve this aspect by providing access to code or datasets used in their experiments.\n\n# Summary Of The Review\nThis paper introduces an innovative framework for adversarial training that leverages compositional task representations, leading to improved model robustness and interpretability. The empirical results strongly support the proposed method's effectiveness, although further exploration of scalability and practical implications could enhance the contribution. Overall, I recommend acceptance for presentation at ICLR.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel approach aimed at enhancing cross-task generalization in large language models (LLMs). The authors claim that CTR shifts the paradigm away from traditional prompt-based methods, introducing a multi-task training framework that enables prompt-free learning and purportedly improves performance in zero-label and few-shot learning scenarios. Empirical results suggest significant performance gains; however, these claims may be overstated in comparison to existing methods and research.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its ambitious goal of redefining task representation in LLMs and its presentation of empirical results that demonstrate improvements in zero-label learning. However, weaknesses include a tendency to exaggerate the novelty of the compositional approach, as similar concepts have been previously explored. Additionally, the claims regarding improved interpretability and controllability of the learned representations may not be as groundbreaking as suggested, given the existing literature on model interpretability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and structured, making it accessible to readers. However, the novelty of the approach is questionable, as it does not sufficiently differentiate itself from existing methodologies. While the authors provide empirical results, the reproducibility of these findings may be hindered by a lack of detailed methodology regarding the multi-task training process and the specific datasets used.\n\n# Summary Of The Review\nOverall, the paper presents an interesting approach to task representation in LLMs, but its contributions may be more incremental than revolutionary. While the empirical results are promising, the claims made regarding novelty and performance require a more nuanced perspective that acknowledges prior work in the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel prompt-free approach that enhances the zero-label learning capabilities of large language models (LLMs). The methodology involves multi-task training to create a discrete codebook of task representations, which are utilized for task performance during inference. Experimental results demonstrate that CTR outperforms existing prompt-based methods, yielding superior results in both zero-label and few-shot settings, particularly against strong baselines like T0 and self-training.\n\n# Strength And Weaknesses\nThe paper presents a significant advancement in the understanding and application of LLMs by proposing CTR as a promising alternative to traditional prompt-based methods. Strengths include its empirical validation showing strong performance gains, the interpretability of learned codes, and the ability to generalize effectively to unseen tasks. However, weaknesses include potential limitations in scalability to larger or more complex tasks and the reliance on multi-task training, which may require substantial resources and data.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its contributions and findings. The methodology is described in detail, allowing for reproducibility of the experiments. The novelty of CTR lies in its compositional generalization perspective, which is a fresh approach compared to existing methods. However, further clarification on the codebook's construction and its implications on model behavior could enhance understanding.\n\n# Summary Of The Review\nOverall, the paper makes a notable contribution to the field of LLMs by introducing CTR, which demonstrates improved performance in zero-label learning tasks while offering enhanced interpretability and generalization capabilities. The findings are compelling, although additional exploration of scalability and the practical implementation of CTR in diverse settings would be beneficial.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper challenges the prevailing assumption that prompts are effective for knowledge extraction in large language models (LLMs), proposing an alternative approach centered on compositional generalization. By hypothesizing that tasks can be represented as combinations of discrete latent codes, the authors investigate the implications for task generalization, particularly in zero-label and few-shot settings. The findings suggest that while the compositional task representation offers a new avenue for generalization, concerns regarding interpretability, overfitting, and the robustness of the learned codes remain significant.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to compositional generalization, which opens new avenues for understanding LLMs beyond traditional prompt-based methods. However, weaknesses include a lack of critical engagement with existing literature on prompt engineering and insufficient validation of the assumption that tasks can be effectively represented by discrete latent codes. Additionally, the reliance on specific benchmarks raises questions about the generalizability of the results and the paper's exploratory nature on overfitting and interpretability could benefit from deeper empirical analysis.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its hypotheses and methodologies, though some concepts, particularly around the interpretability of latent codes and their application across diverse tasks, could be elaborated further. The novelty of the approach is commendable, but the reproducibility of results may be hindered by the specific experimental setups and the limited scope of benchmarks utilized. Overall, while the paper presents an interesting perspective, it could improve in terms of clarity regarding the implications of its findings and reproducibility across broader contexts.\n\n# Summary Of The Review\nOverall, the paper presents a compelling challenge to traditional prompt-based approaches by proposing compositional generalization as a framework for task representation in LLMs. However, the assumptions made regarding the interpretability and generalization capability of the proposed methods require further validation to substantiate the claims made.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel, prompt-free method aimed at enhancing cross-task generalization in large language models (LLMs) through multi-task training. The methodology involves learning a discrete codebook of latent task representations, which allows for effective generalization, especially in zero-label learning scenarios. Experimental results demonstrate that CTR outperforms traditional prompt-based methods across various tasks, showcasing its potential for improved interpretability and controllability in task representation.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to task representation, moving away from conventional prompt-based methods. The use of a discrete codebook enhances flexibility and performance, particularly in scenarios with limited data. However, one notable weakness is the potential complexity introduced by the codebook and its learning process, which may require careful tuning and understanding to fully leverage its benefits. Additionally, while the empirical results are compelling, further exploration on the scalability of CTR across a broader range of tasks would strengthen the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The quality of the writing is high, with a logical flow that facilitates understanding. The novelty of the CTR approach is significant, as it presents a fresh perspective on task representation in LLMs. However, reproducibility could be enhanced by providing more detailed descriptions of the experimental setup, including hyperparameters and the specific datasets used.\n\n# Summary Of The Review\nOverall, the paper presents a substantial advancement in the domain of task generalization for LLMs through its introduction of CTR. The methodology is innovative, and the empirical results validate the effectiveness of the proposed approach. However, further investigation into the complexities and scalability of CTR would benefit future work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel method for improving the performance of neural networks by introducing a new regularization technique that leverages adversarial training combined with a unique data augmentation strategy. The authors propose a framework that integrates these components to enhance the model's generalization capabilities on unseen data. The findings demonstrate that the proposed approach outperforms existing methods in various benchmark datasets, indicating significant improvements in both accuracy and robustness against adversarial attacks.\n\n# Strength And Weaknesses\n**Strengths:**\n- **Innovative Integration**: The combination of adversarial training and novel data augmentation provides a fresh perspective on addressing model overfitting and robustness, potentially leading to significant advancements in neural network training.\n- **Solid Empirical Evaluation**: The methodology is backed by comprehensive experiments across multiple datasets, showcasing the efficacy of the proposed approach against a variety of state-of-the-art techniques.\n- **Theoretical Justifications**: The authors provide a clear theoretical framework that supports their methodology, enhancing the credibility of their claims regarding performance improvements.\n\n**Weaknesses:**\n- **Complexity of Implementation**: The proposed method may be intricate to implement, which could limit its adoption in practice. More detailed implementation guidelines could be beneficial.\n- **Limited Baseline Comparisons**: While the paper includes several comparisons to existing methods, it could benefit from a broader set of baseline models to provide a more thorough evaluation of its performance.\n- **Generalization Assumptions**: Questions arise regarding the generalizability of the proposed technique across diverse domains outside of the tested datasets, which warrant further exploration.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its ideas clearly, though certain complex aspects of the methodology could be articulated more simply for accessibility. The quality of the writing is high, and the figures and tables effectively convey key results. The novelty of the proposed approach is evident, as it combines existing techniques in a novel way, potentially pointing to new directions in the field. However, reproducibility may be hindered by the lack of detailed implementation specifics and dataset availability.\n\n# Summary Of The Review\nThe paper offers an innovative approach to improving neural network performance through a combination of adversarial training and data augmentation, backed by solid empirical evidence. While the contributions are significant, the paper could benefit from clearer methodological explanations and more extensive baseline comparisons. Overall, it represents a valuable addition to the literature with potential implications for future research.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper \"Compositional Task Representations for Large Language Models\" introduces a novel approach to enhancing the generalization capabilities of large language models (LLMs) through a method termed Compositional Task Representations (CTR). The authors propose treating tasks as combinations of latent codes, moving away from traditional prompt-based techniques. By employing multi-task training to create a discrete codebook of compositional codes, CTR enables the model to generalize to new tasks by combining learned codes. Empirical results demonstrate that CTR significantly outperforms conventional prompt-based methods in zero-label learning scenarios, showcasing improved interpretability, controllability, and task generalization.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to task representation, which offers a robust alternative to existing prompt-based methods. The introduction of compositional generalization is a significant contribution that could advance the field of LLMs. Additionally, the empirical results provide compelling evidence of CTR's effectiveness, highlighting its potential for enhanced interpretability and flexibility in task execution. However, a potential weakness is the need for a more comprehensive exploration of the limitations of CTR, such as its scalability and applicability to a wider range of tasks beyond those tested.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible to readers familiar with the field. The methodology is described sufficiently, allowing for reproducibility of the experiments. The novelty of the proposed approach is significant, as it shifts the focus from prompts to a code-based representation, which could inspire further research in compositional generalization. However, the authors could improve the clarity of certain sections that delve into technical details of the multi-task training process.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to improving cross-task generalization in LLMs through Compositional Task Representations. Its strengths in empirical performance and interpretability are noteworthy, though further exploration of its limitations would enhance the discussion. The findings contribute to a deeper understanding of compositional generalization in the context of LLMs.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel approach designed to enhance cross-task generalization in large language models (LLMs) by employing structured, compositional representations of tasks. The authors propose a methodology that utilizes multi-task training to create a discrete codebook for task embedding, which is then mapped to code sequences via an encoder-decoder architecture. Empirical results demonstrate that CTR consistently outperforms traditional prompt-based methods, especially in zero-label learning scenarios, while also providing interpretability and controllability of learned task representations.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to task representation, moving beyond conventional prompt-based methods. The empirical results are robust, showing significant improvements over strong baselines across various tasks. Additionally, the interpretability aspect is a valuable contribution, providing insights into how task representations can be manipulated for desired outcomes. However, the paper could benefit from a more thorough exploration of the limitations of the proposed method and its applicability to a wider range of tasks. Furthermore, while the experiments are extensive, additional qualitative analysis could enhance the understanding of how CTR impacts performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, making the proposed methodology and findings accessible to the reader. The quality of the experiments is high, with a comprehensive analysis of results and ablation studies that effectively demonstrate the contribution of various components of the CTR approach. The novelty of the work is significant, particularly in its shift towards compositional representations of tasks. Reproducibility is supported by the detailed descriptions of datasets and experimental setups; however, the authors could improve reproducibility by providing code or additional resources to facilitate implementation.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to enhancing cross-task generalization in LLMs through Compositional Task Representations. The empirical results are strong, and the methodology is well-articulated, although further exploration of limitations and more qualitative insights would strengthen the contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper \"Compositional Task Representations for Large Language Models\" by Nan Shao et al. introduces a novel approach to enhancing cross-task generalization in large language models (LLMs) through compositional task representations (CTR). The authors propose a prompt-free methodology that utilizes task embeddings and a structured codebook to represent tasks, demonstrating that this approach significantly outperforms traditional prompt-based techniques, particularly in zero-label learning scenarios. Empirical results show consistent improvements in accuracy metrics across various experimental setups, establishing the efficacy of CTR in both zero-label and few-shot learning contexts.\n\n# Strength And Weaknesses\nThe primary strengths of this paper lie in its innovative approach to task representation, which addresses the limitations of existing prompt-based methods. The empirical results are robust, with clear evidence supporting the advantages of CTR. However, the paper could benefit from additional experiments that cover a wider variety of datasets and tasks, as well as more comprehensive comparisons with state-of-the-art techniques. This would enhance the reliability of the findings and provide a more complete picture of CTR's capabilities.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and presents its concepts with clarity and coherence. The methodology is described in detail, making it reproducible for future research. The novelty of the CTR approach is significant, as it provides a fresh perspective on task representation in LLMs and contributes to the growing body of work on compositional generalization. However, the authors could improve reproducibility by providing more detailed hyperparameter settings and training procedures.\n\n# Summary Of The Review\nOverall, this paper presents a substantial advancement in the field of task representation for LLMs through its innovative CTR approach. The empirical validation is strong, although further experiments and comparisons could enhance the findings. The paper is recommended for acceptance with minor revisions.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel prompt-free methodology for leveraging large language models (LLMs) in cross-task generalization. The methodology employs a discrete latent codebook to represent tasks, thereby facilitating improved performance in both zero-label and few-shot learning scenarios. The authors demonstrate through empirical evaluations that CTR significantly outperforms existing prompt-based methods, providing a robust framework for understanding task representations and enhancing generalization capabilities in LLMs.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to compositional generalization, which shifts the focus from traditional prompt engineering to the use of discrete latent codes for task representation. The architecture is well-defined, and the two-phase training methodology is systematic and clearly articulated. However, one notable weakness is the lack of extensive ablation studies, which could further clarify the impact of each component of the CTR framework. Additionally, while the empirical results are promising, the paper could benefit from a more comprehensive exploration of the limitations and potential scenarios where CTR might not perform as well.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, making it accessible to readers with a background in machine learning and natural language processing. The methodology is detailed, with sufficient mathematical rigor to support the proposed approach. The novelty of the CTR framework is significant, as it provides a fresh perspective on task representation in LLMs. While the empirical evaluations are convincing, the reproducibility of results would be enhanced by providing more details on the experimental setup and hyperparameter tuning.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to enhancing cross-task generalization in LLMs through Compositional Task Representations. The methodology is well-articulated, and the empirical results substantiate its effectiveness over traditional prompt-based methods. However, the paper could improve by addressing potential limitations and providing additional details to facilitate reproducibility.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR) as an alternative to existing prompt-based methods for task representation in language models. The methodology involves the use of discrete latent codes derived from prior works, particularly VQ-VAE, to represent tasks. The findings indicate that CTR outperforms certain baseline methods, although the improvements are modest and primarily based on basic performance metrics, lacking comprehensive evaluations of its efficacy compared to traditional approaches.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its proposal of the CTR framework, which aims to enhance task generalization across various domains. However, the paper exhibits several weaknesses. It heavily relies on established concepts without providing novel insights, raising questions about its originality. The empirical results, while showing some performance gains, do not convincingly demonstrate a significant or transformative advancement over existing methods. Concerns regarding the robustness of the training process and the quality of pseudo-labeled data further undermine the reliability of the findings. Additionally, the interpretability of the learned representations is not adequately supported by rigorous analysis.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear in its presentation, but the novelty of the approach is questionable, as it draws heavily on established ideas rather than presenting truly innovative concepts. The quality of the empirical evaluation is lacking, particularly in terms of comprehensive comparisons and rigorous assessments. Reproducibility may be an issue due to the reliance on pseudo-labeled data and sensitivity to initial conditions, which raises concerns about the method’s stability across different settings.\n\n# Summary Of The Review\nOverall, while the CTR framework presents an interesting direction in task representations, it does not provide sufficient evidence to support its claims of significant advancements over established methodologies. The modest empirical gains and reliance on existing concepts limit its impact on the field.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel approach designed to enhance cross-task generalization in large language models (LLMs). The methodology involves representing tasks as compositions of discrete latent codes, enabling the model to generalize effectively to new tasks without requiring labeled data. The findings demonstrate that CTR significantly outperforms traditional prompt-based methods, particularly in zero-label and few-shot learning scenarios, while also providing enhanced interpretability and controllability.\n\n# Strength And Weaknesses\nThe strengths of this paper include its innovative methodology that addresses the limitations of traditional approaches in task representation and its empirical validation showing superior performance across various learning scenarios. The introduction of human-interpretable codes and the ability to dynamically control task behaviors are additional significant contributions. However, the paper may lack a comprehensive comparison with other emerging methods in the same domain, which could provide a clearer context for the advantages of CTR.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions, methodology, and findings. The quality of the experiments and results is high, effectively demonstrating the superiority of CTR. The novelty of the approach is significant, offering fresh insights into compositional generalization. While the methodology appears reproducible, detailed implementation specifics and datasets used for training and evaluation would enhance the clarity for future researchers seeking to replicate the results.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to enhancing the performance of large language models through Compositional Task Representations. Its significant contributions to cross-task generalization and interpretability mark it as a noteworthy advancement in the field, although further comparisons with existing methods could strengthen the claims made.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper introduces a novel theoretical framework for Compositional Task Representations (CTR) aimed at enhancing the compositional generalization capabilities of large language models (LLMs). It posits that traditional prompt-based approaches can be improved by utilizing a latent task codebook, where each code represents specific attributes or skills relevant to tasks. The authors present a multi-task training methodology that allows LLMs to learn from a diverse set of tasks, thereby enriching the latent codebook. The findings suggest that this approach leads to improved generalization, interpretability, and controllability of task representations.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to task representation, which theoretically enhances the model's ability to generalize across unseen tasks. The introduction of a latent task codebook and its implications for multi-task training present a significant advancement in understanding LLM capabilities. However, the paper does not provide empirical validation for the proposed framework, which limits the practical applicability of the theoretical insights. Additionally, the complexity of the proposed methodology may pose challenges for reproducibility.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and clearly articulates its theoretical framework, making it accessible to readers familiar with LLMs and compositional generalization. The quality of the theoretical exposition is high, providing a robust foundation for future research. However, the lack of empirical validation raises concerns about the reproducibility of the findings. The novelty of the approach is significant, as it reframes task representation through a compositional lens, but the practical implications remain to be explored in subsequent studies.\n\n# Summary Of The Review\nOverall, the paper presents a compelling theoretical framework for Compositional Task Representations that could advance the understanding of generalization in LLMs. While the contributions are theoretically sound and novel, the absence of empirical validation and potential challenges in reproducibility limit the paper's immediate impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR) for large language models (LLMs), aiming to enhance cross-task generalization through multi-task training. The methodology involves a two-phase training process where a codebook of discrete task representations is learned, allowing tasks to be composed from latent codes instead of relying solely on prompt-based approaches. Results demonstrate that CTR significantly outperforms existing methods in zero-label learning scenarios, showcasing the effectiveness of this new representation scheme.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to task representation, which addresses limitations of traditional prompt-based methods. The use of a multi-task training framework and the development of two distinct inference algorithms (Code Ensemble and Bitwise Search) add to its robustness. However, a notable weakness is the limited discussion on the broader implications of the findings, as well as a lack of exploration into the qualitative aspects of the task representations learned. The focus is primarily on quantitative metrics, which may overlook deeper insights into the model's behavior and generalization capabilities.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodology clearly, with detailed descriptions of the architecture, training process, and experimental setup. The results are clearly articulated through various tables, providing a comprehensive overview of the performance metrics. The code availability further enhances reproducibility, reflecting a commitment to transparency in research. In terms of novelty, the proposed CTR framework is a significant advancement over existing approaches, although the empirical exploration could benefit from additional qualitative analysis.\n\n# Summary Of The Review\nOverall, the paper presents a novel and effective approach to task representation in LLMs, demonstrating clear improvements over existing methods in benchmarking tasks. While the methodology and results are well-articulated, further discussion on the implications and qualitative evaluations of the task representations could enhance the paper's contributions.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR) for large language models, aiming to enhance task generalization capabilities in zero-label learning scenarios. The authors propose a methodology that focuses on compositional generalization, asserting that their approach outperforms traditional prompt-based methods. They claim that CTR offers improved interpretability and controllability of task representations while demonstrating the ability to generalize to unseen tasks with minimal adjustments. However, the paper does not sufficiently engage with the existing literature on prompt-based methods and their established effectiveness.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to compositional generalization, which could provide a fresh perspective on task representation in language models. However, it has notable weaknesses, including a lack of engagement with prior work, particularly regarding prompt-based methodologies, which have already established strong baselines in task generalization. The authors' dismissal of previous advancements, such as those made by models like T0 and FLAN, undermines the credibility of their contributions. Additionally, while the method claims superior performance over manual-coded features, the comparison lacks depth and fails to consider the strengths of these established methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, but it suffers from clarity issues related to its claims about the novelty of CTR compared to existing methods. The quality of the methodology is adequate, though the lack of nuanced discussion about related works diminishes its impact. The novelty is present in the proposed compositional approach, but it is somewhat overshadowed by the failure to acknowledge prior research. Reproducibility is not adequately addressed, as the paper does not provide sufficient details on the implementation of CTR or the specifics of the experimental setup.\n\n# Summary Of The Review\nOverall, the paper presents an interesting approach to compositional task representations in large language models, but it significantly underestimates the contributions of prior research on prompt-based methods. While the proposed method has potential, the lack of engagement with existing literature and depth in comparative analysis detracts from its overall significance.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper titled \"COMPOSITIONAL TASK REPRESENTATIONS FOR LARGE LANGUAGE MODELS\" introduces a novel prompt-free approach called Compositional Task Representations (CTR) aimed at enhancing the performance of large language models (LLMs). The authors propose a latent task codebook to represent tasks and employ a unique loss function to optimize learning. The findings demonstrate that CTR significantly improves model performance across various benchmarks, although some results lack clarity in their presentation.\n\n# Strength And Weaknesses\nThe paper makes several notable contributions, particularly in advancing the methodology for task representation in LLMs. The introduction of the latent task codebook is innovative and provides a fresh perspective on how tasks can be represented and learned. However, there are weaknesses in clarity and presentation, such as the inconsistent formatting of equations, lack of clear definitions for key terms (e.g., \"zero-label learning\"), and insufficient explanations for metrics used in the results. These issues could hinder the reader's understanding and the reproducibility of the methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a novel approach, its clarity is undermined by various formatting inconsistencies and a lack of clear explanations for certain concepts. The quality of writing suffers from repetitive phrasing and occasional typographical errors. Furthermore, inconsistencies in the references and a need for a more structured abstract detract from the overall professionalism of the paper. As a result, reproducibility may be challenging for readers due to the absence of detailed methodological explanations and clear definitions of terms.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in task representation for large language models through the CTR approach. However, clarity and presentation issues need to be addressed to enhance understanding and reproducibility. The contributions are valuable, yet the execution could be improved for a more professional and coherent presentation.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates compositional generalization, presenting a novel methodology called Compositional Task Representations (CTR) aimed at improving cross-task generalization challenges. The authors demonstrate that CTR can enhance the performance of large language models (LLMs) by enabling better interpretability and controllability of task representations. However, the study is limited to a specific set of tasks, and the authors do not comprehensively address the scalability or applicability of their approach in broader contexts.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to compositional generalization, which holds promise for enhancing the interpretability and controllability of task representations in LLMs. However, several weaknesses are evident, including a lack of exploration into other generalization techniques, such as meta-learning or hierarchical task representations. The experiments conducted are restricted to a narrow range of tasks, limiting the evaluation of CTR's robustness. Additionally, the paper does not sufficiently consider scalability issues, the implications of discrete latent codes for explainability, or the adaptability of CTR with smaller models.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its contributions clearly, though there are areas where clarity could be enhanced, particularly in discussing the practical applications of the learned task codes. The novelty of the CTR method is notable, although further exploration of its implications and limitations is necessary for a comprehensive understanding. Reproducibility could be improved if the authors provided more detailed methodologies for their experiments and additional context for the applicability of their findings.\n\n# Summary Of The Review\nOverall, the paper presents a novel approach to compositional generalization through Compositional Task Representations, but it falls short in addressing key limitations such as scalability and applicability across diverse tasks. Future work should expand on these areas to fully realize the potential of CTR in various real-world applications.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents Compositional Task Representations (CTR), a novel approach aimed at improving the generalization capabilities of large language models (LLMs) across various tasks without relying heavily on traditional prompt-based methods. The authors conduct experiments on a large multi-task dataset to evaluate CTR's performance against established baselines, such as T0 and Self-Training. Empirical results indicate that CTR achieves significant accuracy improvements in zero-label learning scenarios; however, the absence of explicit statistical significance metrics raises concerns regarding the validity of these findings.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its introduction of CTR as a promising alternative to existing methods for enhancing LLM generalization. The experimental setup is thorough, utilizing a diverse dataset and multiple baselines to assess performance. However, the lack of statistical significance tests, such as confidence intervals or p-values, limits the robustness of the claims made in the results. This omission makes it difficult to ascertain whether the observed improvements are statistically meaningful or merely due to chance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its methods and findings clearly, although the lack of statistical validation diminishes the overall quality of the conclusions drawn. The novelty of the CTR approach is significant, offering fresh insights into task representation for LLMs, but its empirical validation is undermined by the absence of rigorous statistical analysis. As a result, reproducibility of the findings may be challenging, as the lack of standard metrics and tests prevents other researchers from fully assessing the reliability of the results.\n\n# Summary Of The Review\nThe paper introduces a novel approach to enhancing the generalization capabilities of LLMs through Compositional Task Representations, showing promising empirical results. However, the absence of robust statistical validation raises concerns about the claims made, limiting the credibility of the findings. Future work should incorporate statistical analyses to strengthen the presented conclusions.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents a novel approach using Compositional Task Representations (CTR) to enhance the generalization capabilities of models across multiple tasks. The methodology involves training on a large multi-task dataset, leveraging learned codes that encapsulate task-specific information. The findings indicate that CTR improves performance on various tasks; however, the paper lacks a comprehensive investigation into the limitations and potential biases of the learned representations, particularly in scenarios with underrepresented training tasks.\n\n# Strength And Weaknesses\nWhile the paper introduces an interesting method for multi-task learning, it has notable weaknesses. It does not thoroughly address the limitations of CTR in generalizing to novel tasks or domains significantly different from the training set. Additionally, the discussion on biases arising from training tasks is limited, raising concerns about the robustness of learned representations. The reliance on large, diverse datasets for effective training is a significant constraint, and the paper fails to explore the implications of using smaller datasets. Hyperparameter choices, such as codebook size and CTR length, are crucial yet not systematically investigated, which diminishes the potential for broader applicability. Moreover, the paper lacks a comprehensive analysis of the interpretability and controllability of the learned codes, as well as the efficiency and scalability of the proposed inference methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is generally acceptable, but the lack of in-depth discussions on limitations and future directions leaves some questions unanswered. The quality of the empirical results is commendable, showing improvements over existing methods; however, the absence of a discussion regarding trade-offs in computational efficiency and practical applicability is a notable gap. In terms of novelty, while the concept of CTR is innovative, the paper does not sufficiently explore its implications or potential integrations with existing systems. The reproducibility of the results could be enhanced by providing more detailed methodologies and discussions on hyperparameter selection.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to addressing multi-task learning challenges through CTR, with empirical results indicating improvements. However, it falls short in addressing critical limitations, biases, and practical considerations that could impact its real-world applicability and scalability.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"Compositional Task Representations for Large Language Models\" proposes a framework for enhancing the compositional generalization capabilities of large language models (LLMs) through what the authors term Compositional Task Representations (CTR). The methodology centers around multi-task training to create a discrete latent task codebook, aiming to improve performance in zero-label and few-shot learning scenarios. Experimental results suggest that CTR outperforms established baselines, with claims of enhanced interpretability and controllability of the models.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its empirical results, which demonstrate improvements over traditional methods in specific learning contexts. However, the conceptual novelty appears limited; the notion of compositionality and task representation has been previously explored in different forms. Additionally, the methodology presents as somewhat basic, lacking a detailed exploration of the implications of the proposed approach. The results, while statistically significant, do not present groundbreaking advancements in the field.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, but it often lacks depth in its exposition of concepts that would be familiar to experienced researchers. The novelty of the proposed method does not feel substantial, as it rehashes existing ideas under new terminology. Reproducibility is a concern, as the paper does not provide sufficient detail on implementation specifics or dataset descriptions, which are crucial for replicating the experiments.\n\n# Summary Of The Review\nOverall, while the paper presents some interesting empirical results regarding the performance of CTR, it fails to deliver significant technical or conceptual innovations in the field of LLMs. The work may be of interest to newcomers, but it does not advance the discussion in a meaningful way for seasoned researchers.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a novel method called Compositional Task Representation (CTR), which leverages discrete latent codes to enhance task representation in multi-task learning settings. The methodology entails a two-phase training approach aimed at improving compositional generalization, enabling models to learn effectively from fewer examples. Empirical results demonstrate that CTR outperforms traditional prompt-based methods, particularly in generalizing to unseen classes, while also offering a degree of interpretability for the learned codes.\n\n# Strength And Weaknesses\nThe strengths of the paper include its innovative approach to task representation through discrete latent codes, which aligns with ongoing research in representation learning. The emphasis on compositional generalization is particularly timely and relevant, given the growing interest in few-shot learning. However, the paper lacks a detailed discussion on computational efficiency and does not provide extensive qualitative analyses or case studies to illustrate the practical implications of the learned representations. Additionally, while the results are promising, a broader evaluation across various benchmarks could strengthen the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its contributions clearly. The methodology is described in a way that is accessible, allowing for reproducibility. However, the novelty of the approach could have been better contextualized within existing literature. While the results are compelling, a more thorough discussion on the implications of computational costs and resource requirements would enhance the quality of the work.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to the field of multi-task learning through the CTR methodology, demonstrating strong empirical results. While it offers innovative insights into task representation and generalization, further exploration of computational efficiency and qualitative analyses would enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces Compositional Task Representations (CTR), a novel method that demonstrates superior performance in both zero-label and few-shot learning scenarios when benchmarked against existing methods. The authors present a comprehensive evaluation of CTR, reporting an average accuracy of 58.88 in the zero-label setting and 60.66 in the few-shot setting, significantly outperforming various baselines, including T0 and different tuning methods. The study also highlights CTR's robustness to the removal of manual prompts and its effectiveness across diverse tasks, particularly in Natural Language Inference and Sentence Completion, underscoring its potential for improved generalization in large language models.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its clear demonstration of CTR's advantages over traditional methods, particularly in terms of accuracy and generalization capabilities across various tasks. The detailed experimental results, including ablation studies, support the claims made regarding the effectiveness of learned compositional task representations. However, the paper could benefit from a more thorough exploration of the underlying mechanisms that allow CTR to achieve these results. Additionally, while the benchmarks are impressive, further comparative analysis with state-of-the-art methods in more complex settings would enhance the discussion on relative performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its methodology, findings, and implications. The quality of the experiments appears robust, with thorough evaluations and ablation studies that reinforce the claims made. In terms of novelty, CTR presents a fresh approach to task representation in language models, which is a significant contribution to the field. However, the reproducibility of the results could be improved by providing additional details on experimental setups and hyperparameter choices.\n\n# Summary Of The Review\nOverall, the paper presents a compelling contribution to the field of language modeling through the introduction of CTR, which demonstrates strong performance in zero-label and few-shot settings. While the methodology and results are promising, further exploration of the underlying mechanisms and more comprehensive comparisons with state-of-the-art methods would strengthen the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"COMPOSITIONAL TASK REPRESENTATIONS FOR LARGE LANGUAGE MODELS\" proposes a novel approach to improving the generalization capabilities of large language models (LLMs) through compositional task representations. The authors introduce a prompt-free methodology that leverages latent codes to enhance compositional generalization, allowing LLMs to perform better on a range of tasks without the need for extensive task-specific prompts. The findings demonstrate significant improvements in performance across various benchmarks, suggesting that this approach effectively addresses some limitations in current LLM architectures.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative approach to enhancing LLM capabilities through compositional task representations, which is a timely and relevant contribution to the field. The empirical results indicate marked improvements in performance, which adds to the validity of the proposed methodology. However, the paper suffers from issues related to clarity and presentation, including overly complex sentence structures and jargon that may hinder accessibility for a broader audience. Additionally, the results section could be better organized to facilitate reader comprehension.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents novel ideas, its clarity is compromised by complex sentence structures and inconsistent terminology. The lack of clear definitions for technical terms and acronyms may alienate readers unfamiliar with the subject matter. The overall quality of writing could benefit from a thorough proofreading process to address typographical errors and enhance readability. The reproducibility of the results is not explicitly addressed, as there is limited discussion on the experimental setup or data used, making it difficult for other researchers to replicate the findings.\n\n# Summary Of The Review\nThe paper presents a valuable contribution to the field of large language models through its innovative prompt-free approach to compositional task representations. However, significant improvements in clarity, organization, and accessibility are needed to enhance the overall impact of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.5791087936420483,
    -1.660619205601131,
    -1.7793686928037007,
    -1.7369297335400324,
    -1.961340581702107,
    -1.6003252569396789,
    -1.6692605820656121,
    -1.7744209126047004,
    -1.7634623001327696,
    -1.7691312785066753,
    -1.5336103444268154,
    -1.432185210378881,
    -1.6224503233674932,
    -1.5721909474688138,
    -1.6985720051820068,
    -1.4850576032187923,
    -1.879180296054036,
    -1.664653958650912,
    -1.5131595837674774,
    -1.869971663285499,
    -1.7876028920796414,
    -1.8000050927759723,
    -1.6808431198536888,
    -1.6782549204489148,
    -1.860759059280753,
    -1.9531506837483383,
    -1.7326679576852897,
    -1.6982452759036615,
    -1.626483850371727
  ],
  "logp_cond": [
    [
      0.0,
      -2.435763195038205,
      -2.4328529706392663,
      -2.4285972646444507,
      -2.427674101105138,
      -2.433810589236536,
      -2.4458958031930833,
      -2.444282192693569,
      -2.4340845839475205,
      -2.44508151694749,
      -2.4393281621030742,
      -2.479397474245415,
      -2.4249742682454056,
      -2.422250358164723,
      -2.4451393367413696,
      -2.4427171986388143,
      -2.452749172583763,
      -2.4261809873727405,
      -2.448422751133644,
      -2.4151298215959325,
      -2.4441503530681397,
      -2.458288764527521,
      -2.4347411580774163,
      -2.4456909883659304,
      -2.4084841819069487,
      -2.432990093140264,
      -2.4414982012896718,
      -2.435369028542733,
      -2.470204449698453
    ],
    [
      -1.239436312666145,
      0.0,
      -1.0708600991420687,
      -1.1569271161110863,
      -1.0639153353609851,
      -1.1620441045525132,
      -1.2482026404216713,
      -1.1346812780627975,
      -1.1411026684396794,
      -1.1609931446129937,
      -1.1075500364338238,
      -1.3420718567835548,
      -1.0639559500178513,
      -1.0980166779788372,
      -1.1513688596007856,
      -1.139974376647376,
      -1.2777818342491645,
      -1.1178397836554181,
      -1.199953660715327,
      -1.1752396370919338,
      -1.1852803898669753,
      -1.2137695517953317,
      -1.206917577030761,
      -1.2180643289522572,
      -1.2483112916842443,
      -1.1155091918004518,
      -1.2005394691438158,
      -1.1926741782106123,
      -1.2124073695279072
    ],
    [
      -1.3699352541613987,
      -1.219028225799717,
      0.0,
      -1.2157730111534621,
      -1.1833804607326286,
      -1.2689462029115037,
      -1.3870136310608638,
      -1.3173203963091638,
      -1.241879334210426,
      -1.294507774112854,
      -1.241084579459138,
      -1.4635971422184053,
      -1.18574160689945,
      -1.2324317369054676,
      -1.2504181725494534,
      -1.2552347713885146,
      -1.378160853254054,
      -1.263411850374427,
      -1.304547961458547,
      -1.2780018827368973,
      -1.3224657616549658,
      -1.366398486820462,
      -1.3820870011481639,
      -1.361762734414922,
      -1.3523965865339933,
      -1.2834976830837046,
      -1.3348172720632567,
      -1.3471918478939247,
      -1.35357680966918
    ],
    [
      -1.4075614392236335,
      -1.3024146930173082,
      -1.2862908529507209,
      0.0,
      -1.2665645692169376,
      -1.2684740960779768,
      -1.3603308897633157,
      -1.3198160896184243,
      -1.2567519671223708,
      -1.2917511313776888,
      -1.3207109168409923,
      -1.4432381583352014,
      -1.250225450692969,
      -1.3026477387435609,
      -1.3290291906356644,
      -1.2934830556550854,
      -1.4336205891602654,
      -1.2608415083055526,
      -1.3616449530761545,
      -1.3195602716344506,
      -1.3715558742618057,
      -1.401888754123093,
      -1.3559708839763522,
      -1.3831540521060024,
      -1.4251088783576646,
      -1.361960862637467,
      -1.3613117655394782,
      -1.3218452883159206,
      -1.3692667248409849
    ],
    [
      -1.597375995108513,
      -1.428179859642898,
      -1.4196393028283703,
      -1.456123513677039,
      0.0,
      -1.4286050118381106,
      -1.579060282120249,
      -1.4450183834606076,
      -1.4700189429094683,
      -1.4793337401996558,
      -1.465037667856954,
      -1.655701721292441,
      -1.3967334460734724,
      -1.444266997808054,
      -1.4920497959731789,
      -1.4747582773055314,
      -1.6170465529287754,
      -1.4463751105230855,
      -1.5168595720462246,
      -1.4871533018401686,
      -1.4883825248798301,
      -1.5384856168179397,
      -1.499856430517,
      -1.5301482269527193,
      -1.5939801273254182,
      -1.4566206320516768,
      -1.573137250517022,
      -1.5372218238360758,
      -1.5655490441225608
    ],
    [
      -1.2345714952417863,
      -1.1505249773575092,
      -1.1032731755031384,
      -1.125612007118173,
      -1.1042482362208133,
      0.0,
      -1.2173055390845815,
      -1.1061259223795898,
      -1.1636613339913495,
      -1.1565710794162885,
      -1.0842161051907897,
      -1.2661583558654839,
      -1.0779775456364178,
      -1.1087158398840966,
      -1.152502300546585,
      -1.1620718801957088,
      -1.246052954724606,
      -1.1520559941188,
      -1.142596817483461,
      -1.1359789262887974,
      -1.1725031654511093,
      -1.1837117756780755,
      -1.226857913461438,
      -1.1574276872548224,
      -1.2716079542672265,
      -1.1432330576027643,
      -1.228157903594806,
      -1.216597042967565,
      -1.2068502092218782
    ],
    [
      -1.4172193064129448,
      -1.3042883996862003,
      -1.2919212880508524,
      -1.2736617103141092,
      -1.3115871924420044,
      -1.2888500293626772,
      0.0,
      -1.3003168912439271,
      -1.341360737678679,
      -1.3108688215182727,
      -1.3398514485795836,
      -1.3581954793215654,
      -1.2888684566132202,
      -1.2840198315010174,
      -1.3048117733262103,
      -1.3375723012062843,
      -1.375714865185612,
      -1.2777090005500669,
      -1.3279005633734817,
      -1.2934013062832528,
      -1.3457673733644955,
      -1.3536731643508515,
      -1.3814670285777224,
      -1.3214157699121036,
      -1.3497621383666254,
      -1.281047217849351,
      -1.3430170801739718,
      -1.3316743400346476,
      -1.3407113649849067
    ],
    [
      -1.3557373627719929,
      -1.2315408959454586,
      -1.1871760836225433,
      -1.2083190018699952,
      -1.1410569862957938,
      -1.1623628032049487,
      -1.3223750969773826,
      0.0,
      -1.2170161822800696,
      -1.2598754017040872,
      -1.1384390863970753,
      -1.438861902911957,
      -1.1419572582665518,
      -1.1695640958895581,
      -1.232299459047882,
      -1.2261095160448967,
      -1.357062300629111,
      -1.2055843037139984,
      -1.2607727332280227,
      -1.2125550261366163,
      -1.2673269064262065,
      -1.282983614970405,
      -1.3058607411086212,
      -1.2713888520574186,
      -1.356129543386161,
      -1.2152499668066201,
      -1.3167829992693636,
      -1.2858811900578935,
      -1.3197373583524579
    ],
    [
      -1.3432177053281897,
      -1.1375986279015833,
      -1.1435788936960725,
      -1.1213284644405321,
      -1.1263078307278724,
      -1.243045649114984,
      -1.288470900694761,
      -1.2408820383262378,
      0.0,
      -1.2259522735430446,
      -1.1729927641243225,
      -1.4289565563597555,
      -1.108443131822935,
      -1.2100356912010952,
      -1.2303092364728698,
      -1.2411714506894718,
      -1.365717452418351,
      -1.186699722927838,
      -1.2820561141303715,
      -1.250113752789297,
      -1.261967507630131,
      -1.2883821146817358,
      -1.2931220264083607,
      -1.2755957464581622,
      -1.3391331747919202,
      -1.1914850458307058,
      -1.2855741071333575,
      -1.2619556550173388,
      -1.3167930341439933
    ],
    [
      -1.4860867516028402,
      -1.3450806832199187,
      -1.3699718271344934,
      -1.3574672167416981,
      -1.3524769024270333,
      -1.382452971631285,
      -1.435132236105358,
      -1.4158148334577871,
      -1.3961153907814576,
      0.0,
      -1.3972520585243517,
      -1.510363663197471,
      -1.3662077860299293,
      -1.4083214090850906,
      -1.4241361796089118,
      -1.3750290452612481,
      -1.4224488800790909,
      -1.3777252000903228,
      -1.4102079965540801,
      -1.3657974071056824,
      -1.3962669237314589,
      -1.402155576963265,
      -1.4006536741301476,
      -1.42262825236335,
      -1.4349345307040933,
      -1.4045320358018447,
      -1.3912744918151958,
      -1.4062841754062236,
      -1.437045034452812
    ],
    [
      -1.143130120077413,
      -0.9405169588956805,
      -0.9483751289504666,
      -1.0093748270088947,
      -0.9727228514673331,
      -1.007102077314303,
      -1.0973373666055815,
      -0.9518010142476949,
      -1.019782641823817,
      -1.0685678199226023,
      0.0,
      -1.1997975034296906,
      -0.9330931557509317,
      -0.9459886798271406,
      -0.9934756814079311,
      -0.9927412170574095,
      -1.1334916529355992,
      -0.9995353963276469,
      -1.074605458848055,
      -0.9849563009639489,
      -1.0483566789296992,
      -1.075187250824816,
      -1.1159135242151,
      -1.0883691073680042,
      -1.1268234758485371,
      -1.0155938488774052,
      -1.1062071414901826,
      -1.0682240970977754,
      -1.1141014103239064
    ],
    [
      -1.220357343300776,
      -1.2119477725279304,
      -1.2322049642350374,
      -1.2044812757591243,
      -1.2042429213680943,
      -1.2152120422561605,
      -1.2117083846750187,
      -1.1930191674190591,
      -1.243915157478824,
      -1.1897671919868937,
      -1.2543939285127306,
      0.0,
      -1.196324632439812,
      -1.220284919038997,
      -1.201228390617945,
      -1.2274211987803059,
      -1.2395297113830839,
      -1.1968556227533036,
      -1.2148035004504014,
      -1.203479238078978,
      -1.2272301081757744,
      -1.1881704735924787,
      -1.2171344520301945,
      -1.2399063275381605,
      -1.1976597287602473,
      -1.2027141052459533,
      -1.2068623199689708,
      -1.2073836843690346,
      -1.1979617544044494
    ],
    [
      -1.3254749995021327,
      -1.0762286785279456,
      -1.110516860626719,
      -1.1211885872932865,
      -1.0580832061813628,
      -1.122267644372214,
      -1.2383841316402433,
      -1.1224039352059476,
      -1.1100715844110458,
      -1.1828787927462854,
      -1.096851982430474,
      -1.3296781081490445,
      0.0,
      -1.0896083233009322,
      -1.1311033759021598,
      -1.155547020227996,
      -1.3025099042980803,
      -1.1097318907346179,
      -1.2041838861834633,
      -1.1512758749761618,
      -1.1432231003642717,
      -1.2459827318321677,
      -1.2009705813424874,
      -1.2050361929261766,
      -1.2790304565593364,
      -1.1480732458549652,
      -1.2341010268607853,
      -1.2115745192390888,
      -1.231855653557448
    ],
    [
      -1.2357664539239779,
      -1.1316533304041312,
      -1.0953793960124625,
      -1.1115094206461265,
      -1.0533278483505921,
      -1.0978353208131668,
      -1.191002375503994,
      -1.0709683218601964,
      -1.1141386836846308,
      -1.2002526385085992,
      -1.0658801289373596,
      -1.2798278861710906,
      -1.0617004419895506,
      0.0,
      -1.0933583508677374,
      -1.1111818873451857,
      -1.2309061832341361,
      -1.0937836750247718,
      -1.1901307484676253,
      -1.0925947953396666,
      -1.1444425763393686,
      -1.161117908286988,
      -1.2083654354575797,
      -1.1458984665592866,
      -1.2078965575559217,
      -1.1324878449026299,
      -1.2114461923834434,
      -1.1557531138320951,
      -1.1976450864967443
    ],
    [
      -1.3323461453022911,
      -1.187578074150984,
      -1.1166767722364772,
      -1.1518532662701155,
      -1.15685333302419,
      -1.1528451143230714,
      -1.285094600275348,
      -1.1851092828128598,
      -1.1997624503074844,
      -1.2440164031916416,
      -1.1494215473281424,
      -1.404817210757871,
      -1.110208364090845,
      -1.1320332758663085,
      0.0,
      -1.0998167171960525,
      -1.2455377296878019,
      -1.1507001076095102,
      -1.230758367276621,
      -1.1704042736378684,
      -1.1825910478622979,
      -1.2305222039031738,
      -1.2752339459041762,
      -1.1753672127536243,
      -1.31816822637287,
      -1.2198268629689284,
      -1.2462415166347862,
      -1.2636110357808883,
      -1.2656769940499528
    ],
    [
      -1.1905859948256003,
      -1.0477944125315881,
      -1.024262663754151,
      -1.0147954238058445,
      -1.036115666739389,
      -1.036395148530993,
      -1.1321793505880402,
      -1.0541657552723451,
      -1.0530582174116199,
      -1.013449983987811,
      -1.0461891802377437,
      -1.2100957535639385,
      -1.0427060551393343,
      -1.079772310807822,
      -1.012730868804377,
      0.0,
      -1.066943244474397,
      -1.0948191020583316,
      -1.101551241153945,
      -1.0366739465367727,
      -1.0163422895886112,
      -1.0795022237232792,
      -1.1221774067879595,
      -1.0729693733076449,
      -1.1404425868474748,
      -1.0495424993883042,
      -1.1079002427277462,
      -1.1134669221182385,
      -1.101384809417902
    ],
    [
      -1.50918188078553,
      -1.4768105154836502,
      -1.4696476759252615,
      -1.474497915797026,
      -1.486674578414787,
      -1.4704574048261265,
      -1.522444686069294,
      -1.4779833102046496,
      -1.4852760943759853,
      -1.5060206211856648,
      -1.4793929950294633,
      -1.588862396563217,
      -1.4781081564086396,
      -1.4750008642438976,
      -1.4886271898450296,
      -1.457455255674444,
      0.0,
      -1.4740612835195377,
      -1.468155734737088,
      -1.5062728880895966,
      -1.444591209864862,
      -1.5100310103782817,
      -1.4984320131062419,
      -1.5052885252092085,
      -1.4846123619323723,
      -1.4879071181699406,
      -1.4803348933903027,
      -1.52574520006394,
      -1.512262792924271
    ],
    [
      -1.31599021216118,
      -1.1335889474964564,
      -1.1004676973981564,
      -1.1540651241445758,
      -1.0703160325296825,
      -1.1296120114321908,
      -1.2747464400545507,
      -1.1492336494409259,
      -1.1650844662434072,
      -1.195645209430949,
      -1.1409717383158677,
      -1.3404030799458762,
      -1.0848951040926549,
      -1.1364283500080103,
      -1.1458461368739108,
      -1.1740533195278606,
      -1.3006204323784092,
      0.0,
      -1.2091234057850138,
      -1.1886219098229793,
      -1.1928647690789131,
      -1.263976077512778,
      -1.2097498181538384,
      -1.2396520813011052,
      -1.2762446847662254,
      -1.1768682578909093,
      -1.2200271195572778,
      -1.2118463535002313,
      -1.257816627996237
    ],
    [
      -1.156874989557704,
      -1.0404148422064856,
      -1.0404508319407486,
      -1.0670999348630406,
      -1.053413391925498,
      -1.067297720050496,
      -1.162509492543975,
      -1.0742064635890267,
      -1.0854482179000227,
      -1.0867063078335517,
      -1.0723098237589763,
      -1.1911115218101336,
      -0.9925152015692984,
      -1.0469046032627531,
      -1.1346738588374097,
      -1.1255754215477507,
      -1.1642030285332936,
      -1.090714477283273,
      0.0,
      -1.0699930172341359,
      -1.1270310183467036,
      -1.110851924484509,
      -1.1130049125211114,
      -1.1648838357741622,
      -1.1469156325820258,
      -1.0713413231883346,
      -1.1170612267782885,
      -1.1392589135961115,
      -1.1153644498774908
    ],
    [
      -1.4150703365375485,
      -1.3863458684173264,
      -1.3883740437415308,
      -1.370060988912499,
      -1.3297748935460567,
      -1.3897652470939257,
      -1.4767497273700205,
      -1.388761251689753,
      -1.4084659709170995,
      -1.4334896747023858,
      -1.3657214780268871,
      -1.5647368136321753,
      -1.3112088690555488,
      -1.3627434197684962,
      -1.3904701950565108,
      -1.389208072600145,
      -1.4941119833902947,
      -1.405459027819118,
      -1.4508437567593149,
      0.0,
      -1.4560408440139896,
      -1.4098755904256146,
      -1.457313557076286,
      -1.4285271278838252,
      -1.4835621210476948,
      -1.399295615080537,
      -1.4331597232628448,
      -1.422563776856779,
      -1.4597175978038943
    ],
    [
      -1.509034810511971,
      -1.4017617295046,
      -1.3913518063431058,
      -1.3985060098087947,
      -1.3754614846769857,
      -1.4042210748793313,
      -1.4581622494690891,
      -1.4259244313921178,
      -1.4088535811082046,
      -1.4482691623038961,
      -1.3920839664080964,
      -1.5153381655921156,
      -1.3738343856165391,
      -1.4045078133589979,
      -1.3757996746578391,
      -1.362809674791958,
      -1.4499151587024368,
      -1.4198028494110304,
      -1.465487796379692,
      -1.3767560939101846,
      0.0,
      -1.4449694452939243,
      -1.4423030783423942,
      -1.3881041741867315,
      -1.4949015480671022,
      -1.463729787697035,
      -1.4831332853879222,
      -1.4141673984513508,
      -1.457032081098743
    ],
    [
      -1.4386432302079666,
      -1.3511313858018814,
      -1.3244366391550186,
      -1.3650787039021641,
      -1.3383556577732854,
      -1.3268330663379353,
      -1.420594075597291,
      -1.3741404149741756,
      -1.3354264446992528,
      -1.394682826618082,
      -1.3052353589282202,
      -1.4882241172539037,
      -1.323411390541945,
      -1.3594258301724833,
      -1.3236137327129969,
      -1.3262409673340367,
      -1.4118210696535458,
      -1.365567710107069,
      -1.358976796881133,
      -1.3380995157796498,
      -1.4137011462573006,
      0.0,
      -1.406521656181991,
      -1.3401775431124947,
      -1.4369336504247514,
      -1.3466705108623291,
      -1.400995247891938,
      -1.3871393345408063,
      -1.3328229809050227
    ],
    [
      -1.3519158014841455,
      -1.2830817328865733,
      -1.3110914679140515,
      -1.300495699360786,
      -1.2271068647365118,
      -1.2824911799854903,
      -1.3485835098147798,
      -1.3173403587351997,
      -1.3157141728099422,
      -1.2888427144093697,
      -1.2614183229621965,
      -1.4188974943033987,
      -1.2496980305597991,
      -1.2920252070902298,
      -1.3427264470415043,
      -1.3101206111873833,
      -1.3400969896492463,
      -1.3053556096689545,
      -1.3138327039077131,
      -1.31062699858114,
      -1.3107368781876598,
      -1.3477885255660988,
      0.0,
      -1.3466934716501102,
      -1.3128335421611759,
      -1.2904245123630063,
      -1.300433816791219,
      -1.3532931266338597,
      -1.3569725092853129
    ],
    [
      -1.3137065314257654,
      -1.312032524520266,
      -1.287876211966993,
      -1.2958068818255366,
      -1.2811021024926272,
      -1.259803601314384,
      -1.3829754804078507,
      -1.2591595475699593,
      -1.2561840933191846,
      -1.31566914220965,
      -1.2971798619327375,
      -1.4115269131321573,
      -1.23613313057178,
      -1.263899063774412,
      -1.2587750866716687,
      -1.2678633320777621,
      -1.304013613121856,
      -1.3173297203939653,
      -1.278520299926564,
      -1.2705960966866832,
      -1.2369045774551262,
      -1.3186393611927458,
      -1.388058961096999,
      0.0,
      -1.3431679219778032,
      -1.3158432745413418,
      -1.3399669835023962,
      -1.2895859444945388,
      -1.3426637324317234
    ],
    [
      -1.4963348215633863,
      -1.524853944804127,
      -1.5060342511294176,
      -1.5538539465483612,
      -1.4915305521990805,
      -1.549898862697864,
      -1.573227319891168,
      -1.5278471064710213,
      -1.5373104634739778,
      -1.56288662947586,
      -1.5515716520850096,
      -1.5832527027709469,
      -1.538266429890096,
      -1.529291962583122,
      -1.580292487299021,
      -1.582504736792509,
      -1.511339334251815,
      -1.5363355003863897,
      -1.5570193480001004,
      -1.5292435576043888,
      -1.5497796988944605,
      -1.5636056896051596,
      -1.5438235922926564,
      -1.535082152732188,
      0.0,
      -1.517623975197854,
      -1.518972968862996,
      -1.5466938333561273,
      -1.5635953053770246
    ],
    [
      -1.556012087389525,
      -1.4117718455465038,
      -1.4057141157581716,
      -1.4209813341737354,
      -1.3798856591534059,
      -1.4283550525104936,
      -1.5183396589165195,
      -1.409369611415333,
      -1.446447250720234,
      -1.5149018458930688,
      -1.4077540560568154,
      -1.629778366819703,
      -1.3618971057679459,
      -1.4055845929814543,
      -1.475811931968405,
      -1.4542929256030863,
      -1.5719323453862055,
      -1.4400029189010848,
      -1.4825187019628256,
      -1.4465566217007058,
      -1.4463943960978105,
      -1.4792945658868204,
      -1.4697752329589466,
      -1.5005634449954233,
      -1.5120150000861683,
      0.0,
      -1.51645792936399,
      -1.483737873714832,
      -1.539791781683522
    ],
    [
      -1.3492006059388846,
      -1.2766434587745645,
      -1.2987822048332114,
      -1.324102817330379,
      -1.2977558925919284,
      -1.2969281748439734,
      -1.3394589502381022,
      -1.3212903199714048,
      -1.3251404422579516,
      -1.2770265357677466,
      -1.3123467275452427,
      -1.3939123979200971,
      -1.2823783706281486,
      -1.2902587126509564,
      -1.351412688962802,
      -1.3098161606241008,
      -1.3171227374834147,
      -1.2932990675412996,
      -1.301534395535964,
      -1.286611504907435,
      -1.3281353196011767,
      -1.3176735069774477,
      -1.3093614064099677,
      -1.3406894011388388,
      -1.322517134415999,
      -1.3060187204644,
      0.0,
      -1.3472971042589499,
      -1.3090263328557512
    ],
    [
      -1.3455999721457357,
      -1.3033286729193392,
      -1.2676770012749872,
      -1.2892301105207773,
      -1.2727822760355485,
      -1.3263585348014861,
      -1.3482012590405674,
      -1.3011251152145724,
      -1.2862698038106295,
      -1.2898585302260606,
      -1.2910905459860982,
      -1.431978715615372,
      -1.3025518202157709,
      -1.3010651926158234,
      -1.3341333274175244,
      -1.3185647408794583,
      -1.3702637069512793,
      -1.3029634438797921,
      -1.3326587263398124,
      -1.2822630991093282,
      -1.322090790906778,
      -1.3399400093727198,
      -1.3223702090840446,
      -1.2891455895361625,
      -1.3127887608424877,
      -1.3117774997749283,
      -1.3392191867452508,
      0.0,
      -1.3463741780594536
    ],
    [
      -1.2710536223366309,
      -1.219136570410463,
      -1.2125233799731305,
      -1.2033826705750612,
      -1.230308209515964,
      -1.246750220088509,
      -1.2508926586183506,
      -1.2646305817309045,
      -1.2369168779070785,
      -1.220071907105653,
      -1.2304202888446738,
      -1.3031794757871744,
      -1.2011078015791057,
      -1.2501883624069146,
      -1.1717948729280863,
      -1.2048226656728631,
      -1.274250615232966,
      -1.2688626788018198,
      -1.2304170275263242,
      -1.2332925377288466,
      -1.2547305236424244,
      -1.1206414311456894,
      -1.2546937892251167,
      -1.2317958631114378,
      -1.2398586898985466,
      -1.1961189594002608,
      -1.2149043802638222,
      -1.2405678895747279,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.14334559860384344,
      0.14625582300278195,
      0.15051152899759757,
      0.1514346925369101,
      0.14529820440551244,
      0.13321299044896495,
      0.1348266009484793,
      0.14502420969452778,
      0.13402727669455805,
      0.13978063153897402,
      0.09971131939663325,
      0.15413452539664263,
      0.15685843547732548,
      0.13396945690067863,
      0.13639159500323395,
      0.12635962105828513,
      0.1529278062693078,
      0.1306860425084042,
      0.16397897204611578,
      0.1349584405739086,
      0.12082002911452738,
      0.14436763556463195,
      0.1334178052761179,
      0.17062461173509957,
      0.1461187005017841,
      0.1376105923523765,
      0.14373976509931508,
      0.10890434394359527
    ],
    [
      0.4211828929349861,
      0.0,
      0.5897591064590624,
      0.5036920894900447,
      0.5967038702401459,
      0.4985751010486179,
      0.4124165651794598,
      0.5259379275383336,
      0.5195165371614516,
      0.49962606098813733,
      0.5530691691673073,
      0.3185473488175763,
      0.5966632555832798,
      0.5626025276222939,
      0.5092503460003455,
      0.5206448289537551,
      0.3828373713519666,
      0.5427794219457129,
      0.46066554488580413,
      0.4853795685091973,
      0.4753388157341558,
      0.44684965380579933,
      0.4537016285703701,
      0.44255487664887383,
      0.4123079139168868,
      0.5451100138006792,
      0.46007973645731526,
      0.4679450273905188,
      0.4482118360732239
    ],
    [
      0.409433438642302,
      0.5603404670039838,
      0.0,
      0.5635956816502385,
      0.5959882320710721,
      0.510422489892197,
      0.39235506174283685,
      0.46204829649453694,
      0.5374893585932747,
      0.4848609186908468,
      0.5382841133445626,
      0.3157715505852954,
      0.5936270859042507,
      0.5469369558982331,
      0.5289505202542473,
      0.5241339214151861,
      0.4012078395496468,
      0.5159568424292738,
      0.4748207313451538,
      0.5013668100668034,
      0.4569029311487349,
      0.41297020598323875,
      0.39728169165553684,
      0.4176059583887788,
      0.4269721062697074,
      0.4958710097199961,
      0.44455142074044396,
      0.43217684490977604,
      0.42579188313452065
    ],
    [
      0.3293682943163989,
      0.43451504052272427,
      0.45063888058931156,
      0.0,
      0.47036516432309483,
      0.46845563746205565,
      0.3765988437767167,
      0.4171136439216081,
      0.48017776641766163,
      0.4451786021623436,
      0.41621881669904015,
      0.293691575204831,
      0.48670428284706335,
      0.43428199479647156,
      0.40790054290436806,
      0.44344667788494707,
      0.3033091443797671,
      0.4760882252344798,
      0.3752847804638779,
      0.4173694619055819,
      0.36537385927822674,
      0.33504097941693933,
      0.3809588495636802,
      0.35377568143403004,
      0.3118208551823678,
      0.37496887090256537,
      0.37561796800055425,
      0.4150844452241118,
      0.36766300869904756
    ],
    [
      0.3639645865935941,
      0.533160722059209,
      0.5417012788737368,
      0.505217068025068,
      0.0,
      0.5327355698639964,
      0.38228029958185794,
      0.5163221982414994,
      0.4913216387926387,
      0.4820068415024512,
      0.4963029138451529,
      0.30563886040966604,
      0.5646071356286346,
      0.517073583894053,
      0.46929078572892813,
      0.48658230439657557,
      0.3442940287733316,
      0.5149654711790215,
      0.44448100965588244,
      0.4741872798619384,
      0.4729580568222769,
      0.4228549648841673,
      0.4614841511851071,
      0.43119235474938766,
      0.36736045437668885,
      0.5047199496504302,
      0.388203331185085,
      0.42411875786603126,
      0.3957915375795462
    ],
    [
      0.36575376169789253,
      0.4498002795821696,
      0.49705208143654045,
      0.47471324982150587,
      0.4960770207188656,
      0.0,
      0.38301971785509736,
      0.494199334560089,
      0.43666392294832934,
      0.4437541775233904,
      0.5161091517488892,
      0.334166901074195,
      0.5223477113032611,
      0.49160941705558225,
      0.4478229563930938,
      0.43825337674397,
      0.3542723022150729,
      0.44826926282087887,
      0.4577284394562178,
      0.4643463306508815,
      0.42782209148856953,
      0.41661348126160336,
      0.37346734347824095,
      0.4428975696848565,
      0.32871730267245236,
      0.4570921993369146,
      0.37216735334487283,
      0.3837282139721139,
      0.3934750477178006
    ],
    [
      0.2520412756526673,
      0.36497218237941187,
      0.37733929401475974,
      0.3955988717515029,
      0.35767338962360773,
      0.3804105527029349,
      0.0,
      0.368943690821685,
      0.3278998443869332,
      0.35839176054733946,
      0.3294091334860285,
      0.31106510274404675,
      0.38039212545239187,
      0.3852407505645947,
      0.3644488087394018,
      0.3316882808593278,
      0.2935457168800002,
      0.39155158151554526,
      0.3413600186921304,
      0.37585927578235934,
      0.32349320870111664,
      0.3155874177147606,
      0.2877935534878897,
      0.3478448121535085,
      0.3194984436989867,
      0.38821336421626107,
      0.3262435018916403,
      0.33758624203096455,
      0.3285492170807054
    ],
    [
      0.4186835498327075,
      0.5428800166592418,
      0.587244828982157,
      0.5661019107347052,
      0.6333639263089066,
      0.6120581093997517,
      0.4520458156273177,
      0.0,
      0.5574047303246308,
      0.5145455109006132,
      0.6359818262076251,
      0.33555900969274344,
      0.6324636543381486,
      0.6048568167151422,
      0.5421214535568184,
      0.5483113965598037,
      0.41735861197558943,
      0.568836608890702,
      0.5136481793766776,
      0.5618658864680841,
      0.5070940061784939,
      0.49143729763429533,
      0.4685601714960792,
      0.5030320605472818,
      0.41829136921853927,
      0.5591709457980802,
      0.45763791333533677,
      0.4885397225468069,
      0.4546835542522425
    ],
    [
      0.4202445948045799,
      0.6258636722311863,
      0.6198834064366971,
      0.6421338356922375,
      0.6371544694048972,
      0.5204166510177857,
      0.4749913994380086,
      0.5225802618065318,
      0.0,
      0.537510026589725,
      0.5904695360084471,
      0.3345057437730141,
      0.6550191683098345,
      0.5534266089316744,
      0.5331530636598998,
      0.5222908494432978,
      0.39774484771441854,
      0.5767625772049316,
      0.48140618600239815,
      0.5133485473434727,
      0.5014947925026385,
      0.4750801854510338,
      0.4703402737244089,
      0.4878665536746074,
      0.42432912534084943,
      0.5719772543020638,
      0.4778881929994121,
      0.5015066451154309,
      0.4466692659887763
    ],
    [
      0.2830445269038351,
      0.4240505952867566,
      0.3991594513721819,
      0.41166406176497716,
      0.41665437607964195,
      0.3866783068753903,
      0.3339990424013173,
      0.35331644504888815,
      0.37301588772521765,
      0.0,
      0.37187921998232354,
      0.2587676153092042,
      0.40292349247674597,
      0.36080986942158466,
      0.3449950988977635,
      0.39410223324542715,
      0.3466823984275844,
      0.39140607841635244,
      0.35892328195259515,
      0.40333387140099286,
      0.3728643547752164,
      0.3669757015434103,
      0.36847760437652766,
      0.3465030261433253,
      0.334196747802582,
      0.3645992427048306,
      0.3778567866914795,
      0.36284710310045165,
      0.3320862440538632
    ],
    [
      0.3904802243494023,
      0.5930933855311349,
      0.5852352154763488,
      0.5242355174179207,
      0.5608874929594824,
      0.5265082671125125,
      0.436272977821234,
      0.5818093301791205,
      0.5138277026029985,
      0.46504252450421313,
      0.0,
      0.3338128409971248,
      0.6005171886758838,
      0.5876216645996748,
      0.5401346630188844,
      0.540869127369406,
      0.40011869149121626,
      0.5340749480991686,
      0.4590048855787605,
      0.5486540434628665,
      0.48525366549711624,
      0.4584230936019995,
      0.4176968202117155,
      0.44524123705881125,
      0.4067868685782783,
      0.5180164955494102,
      0.4274032029366328,
      0.46538624732904,
      0.419508934102909
    ],
    [
      0.21182786707810508,
      0.22023743785095062,
      0.19998024614384358,
      0.2277039346197567,
      0.22794228901078673,
      0.2169731681227205,
      0.2204768257038623,
      0.2391660429598219,
      0.18827005290005694,
      0.2424180183919873,
      0.17779128186615045,
      0.0,
      0.235860577939069,
      0.21190029133988397,
      0.23095681976093596,
      0.20476401159857516,
      0.19265549899579715,
      0.23532958762557743,
      0.2173817099284796,
      0.22870597229990297,
      0.20495510220310664,
      0.2440147367864023,
      0.21505075834868648,
      0.19227888284072048,
      0.23452548161863374,
      0.22947110513292768,
      0.22532289040991027,
      0.22480152600984638,
      0.23422345597443162
    ],
    [
      0.2969753238653605,
      0.5462216448395476,
      0.5119334627407741,
      0.5012617360742067,
      0.5643671171861304,
      0.5001826789952792,
      0.3840661917272499,
      0.5000463881615456,
      0.5123787389564474,
      0.4395715306212078,
      0.5255983409370191,
      0.29277221521844865,
      0.0,
      0.532842000066561,
      0.49134694746533336,
      0.46690330313949713,
      0.31994041906941284,
      0.5127184326328753,
      0.4182664371840299,
      0.4711744483913314,
      0.4792272230032215,
      0.3764675915353255,
      0.4214797420250058,
      0.4174141304413166,
      0.3434198668081567,
      0.474377077512528,
      0.3883492965067079,
      0.4108758041284044,
      0.3905946698100451
    ],
    [
      0.33642449354483595,
      0.44053761706468264,
      0.47681155145635135,
      0.46068152682268737,
      0.5188630991182217,
      0.474355626655647,
      0.3811885719648198,
      0.5012226256086174,
      0.45805226378418307,
      0.3719383089602146,
      0.5063108185314542,
      0.29236306129772327,
      0.5104905054792632,
      0.0,
      0.47883259660107647,
      0.4610090601236281,
      0.3412847642346777,
      0.478407272444042,
      0.3820601990011885,
      0.4795961521291472,
      0.4277483711294452,
      0.4110730391818258,
      0.36382551201123414,
      0.4262924809095272,
      0.3642943899128921,
      0.43970310256618395,
      0.3607447550853704,
      0.4164378336367187,
      0.37454586097206954
    ],
    [
      0.3662258598797157,
      0.5109939310310228,
      0.5818952329455296,
      0.5467187389118913,
      0.5417186721578169,
      0.5457268908589354,
      0.41347740490665874,
      0.513462722369147,
      0.4988095548745224,
      0.45455560199036515,
      0.5491504578538644,
      0.2937547944241359,
      0.5883636410911619,
      0.5665387293156983,
      0.0,
      0.5987552879859543,
      0.45303427549420494,
      0.5478718975724965,
      0.4678136379053859,
      0.5281677315441384,
      0.5159809573197089,
      0.468049801278833,
      0.42333805927783064,
      0.5232047924283825,
      0.3804037788091368,
      0.4787451422130784,
      0.4523304885472206,
      0.4349609694011185,
      0.432895011132054
    ],
    [
      0.294471608393192,
      0.4372631906872042,
      0.46079493946464134,
      0.4702621794129478,
      0.4489419364794034,
      0.4486624546877993,
      0.3528782526307521,
      0.4308918479464472,
      0.43199938580717245,
      0.47160761923098127,
      0.43886842298104867,
      0.2749618496548538,
      0.442351548079458,
      0.4052852924109702,
      0.4723267344144153,
      0.0,
      0.4181143587443954,
      0.39023850116046077,
      0.38350636206484734,
      0.4483836566820196,
      0.46871531363018115,
      0.4055553794955131,
      0.3628801964308328,
      0.41208822991114746,
      0.34461501637131753,
      0.4355151038304881,
      0.3771573604910461,
      0.3715906811005538,
      0.38367279380089037
    ],
    [
      0.3699984152685061,
      0.40236978057038586,
      0.40953262012877456,
      0.4046823802570101,
      0.392505717639249,
      0.4087228912279095,
      0.3567356099847421,
      0.40119698584938646,
      0.39390420167805074,
      0.3731596748683712,
      0.3997873010245727,
      0.2903178994908191,
      0.40107213964539645,
      0.4041794318101384,
      0.3905531062090064,
      0.421725040379592,
      0.0,
      0.40511901253449834,
      0.4110245613169481,
      0.37290740796443944,
      0.43458908618917413,
      0.36914928567575434,
      0.38074828294779417,
      0.3738917708448275,
      0.3945679341216637,
      0.39127317788409544,
      0.39884540266373336,
      0.35343509599009604,
      0.3669175031297651
    ],
    [
      0.348663746489732,
      0.5310650111544555,
      0.5641862612527555,
      0.5105888345063361,
      0.5943379261212294,
      0.5350419472187211,
      0.3899075185963612,
      0.515420309209986,
      0.4995694924075047,
      0.46900874921996283,
      0.5236822203350442,
      0.32425087870503577,
      0.579758854558257,
      0.5282256086429016,
      0.5188078217770011,
      0.4906006391230513,
      0.36403352627250274,
      0.0,
      0.45553055286589816,
      0.4760320488279326,
      0.4717891895719988,
      0.40067788113813396,
      0.4549041404970735,
      0.42500187734980677,
      0.3884092738846865,
      0.4877857007600026,
      0.4446268390936341,
      0.45280760515068064,
      0.40683733065467487
    ],
    [
      0.35628459420977343,
      0.4727447415609918,
      0.4727087518267288,
      0.44605964890443683,
      0.4597461918419794,
      0.44586186371698133,
      0.35065009122350244,
      0.4389531201784507,
      0.42771136586745473,
      0.4264532759339257,
      0.44084976000850107,
      0.3220480619573438,
      0.520644382198179,
      0.46625498050472425,
      0.3784857249300677,
      0.3875841622197267,
      0.3489565552341838,
      0.4224451064842043,
      0.0,
      0.4431665665333415,
      0.3861285654207738,
      0.4023076592829684,
      0.40015467124636594,
      0.3482757479933152,
      0.3662439511854516,
      0.44181826057914275,
      0.39609835698918894,
      0.37390067017136586,
      0.39779513388998655
    ],
    [
      0.4549013267479505,
      0.4836257948681726,
      0.4815976195439682,
      0.49991067437299996,
      0.5401967697394423,
      0.48020641619157334,
      0.3932219359154785,
      0.48121041159574607,
      0.46150569236839956,
      0.43648198858311327,
      0.5042501852586119,
      0.3052348496533237,
      0.5587627942299502,
      0.5072282435170028,
      0.4795014682289882,
      0.480763590685354,
      0.3758596798952043,
      0.4645126354663811,
      0.41912790652618415,
      0.0,
      0.41393081927150943,
      0.4600960728598844,
      0.41265810620921295,
      0.44144453540167383,
      0.3864095422378042,
      0.4706760482049621,
      0.4368119400226542,
      0.4474078864287201,
      0.4102540654816047
    ],
    [
      0.2785680815676703,
      0.3858411625750413,
      0.39625108573653556,
      0.3890968822708467,
      0.4121414074026557,
      0.38338181720031006,
      0.3294406426105523,
      0.36167846068752363,
      0.3787493109714368,
      0.3393337297757453,
      0.395518925671545,
      0.27226472648752575,
      0.41376850646310226,
      0.3830950787206435,
      0.41180321742180226,
      0.4247932172876834,
      0.3376877333772046,
      0.367800042668611,
      0.32211509569994945,
      0.4108467981694568,
      0.0,
      0.34263344678571706,
      0.34529981373724716,
      0.3994987178929099,
      0.2927013440125392,
      0.3238731043826064,
      0.3044696066917192,
      0.37343549362829065,
      0.33057081098089847
    ],
    [
      0.36136186256800573,
      0.4488737069740909,
      0.4755684536209537,
      0.4349263888738082,
      0.46164943500268696,
      0.473172026438037,
      0.3794110171786813,
      0.4258646778017967,
      0.46457864807671956,
      0.40532226615789035,
      0.49476973384775214,
      0.3117809755220686,
      0.4765937022340274,
      0.440579262603489,
      0.47639136006297544,
      0.4737641254419356,
      0.3881840231224265,
      0.4344373826689034,
      0.4410282958948393,
      0.4619055769963225,
      0.3863039465186717,
      0.0,
      0.3934834365939812,
      0.4598275496634776,
      0.3630714423512209,
      0.4533345819136432,
      0.39900984488403424,
      0.412865758235166,
      0.4671821118709496
    ],
    [
      0.32892731836954336,
      0.3977613869671155,
      0.3697516519396373,
      0.38034742049290293,
      0.4537362551171771,
      0.3983519398681985,
      0.332259610038909,
      0.3635027611184891,
      0.36512894704374665,
      0.39200040544431913,
      0.41942479689149237,
      0.2619456255502901,
      0.4311450892938897,
      0.388817912763459,
      0.3381166728121845,
      0.3707225086663055,
      0.34074613020444255,
      0.37548751018473436,
      0.3670104159459757,
      0.37021612127254877,
      0.370106241666029,
      0.33305459428759,
      0.0,
      0.3341496482035786,
      0.36800957769251297,
      0.3904186074906826,
      0.3804093030624698,
      0.32754999321982914,
      0.32387061056837596
    ],
    [
      0.36454838902314934,
      0.3662223959286488,
      0.3903787084819217,
      0.3824480386233782,
      0.39715281795628754,
      0.4184513191345307,
      0.2952794400410641,
      0.4190953728789555,
      0.4220708271297302,
      0.36258577823926474,
      0.3810750585161773,
      0.2667280073167575,
      0.4421217898771348,
      0.4143558566745027,
      0.41947983377724607,
      0.41039158837115264,
      0.37424130732705874,
      0.36092520005494944,
      0.39973462052235087,
      0.4076588237622316,
      0.4413503429937886,
      0.35961555925616895,
      0.29019595935191567,
      0.0,
      0.33508699847111156,
      0.362411645907573,
      0.3382879369465186,
      0.388668975954376,
      0.33559118801719134
    ],
    [
      0.36442423771736676,
      0.3359051144766261,
      0.35472480815133545,
      0.30690511273239185,
      0.36922850708167254,
      0.310860196582889,
      0.2875317393895851,
      0.33291195280973174,
      0.3234485958067752,
      0.2978724298048929,
      0.30918740719574345,
      0.27750635650980615,
      0.3224926293906569,
      0.33146709669763097,
      0.2804665719817321,
      0.2782543224882441,
      0.3494197250289379,
      0.32442355889436336,
      0.3037397112806526,
      0.33151550167636423,
      0.3109793603862925,
      0.29715336967559347,
      0.3169354669880966,
      0.32567690654856496,
      0.0,
      0.34313508408289906,
      0.341786090417757,
      0.3140652259246257,
      0.2971637539037284
    ],
    [
      0.39713859635881343,
      0.5413788382018345,
      0.5474365679901667,
      0.5321693495746029,
      0.5732650245949324,
      0.5247956312378448,
      0.4348110248318189,
      0.5437810723330054,
      0.5067034330281044,
      0.4382488378552696,
      0.545396627691523,
      0.32337231692863533,
      0.5912535779803925,
      0.547566090766884,
      0.47733875177993323,
      0.498857758145252,
      0.3812183383621328,
      0.5131477648472536,
      0.4706319817855127,
      0.5065940620476326,
      0.5067562876505278,
      0.47385611786151793,
      0.4833754507893917,
      0.45258723875291507,
      0.44113568366217004,
      0.0,
      0.4366927543843484,
      0.46941281003350643,
      0.4133589020648163
    ],
    [
      0.3834673517464051,
      0.45602449891072516,
      0.4338857528520783,
      0.40856514035491065,
      0.43491206509336133,
      0.4357397828413163,
      0.39320900744718745,
      0.4113776377138849,
      0.4075275154273381,
      0.4556414219175431,
      0.42032123014004696,
      0.33875555976519256,
      0.45028958705714106,
      0.4424092450343333,
      0.3812552687224877,
      0.4228517970611889,
      0.415545220201875,
      0.43936889014399005,
      0.43113356214932574,
      0.4460564527778548,
      0.404532638084113,
      0.414994450707842,
      0.423306551275322,
      0.39197855654645086,
      0.41015082326929075,
      0.42664923722088965,
      0.0,
      0.3853708534263398,
      0.4236416248295385
    ],
    [
      0.3526453037579258,
      0.3949166029843223,
      0.4305682746286743,
      0.4090151653828842,
      0.425462999868113,
      0.37188674110217534,
      0.35004401686309405,
      0.39712016068908906,
      0.411975472093032,
      0.4083867456776009,
      0.4071547299175633,
      0.26626656028828943,
      0.3956934556878906,
      0.39718008328783805,
      0.36411194848613704,
      0.3796805350242032,
      0.3279815689523822,
      0.39528183202386935,
      0.36558654956384906,
      0.41598217679433325,
      0.3761544849968834,
      0.35830526653094164,
      0.3758750668196169,
      0.40909968636749894,
      0.38545651506117373,
      0.3864677761287332,
      0.3590260891584107,
      0.0,
      0.3518710978442079
    ],
    [
      0.35543022803509605,
      0.40734727996126385,
      0.4139604703985964,
      0.4231011797966657,
      0.39617564085576285,
      0.37973363028321794,
      0.3755911917533763,
      0.36185326864082246,
      0.38956697246464844,
      0.406411943266074,
      0.39606356152705313,
      0.3233043745845525,
      0.42537604879262125,
      0.3762954879648124,
      0.4546889774436407,
      0.4216611846988638,
      0.3522332351387609,
      0.35762117156990714,
      0.39606682284540273,
      0.3931913126428803,
      0.3717533267293025,
      0.5058424192260376,
      0.3717900611466103,
      0.3946879872602891,
      0.3866251604731803,
      0.43036489097146613,
      0.41157947010790474,
      0.3859159607969991,
      0.0
    ]
  ],
  "row_avgs": [
    0.13997490196750476,
    0.4875696084384035,
    0.4774183702687384,
    0.4002504247683523,
    0.45838632625735565,
    0.4325692856629767,
    0.34509433634187514,
    0.5212063886985187,
    0.5184306333897235,
    0.36577902372073096,
    0.4916399020040452,
    0.2191066276236046,
    0.4460990271086775,
    0.42625340929384753,
    0.4884622879828574,
    0.4101285791426778,
    0.38831827561766774,
    0.4696982780494772,
    0.4121547129318949,
    0.4531353214109239,
    0.3609520807456347,
    0.4309014854685197,
    0.36689175200630103,
    0.3766483493048263,
    0.31925645834374844,
    0.4847243175550263,
    0.41746291866849905,
    0.381042746642169,
    0.39515118783485026
  ],
  "col_avgs": [
    0.3527314910839112,
    0.44469114630238377,
    0.45593699378381586,
    0.44542529097608796,
    0.4688802323761975,
    0.44048806829088727,
    0.3641918859528753,
    0.42913762671832917,
    0.42586757390474955,
    0.4127122152157981,
    0.4436680490079827,
    0.2956737850485404,
    0.4776942305683475,
    0.44805497561064656,
    0.42380362564033547,
    0.43142131158268354,
    0.3517452476240171,
    0.43352695082080334,
    0.3982059829428115,
    0.4322068163575062,
    0.410519838552328,
    0.3887678457849223,
    0.38069396425037166,
    0.39569038125414224,
    0.360929734954835,
    0.42470991761660415,
    0.38202887233563493,
    0.39164864849361425,
    0.3736543141982664
  ],
  "combined_avgs": [
    0.24635319652570797,
    0.46613037737039364,
    0.46667768202627713,
    0.42283785787222017,
    0.46363327931677656,
    0.436528676976932,
    0.35464311114737523,
    0.47517200770842394,
    0.4721491036472365,
    0.3892456194682645,
    0.46765397550601395,
    0.2573902063360725,
    0.46189662883851246,
    0.43715419245224707,
    0.45613295681159644,
    0.4207749453626807,
    0.3700317616208424,
    0.4516126144351403,
    0.4051803479373532,
    0.44267106888421504,
    0.38573595964898133,
    0.409834665626721,
    0.37379285812833635,
    0.3861693652794843,
    0.3400930966492917,
    0.45471711758581523,
    0.39974589550206696,
    0.3863456975678916,
    0.3844027510165583
  ],
  "gppm": [
    570.3488826167206,
    590.3777830644151,
    583.2967422992517,
    586.0664616164913,
    575.1929114403273,
    592.3492132424714,
    620.758668307145,
    596.055994130691,
    597.1493990986529,
    600.430116097189,
    592.5103281199617,
    650.3997676888187,
    574.4115900165605,
    587.8286768739191,
    597.5736584503078,
    596.7364720928653,
    625.1393473696106,
    595.2869987822988,
    610.8083866745507,
    590.8651369494355,
    599.5549474217394,
    611.449830798768,
    615.4128805481989,
    608.7500820993631,
    617.3149499458397,
    595.0033028683705,
    616.226568243269,
    608.7331468454986,
    620.2267463980855
  ],
  "gppm_normalized": [
    1.322204816469433,
    1.2791638237472835,
    1.2609179438269316,
    1.266955489957258,
    1.2424289208355883,
    1.2786413647939552,
    1.3472203678149073,
    1.2895107494914915,
    1.2899526160516661,
    1.2996651786943296,
    1.280000352282767,
    1.4118592899306246,
    1.2422592527263305,
    1.273415986512886,
    1.2900240177685063,
    1.2928444833828945,
    1.3546100907287213,
    1.2871949317358633,
    1.322223258963163,
    1.2711024332153793,
    1.2913649774001361,
    1.316660851883821,
    1.3334862941488907,
    1.3087509922118152,
    1.3343911496598568,
    1.2897789973616276,
    1.3328129534616735,
    1.3240830045711018,
    1.3371201995567592
  ],
  "token_counts": [
    890,
    478,
    448,
    442,
    445,
    418,
    452,
    445,
    419,
    443,
    428,
    434,
    473,
    470,
    422,
    478,
    439,
    426,
    441,
    384,
    396,
    387,
    433,
    369,
    405,
    468,
    417,
    502,
    384,
    474,
    506,
    445,
    440,
    760,
    432,
    447,
    385,
    403,
    395,
    512,
    407,
    451,
    431,
    460,
    432,
    397,
    381,
    423,
    424,
    400,
    412,
    382,
    404,
    423,
    393,
    416,
    480,
    350,
    915,
    391,
    409,
    451,
    406,
    405,
    455,
    370,
    378,
    427,
    403,
    522,
    462,
    448,
    413,
    439,
    408,
    375,
    424,
    413,
    457,
    403,
    419,
    429,
    472,
    383,
    374,
    454,
    405
  ],
  "response_lengths": [
    4433,
    2161,
    2329,
    2583,
    2396,
    2311,
    2665,
    2066,
    2129,
    2443,
    2232,
    3049,
    2563,
    2568,
    2253,
    2443,
    2296,
    2209,
    2354,
    2370,
    2553,
    2235,
    2315,
    2372,
    2704,
    2100,
    2189,
    2542,
    2344
  ]
}