{
  "example_idx": 45,
  "reference": "Published as a conference paper at ICLR 2023\n\nHOW ROBUST IS UNSUPERVISED REPRESENTATION LEARNING TO DISTRIBUTION SHIFT?\n\nYuge Shi∗ Department of Engineering Science University of Oxford\n\nImant Daunhawer & Julia E. Vogt Department of Computer Science ETH Zurich\n\nPhilip H.S. Torr Department of Engineering Science University of Oxford\n\nAmartya Sanyal Department of Computer Science & ETH AI Center ETH Zurich\n\nABSTRACT\n\nThe robustness of machine learning algorithms to distributions shift is primarily discussed in the context of supervised learning (SL). As such, there is a lack of insight on the robustness of the representations learned from unsupervised methods, such as self-supervised learning (SSL) and auto-encoder based algorithms (AE), to distribution shift. We posit that the input-driven objectives of unsupervised algorithms lead to representations that are more robust to distribution shift than the target-driven objective of SL. We verify this by extensively evaluating the performance of SSL and AE on both synthetic and realistic distribution shift datasets. Following observations that the linear layer used for classification itself can be susceptible to spurious correlations, we evaluate the representations using a linear head trained on a small amount of out-of-distribution (OOD) data, to isolate the robustness of the learned representations from that of the linear head. We also develop “controllable” versions of existing realistic domain generalisation datasets with adjustable degrees of distribution shifts. This allows us to study the robustness of different learning algorithms under versatile yet realistic distribution shift conditions. Our experiments show that representations learned from unsupervised learning algorithms generalise better than SL under a wide variety of extreme as well as realistic distribution shifts.\n\n1\n\nINTRODUCTION\n\nMachine Learning (ML) algorithms are classically designed under the statistical assumption that the training and test data are drawn from the same distribution. However, this assumption does not hold in most cases of real world deployment of ML systems. For example, medical researchers might obtain their training data from hospitals in Europe, but deploy their trained models in Asia; the changes in conditions such as imaging equipment and demography result in a shift in the data distribution between train and test set (Dockès et al., 2021; Glocker et al., 2019; Henrich et al., 2010). To perform well on such tasks requires the models to generalise to unseen distributions — an important property that is not evaluated on standard machine learning datasets like ImageNet, where the train and test set are sampled i.i.d. from the same distribution.\n\nWith increasing attention on this issue, researchers have been probing the generalisation performance of ML models by creating datasets that feature distribution shift tasks (Koh et al., 2021; Gulrajani and Lopez-Paz, 2020; Shah et al., 2020) and proposing algorithms that aim to improve generalisation performance under distribution shift (Ganin et al., 2016; Arjovsky et al., 2019; Sun and Saenko, 2016; Sagawa et al., 2020; Shi et al., 2022). In this work, we identify three specific problems with current approaches in distribution shift problems, in computer vision, and develop a suite of experiments to address them.\n\n∗Corresponding author, yshi@robots.ox.ac.uk\n\n1\n\nPublished as a conference paper at ICLR 2023\n\nFigure 1: Synthetic vs. realistic distribution shift: The distribution shift in synthetic datasets (left, MNIST-CIFAR and CdSprites) are usually extreme and controllable (adjusted via changing the correlation); for realistic datasets (right, WILDS-Camelyon17 and FMoW) distribution shift can be subtle, hard to identify and impossible to control.\n\n1.1 EXISTING PROBLEMS AND CONTRIBUTIONS\n\nProblem 1: The outdated focus on supervised regime for distribution shift In ML research, distribution shift has been studied in various contexts under different terminologies such as simplicity bias (Shah et al., 2020), dataset bias (Torralba and Efros, 2011), shortcut learning (Geirhos et al., 2020), and domain adaptation and generalisation (Koh et al., 2021; Gulrajani and Lopez-Paz, 2020). Most of these work are carried out under the scope of supervised learning (SL), including various works that either investigate spurious correlations (Shah et al., 2020; Hermann and Lampinen, 2020; Kalimeris et al., 2019) or those that propose specialised methods to improve generalisation and/or avoid shortcut solutions (Arjovsky et al., 2019; Ganin et al., 2016; Sagawa et al., 2020; Teney et al., 2022). However, recent research (Shah et al., 2020; Geirhos et al., 2020) highlighted the extreme vulnerability of SL methods to spurious correlations: they are susceptible to learning only features that are irrelevant to the true labelling functions yet highly predictive of the labels. This behaviour is not surprising given SL’s target-driven objective: when presented with two features that are equally predictive of the target label, SL models have no incentive to learn both as learning only one of them suffices to predict the target label. This leads to poor generalisation when the learned feature is missing in the OOD test set.\n\nOn the other hand, in recent times, research in computer vision has seen a surge of unsupervised representation learning algorithms. These include self-supervised learning (SSL) algorithms (e.g., Chen et al. (2020a); Grill et al. (2020); Chen and He (2021)), which learn representations by enforcing invariance between the representations of two distinctly augmented views of the same image, and auto-encoder based algorithms (AE) (Rumelhart et al., 1985; Kingma and Welling, 2014; Higgins et al., 2017; Burda et al., 2016), which learn representations by reconstructing the input image. The immense popularity of these methods are mostly owed to their impressive performance on balanced in-distribution (ID) test datasets — how they perform on distribution shift tasks remains largely unknown. However, in distribution shift tasks, it is particularly meaningful to study unsupervised algorithms. This is because, in comparison to SL, their learning objectives are more input-driven i.e. they are incentivised to learn representations that most accurately represent the input data (Chen et al., 2020a; Alemi et al., 2017). When presented with two features equally predictive of the labels, unsupervised learning algorithms encourage the model to go beyond learning what’s enough to predict the label, and instead focus on maximising the mutual information between the learned representations and the input. We hypothesise that this property of unsupervised representation learning algorithms helps them avoid the exploitation of spurious correlations, and thus fare better under distribution shift, compared to SL.\n\nContribution: Systematically evaluate SSL and AE on distribution shift tasks. We evaluate and compare the generalisation performance of unsupervised representation learning algorithms, including SSL and AE, with standard supervised learning. See section 2 for more details on our experiments.\n\nProblem 2: Disconnect between synthetic and realistic datasets Broadly speaking, there exists two types of datasets for studying distribution shift: synthetic datasets where the shift between train/test distribution is explicit and controlled (e.g. MNIST-CIFAR (Shah et al., 2020), CdSprites (Shi et al., 2022)) and realistic datasets featuring implicit distribution shift in the real world (e.g. WILDS (Koh et al., 2021)). We provide visual examples in fig. 1.\n\nSynthetic datasets allow for explicit control of the distribution shift and are, thus, an effective diagnostic tool for generalisation performance. However, the simplistic nature of these datasets poses\n\n2\n\nPublished as a conference paper at ICLR 2023\n\nOOD Accuracy (higher is better)\n\nShift Sensitivity (lower is better)\n\n(a) MNIST-CIFAR\n\n(b) CdSprites\n\n(c) Camelyon17-CS\n\n(d) FMoW-CS\n\n(e) Camelyon17\n\n(f) FMoW\n\nFigure 2: Performance of auto-encoder (AE), self-supervised learning (SSL), supervised learning (SL) models. Top row: the OOD test set accuracy (%) using linear heads trained on OOD data; Bottom row: Shift Sensitivity (see section 2 for definition), measures models’ sensitivity to distribution shift. Note here rid = 1 for Camelyon17-CS, FMoW-CS, and CdSprites (see sections 3.1.2 and 3.2.2).\n\nconcerns about the generality of the findings drawn from these experiments; a model’s robustness to spurious correlation on certain toy datasets is not very useful if it fails when tested on similar real-world problems. On the other hand, realistic datasets often feature distribution shifts that are subtle and hard to define (see fig. 1, right). As a result, generalisation performances of different algorithms tend to fluctuate across datasets (Koh et al., 2021; Gulrajani and Lopez-Paz, 2020) with the cause of said fluctuations remaining unknown.\n\nContribution: Controllable but realistic distribution shift tasks. In addition to evaluating models on both synthetic and realistic datasets, we subsample realistic domain generalisation datasets in WILDS to artificially inject explicit spurious correlations between domains and labels. This allows us to directly control the level of shift in these realistic distribution shift datasets. We refer to them as Controllable-Shift (CS) datasets. 1\n\nProblem 3: The linear classifier head strongly biases the evaluation protocol The most popular evaluation protocol for representation learning algorithms (both supervised and unsupervised) is linear probing. This involves freezing the weights of the representation learning model and training a linear classifier head on top of that to predict the labels. For distribution shift problems, this linear classifier is typically trained on the same training set as the representation learning backbone. Kang et al. (2020); Menon et al. (2020) observed the interesting phenomenon that this final layer linear classifier can be extremely susceptible to spurious correlations, causing poor OOD performance. Under simple, synthetic set up, they showed that SL models’ performance on OOD test set can be dramatically improved by simply retraining the linear classifier on data where the spurious correlation is absent. This indicates that the linear classifier can be a strong source of model bias in distribution shift tasks, and to disentangle the linear classifier bias from the generalisation performance of the learned representations, it is advisable to re-train the linear head on OOD data during evaluation. Note that although retraining linear classifier head is already standard practice in transfer learning, its application is necessary as the pre-training task and target task are typically different; on the other hand, retraining linear head is neither necessary nor standard practice in distribution shift problems, despite the recognition of linear head bias in recent work (Kang et al., 2020; Menon et al., 2020).\n\nContribution: OOD linear head. When reporting OOD accuracy, we use a linear head trained on small amount of left-out OOD data as opposed to ID data, as is standard practice. This allows us to isolate the bias of the linear head from the generalisability of learned representations. We also quantify the linear head bias to highlight the importance of this treatment. With these results, we wish to establish OOD linear head evaluation as a standard protocol for evaluating robustness of representation learning algorithms to distribution shift.\n\n1While datasets like ImageNet-9 and SVSF also provides distribution shift controls for real images, our sub-sampling of realistic domain generalisation datasets allows us to gain such control cheaply on a large set of datasets, and in addition provide further analysis on models’ performance on existing benchmarks (WILDS).\n\n3\n\nAESSLSL79.986.151.5AESSLSL52.582.744AESSLSL83.1180.9173.37AESSLSL18.2626.9225.73AESSLSL86.9189.886.84AESSLSL22.7929.6435.6AESSLSL2013.747.6AESSLSL47.517.356AESSLSL4.096.3510.72AESSLSL8.779.2912.26AESSLSL-0.21.633.5AESSLSL4.999.1537.7Published as a conference paper at ICLR 2023\n\nIn summary, we develop a suite of experiments and datasets to evaluate the performance of various representation learning paradigms under distribution shift. Figure 2 provides a summary of our results, comparing a range of methods from the following classes of algorithms: (i) SSL, (ii) AE, and (iii) SL. Note that though the intuition that unsupervised objectives should be better at distribution shift tasks is well-established in theory (Chen et al., 2020a; Alemi et al., 2017), state-of-the-art methods are predominantly developed under SL. To the best of our knowledge, we are the first to systematically evaluate and compare unsupervised representation learning methods to SL under distribution shift. The models are evaluated on both synthetic and realistic distribution shift datasets. Further, the models are also evaluated on CS datasets that contains controllable, explicit spurious correlations in realistic datasets. The main takeaways from this paper are:\n\n• SSL and AE are more robust than SL to extreme distribution shift: Figures 2a to 2d shows results on distribution shift scenarios where the training set encodes extreme spurious correlations. In this setting, for both synthetic (figs. 2a and 2b) and real world (figs. 2c and 2d) datasets, SSL and AE consistently outperforms SL in terms of OOD accuracy (top row);\n\n• Compared to SL, SSL and AE’s performance drop less under distribution shift: The bottom row of fig. 2 compares the shift sensitivity (s) of different models (see section 2 for definition). Smaller s is desirable as it indicates lower sensitivity to distribution shift. Results show that SSL and AE algorithms are significantly more stable under distribution shift than SL;\n\n• Generalisation performance on distribution shift tasks can be significantly improved by retraining the linear head: We show a large performance boost for all models, when evaluated using linear head trained on a small amount of OOD data, in contrast to the baseline linear head trained on ID data. The surprising gain of this cheap procedure, even on realistic problems, highlights the importance of isolating the linear head bias when evaluating generalisation performance.\n\n2 SETING UP\n\nIn section 1 we identified three problems in the existing literature that we wish to address in this work. In this section, we will introduce the necessary experimental set-up in further details. In brief, we compare eight ML algorithms on six datasets using three relevant metrics.\n\nAlgorithms: ×3 SSL, ×4 AE, ×1 SL. We compare seven unsupervised representation learning algorithms against SL, including three SSL algorithms 1) SimCLR (Chen et al., 2020a), 2) SimSiam (Chen and He, 2021), and 3) BYOL (Grill et al., 2020); and four AE algorithms 1) Autoencoder (Rumelhart et al., 1985), 2) Variational Autoencoder (VAE) (Kingma and Welling, 2014), 3) β-VAE (Higgins et al., 2017) and 4) Importance Weighted Autoencoder (IWAE) (Burda et al., 2016). These popular methods in SSL and latent generative models have not yet been systematically evaluated under distribution shift tasks prior to our work. We compare the performance of these models against a standard supervised learning (SL) algorithm used as a representation learning model.\n\nDatasets: ×2 synthetic, ×2 realistic, ×2 controllable shift. We evaluate our models on two synthetic datasets, namely MNIST-CIFAR (Shah et al. (2020); see section 3.1.1) and CdSprites (Shi et al. (2022); see section 3.1.2), as well as two realistic datasets from WILDS (Koh et al., 2021): Camelyon17 and FMoW (see section 3.2.1). However, as mentioned in section 1.1, both the synthetic and the realistic datasets have their own drawbacks. To further understand the models’ performance and draw conclusions that are generalisable, we also provide a framework for creating controllable shift datasets from realistic datasets like those in WILDS, by subsampling the data to introduce spurious correlations between the domain and label information in the training set. Changing this correlation varies the degree of distribution shift between the (ID) train and (OOD) test split, which allows us to analyse the models’ performance more effectively under realistic, yet controllable, distribution shift. We refer to this controllable shift versions of the two datasets Camelyon17-CS and FMoW-CS, and provide further details on the datasets in section 3.2.2.\n\nEvaluation: 3 metrics. Before discussing our proposed metrics, we first define some necessary notations. We separate a model trained to perform a classification task into two parts, namely, 1) backbone f , denoting the part of the model that generates representations from the data, and 2) final linear head c, which takes the representations from f and outputs the final prediction. Further, we refer to the final linear head trained on representations from the ID train set as ci, and that trained on representations from the OOD test set as co. Since the backbone f is always trained on the ID\n\n4\n\nPublished as a conference paper at ICLR 2023\n\ntrain set, we do not make any notation distinction on its training distribution. We also denote the accuracy of f and c on the ID test data as acci(f, c), and on the OOD test data as acco(f, c).\n\nAs noted in section 1.1, we report the OOD accuracy of the algorithms using linear heads trained on OOD data (instead of those trained on ID data as per standard practice), i.e. acco(f, co). This is necessary to disentangle the bias of the linear head from that of the representations. To highlight the importance of this treatment in isolating the generalisability of the representation learning algorithm from the that of the linear head, we also define the linear head bias. It is the difference between the OOD test accuracy evaluated by OOD linear head and that evaluated by the ID linear head, i.e.\n\nb = acco(f, co) − acco(f, ci).\n\n(1)\n\nIn a related work, Taori et al. (2020) proposed to evaluate the effective robustness of OOD generalisation defined as ρ = acci(f, ci) − acco(f, ci), which quantifies the drop in performance (e.g. accuracy) when evaluating the model on OOD test set vs. ID test set. A small ρ is desirable, as it indicates that the performance of the model is relatively insensitive to a distribution shift2. However, we note that a simple decomposition of effective robustness (ρ) shows a hidden linear head bias (b) term\n\nacci(f, ci) − acco(f, ci) (cid:123)(cid:122) (cid:125) (cid:124) effective robustness ρ\n\n= acci(f, ci) − acco(f, ci) − acco(f, co) + acco(f, co)\n\n= acco(f, co) − acco(f, ci) (cid:125)\n\n(cid:123)(cid:122) linear head bias b\n\n(cid:124)\n\n+ acci(f, ci) − acco(f, co) (cid:125)\n\n(cid:123)(cid:122) shift sensitivity s\n\n(cid:124)\n\n.\n\n(2)\n\nThus, we remove the effect of the linear head bias by subtracting b from ρ and reporting the last term in eq. (2). We refer to this as shift sensitivity : s = ρ − b. Alternatively, it is the difference between the OOD accuracy using linear head trained on OOD data, and ID accuracy using linear head trained on ID data. Larger s marks higher sensitivity of f to distribution shift, which is, possibly, dangerous for the deployment of such models. In summary, for each experiment we report the following three metrics: OOD linear head accuracy acco(f, co), linear head bias b and shift sensitivity s.\n\n3 EXPERIMENTAL RESULTS\n\nWe perform a hyperparameter search on learning rate, scheduler, optimiser, representation size, etc. for each model. We use the standard SSL augmentations proposed in He et al. (2020); Chen et al. (2020b) for all models to ensure a fair comparison. See appendix B for details.\n\n3.1 SYNTHETIC DISTRIBUTION SHIFT\n\nIn this section, we evaluate the performance of SL, SSL and AE algorithms on synthetic distribution shift tasks, utilising the MNIST-CIFAR dataset (Shah et al., 2020) and the CdSprites dataset (Shi et al., 2022). All results are averaged over 5 random seeds.\n\n3.1.1 MNIST-CIFAR\n\nFinding: Under this extreme distribution shift setting, SSL and AE significantly outperform SL. The OOD accuracy of SSL and AE can be notably improved by retraining the linear head on OOD data, however the OOD accuracy of SL remains low even with the OOD-trained linear head.\n\nThe MNIST-CIFAR dataset consists of concatenations of images from two classes of MNIST and CIFAR-10. In each concatenated image, the classes of the two datasets are either correlated or uncorrelated depending on the split as discussed below (See fig. 1, MNIST-CIFAR for an example):\n\n• ID train, test: Correlation between MNIST and CIFAR-10 labels is one. Each image belongs to one of the two classes: 1) MNIST “0” and CIFAR-10 “automobile”, and 2) MNIST “1” and CIFAR-10 “plane” (Figure 1, top row);\n\n• OOD train, test: Zero correlation between MNIST and CIFAR-10 labels, images from the two\n\nclasses are randomly paired (Figure 1, bottom row).\n\nSince the MNIST features are much simpler than the CIFAR features, a model trained on the ID train set can use MNIST only to predict the label, even though the CIFAR images are just as predictive\n\n2We negate the original definition of effective robustness from Taori et al. (2020) for ease of understanding.\n\n5\n\nPublished as a conference paper at ICLR 2023\n\nTable 1: Evaluations on the MNIST-CIFAR dataset. We report accuracy on MNIST and CIFAR trained using OOD linear head (acco(f, co)), linear head bias (b) and shift sensitivity (s).\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMNIST (%)\n\nCIFAR (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n99.9 (±1e-2) 99.8 (±8e-3) 99.8 (±9e-3) 99.8 (±2e-2) 99.8 (±1e-2)\n\n99.7 (±1e-2) 99.8 (±2e-1) 99.8 (±4e-2) 99.8 (±8e-2)\n\n0.0 (±1e-2) -0.1 (±9e-3) 0.0 (±4e-3) 0.0 (±4e-2) 0.0 (±1e-2)\n\n0.2 (±1e-3) 0.1 (±2e-1) 0.0 (±1e-2) 0.1 (±5e-2)\n\n0.0 (±2e-3) 0.5 (±1e-4) 0.1 (±5e-3) -0.1 (±3e-2) 0.1 (±9e-3)\n\n-0.2 (±3e-3) 0.0 (±9e-2) 0.9 (±8e-3) 0.2 (±3e-2)\n\n81.1 (±1e+0) 79.7 (±4e+0) 80.8 (±2e+0) 78.0 (±3e+0) 79.9 (±3e+0)\n\n85.8 (±1e+0) 87.8 (±2e+0) 84.8 (±9e-1) 86.1 (±2e+0)\n\n18.8 (±1e+0) 20.2 (±3e+0) 19.0 (±3e+0) 21.8 (±4e+0) 20.0 (±4e+0)\n\n14.1 (±2e+0) 12.1 (±2e+0) 15.0 (±1e+0) 13.7 (±2e+0)\n\n30.2 (±1e+0) 29.2 (±6e+0) 30.0 (±4e+0) 28.0 (±4e+0) 29.3 (±4e+0)\n\n35.5 (±1e+0) 35.6 (±4e+0) 33.2 (±1e+0) 34.8 (±4e+0)\n\nSL\n\nSupervised\n\n97.7 (±9e-1)\n\n1.4 (±1e+0)\n\n-0.3 (±1e+0)\n\n51.5 (±1e+0)\n\n47.6 (±1e+0)\n\n0.8 (±9e-1)\n\n(Shah et al., 2020). This results in poor performance when predicting the CIFAR label on the OOD test set, where there is no correlation between the MNIST and CIFAR labels.\n\nWe train a CNN backbone on the ID train set using the eight SL, SSL and AE algorithms listed in section 2. At test time, we freeze the backbone and train two linear heads on ID train and OOD train set respectively, and evaluate their performance on the ID and OOD test set to compute 1) OOD linear head accuracy acco(f, co), 2) shift sensitivity s and, 3) linear head bias b. See results in table 1.\n\nWe observe that all models achieve near perfect performance when predicting the MNIST label on OOD test set, all with low shift sensitivity and small linear head bias. However, when predicting the labels of the more complex CIFAR images, unsupervised algorithms have a clear advantage over the supervised one: SSL achieves the highest OOD accuracy at 86.1%, followed by AE at 79.9% and SL at 51.5% (near random). The shift sensitivity s of the three objectives follow a similar trend, with SSL and AE scoring significantly lower than SL. This indicates that unsupervised representations are significantly less sensitive to distribution shift compared to those from SL, with the latter suffering a drop as large as 47.6%. Interestingly, the classifier head bias b for SSL and AE are relatively high (around 30%), and is very low for SL (0.8%), indicating that the representations learned from SL is intrinsically un-robust to distribution shift. That is, while there exist (linearly separable) CIFAR features in the representations of SSL and AE that can be extracted using a linear head trained on un-biased (OOD) data, these features are absent from the representations of SL.\n\n3.1.2 CDSPRITES\n\nFinding: Similar to MNIST-CIFAR, under extreme distribution shift, SSL and AE are better than SL; when the shift is less extreme, SSL and SL achieve comparably strong OOD generalisation performance while AE’s performance is much weaker.\n\nCdSprites is a colored variant of the popular dSprites dataset (Matthey et al., 2017), which consists of images of 2D sprites that are procedurally generated from multiple latent factors. The CdSprites dataset induces a spurious correlation between the color and shape of the sprites, by coloring the sprites conditioned on the shape following a controllable correlation coefficient rid. See fig. 1 for an example: when rid = 1 color is completely dependent on shape (top row, oval-purple, heart-cyan, square-white), and when rid = 0, color and shape are randomly matched (bottom row).\n\nShi et al. (2022) observes that when rid is high, SL model tend to use color only to predict the label while ignoring shape features due to the texture bias of CNN (Geirhos et al., 2019; Brendel and Bethge, 2019). First, we consider the setting of extreme distribution shift similar to MNIST-CIFAR by setting rid = 1 in the ID train and test splits. In the OOD train and test splits, the correlation coefficient is set to zero to investigate how well the model learns both the shape and the color features. Table 2 reports the three metrics of interest using the same evaluation protocol as before.\n\nSimilar to MNIST-CIFAR, we observe that all models achieve near perfect performance when predicting the simpler feature, i.e. color on the OOD test set. However, when predicting shape, the more complex feature on the OOD test set, SSL (and also AEs to a lesser extent) is far superior to SL. Additionally, the shift sensitivity of SSL (and AE to a lesser extent) are much smaller than SL, indicating that SSL/AE models are more robust to extreme distribution shift. The linear head bias also follows a similar trend as for MNIST-CIFAR, showing that representations learned using SL methods are inherently not robust to spurious correlations. This is not the case for SSL and AE algorithms where a large linear head bias shows that is the ID linear heads and not the representations that injects the bias.\n\n6\n\nPublished as a conference paper at ICLR 2023\n\nTable 2: Evaluations on the CdSprites dataset with rid = 1.0. We report accuracy for color and shape classifiers trained using OOD linear head (acco(f, co)), linear head bias (b) and shift sensitivity (s).\n\nRegime Method\n\nAE\n\nAE VAE IWAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nColor classification (%)\n\nShape classification (%)\n\nacco(f, co) ↑\n\n100.0 (±0e+0) 99.7 (±3e-1) 100.0 (±0e+0) 99.9 (±9e-1)\n\n100.0 (±0e+0) 100.0 (±0e+0) 100.0 (±0e+0) 100.0 (±0e+0)\n\ns ↓\n\nb\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n0.0 (±2e-3) 0.3 (±3e-1) 0.0 (±2e-3) 0.1 (±9e-2)\n\n0.0 (±0e+0) 0.0 (±0e+0) 0.0 (±0e+0) 0.0 (±0e+0)\n\n0.3 (±5e-1) -0.3 (±3e-1) 0.4 (±5e-1) 0.1 (±4e-1)\n\n0.0 (±1e-1) 0.1 (±1e-1) 0.0 (±0e+0) 0.1 (±3e-2)\n\n46.1 (±6e-1) 52.4 (±2e+0) 58.9 (±2e+0) 52.5 (±2e+0)\n\n87.8 (±5e-1) 69.2 (±2e+0) 91.1 (±4e+0) 82.7 (±2e+0)\n\n53.9 (±6e-1) 47.6 (±2e+0) 41.1 (±2e+0) 47.5 (±2e+0)\n\n12.2 (±5e-1) 30.8 (±2e+0) 8.9 (±4e+0) 17.3 (±2e+0)\n\n12.7 (±5e-1) 18.9 (±3e+0) 25.6 (±2e+0) 19.1 (±2e+0)\n\n54.5 (±5e-1) 35.6 (±2e+0) 57.9 (±4e+0) 49.3 (±4e+0)\n\nSL\n\nSupervised\n\n100.0 (±0e+0)\n\n0.0 (±0e+0)\n\n0.0 (±3e-2)\n\n44.0 (±7e-1)\n\n56.0 (±7e-1)\n\n10.7 (±7e-1)\n\nControllable distribution shift We extend this experiment to probe the performance of these algorithms under varying degrees of distribution shifts. We generate three versions of the CdSprites dataset with three different correlation coefficients rid ∈ {0, 0.5, 1} of the ID train set. As before, the correlation coefficient of the OOD split is set to zeroThe rest of the experimental protocol stays the same. The OOD test accuracy and the shift sensitivity for varying rid is plotted in fig. 3 and a detailed breakdown of results is available in appendix A.\n\nFigure 3 shows that despite increasing distribution shift between the ID and OOD splits (with increasing rid) the OOD performance of SSL and AE does not suffer. However, the OOD accuracy of SL plummets and its shift sensitivity explodes at rid = 1. Interestingly, SSL maintains a high OOD test accuracy regardless of the level of distribution shift: when rid < 1 its performance is on par with SL, and when the distribution shift becomes extreme with rid = 1 it significantly outperforms SL both in terms of accuracy and shift sensitivity. In comparison, AE models’ accuracy lingers around 50%, with increasingly higher shift sensitivity as rid increases. However, under extreme distribution shift with rid = 1 it still performs better than SL, with slightly higher OOD accuracy and lower shift sensitivity.\n\n3.2 REAL-WORLD DISTRIBUTION SHIFT\n\nIn this section we investigate the performance of different objectives on real-world distribution shift tasks. We use two datasets from WILDS (Koh et al., 2021): 1) Camelyon17, which contains tissue scans acquired from different hospitals, and the task is to determine if a given patch contains breast cancer tissue; and 2) FMoW, which features satellite images of landscapes on five different continents, with the classification target as the type of infrastructure. See examples in Figure 1. Following the guidelines from WILDS benchmark, we perform 10 random seed runs for all Camelyon17 experiment and 3 random seed runs for FMoW. The error margin in Figure 3 represent standard deviation.\n\n3.2.1 ORIGINAL WILDS DATASETS\n\nFindings: SL is significantly more sensitive to distribution shift than SSL and AE; representations from SSL obtain higher OOD accuracy than SL on Camelyon17 but lower on FMoW. AE is consistently the least sensitive to distribution shift though it has the lowest accuracy. The performance of all models significantly improves by retraining the linear head on a small amount of OOD data.\n\nThe original Camelyon17 and FMoW dataset from WILDS benchmark both contains the following three splits: ID train, OOD validation and OOD test. We further create five splits specified as follows:\n\n• ID train, test: Contains 90% and 10% of the original ID train split, respectively; • OOD train, test: Contains 10% and 90% of the original OOD test split, respectively; • OOD validation: Same as the original OOD validation split.\n\nFollowing WILDS, we use OOD validation set to perform early stopping and choose hyperparameters; we also use DenseNet-121 (Huang et al., 2017) as the backbone for all models. We follow similar evaluation protocol as previous experiments, and in addition adopt 10-fold cross-validation for the OOD train and test set. See results in Tables 3 and 4, where following WILDS, we report performance on Camelyon17 using standard average accuracy and on FMoW using worst-group accuracy.\n\nOne immediate observation is that in contrast to our previous experiments on synthetic datasets, SL’s OOD accuracy is much higher in comparison on realistic distribution shift tasks: it is the best performing model on FMoW with 35.6% worst-group accuracy on OOD test set; its OOD accuracy is the lowest on Camelyon17, however it is only 3% worse than the highest accuracy achieved by SSL\n\n7\n\nPublished as a conference paper at ICLR 2023\n\nTable 3: Evaluations on test set of Camelyon17, all metrics computed using average accuracy.\n\nTable 4: Evaluations on test set of FMoW, all metrics computed using worst-group accuracy.\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMetrics (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n84.4 (±2e+0) 88.1 (±2e+0) 88.1 (±1e+0) 87.1 (±4e+0) 86.9 (±2e+0)\n\n92.7 (±2e+0) 86.7 (±1e+0) 89.9 (±1e+0) 89.8 (±1e+0)\n\n-0.6 (±1e+0) 0.5 (±2e+0) -0.9 (±3e+0) 0.2 (±4e+0) -0.2 (±3e+0)\n\n0.4 (±1e+0) 3.1 (±1e+0) 1.4 (±1e+0) 1.6 (±1e+0)\n\n12.7 (±2e+0) 39.0 (±2e+0) 39.1 (±4e+0) 36.0 (±5e+0) 31.7 (±3e+0)\n\n8.3 (±1e+0) 7.9 (±3e+0) 10.3 (±2e+0) 8.8 (±2e+0)\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMetrics (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n26.9 (±9e-3) 21.7 (±6e-3) 20.9 (±2e-2) 21.7 (±5e-3) 22.8 (±3e-2)\n\n29.9 (±6e-3) 27.8 (±2e-2) 31.3 (±1e-2) 29.6 (±2e-2)\n\n6.4 (±6e-3) 4.7 (±4e-3) 5.5 (±1e-2) 3.4 (±6e-3) 5.0 (±7e-3)\n\n10.7 (±6e-3) 4.6 (±1e-2) 12.1 (±7e-3) 9.1 (±9e-3)\n\n5.8 (±1e-2) 8.0 (±2e-2) 7.8 (±1e-2) 7.6 (±8e-3) 7.3 (±1e-2)\n\n7.6 (±7e-3) 6.3 (±2e-2) 7.9 (±1e-2) 7.3 (±1e-2)\n\nSL\n\nSupervised\n\n86.8 (±2e+0)\n\n3.5 (±1e+0)\n\n7.4 (±3e+0)\n\nSL\n\nSupervised\n\n35.6 (±7e-3)\n\n37.7 (±4e-2)\n\n6.9 (±9e-3)\n\n(89.8%). This highlights the need to study realistic datasets along with synthetic ones. Nonetheless, we find that SSL is still the best performing method on Camelyon17 and achieves competitive performance on FMoW with accuracy 29.6% — despite learning without labels! AE has much lower OOD accuracy on FMoW compared to the other two methods: we believe this is due to its reconstruction-based objective wasting modelling capacity on high frequency details, a phenomenon frequently observed in prior work (Bao et al., 2021; Ramesh et al., 2021). Note that the standard deviation for all three methods are quite high for Camelyon17: this is a known property of the dataset and similar pattern is observed across most methods on WILDS benchmark (Koh et al., 2021).\n\nIn terms of shift sensitivity, unsupervised objectives including SSL and AE consistently outperforms SL — this stands out the most on FMoW, where the shift sensitivity of SSL and AE are 9.1% and 5.0% respectively, while SL is as high as 37.7%. This observation further validates our previous finding on synthetic datasets, that SSL and AE’s ID accuracy is a relatively reliable indication of their generalisation performance, while SL can undergo a huge performance drop under distribution shift, which can be dangerous for the deployment of such models. We highlight that, in sensitive application domains, a low shift sensitivity is an important criterion as it implies that the model’s performance will remain consistent when the distribution shifts. Another interesting observation here is that for all objectives on both datasets, the classifier bias b is consistently high. This indicates the bias of the linear classification head plays a significant role even for real world distribution shifts, and that it is possible to mitigate this effect by training the linear head using a small amount of OOD data (in this case 10% of the original OOD test set).\n\n3.2.2 WILDS DATASETS WITH CONTROLLABLE SHIFT\n\nFindings: SL’s OOD accuracy drops as more the distribution shift becomes more challenging, with SSL being the best performing model when the distribution shift is the most extreme. The shift sensitivity of SSL and AE are consistently lower than SL regardless of the level of shift.\n\nTo examine models’ generalisation performance under different levels of distribution shift, we create versions of these realistic datasets with controllable shifts, which we name Camelyon17-CS and FMoW-CS. Specifically, we subsample the ID train set of these datasets to artificially create spurious correlation between the domain and label. For instance, given dataset with domain A, B and label 0, 1, to create a version of the dataset where the spurious correlation is 1 we would sample only examples with label 0 from domain A and label 1 from domain B. See Appendix C for further details.\n\nSimilar to CdSprites, we create three versions of both of these datasets with the spurious correlation coefficient rid ∈ {0, 0.5, 1} in ID (train and test) sets. The OOD train, test and validation set remains unchanged3. Using identical experimental setup as in section 3.2.1, we report the results for Camelyon17-CS and FMoW-CS in Figure 3 with detailed numerical results in Appendix A.2.\n\nFor both datasets, the OOD test accuracy of all models drop as the spurious correlation rid increases (top row in Figure 3). However, this drop is the far more obvious in SL than in SSL and AE: when rid = 1, SL’s accuracy is 10% lower than SSL on Camelyon17 and 2% lower on FMoW — a significant drop from its original 3% lag on Camelyon17 and 5% lead on FMoW. This demonstrates that SL is less capable of dealing with more challenging distribution shift settings compared to SSL and AE. In terms of shift sensitivity (bottom row, fig. 3), SL’s remains the highest regardless of rid; curiously, we see a decrease in SL’s shift sensitivity as rid increases in FMoW-CS, however this has more to do with the ID test set accuracy decreasing due to the subsampling of the dataset.\n\n3Note that even when rid = 0, distribution shift between the ID and OOD splits exists, as the spurious\n\ncorrelation is not the only source of the distribution shift.\n\n8\n\nPublished as a conference paper at ICLR 2023\n\n(a) Camelyon17-CS\n\n(b) FMoW-CS\n\n(c) CdSprites\n\nFigure 3: Evaluations on Camelyon17-CS, FMoW-CS, and CdSprites with rid ∈ {0, 0.5, 1.0}. We report OOD test accuracy using OOD-trained linear head (acco(f, co)) and shift sensitivity (s). Blue lines are results averaged over AE models, green lines are SSL models and grey is SL.\n\n4 RELATED WORK\n\nWhile we are the first to systematically evaluate the OOD generalisation performance of unsupervised learning algorithms, there are other insightful work that considers the robustness to distribution shift of other existing, non-specialised methods/techniques. For instance, Liu et al. (2022) studies the impact of different pre-training set-ups to distribution shift robustness, including dataset, objective and data augmentation. Ghosal et al. (2022) focuses on architecture, and found that Vision Transformers are more robust to spurious correlations than ConvNets when using larger models and are given more training data; further, Liu et al. (2021) found that SSL is more robust to data imbalance. Azizi et al. (2022) also performed extensive studies on the generalisation performance of SSL algorithms on medical data. Interestingly, Robinson et al. (2021) also investigates the robustness of contrastive-SSL methods against extreme spurious correlation (i.e.simplicity bias). However, their work did not consider the linear head bias found in (Kirichenko et al., 2022; Kang et al., 2020) and led to opposing conclusions. In contrast, our work investigates the distribution shift performance of unsupervised algorithms, with experiments on both synthetic and realistic settings that go beyond the data imbalance regime. By isolating the linear head bias in our experiments, we find that unsupervised, especially SSL-learned representations, achieves similar if not better generalisation performance than SL under a wide range of distribution shift settings. See Appendix D for a more detailed discussion on distribution shift problems.\n\n5 CONCLUSION AND FUTURE WORK\n\nIn this paper, we investigate the robustness of both unsupervised (AE, SSL) and supervised (SL) objectives for distribution shift. Through extensive and principled experiments on both synthetic and realistic distribution shift tasks, we find unsupervised representation learning algorithms to consistently outperform SL when the distribution shift is extreme. In addition, we see that SSL’s OOD accuracy is comparable, if not better to SL in all experiments. This is particularly crucial, as most work studying distribution shift for images are developed in the SL regime. We hope that these results inspire more future work on unsupervised/semi-supervised representation learning methods for OOD generalisation. Another important finding is that unsupervised models’ performance remains relatively stable under distribution shift. This is especially crucial for the real-world application of these machine learning systems, as this indicates that the ID performance of SSL/AE algorithms are a more reliable indicator of how they would perform in different environments at deployment, while that of SL is not. It is also worth noting that while models trained with AE objectives are consistently the least sensitive to distribution shift on realistic datasets, their OOD performance can be low especially when presented with complex data (such as FMoW). This is consistent to the observation in prior work that these models can waste modelling capacity on high frequency details, and suggests that one should be careful about employing AE algorithms on large scale, complex tasks. Finally, a key contribution of this work is establishing the existence of linear head bias even for realistic distribution shift problems. We believe that using an OOD-trained linear head is necessary to be able to make comparisons between various algorithms irrespective of the final downstream task, and on the other hand, more efforts in the field of distribution shift could be devoted into re-balancing the linear layer.\n\n9\n\n0.00.51.0rid708090Test accuracySLSSLAE0.00.51.0rid203040Test accuracySLSSLAE0.00.51.0rid020406080100Test accuracy ()SLSSLAE0.00.51.0rid01020Shift Sensitivity sSLSSLAE0.00.51.0rid02040Shift Sensitivity sSLSSLAE0.00.51.0rid020406080100Shift Sensitivity s ()SLSSLAEPublished as a conference paper at ICLR 2023\n\nACKNOWLEDGEMENTS\n\nYS and PHST were supported by the UKRI grant: Turing AI Fellowship EP/W002981/1 and EPSRC/MURI grant: EP/N019474/1. We would also like to thank the Royal Academy of Engineering and FiveAI. YS was additionally supported by Remarkdip through their PhD Scholarship Programme. ID was supported by the SNSF grant #200021_188466. AS was partially supported by the ETH AI Center postdoctoral fellowship. Special thanks to Alain Ryser for suggesting the design of controllable versions of the WILDS dataset, and to Josh Dillon for helpful suggestions in the early stage of this project.\n\nREFERENCES\n\nAlexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy. Deep variational information\n\nbottleneck. In International Conference on Learning Representations, 2017. 2, 4\n\nMartin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.\n\narXiv:1907.02893, 2019. 1, 2, 20\n\nShekoofeh Azizi, Laura Culp, Jan Freyberg, Basil Mustafa, Sebastien Baur, Simon Kornblith, Ting Chen, Patricia MacWilliams, S Sara Mahdavi, Ellery Wulczyn, et al. Robust and efficient medical imaging with self-supervision. arXiv:2205.09723, 2022. 9\n\nHangbo Bao, Li Dong, and Furu Wei. Beit: Bert pre-training of image transformers. ArXiv preprint,\n\nabs/2106.08254, 2021. 8\n\nShai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman\n\nVaughan. A theory of learning from different domains. Machine learning, 2010. 20\n\nWieland Brendel and Matthias Bethge. Approximating cnns with bag-of-local-features models works surprisingly well on imagenet. In International Conference on Learning Representations, 2019. 6\n\nYuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. In\n\nInternational Conference on Learning Representations, 2016. 2, 4\n\nTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. A simple framework for contrastive learning of visual representations. In International Conference on Machine Learning, 2020a. 2, 4\n\nXinlei Chen and Kaiming He. Exploring simple siamese representation learning. In IEEE Conference\n\non Computer Vision and Pattern Recognition, 2021. 2, 4\n\nXinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved baselines with momentum\n\ncontrastive learning. arXiv preprint arXiv:2003.04297, 2020b. 5, 15\n\nVictor Guilherme Turrisi da Costa, Enrico Fini, Moin Nabi, Nicu Sebe, and Elisa Ricci. solo-learn: A library of self-supervised methods for visual representation learning. Journal of Machine Learning Research, 2022. 15\n\nJérôme Dockès, Gaël Varoquaux, and Jean-Baptiste Poline. Preventing dataset shift from breaking\n\nmachine-learning biomarkers. GigaScience, 2021. 1\n\nYaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal of machine learning research, 2016. 1, 2, 20\n\nRobert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A. Wichmann, and Wieland Brendel. Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. In International Conference on Learning Representations, 2019. 6\n\nRobert Geirhos, Jörn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2020. 2, 19\n\n10\n\nPublished as a conference paper at ICLR 2023\n\nSoumya Suvra Ghosal, Yifei Ming, and Yixuan Li. Are vision transformers robust to spurious\n\ncorrelations? arXiv:2203.09125, 2022. 9\n\nBen Glocker, Robert Robinson, Daniel C Castro, Qi Dou, and Ender Konukoglu. Machine learning with multi-site imaging data: an empirical study on the impact of scanner effects. arXiv:1910.04597, 2019. 1\n\nA. Gretton, AJ. Smola, J. Huang, M. Schmittfull, KM. Borgwardt, and B. Schölkopf. Covariate shift\n\nand local learning by distribution matching. 2009a. 20\n\nArthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt, and Bernhard Schölkopf. Covariate shift by kernel mean matching. Dataset shift in machine learning, 2009b. 20\n\nJean-Bastien Grill, Florian Strub, Florent Altché, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Ávila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, Rémi Munos, and Michal Valko. Bootstrap your own latent - A new approach to self-supervised learning. In Conference on Neural Information Processing Systems, 2020. 2, 4\n\nIshaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv:2007.01434,\n\n2020. 1, 2, 3\n\nSivan Harary, Eli Schwartz, Assaf Arbelle, Peter Staar, Shady Abu-Hussein, Elad Amrani, Roei Herzig, Amit Alfassy, Raja Giryes, Hilde Kuehne, et al. Unsupervised domain generalization In IEEE Conference on Computer Vision and Pattern by learning a bridge across domains. Recognition, 2022. 20\n\nKaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross B. Girshick. Momentum contrast for unsupervised visual representation learning. In IEEE Conference on Computer Vision and Pattern Recognition, 2020. 5, 15\n\nJoseph Henrich, Steven J Heine, and Ara Norenzayan. Most people are not weird. Nature, 2010. 1\n\nKatherine Hermann and Andrew Lampinen. What shapes feature representations? exploring datasets,\n\narchitectures, and training. Conference on Neural Information Processing Systems, 2020. 2\n\nIrina Higgins, Loïc Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017. 2, 4\n\nWeihua Hu, Gang Niu, Issei Sato, and Masashi Sugiyama. Does distributionally robust supervised learning give robust classifiers. In International Conference on Machine Learning, 2018. 20\n\nGao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks. In IEEE Conference on Computer Vision and Pattern Recognition, 2017. 7, 18\n\nDimitris Kalimeris, Gal Kaplun, Preetum Nakkiran, Benjamin Edelman, Tristan Yang, Boaz Barak, and Haofeng Zhang. Sgd on neural networks learns functions of increasing complexity. Conference on Neural Information Processing Systems, 2019. 2\n\nBingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition. In International Conference on Learning Representations, 2020. 3, 9, 20\n\nByungju Kim, Hyunwoo Kim, Kyungsu Kim, Sungjin Kim, and Junmo Kim. Learning not to learn: Training deep neural networks with biased data. In IEEE Conference on Computer Vision and Pattern Recognition, 2019. 19\n\nDiederik P. Kingma and Max Welling. Auto-encoding variational bayes. In International Conference\n\non Learning Representations, 2014. 2, 4\n\n11\n\nPublished as a conference paper at ICLR 2023\n\nPolina Kirichenko, Pavel Izmailov, and Andrew Gordon Wilson. Last layer re-training is sufficient\n\nfor robustness to spurious correlations. arXiv:2204.02937, 2022. 9, 20\n\nPang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, Berton Earnshaw, Imran Haque, Sara M. Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn, and Percy Liang. WILDS: A benchmark of in-the-wild distribution shifts. In International Conference on Machine Learning, 2021. 1, 2, 3, 4, 7, 8, 17, 18\n\nMasanori Koyama and Shoichiro Yamaguchi. Out-of-distribution generalization with maximal\n\ninvariant predictor. In arXiv e-prints, 2021. 20\n\nSebastian Lapuschkin, Stephan Wäldchen, Alexander Binder, Grégoire Montavon, Wojciech Samek, and Klaus-Robert Müller. Unmasking clever hans predictors and assessing what machines really learn. Nature communications, 2019. 19\n\nRonan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers, Matthew Peters, Ashish Sabharwal, and Yejin Choi. Adversarial filters of dataset biases. In International Conference on Machine Learning, 2020. 19\n\nHong Liu, Jeff Z HaoChen, Adrien Gaidon, and Tengyu Ma. Self-supervised learning is more robust\n\nto dataset imbalance. arXiv:2110.05025, 2021. 9\n\nZiquan Liu, Yi Xu, Yuanhong Xu, Qi Qian, Hao Li, Rong Jin, Xiangyang Ji, and Antoni B Chan. An empirical study on distribution shift robustness from the perspective of pre-training and data augmentation. arXiv:2205.12753, 2022. 9\n\nDavid Lopez-Paz and Marc’Aurelio Ranzato. Gradient episodic memory for continual learning. In\n\nConference on Neural Information Processing Systems, 2017. 20\n\nXu Luo, Longhui Wei, Liangjian Wen, Jinrong Yang, Lingxi Xie, Zenglin Xu, and Qi Tian. Rectifying the shortcut learning of background for few-shot learning. Conference on Neural Information Processing Systems, 2021. 19\n\nLoic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner. dsprites: Disentanglement\n\ntesting sprites dataset. https://github.com/deepmind/dsprites-dataset/, 2017. 6\n\nAditya Krishna Menon, Ankit Singh Rawat, and Sanjiv Kumar. Overparameterisation and worst-case generalisation: friend or foe? In International Conference on Learning Representations, 2020. 3\n\nAditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning, 2021. 8\n\nJoshua Robinson, Li Sun, Ke Yu, Kayhan Batmanghelich, Stefanie Jegelka, and Suvrit Sra. Can contrastive learning avoid shortcut solutions? Conference on Neural Information Processing Systems, 2021. 9, 20\n\nDavid E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning internal representations by error propagation. Technical report, California Univ San Diego La Jolla Inst for Cognitive Science, 1985. 2, 4\n\nShiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, and Percy Liang. Distributionally robust\n\nneural networks. In International Conference on Learning Representations, 2020. 1, 2, 20\n\nHarshay Shah, Kaustav Tamuly, Aditi Raghunathan, Prateek Jain, and Praneeth Netrapalli. The pitfalls of simplicity bias in neural networks. In Conference on Neural Information Processing Systems, 2020. 1, 2, 4, 5, 6, 15, 19\n\nYuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve. Gradient matching for domain generalization. In International Conference on Learning Representations, 2022. 1, 2, 4, 5, 6, 20\n\n12\n\nPublished as a conference paper at ICLR 2023\n\nBaochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In\n\nEuropean conference on computer vision, pages 443–450. Springer, 2016. 1\n\nRohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig Schmidt. Measuring robustness to natural distribution shifts in image classification. Advances in Neural Information Processing Systems, 33:18583–18599, 2020. 5\n\nDamien Teney, Ehsan Abbasnejad, Simon Lucey, and Anton van den Hengel. Evading the simplicity bias: Training a diverse set of models discovers solutions with superior ood generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16761–16772, 2022. 2, 19\n\nAntonio Torralba and Alexei A Efros. Unbiased look at dataset bias. In CVPR 2011, pages 1521–1528.\n\nIEEE, 2011. 2, 19\n\nHaohan Wang, Songwei Ge, Zachary C. Lipton, and Eric P. Xing. Learning robust global representations by penalizing local predictive power. In Advances in Neural Information Processing Systems, volume 32, pages 10506–10518, 2019. 20\n\nXingxuan Zhang, Linjun Zhou, Renzhe Xu, Peng Cui, Zheyan Shen, and Haoxin Liu. Towards unsupervised domain generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4910–4920, 2022. 20\n\n13\n\nPublished as a conference paper at ICLR 2023\n\n(a) acco(f, co) (%).\n\n(b) Shift sensitivity s (%).\n\n(c) Linear head bias b (%).\n\nFigure 4: Evaluations on the CdSprites dataset with rid ∈ {0.25, 0.5, 0.75, 1.0}. We report shape classification accuracy using OOD-trained linear head (acco(f, co)), shift sensitivity s, and linear head bias b. Results are shown for individual models from the class of AE (blue), SSL (green), and SL (grey) algorithms. The black horizontal line denotes the random baseline (33.3% for three classes).\n\nA ADDITIONAL EXPERIMENTAL RESULTS\n\nA.1 CDSPRITES\n\nIn addition to our results in table 2, where we use a dataset with perfectly correlated features (rid = 1) to train the backbones, in fig. 4 we vary rid to analyse the effect of imperfectly correlated features. Notably, with imperfect correlation (rid < 1), the OOD linear heads trained on top of the SL and SSL backbones perform perfectly. For the AE, we observe that the performance of the OOD linear head does not depend on the correlation rid in the data used to train the backbones. Our results suggest that with imperfect correlation between features, SL and SSL models learn a linearly separable representation of the features, whereas AE does not.\n\nIn fig. 5 we provide an ablation where we also vary rood, the correlation in the data used to train and evaluate the linear head. Figures 5b and 5c corroborate our results that SSL performs on par with SL for rid < 1 and strictly better when rid = 1. For the AE (Figure 5a), we observe an interesting pattern where the performance of the OOD linear head depends on the OOD correlation rood, but not on the correlation rid in the data used to train the backbones. Hence, the ablation corroborates our result that SL and SSL models learn a linearly separable representation of the shape and color features when there is an imperfect correlation between the features, whereas AE does not.\n\n(a) AE\n\n(b) SSL\n\n(c) SL\n\nFigure 5: Correlation coefficient ablation for CdSprites. Shape classification accuracy for the CdSprites experiment with varying correlation of the ID training data (rid, x-axis) and OOD training and test data (rood, y-axis). Backbones were trained on data with correlation rid and linear classifiers trained and evaluated on top of the frozen backbones with correlation rood.\n\nA.2 CAMELYON17-C AND FMOW-C\n\nIn this section we report the numerical results for Camelyon17-C and FMoW-C with rid = 0.5 (see tables 5 and 6) and rid = 1 (see tables 7 and 8).\n\n14\n\n0.000.250.500.751.00rid020406080100Test accuracy ()AEVAEIWAESimCLRBYOLSimSiamSLrandom0.000.250.500.751.00rid020406080100Shift Sensitivity s ()AEVAEIWAESimCLRBYOLSimSiamSL0.000.250.500.751.00rid020406080100Linear head bias bAEVAEIWAESimCLRBYOLSimSiamSL0.00.250.50.751.0rid1.00.750.50.250.0rood1001001001001008383.683.383.783.868.168.267.768.768.457.356.855.957.356.453.252.351.552.951.14050607080901000.00.250.50.751.0rid1.00.750.50.250.0rood1001001001001001001001001009510010010099.991.610010010099.989.110010010099.986.44050607080901000.00.250.50.751.0rid1.00.750.50.250.0rood10010010010010010010010010079.410010010010065.510010010010051.710010010010044.4405060708090100Published as a conference paper at ICLR 2023\n\nTable 5: Evaluations on test set of Camelyon17C with rid = 0.5, all metrics computed using average accuracy.\n\nTable 6: Evaluations on test set of FMoW-C with rid = 0.5, all metrics computed using worstgroup accuracy.\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMetrics (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n80.4 (±3e+0) 88.6 (±2e+0) 87.8 (±1e+0) 88.5 (±2e+0) 86.3 (±2e+0)\n\n84.5 (±2e+0) 86.1 (±2e+0) 86.4 (±2e+0) 85.7 (±2e+0)\n\n6.0 (±2e+0) -0.5 (±1e+0) -0.2 (±1e+0) 0.1 (±9e-1) 1.4 (±1e+0)\n\n8.0 (±1e+0) 5.7 (±1e+0) 4.5 (±2e+0) 6.1 (±2e+0)\n\n19.0 (±4e+0) 17.8 (±6e+0) 26.4 (±6e+0) 19.7 (±6e+0) 20.7 (±5e+0)\n\n6.6 (±2e+0) 8.3 (±4e+0) 8.8 (±4e+0) 7.9 (±3e+0)\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMetrics (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n23.4 (±1e+0) 18.7 (±1e+0) 18.5 (±2e+0) 21.4 (±3e-1) 20.5 (±2e+0)\n\n29.5 (±9e-1) 27.9 (±2e+0) 32.6 (±3e+0) 30.0 (±2e+0)\n\n8.6 (±6e-1) 7.7 (±6e-1) 7.3 (±2e+0) 4.0 (±4e-1) 6.9 (±8e-1)\n\n9.2 (±6e-1) 7.5 (±1e+0) 7.9 (±2e+0) 8.2 (±1e+0)\n\n4.2 (±8e-1) 1.5 (±6e-1) 2.2 (±1e+0) 3.9 (±7e-1) 3.0 (±9e-1)\n\n6.9 (±7e-1) 4.6 (±1e+0) 8.5 (±2e+0) 6.7 (±1e+0)\n\nSL\n\nSupervised\n\n81.5 (±5e+0)\n\n13.2 (±3e+0)\n\n3.4 (±4e+0)\n\nSL\n\nSupervised\n\n32.3 (±3e+0)\n\n25.1 (±3e+0)\n\n6.0 (±2e+0)\n\nTable 7: Evaluations on test set of Camelyon17C with rid = 1, all metrics computed using average accuracy.\n\nTable 8: Evaluations on test set of FMoW-C with rid = 1, all metrics computed using worst-group accuracy.\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMetrics (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n75.7 (±5e+0) 86.0 (±3e+0) 86.1 (±1e+0) 84.7 (±2e+0) 83.1 (±3e+0)\n\n85.8 (±8e+1) 82.1 (±1e+0) 74.8 (±5e+0) 80.9 (±2e+0)\n\n7.3 (±2e+0) 2.7 (±1e+0) 2.6 (±7e-1) 3.8 (±1e+0) 4.1 (±1e+0)\n\n2.8 (±4e-1) 6.0 (±7e-1) 10.3 (±2e+0) 6.3 (±1e+0)\n\n35.1 (±4e+0) 12.4 (±4e+0) 9.1 (±3e+0) 15.5 (±4e+0) 18.0 (±4e+0)\n\n6.2 (±2e+0) 8.3 (±4e+0) -2.2 (±4e+0) 4.1 (±3e+0)\n\nRegime Method\n\nAE\n\nAE VAE IWAE β-VAE\n\nAE average\n\nSSL\n\nSimCLR SimSiam BYOL\n\nSSL average\n\nMetrics (%)\n\nacco(f, co) ↑\n\ns ↓\n\nb\n\n22.4 (±1e+0) 16.6 (±9e-1) 17.2 (±5e-1) 16.7 (±3e-1) 18.3 (±3e+0)\n\n26.3 (±1e+0) 27.1 (±5e-1) 27.4 (±2e+0) 26.9 (±6e-1)\n\n10.0 (±6e-1) 8.6 (±1e+0) 8.7 (±6e-1) 7.9 (±4e-1) 8.8 (±7e-1)\n\n10.6 (±8e-1) 6.3 (±7e-1) 11.1 (±1e+0) 9.3 (±1e+0)\n\n3.8 (±7e-1) 2.8 (±8e-1) 3.8 (±5e-1) 3.2 (±4e-1) 3.4 (±6e-1)\n\n7.2 (±1e+0) 7.8 (±3e-1) 6.5 (±2e+0) 7.2 (±1e+0)\n\nSL\n\nSupervised\n\n73.4 (±6e+0)\n\n10.7 (±3e+0)\n\n5.9 (±8e+0)\n\nSL\n\nSupervised\n\n25.7 (±5e-1)\n\n12.3 (±2e+0)\n\n5.3 (±1e+0)\n\nB ARCHITECTURE AND HYPERPARAMETERS\n\nIn this appendix we list the architecture and hyperparameters used in our experiments. Our code is developed on the amazing solo-learn code base (da Costa et al., 2022), which is originally developed as a library for SSL algorithms. For all experiments we follow the standard set of augmentations established in He et al. (2020); Chen et al. (2020b), including random resize crop, random color jittering, random grayscale, random Gaussian blur, random solorisation and random horizontal flip. An exception is the CdSprites experiment where we remove color jittering, as color classification is one of the tasks we are interested in and color jittering would add noise to the labels. For MNIST-CIFAR, we independently apply random augmentation to MNIST and CIFAR respectively (drawn from the same set of augmentations as detailed above) and then concatenate them to construct training examples.\n\nPlease see implementation details for each dataset in the respective subsection.\n\nB.1 MNIST-CIFAR\n\nWe use the same hyperparameter search range for models in each category of AE, SSL and SL, as outlined in table 9. The chosen hyperparameters for each model are specified in table 10.\n\nIn Shah et al. (2020) where MNIST-CIFAR was originally proposed, authors utilised more complex backbone architecture such as DenseNet and MobileNet. However in our experiments, we find that a lightweight 4-layer CNN can already achieve very high accuracy on both MNIST and CIFAR. The architecture of the CNN we use can be found in table 11. Note that for SL and SSL we only use the encoder and for AE we use the decoder as well. The size of base channel C and latent dimension L are found through hyperparameter search.\n\n15\n\nPublished as a conference paper at ICLR 2023\n\nTable 9: Hyperparameter search range for MNIST-CIFAR, including base channel size of CNN (C), learning rate (lr.), weight decay (wd.), optimiser (optim.), learning rate scheduler (lr. scheduler).\n\nC\n\nlr.\n\nwd.\n\nOptim.\n\nlr. scheduler\n\nAE {16, 32, 64, 128} SSL {16, 32, 64, 128} {16, 32, 64, 128} SL\n\n{1e-4, 5e-4, 1e-3, 5e-3, 1e-2} uniformly sampled from [0.1, 1] {1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 1e-1, 5e-1}\n\n{0, 1e-4} {0, 1e-4} {0, 1e-4}\n\n{Adam, SGD} {Adam, SGD} {Adam, SGD}\n\n{warmup cosine, step, none} {warmup cosine, step, none} {warmup cosine, step, none}\n\nTable 10: Chosen hyperparameters for MNIST-CIFAR including latent dimension (L), base feature size of CNN (C), batch size (B), learning rate (lr.), weight decay (wd.), optimiser (optim.), learning rate scheduler (lr.scheduler).\n\nAE VAE IWAE β-VAE\n\nSimCLR BYOL SimSiam\n\nSupervised\n\nL\n\n128 128 128 128\n\n128 128 128\n\n128\n\nC\n\n16 32 32 16\n\n32 64 128\n\n16\n\nB\n\n128 128 128 128\n\n128 128 128\n\n128\n\nlr.\n\nwd. Optim.\n\nlr. scheduler\n\n1e-3 1e-4 1e-4 1e-4\n\n6e-1 7e-1 6e-1\n\n1e-4\n\n0 0\n0 0\n\n1e-4 0\n1e-5\n\n0\n\nAdam warmup cosine Adam warmup cosine Adam Adam\n\nstep step\n\nSGD SGD SGD\n\nSGD\n\nwarmup cosine warmup cosine warmup cosine\n\nwarmup cosine\n\nEncoder Input ∈ R3×64×32 4x4 conv. C stride 2x2 pad 1x1 & ReLU 4x4 conv. 2C stride 2x2 pad 1x1 & ReLU 4x4 conv. 4C stride 2x2 pad 1x1 & ReLU 4x1 conv. 4C stride 2x1 pad 1x0 & ReLU 4x4 conv. L stride 1 pad 0, 4x4 conv. L stride 1x1 pad 0x0\n\nDecoder Input ∈ RL 4x4 upconv. 4C stride 1x1 pad 0x0 & ReLU 4x1 upconv. 4C stride 2x1 pad 1x0 & ReLU 4x4 upconv. 2C stride 2x2 pad 1x1 & ReLU 4x4 upconv. C stride 2x2 pad 1x1 & ReLU 4x4 upconv. 3 stride 2x2 pad 1x1 & Sigmoid\n\nTable 11: CNN architecture, MNIST-CIFAR dataset.\n\nB.2 CDSPRITES\n\nWe found all models to be relatively robust to hyperparameters, as most configurations result in close to perfect shape and color classification accuracy on the ID validation set. The chosen hyperparameters for each model are specified in table 12. We omit β-VAE from the comparison, as we empirically found that β = 1 leads to the best performance on the ID validation set and therefore the results for the β-VAE would be similar to the VAE. We use the same augmentations (random crops and horizontal flips) for all models and use no color augmentations in order to keep the invariance of the learned representations with respect to color. The encoder and decoder architectures are described in table 13.\n\n16\n\nPublished as a conference paper at ICLR 2023\n\nTable 14: Hyperparameter search range for Camelyon17, including decoder type, latent dimension (L), learning rate (lr.), weight decay (wd.), optimiser (optim.), learning rate scheduler (lr. scheduler).\n\nDecoder type\n\nL\n\nlr.\n\nwd.\n\nOptim.\n\nlr. scheduler\n\nAE SSL SL\n\n[CNN, MLP, ResNet] -\n-\n\n{256, 512, 1024} {256, 512, 1024} {256, 512, 1024}\n\n{1e-4, 5e-4, 1e-3, 5e-3, 1e-2} {1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 1e-1, 5e-1, 1} {1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 1e-1, 5e-1}\n\n{0, 1e-4} {0, 1e-3, 1e-4, 1e-5} {0, 1e-4}\n\n{Adam, SGD} {Adam, SGD} {Adam, SGD}\n\n{warmup cosine, step, none} {warmup cosine, step, none} {warmup cosine, step, none}\n\nTable 12: Chosen hyperparameters for CdSprites including latent dimension (L), base feature size of CNN (C), batch size (B), learning rate (lr.), weight decay (wd.), optimiser (optim.), learning rate scheduler (lr.scheduler).\n\nAE VAE IWAE\n\nSimCLR BYOL SimSiam\n\nL\n\n512 512 512\n\n64 64 64\n\nSupervised\n\n512\n\nC\n\n64 64 64\n\n32 32 32\n\n64\n\nB\n\n128 128 128\n\n64 64 64\n\n128\n\n5e-5 5e-5 5e-5\n\n5e-3 5e-1 8e-2\n\n5e-5\n\nlr.\n\nwd. Optim.\n\n1e-4 Adam 1e-4 Adam 1e-4 Adam\n\nnone\n\nnone none none\n\n1e-5 1e-5 1e-5\n\nSGD SGD SGD\n\nwarmup cosine warmup cosine warmup cosine\n\n1e-4 Adam\n\nnone\n\nEncoder Input ∈ R3×64×64 4x4 conv. C stride 2x2 pad 1x1 & ReLU 4x4 conv. 2C stride 2x2 pad 1x1 & ReLU 4x4 conv. 4C stride 2x2 pad 1x1 & ReLU 4x4 conv. 8C stride 2x2 pad 1x1 & ReLU 4x4 conv. L stride 1 pad 0\n\nDecoder Input ∈ RL 4x4 upconv. 8C stride 1x1 pad 0x0 & ReLU 4x4 upconv. 4C stride 2x2 pad 1x1 & ReLU 4x4 upconv. 2C stride 2x2 pad 1x1 & ReLU 4x4 upconv. C stride 2x2 pad 1x1 & ReLU 4x4 upconv. 3 stride 2x2 pad 1x1\n\nTable 13: CNN architecture, CdSprites dataset.\n\nB.3 CAMELYON17 AND FMOW\n\nFor hyperparameters including batch size, max epoch and model selection criteria, we follow the same protocol as in WILDS (Koh et al., 2021): for Camelyon17 we use a batch size of 32, train all models for 10 epochs and select the model that results in the highest accuracy on the validation set, and for FMoW the batch size is 32, max epoch is 60 and model selection criteria is worst group accuracy on OOD validation set. For the rest, we use the same hyperparameter search range for models in each category of AE, SSL and SL, as outlined in table 14. The chosen hyperparameters for Camelyon17 are specified in table 15, and for FMoW in table 16. For Camelyon17-C and FMoW-C we use these same hyperparameters.\n\nTable 15: Chosen hyperparameters for Camelyon17 including latent dimension (L), learning rate (lr.), weight decay (wd.), optimiser (optim.), learning rate scheduler (lr. scheduler).\n\nDecoder\n\nlr.\n\nwd. Optim.\n\nlr. scheduler\n\nAE VAE IWAE β-VAE\n\nSimCLR BYOL SimSiam\n\nSupervised\n\nResNet MLP MLP MLP\n\n- -\n-\n\n-\n\n5e-4 1e-4 1e-4 1e-4\n\n1e-1 1e-1 1e-1\n\n1e-3\n\n1e-5 0\n0 0\n\n0 1e-5 1e-5\n\n1e-3\n\n17\n\nSGD Adam Adam Adam\n\nSGD SGD SGD\n\nSGD\n\nwarmup cosine none none none\n\nnone warmup cosine warmup cosine\n\nnone\n\nPublished as a conference paper at ICLR 2023\n\nTable 16: Chosen hyperparameters for FMoW including latent dimension (L), learning rate (lr.), weight decay (wd.), optimiser (optim.), learning rate scheduler (lr. scheduler).\n\nDecoder\n\nlr.\n\nwd. Optim.\n\nlr. scheduler\n\nAE VAE IWAE β-VAE\n\nSimCLR BYOL SimSiam\n\nSupervised\n\nCNN MLP MLP MLP\n\n- -\n-\n\n-\n\n1e-1 1e-6 1e-6 1e-6\n\n5e-4 1e-2 5e-4\n\n1e-4\n\n1e-4 SGD 1e-4 Adam 1e-4 Adam 1e-4 Adam\n\n1e-3 1e-4 0\n\nSGD SGD SGD\n\n0\n\nAdam\n\nnone step step step\n\nstep step step\n\nstep\n\nWe follow Koh et al. (2021) and use DenseNet121 (Huang et al., 2017) as backbone architecture. For the decoder of the AE models, we perform hyperparameter search between three architectures: a CNN (see table 17), a simple 3-layer MLP (see table 18) and a ResNet-like decoder with skip connections (see table 19).\n\nCNN, Decoder Input ∈ RL 4x4 upconv. 8C stride 2x2 pad 1x1 & ReLU 4x4 upconv. 8C stride 2x2 pad 0x0 & ReLU 4x4 upconv. 4C stride 2x2 pad 1x1 & ReLU 4x4 upconv. 2C stride 2x2 pad 1x1 & ReLU 4x4 upconv. C stride 2x2 pad 1x1 & ReLU 4x4 upconv. 3 stride 2x2 pad 1x1 & Sigmoid\n\nTable 17: CNN architecture, Camelyon17 dataset.\n\nMLP, Decoder Input ∈ RL fc. 2L & ReLU fc. 4L & ReLU fc. 3*96*96 & ReLU\n\nTable 18: MLP architecture, Camelyon17 dataset.\n\nResNet, Decoder Input ∈ RL fc. 2048 & ReLU 3x3 conv. 16C stride 1x1 pad 1x1 3x3 conv. 16C stride 1x1 pad 1x1 x2 upsample 3x3 conv. 8C stride 1x1 pad 1x1 3x3 conv. 8C stride 1x1 pad 1x1 x2 upsample 3x3 conv. 8C stride 1x1 pad 1x1 3x3 conv. 8C stride 1x1 pad 1x1 3x3 conv. 3 stride 1x1 pad 1x1\n\nTable 19: ResNet decoder architecture, Camelyon17 dataset.\n\nC CONSTRUCTING CAMELYON17-CS AND FMOW-CS\n\nWe subsample Camelyon17 and FMoW dataset to create varying degree of spurious correlation between the domain and label information. We refer to these datasets as Camelyon17-CS and FMoW-CS. To construct such datasets, we first find some domain-label pairing in each dataset, such that if we sample the dataset according to this pairing, the population of each class with respect to the total number of examples in the dataset remains relatively stable. The rid = 1 versions of both Camelyon17-CS and FMoW-CS can be acquired by simply subsampling the dataset following the domain label pairing; to ensure fairness in comparison, when constructing the rid ∈ {0, 0.5} versions of these datasets, we first mix in anti-bias samples (i.e. samples that are not in the domain-label\n\n18\n\nPublished as a conference paper at ICLR 2023\n\nFigure 6: Linear head bias on controllable shift datasets\n\npairing) to change the spurious correlation, and then subsample the dataset such that the size of the dataset is the same as the rid = 1 version.\n\nThe domain-label pairing of Camelyon17-CS can be found in table 20 and FMoW-CS in table 21.\n\nLinear head bias We also plot the linear head bias for the experiments conducted on Camelyon17CS, FMoW-CS, and CdSprites in Figure 6. The experimental protocol follows that from Figure 3.\n\nTable 20: Domain-label pairing for Camelyon17-CS.\n\nDomain (hospital)\n\nLabel\n\nHospital 1, 2 Hospital 3\n\nBenign Malignant\n\nTable 21: Domain-label pairing for FMoW-CS.\n\nDomain (region)\n\nLabel\n\nAsia\n\nEurope\n\nAfrica\n\nAmericas\n\nOceania\n\nMilitary facility, multi-unit residential, tunnel opening, wind farm, toll booth, road bridge, oil or gas facility, helipad, nuclear powerplant, police station, port\n\nSmokestack, barn, waste disposal, hospital, water treatment facility, amusement park, fire station, fountain, construction site, shipyard, solar farm, space facility\n\nPlace of worship, crop field, dam, tower, runway, airport, electric substation, flooded road, border checkpoint, prison, archaeological site, factory or powerplant, impoverished settlement, lake or pond\n\nRecreational facility, swimming pool, educational institution, stadium, golf course, office building, interchange, car dealership, railway bridge, storage tank, surface mine, zoo\n\nSingle-unit residential, parking lot or garage, race track, park, ground transportation station, shopping mall, airport terminal, airport hangar, lighthouse, gas station, aquaculture, burial site, debris or rubble\n\nD OTHER RELATED WORK\n\nExplicit, extreme distribution shift Refers to when the features that caused distribution shift is explicit, known, controllable, and in some cases, extreme (e.g. MNIST-CIFAR, CdSprites). This type of settings are popular in works that investigate simplicity bias (Shah et al., 2020), dataset bias (Torralba and Efros, 2011) and shortcut learning (Geirhos et al., 2020; Lapuschkin et al., 2019), as it allows for users to easily adjust the level of distribution shift between train and test set. Various specialised methods that either mitigate or address these problems under the supervised learning regime have been proposed, including Teney et al. (2022) that proposes to find shortcut solutions by ensembles, Luo et al. (2021) that avoids shortcut learning by extracting foreground objects for representation learning only, as well as Torralba and Efros (2011); Kim et al. (2019); Le Bras et al. (2020) that re-sample the dataset to reduce the spurious correlation.\n\n19\n\n0.00.51.0rid02040Linear head bias bSLSSLAE0.00.51.0rid0.02.55.07.510.0Linear head bias bSLSSLAE0.00.51.0rid020406080100Linear head bias bSLSSLAEPublished as a conference paper at ICLR 2023\n\nImportantly Kirichenko et al. (2022); Kang et al. (2020) shows that this extreme simplicity bias can be mitigated in some cases by retraining the final linear layer. This is a game changer, as it for the first time decouples the bias of the linear head from that of the main representation learning model. Interestingly, Robinson et al. (2021) also investigates the robustness of contrastive-SSL methods against simplicity bias. However, without training the linear head on OOD data, their finding is opposite to ours — that SSL methods are not able to avoid shortcut solutions.\n\nImplicit, subtle distribution shift This type of problem is commonly seen in realistic distribution shift datasets (such as WILDS) and are often studied in Domain generalisation (DG). In this regime, the training data are sampled from multiple domains, while data from a new, unseen target domain is used as test set. Note that here we omitted the discussion on domain adaptation (DA), as in DA models typically have access to unlabelled data from the target domain, which is different from the settings we consider in this work.\n\nThere are mainly two lines of work in DG, namely 1) Distributional Robustness approaches (DRO), which minimises the worst group accuracy to address covariate shift (Gretton et al., 2009a;b) and subpopulation shift (Sagawa et al., 2020; Hu et al., 2018); 2) Domain invariance, which consists of methods that directly learn representations that are invariant across domains (Ben-David et al., 2010; Ganin et al., 2016; Wang et al., 2019), encourage the alignment of gradients from different domains (Koyama and Yamaguchi, 2021; Lopez-Paz and Ranzato, 2017; Shi et al., 2022), or optimise for representations that result in the same optimal classifier for different domains (Arjovsky et al., 2019). Apart from these supervised learning methods, the recent advancement of SSL has also inspired works in unsupervised domain generalisation (Zhang et al., 2022; Harary et al., 2022). While all these methods achieved impressive performance, we note that they are all specially designed for DG with the majority of the methods relying on domain information and label information. In contrast, our work studies how existing standard representation learning methods such as SSL and AE performs on DG tasks, with none of the methods relying on human annotations.\n\n20",
  "translations": [
    "# Summary Of The Paper\n\nThis paper provides a comprehensive empirical study of the OOD generalization performance of SSL, AE and SL. In addition to testing standard algorithms on standard distribution shift datasets, the paper proposes a new controllable realistic distribution shift task, and also consider a setting where the linear head is retrained on the OOD data. Results suggest that SSL and AE are more robust to distribution shift than SL.\n\n# Strength And Weaknesses\n\nStrength:\n- The experiments are very comprehensive and implementation details are provided.\n- The construction of the controllable distribution shift dataset is novel.\n- As far as I know, this is the first work that explicitly takes retraining the linear head into consideration, and compare its performance side by side with using the ID linear head. This could be an important point that is worth highlighting to the community.\n\nWeakness\n- There's limited explanation about why SSL/AE works better than SL on shifted distribution beyond what people already know in the literature.\n- To some extent, I feel there's nothing surprising about the findings in this paper. Although it's always nice to have more comprehensive experiments, it's unclear what's the conceptual insight that a reader can gain from this paper.\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThe paper is clear and the writing is of good quality.\n\n# Summary Of The Review\n\nI think this paper provides a reasonably good empirical comparison between SSL/AE and SL in various settings with different datasets. Although the result doesn't sound surprising, it's good to have this as an addition to the community, hence I would love to recommend for its acceptance.\n\n# Correctness\n\n4: All of the claims and statements are well-supported and correct.\n\n# Technical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.\n\n# Empirical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.",
    "# Summary Of The Paper\nThis paper investigates the robustness of unsupervised representation learning methods, specifically Self-Supervised Learning (SSL) and Auto-Encoders (AE), in comparison to supervised learning (SL) when subjected to distribution shifts. The authors systematically evaluate various SSL and AE methods against standard SL techniques across both synthetic and realistic datasets, demonstrating that unsupervised methods tend to outperform supervised methods under extreme distribution shifts. They also introduce novel \"controllable\" datasets to facilitate the examination of distribution shifts, and propose a method for isolating the impact of classifier bias through retraining on out-of-distribution (OOD) data.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its systematic evaluation of unsupervised methods in the context of distribution shifts, filling a notable gap in existing literature that has predominantly focused on supervised learning. The introduction of controllable datasets and the OOD linear head evaluation method are significant contributions that enhance the reproducibility and relevance of the findings. However, a potential weakness is the reliance on specific datasets, which may limit the generalizability of the results. Furthermore, while the results are promising, the paper could benefit from a more extensive discussion on the implications of these findings for real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its methodology, experimental setup, and findings. The introduction effectively contextualizes the research problem, while the results are supported by comprehensive experiments across various datasets. The novelty of the approach is notable, particularly in the development of controllable datasets and the evaluation of classifier bias. Reproducibility is enhanced through the clear description of methodologies and datasets used, although the practical applicability of the findings in diverse real-world scenarios could be elaborated upon.\n\n# Summary Of The Review\nOverall, the paper makes a valuable contribution to the understanding of unsupervised representation learning under distribution shifts, offering robust empirical results and novel methodologies. While the findings are significant, a broader applicability discussion would strengthen the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods, specifically self-supervised learning (SSL) and auto-encoder (AE) algorithms, against distribution shifts, contrasting these with supervised learning (SL). The authors propose that the input-driven nature of unsupervised methods leads to more robust representations compared to the target-driven objectives of SL. They introduce controllable datasets designed to study the performance of various learning algorithms under distribution shifts and propose an evaluation protocol that uses an out-of-distribution (OOD)-trained linear classifier to mitigate bias in performance evaluation. The findings reveal that SSL and AE significantly outperform SL in scenarios with extreme distribution shifts, highlighting the benefits of unsupervised learning in real-world applications.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its comprehensive evaluation of SSL and AE across various datasets and conditions, as well as its novel contributions in creating controllable datasets for studying the effects of distribution shifts. The introduction of an OOD-trained linear head to isolate bias is particularly noteworthy and enhances the rigor of the evaluation. However, the performance of AE models is relatively poor on more complex datasets, such as FMoW, which raises concerns about their applicability in real-world tasks. Additionally, the generalizability of the findings across other domains remains uncertain, and the necessity of retraining the linear head could complicate comparisons with other studies.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its methodology and findings, making it accessible to readers. The quality of the experimental design is commendable, with a systematic approach to evaluating the robustness of different learning algorithms. The novelty of the research is significant, particularly in the development of controllable datasets and the evaluation protocol. However, while the experiments are well-documented, the reproducibility could be impacted by the specific protocols employed for training and evaluation, which may not align with standard practices in the field.\n\n# Summary Of The Review\nOverall, the paper presents a compelling argument for the robustness of unsupervised representation learning methods in the face of distribution shifts, supported by a thorough experimental analysis. While the contributions are significant, particularly in the context of controllable datasets and evaluation techniques, the limitations of AE models and the generalizability of the findings suggest areas for further research.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" investigates the robustness of unsupervised representation learning approaches, such as self-supervised learning (SSL) and autoencoders (AE), in the face of distribution shifts, contrasting their performance with supervised learning (SL) methods. The authors systematically evaluate various SSL and AE algorithms using both synthetic and realistic datasets, introducing controllable versions of existing datasets to study robustness under different conditions. The findings indicate that unsupervised methods exhibit better generalization capabilities than supervised counterparts, especially in scenarios with significant distribution shifts.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its systematic approach to evaluating unsupervised representation learning against supervised methods, highlighting a gap in the existing literature focused predominantly on SL. The introduction of controllable yet realistic datasets allows for a more nuanced understanding of robustness. Additionally, the authors effectively isolate linear head bias, providing a clearer assessment of model performance. However, the paper could benefit from additional exploration of the limitations of unsupervised methods, particularly in terms of their performance on more complex real-world tasks where the distribution shifts may be less controllable.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its methodology, findings, and implications. The theoretical foundations are clearly defined, and the results are presented with appropriate metrics that bolster the claims made. The novelty is significant, as it addresses an overlooked area in the study of distribution shifts and representation learning. Moreover, the use of controllable datasets enhances reproducibility, although the paper could provide more detailed experimental procedures to further this aspect.\n\n# Summary Of The Review\nOverall, this paper makes a valuable contribution to the understanding of robustness in representation learning by demonstrating that unsupervised methods can outperform supervised methods under distribution shifts. The systematic evaluation and introduction of controllable datasets are commendable, though the paper could delve deeper into the limitations of the proposed methods.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" presents a comprehensive evaluation of self-supervised learning (SSL) and auto-encoder (AE) methods in the context of distribution shifts, comparing their performance against supervised learning (SL). The authors introduce a novel approach to isolate the bias of linear classifier heads by retraining them on out-of-distribution (OOD) data, enabling a clearer understanding of the underlying robustness of learned representations. The findings demonstrate that SSL and AE approaches frequently outperform SL in terms of OOD accuracy and stability, although their performance can vary based on the complexity of the task. Additionally, the authors contribute the Controllable-Shift (CS) datasets, which facilitate a more nuanced exploration of the effects of distribution shifts.\n\n# Strength And Weaknesses\nThe paper's strengths include a thorough evaluation of unsupervised methods, the introduction of an innovative bias isolation technique, and the development of controllable datasets that enhance the research landscape. However, limitations include the restricted scope of datasets, which may affect generalizability, assumptions regarding the necessity of linear head retraining, and insufficient exploration of the implications of not retraining in various contexts. Furthermore, while the results indicate improved robustness of unsupervised methods, the authors acknowledge potential underperformance in complex scenarios, suggesting that their findings may not be universally applicable.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and well-organized, with a logical flow of ideas that makes the contributions easy to follow. The quality of the experimental design is commendable, particularly the establishment of the OOD linear head evaluation protocol. However, the reproducibility of results could be enhanced by providing more extensive discussions on the datasets used and the implications of the findings in real-world applications. The novelty of the proposed methods is significant, particularly in the context of isolating linear head biases.\n\n# Summary Of The Review\nOverall, the paper makes valuable contributions to the understanding of unsupervised representation learning under distribution shifts, particularly through its novel methods and the creation of new datasets. While it provides important insights and a solid foundation for future research, it would benefit from addressing the limitations related to generalizability and practical implications.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"How Resilient is Self-Supervised Representation Learning to Distribution Variability?\" by Yuge Shi et al. investigates the robustness of self-supervised learning (SSL) and variational auto-encoder (VAE) methodologies against data distribution variability. The authors present a systematic evaluation of these methods using newly constructed \"Dynamic-Shift\" datasets that allow for controlled variability. Key findings indicate that representations learned through SSL and VAE demonstrate significantly greater resilience to distribution shifts compared to conventional supervised learning (SL) methods, with innovative metrics introduced to quantify this robustness.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its comprehensive approach to evaluating SSL and VAE under varying distributional conditions and its introduction of the Dynamic-Shift datasets, which represent a novel contribution to the field. The decoupling of representation evaluation from classifier bias is another significant advancement, providing clearer insights into the robustness of learned representations. However, the paper could benefit from a broader exploration of real-world datasets and scenarios to validate its findings further, as the current focus primarily centers on synthetic and controlled settings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its methodology and findings, making it accessible to a broad audience. The quality of writing is high, and the figures and tables effectively support the presented data. The novelty of introducing Dynamic-Shift datasets and the proposed metrics for robustness assessment is commendable, enhancing the reproducibility of the study. The methodology is sufficiently detailed, allowing for potential replication by other researchers.\n\n# Summary Of The Review\nOverall, this paper presents a significant contribution to understanding the resilience of self-supervised and variational auto-encoder methodologies to distributional variability. The innovative dataset and metrics proposed provide valuable tools for future research, although further validation in more complex real-world scenarios would strengthen the findings.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper investigates the robustness of adversarial training techniques against distribution shifts that frequently occur in real-world applications. The authors systematically evaluate various adversarial training methodologies under these conditions, utilizing both synthetic and real-world datasets. They introduce controllable adversarial datasets to analyze the impact of distribution shifts and emphasize the significance of the classification layer's bias. Their findings reveal that adversarially trained models exhibit varying degrees of performance degradation when faced with distribution shifts, and they propose new metrics to measure model sensitivity to such shifts.\n\n# Strength And Weaknesses\n**Strengths:**\n1. The systematic evaluation of adversarial training methodologies against distribution shifts is timely and necessary, addressing a significant gap in existing research.\n2. The introduction of controllable adversarial datasets is innovative, enhancing the ability to study the robustness of adversarial training under varying conditions.\n3. The focus on isolating adversarial head bias offers valuable insights into the true robustness of models, which is often overlooked in prior studies.\n\n**Weaknesses:**\n1. The paper may benefit from a broader range of adversarial training methods being evaluated to provide a more comprehensive overview.\n2. While the proposed robustness metrics are useful, their practical applicability in real-world scenarios may require further validation.\n3. Some experimental results could be more thoroughly discussed to clarify their implications for the broader field.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and structured, presenting its methodology and findings clearly. The quality of the experiments is commendable, with a logical flow from the introduction to the conclusion. The novelty of the work lies in its focus on distribution shifts, which is less explored in adversarial training literature. However, the reproducibility of results could be bolstered by providing additional details on experimental setups and hyperparameter settings.\n\n# Summary Of The Review\nOverall, this paper presents significant contributions to understanding the limitations of adversarial training in the context of distribution shifts. The introduction of controllable datasets and the analysis of classifier bias are particularly noteworthy. While there are some areas for improvement, particularly in evaluating a wider range of techniques, the findings are valuable for both researchers and practitioners in the field.\n\n# Correctness\n4/5 - The methodologies and findings appear robust, though some areas would benefit from clearer explanations.\n\n# Technical Novelty And Significance\n4/5 - The focus on distribution shifts is a novel angle in adversarial training research, though the techniques themselves are established.\n\n# Empirical Novelty And Significance\n4/5 - The findings regarding classifier bias and the proposed metrics contribute significantly to the field, though further validation is needed for practical applications.",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods, specifically self-supervised learning (SSL) and autoencoders (AE), in the context of distribution shifts. It makes three key contributions: a novel evaluation framework for SSL and AE against supervised learning (SL), the introduction of controllable datasets to assess algorithm performance under varying distribution changes, and an analysis of the bias introduced by linear classifier heads. The authors claim that SSL and AE consistently outperform SL across all scenarios and demonstrate lower sensitivity to distribution shifts, asserting that this work sets a new benchmark for future research in representation learning.\n\n# Strength And Weaknesses\nThe strengths of this paper lie in its ambitious goals to evaluate unsupervised learning methods comprehensively in the context of distribution shifts, along with the introduction of controllable datasets, which may facilitate deeper insights into algorithmic behavior. However, the paper suffers from several weaknesses, including an overstatement of its contributions and findings. Many of the proposed methods and analyses are not novel and have been discussed in existing literature, which diminishes the paper's overall impact. Additionally, the experimental results are based on overly simplistic synthetic datasets, limiting their applicability to real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear in its presentation. However, the novelty of the contributions is questionable, as much of the work appears to reiterate known techniques within the community. The reproducibility of findings is supported by the use of established methods and datasets, but the simplicity of the experimental setups may undermine the generalizability of the results.\n\n# Summary Of The Review\nOverall, while the paper presents a well-organized exploration of unsupervised representation learning's robustness, it tends to exaggerate the significance of its contributions and findings. The work, although methodologically sound, does not provide sufficient novel insights or empirical evidence to warrant its ambitious claims.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods, specifically self-supervised learning (SSL) and auto-encoder (AE) algorithms, to distribution shifts compared to supervised learning (SL). The authors propose that unsupervised methods yield representations that are more resilient to such shifts. Through extensive evaluations with both synthetic and realistic datasets featuring adjustable distribution shifts, the findings indicate that unsupervised learning algorithms outperform SL in terms of generalization, demonstrating lower sensitivity to shifts and higher out-of-distribution (OOD) accuracy.\n\n# Strength And Weaknesses\nOne of the primary strengths of this paper is its systematic evaluation of unsupervised methods against supervised counterparts, addressing a significant gap in existing literature. The introduction of controllable shift datasets provides clarity and relevance to the research, allowing for a better understanding of the robustness of different learning paradigms. Furthermore, the OOD linear head evaluation method effectively mitigates biases in performance assessment. However, a weakness lies in the reliance on a limited selection of datasets, which may not fully represent the diversity of real-world distribution shifts. Additionally, while the results are promising, the paper could benefit from a deeper discussion on the practical implications of these findings in various applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The quality of the experimental design is high, with robust statistical analyses supporting the claims. The novelty lies in the comparative approach to evaluating unsupervised and supervised methods under distribution shifts, which is less explored in prior work. Reproducibility is supported through detailed descriptions of the datasets and methodologies used, although sharing the code and data publicly would further enhance reproducibility.\n\n# Summary Of The Review\nOverall, the paper provides significant insights into the robustness of unsupervised representation learning methods in the face of distribution shifts, highlighting their superiority over supervised methods. While the findings are compelling, there is room for improvement in dataset diversity and practical implications discussion.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised learning (UL) methods, particularly self-supervised learning (SSL) and autoencoders (AE), in comparison to supervised learning (SL) under distribution shifts. It posits that UL methods possess inherent advantages in generalization due to input-driven objectives, and it evaluates this hypothesis primarily through experiments on synthetic datasets with controllable shifts. The findings suggest that UL methods outperform SL in specific settings, but the authors caution against overgeneralization, calling for further investigation into the complexities of real-world data scenarios.\n\n# Strength And Weaknesses\nThe paper makes a notable contribution by challenging the prevailing notion that supervised learning is superior in all contexts, particularly regarding robustness to distribution shifts. The methodology leverages synthetic datasets to establish comparisons, which is a strength in terms of control but raises concerns about generalizability to real-world applications. A significant weakness is the reliance on linear probing as the primary evaluation metric, which may not capture the intricacies of model interactions in more complex tasks. Furthermore, the emphasis on spurious correlations as a central theme may limit the broader applicability of the findings, as it overlooks other critical factors influencing model robustness.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, presenting a clear argument and logical structure. However, some assumptions, particularly regarding the transcendence of results from synthetic to real-world datasets, could be articulated more thoroughly to avoid confusion. The quality of the experimental design is solid, yet the reproducibility may be compromised due to potential biases introduced by the synthetic datasets. Overall, while the novelty of the approach is commendable, the assumptions made warrant more cautious interpretation.\n\n# Summary Of The Review\nThis paper presents an interesting perspective on the robustness of unsupervised learning methods compared to supervised ones under distribution shifts, supported by controlled experiments. However, the reliance on synthetic datasets and specific evaluation metrics limits the generalizability of the findings, necessitating further exploration of the assumptions made.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" investigates the resilience of unsupervised representation learning methods, specifically self-supervised learning (SSL) and autoencoders (AE), compared to supervised learning (SL) in the face of distribution shifts. The authors argue that unsupervised methods yield more robust representations due to their input-driven objectives. They conduct extensive experiments across eight algorithms and six datasets, utilizing metrics such as out-of-distribution (OOD) accuracy, linear head bias, and shift sensitivity. The findings demonstrate that SSL and AE significantly outperform SL under extreme distribution shifts, especially highlighting SSL's superior robustness in both synthetic and real-world scenarios.\n\n# Strength And Weaknesses\nThe paper makes a valuable contribution to the understanding of unsupervised learning in the context of distribution shifts, which is a relatively underexplored area. The introduction of controllable shift datasets and a protocol for evaluating the influence of linear classifier heads on representation performance is a notable strength. However, a weakness lies in the limited variety of unsupervised methods explored, as the evaluation could benefit from including a broader range of state-of-the-art techniques to better contextualize the findings. Additionally, while the experimental results are comprehensive, the paper could have provided more detailed discussions on the practical implications of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly articulates its contributions and methodology. The experimental setup is described in sufficient detail, allowing for reproducibility of the results. The novelty of the work lies in its focus on unsupervised learning methods in relation to distribution shift, a topic that has received limited attention compared to supervised approaches. Overall, the quality of writing is high, though some sections could be more concise to enhance clarity.\n\n# Summary Of The Review\nOverall, the paper presents a significant exploration of the robustness of unsupervised representation learning against distribution shifts, providing valuable insights and experimental evidence. While the contributions are noteworthy, the study could be strengthened by incorporating a wider range of unsupervised methods and more practical discussions of the implications.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper investigates the robustness of various machine learning algorithms under conditions of distribution shifts, with a particular focus on comparing unsupervised representation learning to traditional supervised learning methods. The authors propose a systematic framework for evaluating the performance of different algorithms across diverse experimental setups. Their findings indicate that certain learning paradigms exhibit better robustness than others when faced with distribution shifts, although the depth of the results presentation leaves room for further exploration of their implications.\n\n# Strength And Weaknesses\nThe paper makes a significant contribution by addressing a gap in the existing literature concerning the robustness of unsupervised learning methods. The proposed framework for evaluation is a valuable asset for future research. However, the methodology lacks specificity regarding dataset selection and experimental conditions, which could affect the reproducibility of the results. Furthermore, the presentation of results is somewhat superficial, hindering a comprehensive understanding of the findings' significance.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a novel perspective on an important topic, the clarity of the results and discussions could be improved. The quality of the writing is generally good, but the lack of detailed explanations regarding experimental conditions and evaluation metrics reduces the overall quality and reproducibility of the findings. A more thorough discussion of the implications of the results and their statistical significance would enhance the paper's clarity and impact.\n\n# Summary Of The Review\nThis paper presents a timely investigation into the robustness of unsupervised learning methods under distribution shifts, contributing valuable insights to the field. However, the clarity of the results and the depth of the discussion regarding their implications require improvement to fully realize the paper's potential impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods—specifically self-supervised learning (SSL) and auto-encoder (AE) algorithms—against distribution shifts, a topic primarily explored within the realm of supervised learning (SL). The authors hypothesize that the input-driven nature of unsupervised methods leads to more robust representations. To evaluate this hypothesis, the paper systematically compares the performance of SSL and AE on both synthetic and realistic datasets under varying distribution shifts. The findings indicate that unsupervised methods exhibit superior generalization capabilities compared to SL, particularly in extreme distribution shift scenarios, suggesting that SSL methods maintain competitive out-of-distribution accuracy and stability.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its systematic approach to assessing the robustness of unsupervised representation learning, an area that has received limited attention compared to SL. The introduction of controllable versions of realistic datasets is a notable contribution, allowing for a more nuanced understanding of how these methods perform under various conditions. However, a potential weakness includes the observation that while AE methods demonstrate robustness, they may not perform optimally in complex tasks due to inefficient use of model capacity. Additionally, the paper could elaborate further on the implications of linear head bias in evaluation protocols.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its objectives, methodology, and findings. The quality of the experiments appears robust, with a thoughtful design that addresses important gaps in existing literature. The novelty of the paper is significant, as it shifts the focus from traditional SL methods to unsupervised learning in the context of distribution shifts. Reproducibility is supported through the use of diverse datasets and thorough evaluations, although additional details on the implementation would enhance confidence in replicating the results.\n\n# Summary Of The Review\nOverall, this paper makes a valuable contribution to the understanding of unsupervised representation learning's robustness to distribution shifts, demonstrating that such methods can outperform supervised techniques under challenging conditions. The systematic evaluation and the introduction of controllable datasets are commendable, though further exploration of certain limitations could strengthen the findings.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" investigates the robustness of unsupervised learning methods, specifically self-supervised learning (SSL) and autoencoders (AE), compared to supervised learning (SL) under distribution shifts. The authors propose a novel framework for evaluating these methods by developing controllable domain generalization datasets. They find that unsupervised methods consistently outperform supervised ones in terms of out-of-distribution (OOD) accuracy and stability, especially under extreme shifts. Additionally, the paper emphasizes the importance of retraining linear classifiers on OOD data to mitigate biases that may overestimate the robustness of SL models.\n\n# Strength And Weaknesses\nStrengths of the paper include its timely focus on the often-overlooked area of unsupervised learning's robustness to distribution shifts, which has been primarily dominated by SL research. The introduction of controllable datasets to assess robustness provides a structured approach to evaluate the performance of different learning paradigms. The findings are significant and well-supported by empirical evidence, demonstrating the advantages of unsupervised methods. However, a potential weakness is the reliance on linear classifiers for evaluation, which may limit the generalizability of the findings to more complex scenarios. Additionally, further exploration of the practical implications of these results in real-world applications could enhance the paper’s impact.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its contributions clearly, making it accessible to both researchers and practitioners in the field. The methodology is sound, with a rigorous experimental setup that allows for reproducibility of the results. The novelty lies in the comparative analysis of unsupervised versus supervised methods under distribution shifts, an area that has not been extensively explored until now. The authors provide sufficient detail regarding their experimental design, enabling other researchers to replicate their findings effectively.\n\n# Summary Of The Review\nOverall, the paper provides a valuable contribution to the understanding of unsupervised learning's robustness in the face of distribution shifts, highlighting significant advantages over traditional supervised approaches. While the methodology is strong, the paper could benefit from addressing its reliance on linear classifiers and suggesting broader applications of its findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" by Yuge Shi et al. investigates the robustness of unsupervised representation learning (SSL) and autoencoders (AE) in comparison to supervised learning (SL) in the context of distribution shifts. The authors systematically evaluate various SSL and AE methods on both synthetic and realistic datasets, proposing controllable dataset variations to assess robustness. The findings reveal that SSL and AE methods exhibit significantly greater robustness to distribution shifts than SL, with performance benefits evident from retraining linear heads on out-of-distribution (OOD) data.\n\n# Strength And Weaknesses\nThe paper's strengths include a systematic and comprehensive evaluation of unsupervised learning methods across multiple datasets, both synthetic and realistic, which enhances the generalizability of the findings. The development of controllable datasets is a notable contribution, enabling a fine-grained analysis of robustness. However, a potential weakness lies in the discussion of discrepancies between synthetic and realistic dataset performances, which could benefit from deeper analysis and explanation. Additionally, while the paper addresses the linear head bias, further exploration of this aspect could enhance the robustness of the conclusions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, making it accessible to both experts in the field and newcomers. The methodology and results are presented with sufficient detail, allowing for reproducibility. The novelty of the work is significant, particularly in the context of evaluating SSL and AE against SL under distribution shifts. The authors provide a robust experimental framework, although some aspects of the analysis could be expanded for clarity and depth.\n\n# Summary Of The Review\nOverall, this paper presents a valuable contribution to the understanding of the robustness of unsupervised representation learning in the face of distribution shifts. The systematic evaluation and the introduction of controllable datasets are particularly noteworthy. While the analysis is comprehensive, there are areas that could be further elaborated to strengthen the conclusions.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning, particularly self-supervised learning (SSL) and auto-encoder (AE) frameworks, against distributional shifts, contrasting them with supervised learning (SL) methodologies. The authors hypothesize that the input-centric objectives of unsupervised techniques lead to more robust representations than the target-centric goals of supervised approaches. Through extensive empirical assessments on both synthetic and realistic datasets, they demonstrate that SSL and AE consistently outperform SL in terms of generalization under various distributional shifts. The study further introduces controllable datasets to modulate the severity of distributional shifts and employs out-of-distribution (OOD) trained linear classifiers to better isolate the representation quality from classifier biases.\n\n# Strength And Weaknesses\nThe paper makes several important contributions, including a comprehensive evaluation of various unsupervised representation learning methods against SL in the context of distributional shifts, addressing existing gaps in the literature. The introduction of controllable datasets provides a novel way to study the effects of distribution shifts, enhancing the relevance of their findings. However, the paper could benefit from a more in-depth discussion of the implications of their results on practical applications and potential limitations of unsupervised methods in more complex scenarios. Additionally, while the empirical results are robust, the choice of datasets and the specific metrics used could be better justified to strengthen the claims of generalizability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its methodology and findings, making it accessible to readers. The quality of the experiments is commendable, with a solid experimental setup and appropriate metrics employed to assess performance. The novelty lies in the focus on unsupervised representation learning within the context of distributional shifts, a relatively underexplored area. The reproducibility of the results is supported by detailed appendices, which provide additional information on experimental setups and hyperparameters.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in understanding the robustness of unsupervised representation learning techniques against distributional shifts, providing empirical evidence that underscores their potential advantages over supervised learning methods. The introduction of controllable datasets adds a valuable dimension to this research area, although further exploration of practical implications would strengthen the contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper aims to systematically evaluate unsupervised representation learning algorithms under distribution shift, claiming to be the first to do so. It employs synthetic datasets, such as MNIST-CIFAR and CdSprites, to analyze the performance of these algorithms compared to supervised learning (SL) models. The findings suggest that self-supervised learning (SSL) and autoencoders (AEs) outperform SL under extreme distribution shifts. However, the paper lacks novel methodologies and fails to offer a robust analysis of the results.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address the performance of unsupervised learning methods in the context of distribution shifts, a relevant and timely topic. However, the weaknesses are pronounced: the experimental design relies heavily on synthetic datasets, potentially limiting the generalizability of the findings. Additionally, the analysis of results is insufficient, particularly regarding the observed performance differences between models. The paper also suffers from a lack of engagement with existing literature and fails to address practical implications for deploying these models in real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is undermined by an overemphasis on linear classifier heads, which oversimplifies the complexities of the evaluated models. The quality of the experiments is questionable due to their reliance on synthetic datasets and inadequate treatment of AEs. The novelty claimed by the authors is overstated, as the work largely reiterates known limitations of supervised learning without introducing groundbreaking approaches. Reproducibility may be challenging due to the lack of clear metrics and insufficient acknowledgment of the limitations inherent in the chosen methodologies.\n\n# Summary Of The Review\nOverall, the paper presents a relevant inquiry into unsupervised representation learning under distribution shifts but falls short in execution. The reliance on synthetic datasets, insufficient analysis, and lack of depth in addressing practical applications significantly weaken its contributions to the field.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods, specifically self-supervised learning (SSL) and autoencoders (AE), against distribution shifts, comparing their performance to traditional supervised learning (SL). The authors introduce controllable versions of datasets to systematically study the effects of distribution shifts in a realistic context. Key findings indicate that unsupervised methods demonstrate superior generalization and stability under extreme shifts, outperforming SL in out-of-distribution (OOD) accuracy and showing lower sensitivity to shifts. Additionally, the research highlights the effectiveness of retraining the linear head on OOD data as a strategy to enhance model performance.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative approach to creating controllable shift datasets, which enables detailed exploration of distribution shifts without compromising realism. This methodological advancement significantly enhances the study's rigor and practical relevance. Furthermore, the findings provide compelling evidence for the robustness of unsupervised learning methods, suggesting their suitability for real-world applications. However, a potential weakness could be the limited scope of datasets used for evaluation, which may restrict the generalizability of the results across various domains.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, facilitating understanding of complex concepts and methodologies. The quality of the experiments is high, with thorough evaluations that support the claims made. The novelty of the research is evident in both the methodological innovations and the insights gained regarding the robustness of unsupervised methods. The introduction of controllable shift datasets enhances reproducibility, allowing future researchers to build upon this work and validate the findings in different contexts.\n\n# Summary Of The Review\nOverall, the paper presents significant contributions to the understanding of unsupervised representation learning under distribution shifts, showcasing their robustness and adaptability compared to supervised methods. The methodological advancements and empirical findings provide a strong foundation for future research in this area.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a theoretical exploration of unsupervised representation learning, particularly in the context of distribution shifts. It argues that traditional supervised learning (SL) methods, which assume identical distributions for training and testing data, are often inadequate in real-world scenarios where such assumptions are violated. The authors propose that unsupervised learning approaches, including self-supervised learning (SSL) and auto-encoders (AE), provide more robust representations by focusing on input-driven objectives rather than target-driven ones. Key findings include the identification of spurious correlations as a significant risk in SL and the development of a shift sensitivity metric to evaluate model robustness against distribution shifts.\n\n# Strength And Weaknesses\nOne of the strengths of the paper is its systematic evaluation framework, which introduces controllable datasets for studying the effects of distribution shifts. This contributes to a deeper understanding of algorithm behavior under different conditions. However, the paper could benefit from more empirical validation of the theoretical claims made, particularly regarding the advantages of unsupervised methods over supervised ones. The discussion around linear probing bias could be expanded to illustrate its implications with more concrete examples.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its ideas clearly, making complex theoretical concepts accessible. However, some sections could be enhanced with additional examples or illustrations to aid comprehension. The novelty lies in the theoretical insights into unsupervised learning's potential advantages, though the empirical validation is somewhat lacking. Reproducibility is not directly addressed, as the focus is primarily theoretical; inclusion of practical experiments would strengthen this aspect.\n\n# Summary Of The Review\nOverall, the paper provides valuable theoretical insights into unsupervised representation learning and its robustness to distribution shifts. While it lays a strong foundation for future research, the lack of empirical validation and concrete examples detracts from its overall impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper titled \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" investigates the robustness of various unsupervised representation learning techniques under distribution shifts. The authors conduct a systematic comparison of self-supervised learning (SSL) methods, auto-encoders (AE), and supervised learning algorithms across both synthetic and realistic datasets. Key metrics, including out-of-distribution (OOD) linear head accuracy, linear head bias, and shift sensitivity, are employed to evaluate performance. The findings reveal significant differences in robustness across the different methods, with implications for the deployment of these techniques in real-world scenarios.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its comprehensive evaluation of multiple representation learning paradigms and the thoughtful selection of datasets that include both synthetic and real-world scenarios. The detailed implementation protocols, including hyperparameter settings and training procedures, enhance the reproducibility of the results. However, the paper has weaknesses in that it does not adequately discuss the broader implications of its findings. While the experimental results are robust, the lack of theoretical insights into why certain methods perform better under distribution shift detracts from its overall contribution.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly written, making it accessible to a broad audience. The quality of the experiments is high, with results averaged over multiple trials to ensure reliability. The novelty of the approach lies in the systematic examination of robustness across various unsupervised learning methods. Reproducibility is well-facilitated by the provision of detailed training protocols and hyperparameter configurations; however, the code's availability on the \"solo-learn\" code base should be highlighted more explicitly to encourage further research.\n\n# Summary Of The Review\nOverall, the paper provides valuable insights into the robustness of unsupervised representation learning methods against distribution shifts. While the methodology and experiments are commendable, the authors could enhance the paper by discussing the implications of their findings and providing a deeper theoretical understanding of the observed behaviors.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper investigates the performance of unsupervised learning methods, specifically Self-Supervised Learning (SSL) and Autoencoders (AE), in comparison to traditional Supervised Learning (SL) under conditions of distribution shift. The authors claim to be the first to systematically evaluate these methods in this context and propose a framework involving controllable datasets to address the limitations of synthetic data. The findings suggest that SSL and AE outperform SL, particularly emphasizing the importance of retraining linear models on out-of-distribution (OOD) data to reduce bias. However, the paper fails to engage with existing literature adequately, which diminishes the significance of its contributions.\n\n# Strength And Weaknesses\nThe paper presents a thorough experimental design that explores the robustness of SSL and AE techniques in the face of distribution shifts, which is commendable. However, its novelty is undermined by the authors' lack of engagement with prior research that has already highlighted the weaknesses of SL and the challenges associated with synthetic datasets. The claims around the superiority of unsupervised methods are presented without sufficient nuance, failing to consider scenarios where SL may still be effective. Additionally, the authors inadequately address existing biases in linear classifiers and do not critically engage with counterarguments regarding their findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, but the clarity is marred by its failure to adequately contextualize its findings within the existing body of literature. While the experimental quality is high, the lack of discussion regarding dataset limitations and generalizability detracts from its overall quality. The novelty of the contributions is questionable, as similar themes have been explored in prior works, thereby impacting the paper's perceived significance. Reproducibility is not explicitly addressed, which raises concerns about the practical application of the proposed methods.\n\n# Summary Of The Review\nOverall, the paper makes an important contribution to the discourse on unsupervised learning methods under distribution shift, but it lacks originality and fails to engage critically with existing research. The findings, while potentially valuable, are not presented within a sufficiently nuanced framework, limiting their impact on the field.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThe paper titled \"How Robust is Unsupervised Representation Learning to Distribution Shift?\" investigates the resilience of unsupervised learning algorithms, particularly self-supervised learning (SSL) and autoencoders (AE), to distributional changes in data. The authors propose a new evaluation metric called \"shift sensitivity\" and conduct extensive experiments to assess various algorithms' performance under different out-of-distribution (OOD) scenarios. The findings highlight significant vulnerabilities in existing models, suggesting that their robustness to distribution shift is often overestimated.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its rigorous empirical analysis, which offers valuable insights into the limitations of current unsupervised learning techniques against distributional shifts. The introduction of the \"shift sensitivity\" metric is a novel contribution that can facilitate future research in this area. However, the paper suffers from several clarity issues, such as inconsistent terminology and inadequate definitions of key terms upon first use. Additionally, the formatting inconsistencies throughout the manuscript detract from its overall professionalism.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a compelling investigation, its clarity is undermined by inconsistent terminology and formatting. The novelty of the proposed metric and the empirical findings are significant, but the lack of clear definitions and standardized notation may hinder reproducibility. Furthermore, the informal language in certain sections diminishes the paper's academic rigor.\n\n# Summary Of The Review\nThe paper makes a substantial contribution to understanding the robustness of unsupervised learning algorithms to distribution shifts, introducing important new metrics and findings. However, clarity and consistency issues need to be addressed to improve the overall quality and reproducibility of the work.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods, specifically focusing on their performance under distribution shifts. The authors compare various unsupervised learning techniques, such as self-supervised learning (SSL) and autoencoders (AE), against supervised methods using synthetic and realistic datasets. Their findings suggest that unsupervised approaches can outperform supervised ones in specific scenarios, highlighting the importance of evaluating linear head bias. However, the paper lacks a comprehensive exploration of other critical domains, such as natural language processing and audio data, and does not address the influence of dataset size, architecture variations, or augmentation strategies on model performance.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its empirical evaluation of unsupervised learning methods under distribution shifts, providing valuable insights into the effectiveness of these approaches. However, it has notable weaknesses, including a narrow focus on computer vision, insufficient discussion of dataset biases, and limited evaluation metrics. The lack of thorough comparisons with state-of-the-art techniques and the absence of a detailed methodology for dataset creation further limit the paper's impact. Additionally, it does not adequately address the practical implications of its findings or suggest future research directions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and clear in its presentation of results and methodology. However, the reproducibility could be enhanced by a more detailed description of the dataset creation process and the augmentation strategies employed. The novelty of the research is somewhat constrained by its limited scope and failure to explore a broader range of unsupervised learning techniques. The paper's contributions to the field are significant, yet they could be more impactful with a more comprehensive approach.\n\n# Summary Of The Review\nOverall, the paper presents an important investigation into the robustness of unsupervised representation learning methods under distribution shifts. While it offers valuable empirical insights, its limited scope and lack of thorough analysis in several areas weaken its contributions. A broader exploration and more detailed methodology would significantly enhance the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods under distribution shifts, a common issue in machine learning applications. It introduces a statistical framework for evaluating models based on out-of-distribution (OOD) accuracy, shift sensitivity, and linear head bias. The findings indicate that self-supervised learning (SSL) and autoencoders (AE) outperform supervised learning (SL) in terms of OOD accuracy, suggesting that these unsupervised methods exhibit greater robustness to distribution shifts. The paper emphasizes the importance of statistical significance in performance evaluation, utilizing diverse datasets to validate its claims.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its rigorous statistical methodology and comprehensive experimental design, which includes both synthetic and real-world datasets. The use of multiple evaluation metrics (OOD accuracy, shift sensitivity, and linear head bias) provides a nuanced understanding of model performance. However, a notable weakness is the lack of detailed hypothesis testing methods, which could enhance the robustness of the statistical claims. Additionally, while the paper proposes new standards for evaluating models, it could benefit from discussing the practical implications of its findings in real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with clear explanations of the statistical methods and experimental setups. The quality of the analysis is high, with thorough comparisons across different learning paradigms. The novelty is significant, as it addresses a critical gap in understanding how different representation learning methods cope with distribution shifts. Reproducibility is supported through the detailed reporting of metrics and statistical significance, although the absence of explicit hypothesis testing may limit full reproducibility.\n\n# Summary Of The Review\nOverall, the paper makes a valuable contribution to the field of unsupervised representation learning by providing a robust statistical framework for evaluating model performance under distribution shifts. While the analysis is thorough and the findings are significant, the lack of detailed hypothesis testing could be improved to better support the claims made.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning in the context of various distribution shifts, focusing on extreme and realistic scenarios. The authors analyze the performance of learned representations by evaluating linear classifiers on different datasets. However, the study primarily highlights the biases introduced by linear head evaluations and demonstrates the potential limitations of unsupervised methods under certain conditions. Notably, the paper does not delve into the broader implications of architecture choices or hyperparameter settings, nor does it explore future directions for enhancing robustness.\n\n# Strength And Weaknesses\nThe paper presents valuable insights into the performance of unsupervised representation learning when faced with significant distribution shifts, which is a relevant topic in the field. However, it exhibits several weaknesses: it does not comprehensively cover the robustness across a wider range of distribution shifts, neglects the influence of model architectures and hyperparameters, and fails to propose actionable directions for future research. Additionally, the lack of consideration for practical applicability, such as computational costs and label noise, limits the paper's overall contribution.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear in its presentation, but the lack of thorough exploration of various aspects diminishes its overall quality. While the novelty lies in the focused analysis of linear head bias, the paper does not significantly advance the understanding of unsupervised representation learning. Reproducibility may be affected due to the limited exploration of hyperparameters and data quality, as well as the reliance on synthetic datasets that may not reflect real-world scenarios.\n\n# Summary Of The Review\nOverall, the paper provides a focused examination of unsupervised representation learning's robustness under specific distribution shifts; however, it lacks depth in exploring various important factors. The limitations in methodology and future directions hinder the potential impact of the findings, which could benefit from a more comprehensive approach.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates the robustness of unsupervised representation learning methods, specifically Self-Supervised Learning (SSL) and Autoencoders (AE), in the face of distribution shifts. The authors claim that these methods exhibit improved performance compared to traditional supervised learning approaches under such conditions. Their methodology includes creating controllable datasets to systematically study the effects of distribution shifts, followed by empirical evaluations of various algorithms across synthetic and realistic datasets. The findings suggest that unsupervised methods are generally more resilient to distribution shifts than supervised methods, a conclusion that aligns with existing literature but is presented with new experimental setups.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its structured approach to evaluating unsupervised methods in a challenging context, which is of relevance to current trends in machine learning. However, the weaknesses are notable: the contributions feel incremental rather than groundbreaking, often reiterating well-established concepts without providing significant new insights. The critiques of existing practices in supervised learning lack depth and fail to engage with the complexities of the subject matter. Furthermore, the novelty of the findings is diminished by their predictability, and the potential implications for future research appear underexplored.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is written clearly, with a logical flow from introduction through to conclusions. However, the quality of the insights is undermined by the lack of novel contributions. While the methodology is reproducible, the novelty of the experimental results is questionable, as they largely reaffirm existing knowledge rather than challenge or expand it. This diminishes the overall impact of the work, as the findings do not provoke further inquiry or offer significant new pathways for research.\n\n# Summary Of The Review\nOverall, this paper presents a well-structured examination of unsupervised representation learning in the context of distribution shifts, but it ultimately falls short of delivering novel insights. The contributions are mostly reiterative and lack the depth necessary to advance the field meaningfully. The work may serve as a review for newcomers but offers little for seasoned researchers.\n\n# Correctness\n4/5. The methodology and findings are sound, but the insights are largely predictable.\n\n# Technical Novelty And Significance\n2/5. The paper does not significantly advance the state of the art and tends to restate established concepts.\n\n# Empirical Novelty And Significance\n2/5. While the empirical evaluations are methodologically sound, they do not provide significant new findings that challenge existing knowledge.",
    "# Summary Of The Paper\nThis paper investigates the robustness of unsupervised representation learning techniques, such as self-supervised learning (SSL) and autoencoders (AE), in comparison to supervised learning (SL) under distribution shifts. The authors introduce controllable distribution shift datasets to evaluate these methods and argue for the retraining of linear classifier heads on out-of-distribution (OOD) data to reduce bias in evaluation protocols. Findings indicate that SSL and AE outperform SL in both synthetic and realistic distribution shift scenarios, with SSL showing particularly stable performance. The paper concludes by calling for further research into unsupervised learning methodologies for OOD generalization.\n\n# Strength And Weaknesses\nThe paper's strengths include its timely focus on unsupervised methods, which are gaining traction in the machine learning community, and the introduction of controlled distribution shift datasets that could serve as a valuable resource for future research. The advocacy for retraining on OOD data highlights an important gap in current evaluation practices and encourages a more nuanced understanding of model performance. However, one weakness is the limited exploration of the implications of these findings across various applications, which could benefit from a broader discussion on the practical integration of these techniques.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and findings. The methodology is described in sufficient detail for reproducibility, particularly the creation of controllable datasets and the evaluation protocols. The novelty lies in the emphasis on the bias of linear classifiers and the robust performance of unsupervised methods under distribution shifts, areas that are not extensively covered in current literature. The call for further research into these topics adds to the paper's significance.\n\n# Summary Of The Review\nOverall, the paper presents significant contributions to the understanding of unsupervised representation learning's robustness in the context of distribution shifts. Its methodological innovations and insights into evaluation biases provide a foundation for future research, although a more comprehensive exploration of practical applications would strengthen the impact of the findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper investigates the performance of unsupervised representation learning methods (Self-Supervised Learning and Autoencoders) compared to traditional supervised learning under conditions of distribution shift. The authors employ both synthetic and real-world datasets to evaluate out-of-distribution (OOD) accuracy and shift sensitivity. Key findings indicate that unsupervised methods consistently outperform supervised learning, demonstrating higher OOD accuracy and lower sensitivity to distribution shifts across various tasks, including color and shape classification as well as real-world applications like Camelyon17 and FMoW.\n\n# Strength And Weaknesses\nStrengths of the paper include its comprehensive evaluation across multiple datasets, which highlights the robustness of unsupervised methods in real-world scenarios. The clear distinction in performance metrics, such as OOD accuracy and shift sensitivity, provides strong empirical evidence for the proposed claims. However, the paper could benefit from a more detailed discussion on the implications of these findings for practical applications and the potential limitations of unsupervised methods. Additionally, while the experiments are well-structured, further exploration of the underlying mechanisms contributing to the observed performance differences would enhance the understanding of the results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a logical flow and clear presentation of results. The methodology is sound and the data analysis is robust, which contributes to the overall quality of the work. The novelty lies in the comparative analysis of unsupervised versus supervised learning under distribution shifts, a topic of growing importance. However, the reproducibility could be improved by providing more details on the implementation, hyperparameters, and dataset preprocessing steps to facilitate replication of the results by other researchers.\n\n# Summary Of The Review\nOverall, this paper presents compelling evidence that unsupervised representation learning methods are more effective than supervised learning in terms of generalization under distribution shifts. The findings are significant and timely, given the increasing prevalence of distribution shifts in real-world applications.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel framework for addressing spurious correlations in supervised learning (SL) models, particularly in out-of-distribution (OOD) scenarios. The authors propose a new methodology that combines data augmentation and adversarial training techniques to mitigate the impact of these correlations on model performance. Experimental results demonstrate that the proposed framework significantly improves robustness and generalization compared to baseline methods across multiple datasets.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative approach to a pressing issue in machine learning, providing a clear methodology that enhances robustness against spurious correlations. However, weaknesses include a complex presentation of findings, which may obscure the impact of the results. Additionally, the heavy use of technical jargon without adequate explanation could hinder accessibility for a broader audience. The paper also lacks visual aids that could help convey complex experimental results more effectively.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper proposes a novel approach, clarity suffers due to dense writing and the frequent use of technical jargon. The methodology is sound, but the presentation could be improved with more concise explanations and visual aids. Reproducibility is somewhat hindered by a lack of detailed descriptions of the experimental setup; diagrams or flowcharts could enhance understanding. Overall, the quality of writing needs refinement to ensure that key contributions are communicated effectively.\n\n# Summary Of The Review\nThe paper addresses a significant challenge in supervised learning, offering a new methodology that effectively mitigates spurious correlations and enhances model robustness. However, the complex presentation of results and heavy use of jargon detract from its clarity and accessibility. Improved organization and visual aids would greatly enhance the overall impact of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.2568993092152936,
    -1.5278969752706086,
    -1.647532890848263,
    -1.7431081423259343,
    -1.782796168963181,
    -1.625966032743397,
    -1.5876600874169817,
    -1.6997181524063525,
    -1.636983006137787,
    -1.7886409939033436,
    -1.706938339620892,
    -1.6749825041433721,
    -1.7511961424034992,
    -1.5467974807490745,
    -1.5549145539141878,
    -1.6368093873063096,
    -1.7497000785872583,
    -1.47472589614657,
    -1.6441388538829251,
    -1.6779977951099374,
    -1.7949713390255737,
    -1.610295345530586,
    -1.5557676139077123,
    -1.5444941133014376,
    -1.852758087873849,
    -1.7374525999110355,
    -1.6742403153810788,
    -1.4106415800906378,
    -1.7617263677851156
  ],
  "logp_cond": [
    [
      0.0,
      -1.8688339091611024,
      -1.8546691393740253,
      -1.8626434657231516,
      -1.8561951402825598,
      -1.9514244455527316,
      -1.9955802500646123,
      -1.8892117248884843,
      -1.8543345992375195,
      -1.9223443487972935,
      -1.8562783491411754,
      -1.9947699657643538,
      -1.8645635995975054,
      -1.8691578021155661,
      -1.8588617769632163,
      -1.8668060523879018,
      -1.9434248618481296,
      -1.8499389979559988,
      -1.9521807084146359,
      -1.9020347392465833,
      -1.8837350850690469,
      -1.9740877216156052,
      -1.9184259626252111,
      -1.921383734241702,
      -1.9884454344780624,
      -1.9024930093164518,
      -1.8413775485263506,
      -1.9230641690033234,
      -2.008035588465558
    ],
    [
      -1.1361793112870011,
      0.0,
      -1.0478664840428542,
      -1.0340556362140993,
      -1.0480495039435076,
      -1.173662073818991,
      -1.1841551757858486,
      -1.1149381012409159,
      -1.0289811319415707,
      -1.1664668178524538,
      -1.0583143852273118,
      -1.1862252688236128,
      -1.0372612291338004,
      -1.061463861980275,
      -1.0362329886990247,
      -1.0784335270848524,
      -1.1732427751740062,
      -1.0904181345038488,
      -1.218687137706426,
      -1.123988060665017,
      -1.100824800733662,
      -1.2595015184237932,
      -1.1353369940728308,
      -1.1730155722257947,
      -1.1823760568802033,
      -1.1845151314380256,
      -1.078019210768193,
      -1.206866297037664,
      -1.2522203683657644
    ],
    [
      -1.3336947232723377,
      -1.2304453018991997,
      0.0,
      -1.2493381623643816,
      -1.2346449074919856,
      -1.3752912238196953,
      -1.4049346735471444,
      -1.281783176914432,
      -1.2420272298263109,
      -1.2542127087982042,
      -1.2120781743475402,
      -1.3761256465116962,
      -1.147901804506202,
      -1.2748584991749785,
      -1.2852166547617936,
      -1.2008834116697604,
      -1.3357643354519237,
      -1.257000217060884,
      -1.3170522331291274,
      -1.329705173494188,
      -1.2941574975495589,
      -1.4078611685801128,
      -1.333486156689978,
      -1.3310046134606175,
      -1.331453931989302,
      -1.333545600510095,
      -1.3004793743842573,
      -1.3649233298807035,
      -1.4215966566125837
    ],
    [
      -1.3667712392961826,
      -1.2245350189086994,
      -1.22715550499393,
      0.0,
      -1.2408210892667912,
      -1.3343650269300822,
      -1.3454839594659038,
      -1.2632702693121667,
      -1.2118715479673783,
      -1.2947610714777131,
      -1.2664145630343815,
      -1.3669592277400469,
      -1.1252279903178648,
      -1.2438088435217138,
      -1.1823795450358683,
      -1.2661590350047467,
      -1.3419154095125267,
      -1.297822420092001,
      -1.324448168221136,
      -1.3074768876009344,
      -1.2982271922958186,
      -1.4061888746249067,
      -1.3136529416398075,
      -1.3314809560886527,
      -1.3457585151446132,
      -1.34560881853615,
      -1.288764140763612,
      -1.3538824348625067,
      -1.4192271486012475
    ],
    [
      -1.4192724878856307,
      -1.340805137317574,
      -1.3183285685693045,
      -1.3363015957794222,
      0.0,
      -1.4177941288516998,
      -1.4607613757954994,
      -1.3253463786718278,
      -1.315411098186596,
      -1.4114000999676424,
      -1.3197955605555207,
      -1.4316234671275525,
      -1.344681185585644,
      -1.3157372308155697,
      -1.3158176059989524,
      -1.3703263944725486,
      -1.4142433787496742,
      -1.3778695544057078,
      -1.4436574613603796,
      -1.3674673967310822,
      -1.3565688193650145,
      -1.4319235768054461,
      -1.3889471708570957,
      -1.397785680161063,
      -1.381955853047254,
      -1.4420116713336606,
      -1.3541226838777736,
      -1.436425826937904,
      -1.5062499942979877
    ],
    [
      -1.2754691360423045,
      -1.2179479491298268,
      -1.1933275772082588,
      -1.1328135984574959,
      -1.1500154414336443,
      0.0,
      -1.2871070978765702,
      -1.1983030787341231,
      -1.2000942841512794,
      -1.2290512346499756,
      -1.1677916463988454,
      -1.260196504252291,
      -1.235145142067409,
      -1.1878617716567057,
      -1.149657432279903,
      -1.2246794988033525,
      -1.2771494176715275,
      -1.2684438542575873,
      -1.2256813057747094,
      -1.2214575978292623,
      -1.2371406960366238,
      -1.252328250647239,
      -1.2476623315274045,
      -1.2621364703510338,
      -1.2761851884558073,
      -1.2750626581962201,
      -1.2339582823145547,
      -1.2782966500503359,
      -1.2911421461909884
    ],
    [
      -1.3246743998526003,
      -1.2588740256689999,
      -1.2588824063623951,
      -1.2315974014606705,
      -1.2621308128880446,
      -1.306391398993757,
      0.0,
      -1.2752817617265608,
      -1.2605172157874884,
      -1.3425751397988466,
      -1.2733588879860673,
      -1.3523290015370788,
      -1.2562359254856914,
      -1.313975891383791,
      -1.272515315885337,
      -1.267628591766415,
      -1.3426442955609799,
      -1.3149030735421734,
      -1.3134608089139446,
      -1.318269427566505,
      -1.2769703603536464,
      -1.3535936303988159,
      -1.3137823734650174,
      -1.3138725121409487,
      -1.3309759123374805,
      -1.3045662191823135,
      -1.3008938414783378,
      -1.3387379345989767,
      -1.3795202213104656
    ],
    [
      -1.3229778940395096,
      -1.2266882210728887,
      -1.2421735431762424,
      -1.2177297468424935,
      -1.228269838817872,
      -1.2984787776805107,
      -1.3428680939872595,
      0.0,
      -1.2824671122518436,
      -1.3488567056950755,
      -1.2295373899408382,
      -1.3135518099257828,
      -1.2143538739648625,
      -1.2428022419331684,
      -1.2561350514336644,
      -1.268001607335091,
      -1.314122679733141,
      -1.2504164758616931,
      -1.29276270893016,
      -1.2687533700992537,
      -1.2952875956046568,
      -1.33402443716304,
      -1.2815604268173355,
      -1.26611000121858,
      -1.2990932767127967,
      -1.2815404165905795,
      -1.2498883455434915,
      -1.3235528429105197,
      -1.382904601927151
    ],
    [
      -1.2874716381148987,
      -1.154517487664469,
      -1.1452275906983653,
      -1.1153829632610426,
      -1.1646469903878902,
      -1.2705555750747013,
      -1.3045269515746536,
      -1.1989240253031386,
      0.0,
      -1.2280663696525922,
      -1.1593827131326577,
      -1.2866737198052873,
      -1.0849085244193224,
      -1.1562232785949154,
      -1.1678750924177925,
      -1.1443979953816354,
      -1.289267498876986,
      -1.1701929970641571,
      -1.25520038282118,
      -1.2067141713687823,
      -1.224200607474155,
      -1.2982549206201324,
      -1.2739556345653473,
      -1.2137048530484669,
      -1.2772299018961142,
      -1.2858529286408285,
      -1.1848136092645616,
      -1.2446896704799197,
      -1.3088718104567878
    ],
    [
      -1.4362517031044193,
      -1.3924564695021142,
      -1.3728153154391443,
      -1.3358048596668481,
      -1.398099652458286,
      -1.422977639483894,
      -1.4968128846297475,
      -1.4039319930314045,
      -1.3766320247001895,
      0.0,
      -1.3381045194516639,
      -1.416487261284891,
      -1.320078764013062,
      -1.3714984442455511,
      -1.3760329767437502,
      -1.3621885401763125,
      -1.470935631429785,
      -1.4092946124953993,
      -1.4227587800941828,
      -1.4199521147047856,
      -1.436943771254816,
      -1.466010690296134,
      -1.4395232861538056,
      -1.4191352445348724,
      -1.4538613150025204,
      -1.484601319515504,
      -1.4208355568780697,
      -1.4644380674073838,
      -1.469686435203938
    ],
    [
      -1.3256265766128517,
      -1.2155979673655462,
      -1.1836014227046818,
      -1.2052121443709805,
      -1.20749704368257,
      -1.3085053578962422,
      -1.3801710353136856,
      -1.222915367666755,
      -1.2329616697506662,
      -1.280207492682369,
      0.0,
      -1.3307529362274877,
      -1.2164737494791105,
      -1.2110132394798956,
      -1.243045860683854,
      -1.2386291385597998,
      -1.3471050312136452,
      -1.2600626481357207,
      -1.2818752458626266,
      -1.2541724189434194,
      -1.298340287200593,
      -1.3317357098915907,
      -1.3203329852648236,
      -1.2601815050327578,
      -1.3427742060186507,
      -1.3677306580008586,
      -1.2149296479195393,
      -1.337844166701728,
      -1.3881734462948334
    ],
    [
      -1.2930098136447858,
      -1.2383928862964781,
      -1.2436713828254844,
      -1.2270552973381417,
      -1.2509538304404455,
      -1.2911097543307835,
      -1.2697451594813194,
      -1.2487036942245593,
      -1.2326563349739044,
      -1.2408317797143682,
      -1.2484750954730872,
      0.0,
      -1.224829621911374,
      -1.218298151331417,
      -1.2537147646347047,
      -1.272442300124811,
      -1.2701242413266254,
      -1.264016005142397,
      -1.3044496705648478,
      -1.2732567404923052,
      -1.21342363319682,
      -1.2826381428720257,
      -1.242960871845116,
      -1.2607968489722736,
      -1.2831630365262745,
      -1.277215179206134,
      -1.2773360834218268,
      -1.2650459042809155,
      -1.281854649434815
    ],
    [
      -1.404067097440774,
      -1.3344618934332928,
      -1.2501886450815705,
      -1.2014918097462877,
      -1.2966709425966538,
      -1.4013805237256969,
      -1.4175178275036648,
      -1.3393233665712145,
      -1.295345400262658,
      -1.3212948290256212,
      -1.2953764790869915,
      -1.407576489351779,
      0.0,
      -1.335405067098905,
      -1.299303184149269,
      -1.2936350588010528,
      -1.3732216457448032,
      -1.2992522481775035,
      -1.4002237896637508,
      -1.393851117937445,
      -1.3346254531704493,
      -1.450332146996879,
      -1.3669530555546083,
      -1.367215449894061,
      -1.3600945337879802,
      -1.4149296466069872,
      -1.3694567767513408,
      -1.399906556857873,
      -1.4608157993209472
    ],
    [
      -1.21891671210822,
      -1.1139398972074182,
      -1.1080040721370807,
      -1.0725575926148874,
      -1.0819023757384059,
      -1.1802364948979813,
      -1.2518764376218974,
      -1.1410532037665961,
      -1.1115319312882455,
      -1.1626269997130454,
      -1.0740615113387266,
      -1.1917345835015678,
      -1.1028757719758278,
      0.0,
      -1.0844982223456996,
      -1.1262623365625841,
      -1.2345705435585934,
      -1.1355443611042315,
      -1.189901406461654,
      -1.1636559597079315,
      -1.1708217486224097,
      -1.2279523724766257,
      -1.2033118214441325,
      -1.1554029053542934,
      -1.1999988350081872,
      -1.2387668594898529,
      -1.0635640785167884,
      -1.198006915467014,
      -1.2431833303481552
    ],
    [
      -1.1002135654388376,
      -0.9890493376504025,
      -1.0302602855142644,
      -0.9459772674767866,
      -0.9929765863320368,
      -1.111691319377406,
      -1.1854172382938792,
      -1.0733028820008896,
      -1.0604848088532686,
      -1.1232331785191136,
      -1.014929047315277,
      -1.2070731192911177,
      -1.0282674077715461,
      -0.9973224628057181,
      0.0,
      -1.0803943023995755,
      -1.17023325471529,
      -1.0822989299391514,
      -1.1490278964075054,
      -1.097763515433037,
      -1.0602457410446962,
      -1.18970429444381,
      -1.1222038109049655,
      -1.1039282544235445,
      -1.1669402269416365,
      -1.176957389530694,
      -1.045422505067222,
      -1.1799766345204759,
      -1.258379227562036
    ],
    [
      -1.2964831367398038,
      -1.2177785996644943,
      -1.1528716057505723,
      -1.2084242754776318,
      -1.2282068800995987,
      -1.3367521699607494,
      -1.330292882490239,
      -1.2418797161828727,
      -1.2292729750697617,
      -1.2682741564580717,
      -1.2113144333883266,
      -1.3081318370508128,
      -1.1915987736496723,
      -1.2479758198249047,
      -1.2303090417927534,
      0.0,
      -1.325196881688718,
      -1.2826890355764287,
      -1.3133754491741458,
      -1.3213733193967054,
      -1.256668728735354,
      -1.3672510983735684,
      -1.3258584525580297,
      -1.2978253212797086,
      -1.3417217442665232,
      -1.3260401838499498,
      -1.2465542683039808,
      -1.3116323971802377,
      -1.366234742497529
    ],
    [
      -1.4307924264767795,
      -1.3180099287045177,
      -1.2932132359451782,
      -1.3379262861970003,
      -1.3339339313683851,
      -1.3804398111944898,
      -1.3927502946040082,
      -1.3119857312992549,
      -1.351356351164334,
      -1.3583863337830644,
      -1.3282259735319561,
      -1.386639219591604,
      -1.3214409993309508,
      -1.3082498738333854,
      -1.3401900526232626,
      -1.3663924938402014,
      0.0,
      -1.3124182833488294,
      -1.3471654106010291,
      -1.3545714297485896,
      -1.2563504452622856,
      -1.3595672725515249,
      -1.332580681185233,
      -1.3194544341504846,
      -1.3371602005030994,
      -1.3425584282696648,
      -1.3027674086042962,
      -1.386741577606319,
      -1.4443024114224232
    ],
    [
      -1.1064543529271684,
      -0.9908460328971705,
      -1.0607010768198324,
      -0.9694932674723615,
      -0.9997569803030125,
      -1.1039626228594173,
      -1.160043017820414,
      -1.0862174592512504,
      -0.9763790535790022,
      -1.0717787420912335,
      -1.0111426528820042,
      -1.0840562315126028,
      -0.9376161256404393,
      -1.002286718140996,
      -1.0013735675593045,
      -1.0606439877113112,
      -1.1237104964462756,
      0.0,
      -1.083500711949954,
      -1.0571165198345993,
      -1.0350512473310995,
      -1.1250268471782994,
      -1.098184505907551,
      -1.0002863089463496,
      -1.0923372287259312,
      -1.1189235774209687,
      -1.0425064693031287,
      -1.0258619115193646,
      -1.1800069052743014
    ],
    [
      -1.3334625024373612,
      -1.3160905111275722,
      -1.223526987598463,
      -1.2747653544997508,
      -1.2840218369275753,
      -1.326180837799255,
      -1.344739206253099,
      -1.3006347927769555,
      -1.3045799044551847,
      -1.289747271733723,
      -1.2478668449726107,
      -1.3451486941910646,
      -1.2327637068960389,
      -1.3097327582310117,
      -1.2958434704985906,
      -1.2857655976864002,
      -1.3299723155285195,
      -1.3133263860856266,
      0.0,
      -1.2708997613314836,
      -1.2712792998018208,
      -1.2823424473626526,
      -1.319049719343905,
      -1.3194730700613309,
      -1.3577605449533343,
      -1.3148247304628438,
      -1.3238568028247382,
      -1.3649324646463585,
      -1.3679604785560489
    ],
    [
      -1.3307658879385609,
      -1.2511734318723606,
      -1.26028031313787,
      -1.2429070262067767,
      -1.2585600659969378,
      -1.3268607456237675,
      -1.3656838072879423,
      -1.3044484123924935,
      -1.2724916579808425,
      -1.3073502232824354,
      -1.2357431925936937,
      -1.3337288344992502,
      -1.2646594721516777,
      -1.3096987491173933,
      -1.2576528978865682,
      -1.313834094613208,
      -1.3154030879965746,
      -1.2883678588744343,
      -1.3108097778841967,
      0.0,
      -1.2898829987765423,
      -1.2842207018576002,
      -1.2673762330330391,
      -1.2668675456688854,
      -1.2948636610745157,
      -1.3350329287599763,
      -1.3071256378280043,
      -1.2940818472533844,
      -1.3610553220297499
    ],
    [
      -1.4174821968513187,
      -1.4065671507025315,
      -1.368396500182255,
      -1.3927437893239232,
      -1.3536752655213586,
      -1.4698552814244537,
      -1.4633726029673664,
      -1.380854164079599,
      -1.4045989599964135,
      -1.4254507618404377,
      -1.4402310513392365,
      -1.5015839785432825,
      -1.4107423981332534,
      -1.3624657889312175,
      -1.365499283254064,
      -1.3940755385770116,
      -1.4144115601189982,
      -1.3955698400650245,
      -1.3903406225858885,
      -1.453865197615948,
      0.0,
      -1.5151280812482806,
      -1.4907134777735962,
      -1.433731566689733,
      -1.481080063701147,
      -1.4288665056827472,
      -1.3853873805364771,
      -1.4678367194648652,
      -1.5938060011693769
    ],
    [
      -1.3024961999141178,
      -1.2498351871862636,
      -1.2687446416358157,
      -1.2251730829275638,
      -1.2376243342007214,
      -1.21619253524714,
      -1.245685568423734,
      -1.2372432286312676,
      -1.2699321547224944,
      -1.2633613669065484,
      -1.2004765812355642,
      -1.2309862049474802,
      -1.2523629099019047,
      -1.2401337361234037,
      -1.2282433444764655,
      -1.2709878643305772,
      -1.2320898388946697,
      -1.2589024381908644,
      -1.2035958187833025,
      -1.2038528483877102,
      -1.2111673834129093,
      0.0,
      -1.238653614997835,
      -1.2376499613204373,
      -1.2651244134270483,
      -1.2451214292575155,
      -1.268332075886458,
      -1.2783922434571469,
      -1.2244668632364992
    ],
    [
      -1.2579954028366518,
      -1.147671866211014,
      -1.1746365077503385,
      -1.1192469757424537,
      -1.1494947811930174,
      -1.223439029113066,
      -1.2398604863576494,
      -1.1945143310734567,
      -1.1920220462148894,
      -1.217280590134575,
      -1.167470448441346,
      -1.1901973738119063,
      -1.128947753846613,
      -1.1597485732589283,
      -1.1527489713319161,
      -1.18496407030669,
      -1.2032390738424616,
      -1.178986397462892,
      -1.2506384246715219,
      -1.1372290253050128,
      -1.1745779680715704,
      -1.229679447838003,
      0.0,
      -1.1500111745400767,
      -1.1448592306410816,
      -1.211100432504746,
      -1.1520729875334408,
      -1.228098024917768,
      -1.2313798931888016
    ],
    [
      -1.1758996705067666,
      -1.0891855957557988,
      -1.0893623940555752,
      -1.0748834242792515,
      -1.0846695347034598,
      -1.1852758543581017,
      -1.2342905709099643,
      -1.0735835681671857,
      -1.066537897710577,
      -1.1594233301473238,
      -1.0351524416898072,
      -1.172970999636931,
      -1.0593893771206215,
      -1.0858054725145676,
      -1.0857136376364702,
      -1.1069910977536885,
      -1.1451536153185418,
      -1.0868929347703236,
      -1.1672848261030353,
      -1.0326506988142528,
      -1.142792382074683,
      -1.1845127926165504,
      -1.118397832909459,
      0.0,
      -1.1657652241035423,
      -1.1915595794609217,
      -1.0748980415177778,
      -1.1301605367573244,
      -1.2413672222816348
    ],
    [
      -1.5205703944233613,
      -1.4562393614225997,
      -1.4439459494252083,
      -1.4194243025573317,
      -1.4247507053178226,
      -1.5073011944054489,
      -1.5473765580054721,
      -1.4312481870613092,
      -1.4795509796912212,
      -1.4897297455069112,
      -1.4590639429453396,
      -1.4956990713320981,
      -1.4282399196071047,
      -1.475026805442095,
      -1.4329721405705926,
      -1.4978628036268722,
      -1.4619793316999585,
      -1.4898001950120998,
      -1.5791563607889336,
      -1.4767199635928596,
      -1.4756856582156608,
      -1.5362402627614096,
      -1.4367274303290152,
      -1.472002708853829,
      0.0,
      -1.5531938363537794,
      -1.453503984424027,
      -1.5545576094092866,
      -1.5707013247815813
    ],
    [
      -1.400768543137577,
      -1.354215365442673,
      -1.3951399289186182,
      -1.3510876650659969,
      -1.3965973853349878,
      -1.4392076529142892,
      -1.3878152655345675,
      -1.3198595921786251,
      -1.3812776298048324,
      -1.4375262370072097,
      -1.4162644228577448,
      -1.4340598200744348,
      -1.3662621699860324,
      -1.3876444363740619,
      -1.3720152842911113,
      -1.3848647827168048,
      -1.4146278298293316,
      -1.3948625440388223,
      -1.4037667091048036,
      -1.4136211871653086,
      -1.3180294877577583,
      -1.417118598508315,
      -1.3965887441076077,
      -1.4413414205201804,
      -1.4403708800406145,
      0.0,
      -1.3881869825467645,
      -1.4285495939646728,
      -1.4484217849267298
    ],
    [
      -1.2708166702401793,
      -1.157894525339143,
      -1.1801794036410724,
      -1.1780032184499707,
      -1.1602534436985945,
      -1.2662627119471497,
      -1.3367854496713714,
      -1.2342822953660113,
      -1.178515220805624,
      -1.2418419107347063,
      -1.1838818040628472,
      -1.286446547201481,
      -1.1596332276424797,
      -1.157505744570595,
      -1.1591995413784415,
      -1.2259177664480572,
      -1.3030248736117316,
      -1.1848044417327812,
      -1.2704364103054873,
      -1.2392307551160513,
      -1.2327773237215767,
      -1.3464667603870417,
      -1.218736998866734,
      -1.2528951855895742,
      -1.2481448180950347,
      -1.3460347394729626,
      0.0,
      -1.3204403275001682,
      -1.3590203116539061
    ],
    [
      -1.1029961832334634,
      -1.0488161041871533,
      -1.043578729172418,
      -1.0296923296083624,
      -1.0341676920009066,
      -1.0979537985844015,
      -1.1059613512560982,
      -1.0557338917885242,
      -0.9650376139136666,
      -1.029810935616528,
      -1.0068055234845366,
      -1.0774254484111236,
      -1.0210406693713332,
      -1.009149488600932,
      -1.0813635482007382,
      -1.0409101660894906,
      -1.0671929014600539,
      -0.9859142149093687,
      -1.0493173568240812,
      -1.0473229341309354,
      -1.051161482116943,
      -1.0824213958723055,
      -1.0694845840084495,
      -0.977548624118311,
      -1.1172701569264982,
      -1.0676929195473435,
      -1.0704514367565294,
      0.0,
      -1.1356600144360203
    ],
    [
      -1.4117275064649089,
      -1.3750271338226012,
      -1.398046962752662,
      -1.377769760106266,
      -1.3953514450166948,
      -1.4162471821589198,
      -1.4567833696999208,
      -1.414451798586925,
      -1.3742936657949036,
      -1.3779664180707778,
      -1.366931344295736,
      -1.413273237547628,
      -1.3738992214869545,
      -1.3969674875601423,
      -1.4107657337701647,
      -1.4051180762054603,
      -1.428541851448338,
      -1.4141019859225126,
      -1.4301690086030303,
      -1.395158853805718,
      -1.4447668475803377,
      -1.402950015416917,
      -1.398524207204964,
      -1.4276327812994072,
      -1.4281285762686653,
      -1.4536078071811402,
      -1.4080492404518445,
      -1.4123810430497967,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.3880654000541912,
      0.40223016984126825,
      0.39425584349214193,
      0.40070416893273375,
      0.30547486366256194,
      0.2613190591506813,
      0.36768758432680926,
      0.40256470997777405,
      0.33455496041800004,
      0.4006209600741182,
      0.26212934345093974,
      0.3923357096177882,
      0.38774150709972743,
      0.3980375322520773,
      0.3900932568273918,
      0.313474447367164,
      0.40696031125929477,
      0.3047186008006577,
      0.3548645699687103,
      0.3731642241462467,
      0.2828115875996884,
      0.33847334659008244,
      0.33551557497359163,
      0.26845387473723115,
      0.35440629989884176,
      0.415521760688943,
      0.33383514021197014,
      0.2488637207497355
    ],
    [
      0.3917176639836075,
      0.0,
      0.48003049122775443,
      0.4938413390565093,
      0.47984747132710104,
      0.35423490145161773,
      0.34374179948476,
      0.4129588740296928,
      0.49891584332903793,
      0.3614301574181549,
      0.46958259004329683,
      0.34167170644699585,
      0.49063574613680827,
      0.46643311329033366,
      0.49166398657158394,
      0.44946344818575623,
      0.3546542000966024,
      0.4374788407667598,
      0.30920983756418274,
      0.40390891460559164,
      0.42707217453694657,
      0.26839545684681543,
      0.3925599811977778,
      0.35488140304481397,
      0.34552091839040533,
      0.3433818438325831,
      0.4498777645024157,
      0.3210306782329446,
      0.2756766069048442
    ],
    [
      0.3138381675759252,
      0.4170875889490633,
      0.0,
      0.3981947284838814,
      0.4128879833562773,
      0.27224166702856767,
      0.24259821730111852,
      0.3657497139338308,
      0.40550566102195207,
      0.3933201820500587,
      0.43545471650072276,
      0.2714072443365667,
      0.499631086342061,
      0.3726743916732844,
      0.36231623608646935,
      0.4466494791785025,
      0.3117685553963392,
      0.3905326737873789,
      0.3304806577191355,
      0.3178277173540749,
      0.35337539329870404,
      0.23967172226815014,
      0.3140467341582849,
      0.31652827738764544,
      0.316078958858961,
      0.31398729033816797,
      0.3470535164640056,
      0.2826095609675594,
      0.2259362342356792
    ],
    [
      0.37633690302975165,
      0.5185731234172348,
      0.5159526373320042,
      0.0,
      0.502287053059143,
      0.40874311539585206,
      0.39762418286003043,
      0.47983787301376757,
      0.531236594358556,
      0.4483470708482211,
      0.47669357929155276,
      0.3761489145858874,
      0.6178801520080694,
      0.4992992988042204,
      0.560728597290066,
      0.47694910732118756,
      0.4011927328134075,
      0.44528572223393326,
      0.41865997410479827,
      0.43563125472499986,
      0.44488095003011563,
      0.33691926770102754,
      0.42945520068612675,
      0.41162718623728156,
      0.39734962718132105,
      0.39749932378978414,
      0.45434400156232235,
      0.38922570746342755,
      0.3238809937246867
    ],
    [
      0.3635236810775504,
      0.44199103164560705,
      0.4644676003938766,
      0.44649457318375885,
      0.0,
      0.3650020401114813,
      0.3220347931676817,
      0.45744979029135324,
      0.467385070776585,
      0.3713960689955387,
      0.46300060840766033,
      0.35117270183562854,
      0.43811498337753707,
      0.46705893814761135,
      0.4669785629642287,
      0.4124697744906325,
      0.36855279021350684,
      0.40492661455747325,
      0.3391387076028014,
      0.41532877223209885,
      0.42622734959816655,
      0.3508725921577349,
      0.3938489981060853,
      0.38501048880211797,
      0.40084031591592706,
      0.34078449762952046,
      0.4286734850854075,
      0.34637034202527706,
      0.2765461746651934
    ],
    [
      0.3504968967010924,
      0.40801808361357006,
      0.43263845553513813,
      0.49315243428590105,
      0.4759505913097526,
      0.0,
      0.3388589348668267,
      0.4276629540092738,
      0.4258717485921175,
      0.39691479809342134,
      0.45817438634455154,
      0.365769528491106,
      0.3908208906759878,
      0.4381042610866912,
      0.476308600463494,
      0.40128653394004443,
      0.34881661507186945,
      0.3575221784858096,
      0.40028472696868755,
      0.4045084349141346,
      0.3888253367067731,
      0.37363778209615783,
      0.37830370121599244,
      0.3638295623923631,
      0.3497808442875896,
      0.3509033745471768,
      0.39200775042884217,
      0.347669382693061,
      0.33482388655240847
    ],
    [
      0.26298568756438145,
      0.32878606174798186,
      0.3287776810545866,
      0.3560626859563112,
      0.3255292745289371,
      0.2812686884232247,
      0.0,
      0.3123783256904209,
      0.3271428716294933,
      0.24508494761813515,
      0.3143011994309144,
      0.23533108587990292,
      0.3314241619312903,
      0.27368419603319083,
      0.31514477153164466,
      0.32003149565056677,
      0.24501579185600186,
      0.27275701387480833,
      0.27419927850303716,
      0.2693906598504767,
      0.3106897270633353,
      0.23406645701816586,
      0.27387771395196436,
      0.27378757527603304,
      0.25668417507950125,
      0.2830938682346682,
      0.28676624593864397,
      0.248922152818005,
      0.20813986610651614
    ],
    [
      0.3767402583668429,
      0.4730299313334638,
      0.4575446092301101,
      0.481988405563859,
      0.4714483135884804,
      0.4012393747258418,
      0.356850058419093,
      0.0,
      0.41725104015450887,
      0.35086144671127695,
      0.4701807624655143,
      0.3861663424805697,
      0.48536427844149,
      0.45691591047318414,
      0.44358310097268805,
      0.43171654507126145,
      0.3855954726732116,
      0.44930167654465936,
      0.4069554434761924,
      0.4309647823070988,
      0.4044305568016957,
      0.3656937152433124,
      0.418157725589017,
      0.4336081511877725,
      0.40062487569355576,
      0.418177735815773,
      0.449829806862861,
      0.3761653094958328,
      0.31681355047920157
    ],
    [
      0.3495113680228883,
      0.482465518473318,
      0.4917554154394217,
      0.5216000428767444,
      0.4723360157498968,
      0.36642743106308573,
      0.33245605456313343,
      0.43805898083464845,
      0.0,
      0.40891663648519483,
      0.4776002930051293,
      0.3503092863324997,
      0.5520744817184646,
      0.48075972754287166,
      0.4691079137199945,
      0.4925850107561516,
      0.3477155072608009,
      0.4667900090736299,
      0.38178262331660706,
      0.4302688347690047,
      0.4127823986636321,
      0.33872808551765465,
      0.3630273715724397,
      0.42327815308932015,
      0.35975310424167284,
      0.35113007749695857,
      0.45216939687322544,
      0.3922933356578673,
      0.3281111956809992
    ],
    [
      0.35238929079892434,
      0.3961845244012294,
      0.4158256784641994,
      0.4528361342364955,
      0.3905413414450576,
      0.36566335441944964,
      0.29182810927359615,
      0.38470900087193916,
      0.4120089692031541,
      0.0,
      0.45053647445167977,
      0.3721537326184525,
      0.4685622298902816,
      0.4171425496577925,
      0.4126080171595934,
      0.4264524537270311,
      0.31770536247355863,
      0.3793463814079443,
      0.36588221380916086,
      0.3686888791985581,
      0.35169722264852754,
      0.32263030360720957,
      0.349117707749538,
      0.36950574936847125,
      0.3347796789008233,
      0.30403967438783974,
      0.3678054370252739,
      0.32420292649595983,
      0.3189545586994056
    ],
    [
      0.38131176300804026,
      0.49134037225534577,
      0.5233369169162101,
      0.5017261952499115,
      0.49944129593832187,
      0.3984329817246497,
      0.32676730430720635,
      0.4840229719541369,
      0.4739766698702257,
      0.4267308469385229,
      0.0,
      0.3761854033934042,
      0.49046459014178145,
      0.49592510014099633,
      0.463892478937038,
      0.4683092010610921,
      0.3598333084072467,
      0.44687569148517126,
      0.42506309375826534,
      0.45276592067747257,
      0.408598052420299,
      0.3752026297293012,
      0.38660535435606835,
      0.4467568345881341,
      0.3641641336022412,
      0.33920768162003334,
      0.49200869170135264,
      0.3690941729191639,
      0.3187648933260585
    ],
    [
      0.3819726904985863,
      0.436589617846894,
      0.43131112131788774,
      0.44792720680523046,
      0.42402867370292663,
      0.3838727498125887,
      0.40523734466205275,
      0.42627880991881284,
      0.44232616916946776,
      0.43415072442900393,
      0.4265074086702849,
      0.0,
      0.45015288223199823,
      0.4566843528119551,
      0.42126773950866747,
      0.40254020401856105,
      0.40485826281674675,
      0.41096649900097515,
      0.3705328335785243,
      0.40172576365106694,
      0.4615588709465521,
      0.3923443612713464,
      0.4320216322982562,
      0.4141856551710985,
      0.3918194676170976,
      0.3977673249372382,
      0.3976464207215453,
      0.4099365998624567,
      0.39312785470855705
    ],
    [
      0.3471290449627251,
      0.4167342489702064,
      0.5010074973219287,
      0.5497043326572115,
      0.45452519980684536,
      0.3498156186778023,
      0.33367831489983435,
      0.41187277583228465,
      0.4558507421408411,
      0.42990131337787796,
      0.4558196633165077,
      0.34361965305172015,
      0.0,
      0.41579107530459414,
      0.45189295825423015,
      0.4575610836024464,
      0.377974496658696,
      0.4519438942259957,
      0.35097235273974836,
      0.3573450244660541,
      0.41657068923304985,
      0.3008639954066201,
      0.38424308684889086,
      0.3839806925094382,
      0.391101608615519,
      0.336266495796512,
      0.3817393656521584,
      0.35128958554562617,
      0.290380343082552
    ],
    [
      0.32788076864085447,
      0.4328575835416564,
      0.4387934086119938,
      0.47423988813418716,
      0.46489510501066866,
      0.3665609858510932,
      0.29492104312717715,
      0.4057442769824784,
      0.43526554946082907,
      0.38417048103602913,
      0.4727359694103479,
      0.3550628972475067,
      0.44392170877324677,
      0.0,
      0.46229925840337494,
      0.4205351441864904,
      0.3122269371904811,
      0.411253119644843,
      0.35689607428742054,
      0.3831415210411431,
      0.3759757321266648,
      0.31884510827244883,
      0.343485659304942,
      0.3913945753947812,
      0.34679864574088737,
      0.30803062125922165,
      0.48323340223228617,
      0.3487905652820604,
      0.3036141504009193
    ],
    [
      0.4547009884753501,
      0.5658652162637853,
      0.5246542683999234,
      0.6089372864374012,
      0.561937967582151,
      0.4432232345367817,
      0.3694973156203085,
      0.4816116719132981,
      0.4944297450609192,
      0.4316813753950741,
      0.5399855065989108,
      0.34784143462307004,
      0.5266471461426416,
      0.5575920911084696,
      0.0,
      0.4745202515146123,
      0.3846812991988977,
      0.4726156239750363,
      0.4058866575066824,
      0.4571510384811508,
      0.4946688128694916,
      0.36521025947037766,
      0.4327107430092223,
      0.4509862994906433,
      0.3879743269725513,
      0.3779571643834938,
      0.5094920488469659,
      0.3749379193937119,
      0.29653532635215174
    ],
    [
      0.3403262505665059,
      0.41903078764181534,
      0.4839377815557373,
      0.4283851118286779,
      0.408602507206711,
      0.30005721734556023,
      0.30651650481607073,
      0.3949296711234369,
      0.4075364122365479,
      0.3685352308482379,
      0.4254949539179831,
      0.32867755025549683,
      0.4452106136566374,
      0.38883356748140496,
      0.4065003455135563,
      0.0,
      0.3116125056175916,
      0.354120351729881,
      0.3234339381321638,
      0.3154360679096042,
      0.3801406585709557,
      0.26955828893274125,
      0.31095093474827995,
      0.338984066026601,
      0.2950876430397864,
      0.31076920345635983,
      0.3902551190023289,
      0.32517699012607193,
      0.2705746448087807
    ],
    [
      0.3189076521104788,
      0.43169014988274057,
      0.45648684264208006,
      0.411773792390258,
      0.41576614721887317,
      0.3692602673927685,
      0.35694978398325006,
      0.4377143472880034,
      0.39834372742292423,
      0.3913137448041939,
      0.42147410505530214,
      0.3630608589956543,
      0.42825907925630746,
      0.44145020475387287,
      0.40951002596399566,
      0.38330758474705684,
      0.0,
      0.4372817952384289,
      0.40253466798622917,
      0.3951286488386687,
      0.4933496333249727,
      0.3901328060357334,
      0.4171193974020253,
      0.4302456444367737,
      0.41253987808415893,
      0.40714165031759353,
      0.4469326699829621,
      0.3629585009809393,
      0.3053976671648351
    ],
    [
      0.3682715432194015,
      0.48387986324939936,
      0.4140248193267375,
      0.5052326286742084,
      0.4749689158435574,
      0.37076327328715264,
      0.31468287832615593,
      0.38850843689531955,
      0.49834684256756767,
      0.40294715405533643,
      0.4635832432645657,
      0.39066966463396713,
      0.5371097705061306,
      0.4724391780055739,
      0.4733523285872654,
      0.4140819084352587,
      0.3510153997002943,
      0.0,
      0.3912251841966159,
      0.4176093763119706,
      0.43967464881547036,
      0.34969904896827053,
      0.3765413902390189,
      0.4744395872002203,
      0.3823886674206387,
      0.3558023187256012,
      0.43221942684344117,
      0.44886398462720534,
      0.2947189908722685
    ],
    [
      0.31067635144556394,
      0.3280483427553529,
      0.42061186628446223,
      0.3693734993831743,
      0.3601170169553498,
      0.31795801608367014,
      0.2993996476298262,
      0.34350406110596965,
      0.33955894942774045,
      0.3543915821492021,
      0.39627200891031444,
      0.2989901596918605,
      0.41137514698688626,
      0.3344060956519135,
      0.3482953833843345,
      0.35837325619652494,
      0.31416653835440567,
      0.33081246779729856,
      0.0,
      0.3732390925514415,
      0.3728595540811044,
      0.36179640652027256,
      0.3250891345390201,
      0.3246657838215943,
      0.2863783089295908,
      0.3293141234200814,
      0.32028205105818697,
      0.2792063892365666,
      0.2761783753268763
    ],
    [
      0.34723190717137653,
      0.4268243632375768,
      0.4177174819720675,
      0.4350907689031607,
      0.4194377291129996,
      0.35113704948616986,
      0.31231398782199515,
      0.37354938271744387,
      0.4055061371290949,
      0.37064757182750196,
      0.4422546025162437,
      0.34426896061068724,
      0.4133383229582597,
      0.36829904599254415,
      0.4203448972233692,
      0.3641637004967293,
      0.36259470711336284,
      0.3896299362355031,
      0.3671880172257407,
      0.0,
      0.3881147963333951,
      0.39377709325233723,
      0.41062156207689826,
      0.41113024944105203,
      0.38313413403542174,
      0.34296486634996115,
      0.3708721572819331,
      0.38391594785655303,
      0.3169424730801875
    ],
    [
      0.377489142174255,
      0.38840418832304224,
      0.4265748388433188,
      0.40222754970165053,
      0.44129607350421507,
      0.32511605760112006,
      0.33159873605820733,
      0.41411717494597466,
      0.3903723790291602,
      0.369520577185136,
      0.35474028768633725,
      0.2933873604822912,
      0.3842289408923203,
      0.4325055500943562,
      0.4294720557715097,
      0.4008958004485621,
      0.38055977890657555,
      0.3994014989605492,
      0.4046307164396852,
      0.3411061414096257,
      0.0,
      0.27984325777729313,
      0.3042578612519775,
      0.3612397723358407,
      0.31389127532442673,
      0.3661048333428265,
      0.40958395848909657,
      0.32713461956070855,
      0.20116533785619684
    ],
    [
      0.30779914561646815,
      0.3604601583443223,
      0.34155070389477027,
      0.3851222626030222,
      0.3726710113298646,
      0.39410281028344585,
      0.36460977710685194,
      0.3730521168993184,
      0.3403631908080915,
      0.3469339786240375,
      0.40981876429502173,
      0.3793091405831057,
      0.35793243562868127,
      0.37016160940718223,
      0.3820520010541204,
      0.33930748120000875,
      0.37820550663591623,
      0.3513929073397215,
      0.4066995267472835,
      0.4064424971428757,
      0.39912796211767665,
      0.0,
      0.37164173053275085,
      0.3726453842101487,
      0.34517093210353766,
      0.3651739162730705,
      0.34196326964412793,
      0.3319031020734391,
      0.3858284822940867
    ],
    [
      0.29777221107106056,
      0.40809574769669843,
      0.3811311061573739,
      0.43652063816525866,
      0.40627283271469494,
      0.33232858479464644,
      0.3159071275500629,
      0.3612532828342556,
      0.36374556769282296,
      0.33848702377313744,
      0.3882971654663663,
      0.3655702400958061,
      0.4268198600610993,
      0.396019040648784,
      0.4030186425757962,
      0.3708035436010224,
      0.3525285400652507,
      0.3767812164448203,
      0.3051291892361905,
      0.41853858860269955,
      0.3811896458361419,
      0.32608816606970925,
      0.0,
      0.4057564393676356,
      0.4109083832666307,
      0.34466718140296626,
      0.40369462637427156,
      0.32766958898994436,
      0.32438772071891075
    ],
    [
      0.368594442794671,
      0.45530851754563884,
      0.4551317192458624,
      0.46961068902218606,
      0.45982457859797776,
      0.3592182589433359,
      0.3102035423914733,
      0.4709105451342519,
      0.47795621559086054,
      0.3850707831541138,
      0.5093416716116304,
      0.3715231136645065,
      0.48510473618081607,
      0.45868864078687,
      0.4587804756649674,
      0.43750301554774906,
      0.39934049798289584,
      0.45760117853111404,
      0.3772092871984023,
      0.5118434144871848,
      0.40170173122675457,
      0.3599813206848872,
      0.42609628039197855,
      0.0,
      0.37872888919789527,
      0.3529345338405159,
      0.4695960717836598,
      0.4143335765441132,
      0.30312689101980284
    ],
    [
      0.3321876934504877,
      0.3965187264512493,
      0.4088121384486407,
      0.43333378531651734,
      0.42800738255602644,
      0.34545689346840014,
      0.30538152986837686,
      0.4215099008125398,
      0.3732071081826278,
      0.3630283423669378,
      0.3936941449285094,
      0.3570590165417509,
      0.42451816826674427,
      0.377731282431754,
      0.41978594730325636,
      0.3548952842469768,
      0.39077875617389046,
      0.3629578928617492,
      0.27360172708491537,
      0.37603812428098937,
      0.3770724296581882,
      0.3165178251124394,
      0.4160306575448338,
      0.38075537902002,
      0.0,
      0.2995642515200696,
      0.39925410344982204,
      0.29820047846456244,
      0.2820567630922677
    ],
    [
      0.3366840567734586,
      0.38323723446836255,
      0.34231267099241736,
      0.38636493484503864,
      0.3408552145760477,
      0.2982449469967463,
      0.34963733437646805,
      0.41759300773241037,
      0.35617497010620314,
      0.2999263629038258,
      0.3211881770532907,
      0.30339277983660073,
      0.37119042992500306,
      0.34980816353697364,
      0.3654373156199242,
      0.3525878171942307,
      0.32282477008170396,
      0.34259005587221325,
      0.3336858908062319,
      0.3238314127457269,
      0.4194231121532772,
      0.3203340014027205,
      0.3408638558034278,
      0.2961111793908551,
      0.297081719870421,
      0.0,
      0.349265617364271,
      0.30890300594636266,
      0.2890308149843057
    ],
    [
      0.40342364514089946,
      0.5163457900419357,
      0.4940609117400063,
      0.49623709693110807,
      0.5139868716824842,
      0.4079776034339291,
      0.3374548657097074,
      0.43995802001506745,
      0.49572509457545477,
      0.43239840464637247,
      0.4903585113182316,
      0.38779376817959776,
      0.5146070877385991,
      0.5167345708104838,
      0.5150407740026373,
      0.4483225489330216,
      0.3712154417693472,
      0.48943587364829755,
      0.4038039050755915,
      0.43500956026502746,
      0.4414629916595021,
      0.32777355499403704,
      0.4555033165143447,
      0.4213451297915045,
      0.426095497286044,
      0.32820557590811616,
      0.0,
      0.3537999878809106,
      0.3152200037271726
    ],
    [
      0.3076453968571744,
      0.36182547590348446,
      0.3670628509182199,
      0.38094925048227535,
      0.37647388808973115,
      0.31268778150623633,
      0.3046802288345396,
      0.3549076883021136,
      0.4456039661769712,
      0.38083064447410986,
      0.4038360566061012,
      0.33321613167951414,
      0.3896009107193046,
      0.40149209148970577,
      0.32927803188989957,
      0.3697314140011472,
      0.3434486786305839,
      0.4247273651812691,
      0.36132422326655655,
      0.3633186459597024,
      0.35948009797369473,
      0.3282201842183323,
      0.3411569960821883,
      0.4330929559723268,
      0.29337142316413956,
      0.3429486605432943,
      0.34019014333410835,
      0.0,
      0.2749815656546175
    ],
    [
      0.34999886132020674,
      0.3866992339625144,
      0.36367940503245366,
      0.38395660767884965,
      0.36637492276842076,
      0.34547918562619584,
      0.30494299808519476,
      0.34727456919819066,
      0.38743270199021196,
      0.3837599497143378,
      0.39479502348937956,
      0.3484531302374876,
      0.38782714629816106,
      0.36475888022497327,
      0.3509606340149509,
      0.35660829157965535,
      0.3331845163367777,
      0.347624381862603,
      0.3315573591820853,
      0.3665675139793976,
      0.3169595202047779,
      0.3587763523681986,
      0.36320216058015165,
      0.3340935864857084,
      0.3335977915164503,
      0.30811856060397536,
      0.35367712733327106,
      0.3493453247353189,
      0.0
    ]
  ],
  "row_avgs": [
    0.3506742331489415,
    0.4003506340180604,
    0.3453376555732989,
    0.4454496480310278,
    0.39913076240921586,
    0.3953908097989226,
    0.2855472735800764,
    0.4184713992917274,
    0.41906408106418763,
    0.3744213555853981,
    0.42810016251527466,
    0.4160478300709421,
    0.39819911260563984,
    0.38798464930700133,
    0.4569261792722526,
    0.35888124707484026,
    0.4048582597750386,
    0.4173950168856648,
    0.3387621289170924,
    0.38332185176641304,
    0.3661023487284377,
    0.3671943501711767,
    0.37033506790264487,
    0.42090230781307547,
    0.36814127617516224,
    0.33994931619137564,
    0.434974871550694,
    0.35807438385397644,
    0.3542752048717821
  ],
  "col_avgs": [
    0.3499122668720903,
    0.4265698886434886,
    0.4350507531478732,
    0.4480407040123189,
    0.4328934124105444,
    0.35328531975478483,
    0.3261318383664887,
    0.40695735030739444,
    0.42391445170291936,
    0.3787590128693211,
    0.4330836726475167,
    0.3428693267950921,
    0.4483983105894427,
    0.423540515517547,
    0.42527352188159767,
    0.4079194512914169,
    0.351626479173683,
    0.40246118471525577,
    0.36152452529691403,
    0.390272184740234,
    0.40075265260878973,
    0.3302997010908209,
    0.37460750836934226,
    0.38354933344334957,
    0.3525035392526581,
    0.34536939105972303,
    0.4048555513045618,
    0.34742088843170066,
    0.29642068165247204
  ],
  "combined_avgs": [
    0.3502932500105159,
    0.4134602613307745,
    0.39019420436058605,
    0.44674517602167335,
    0.41601208740988016,
    0.3743380647768537,
    0.30583955597328255,
    0.4127143747995609,
    0.4214892663835535,
    0.37659018422735957,
    0.4305919175813957,
    0.3794585784330171,
    0.4232987115975413,
    0.40576258241227414,
    0.44109985057692513,
    0.3834003491831286,
    0.3782423694743608,
    0.40992810080046027,
    0.35014332710700324,
    0.3867970182533235,
    0.38342750066861375,
    0.3487470256309988,
    0.37247128813599356,
    0.40222582062821255,
    0.36032240771391016,
    0.34265935362554933,
    0.4199152114276279,
    0.35274763614283855,
    0.32534794326212707
  ],
  "gppm": [
    576.98439060513,
    550.9773598971675,
    542.5224080374061,
    538.6198728089054,
    542.2006241395593,
    583.4926971762014,
    589.8296311675806,
    557.7971423776363,
    550.4950925055006,
    568.4110015513229,
    544.7169267213601,
    589.7223024610577,
    536.7739600380057,
    551.0015596864184,
    551.4831289716559,
    555.2331529581047,
    582.1215740201558,
    563.3542087562555,
    579.5338518692635,
    565.3158231668457,
    557.0372547064683,
    595.9173764851372,
    574.4119939836726,
    570.8087957008273,
    580.7569561014135,
    580.7648091443682,
    558.6502543615264,
    588.9444193005,
    609.0526030399877
  ],
  "gppm_normalized": [
    1.3646379875887866,
    1.3241632543925668,
    1.3063736525061753,
    1.300047973790153,
    1.3015817931244074,
    1.406372354338714,
    1.4204310930018824,
    1.348339743705197,
    1.3243206936085852,
    1.3701163260016584,
    1.3092603915302683,
    1.4341894617611115,
    1.2908197654040479,
    1.3244898897798094,
    1.331626770523794,
    1.3364783203959807,
    1.4030152820924642,
    1.3571719548953343,
    1.3956008660952695,
    1.3612148210550694,
    1.344466443167389,
    1.4363967952987748,
    1.3828587926991613,
    1.3785300883269702,
    1.4005616794396032,
    1.3990028687995595,
    1.3429049619767564,
    1.4192086516481912,
    1.4674104660274223
  ],
  "token_counts": [
    301,
    388,
    419,
    442,
    388,
    427,
    412,
    466,
    407,
    425,
    397,
    630,
    398,
    392,
    463,
    417,
    423,
    430,
    413,
    414,
    437,
    427,
    409,
    455,
    430,
    420,
    403,
    426,
    422,
    742,
    457,
    402,
    407,
    384,
    425,
    586,
    447,
    476,
    395,
    412,
    440,
    450,
    425,
    400,
    433,
    422,
    379,
    389,
    427,
    392,
    371,
    364,
    413,
    432,
    393,
    358,
    382,
    420,
    606,
    434,
    448,
    474,
    401,
    495,
    477,
    426,
    580,
    412,
    415,
    465,
    498,
    455,
    421,
    458,
    403,
    420,
    442,
    452,
    435,
    381,
    344,
    473,
    422,
    437,
    351,
    428,
    360,
    852,
    466,
    462,
    474,
    415,
    413,
    436,
    422,
    465,
    448,
    470,
    377,
    462,
    415,
    455,
    415,
    425,
    413,
    422,
    411,
    459,
    427,
    407,
    447,
    412,
    368,
    423,
    422,
    431,
    885,
    465,
    444,
    471,
    435,
    421,
    397,
    467,
    393,
    448,
    471,
    447,
    418,
    426,
    423,
    395,
    392,
    431,
    460,
    459,
    395,
    389,
    413,
    412,
    402,
    405,
    364,
    428,
    394,
    389,
    442,
    502,
    431,
    485,
    414,
    543,
    421,
    441,
    441,
    462,
    364,
    465,
    477,
    435,
    486,
    420,
    424,
    410,
    443,
    468,
    375,
    436,
    428,
    405,
    503,
    435,
    423,
    372
  ],
  "response_lengths": [
    2001,
    2516,
    2829,
    2526,
    2729,
    2363,
    3142,
    2345,
    2536,
    2500,
    2602,
    2159,
    2699,
    2694,
    2411,
    2870,
    2314,
    2466,
    2366,
    2508,
    2568,
    2110,
    2530,
    2453,
    2331,
    2866,
    2489,
    2448,
    2131
  ]
}