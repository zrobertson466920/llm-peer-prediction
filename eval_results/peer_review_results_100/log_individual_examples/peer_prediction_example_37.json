{
  "example_idx": 37,
  "reference": "Under review as a conference paper at ICLR 2023\n\nLEARNING MULTIOBJECTIVE PROGRAM THROUGH ONLINE LEARNING\n\nAnonymous authors Paper under double-blind review\n\nABSTRACT\n\nWe investigate the problem of learning the parameters (i.e., objective functions or constraints) of a multiobjective decision making model, based on a set of sequentially arrived decisions. In particular, these decisions might not be exact and possibly carry measurement noise or are generated with the bounded rationality of decision makers. In this paper, we propose a general online learning framework to deal with this learning problem using inverse multiobjective optimization, and prove that this framework converges at a rate of O(1/ T ) under certain regularity conditions. More precisely, we develop two online learning algorithms with implicit update rules which can handle noisy data. Numerical results with both synthetic and real world datasets show that both algorithms can learn the parameters of a multiobjective program with great accuracy and are robust to noise.\n\n√\n\n1\n\nINTRODUCTION\n\nIn this paper, we aim to learn the parameters (i.e., constraints and a set of objective functions) of a decision making problem with multiple objectives, instead of solving for its efficient (or Pareto) optimal solutions, which is the typical scenario. More precisely, we seek to learn θ given {yi}i∈[N ] that are observations of the efficient solutions of the multiobjective optimization problem (MOP):\n\n{f1(x, θ), f2(x, θ), . . . , fp(x, θ)}\n\nmin x\ns.t. x ∈ X(θ),\n\nwhere θ is the true but unknown parameter of the MOP. In particular, we consider such learning problems in online fashion, noting observations are unveiled sequentially in practical scenarios. Specifically, we study such learning problem as an inverse multiobjective optimization problem (IMOP) dealing with noisy data, develop online learning algorithms to derive parameters for each objective function and constraint, and finally output an estimation of the distribution of weights (which, together with objective functions, define individuals’ utility functions) among human subjects.\n\nLearning human participants’ decision making scheme is critical for an organization in designing and providing services or products. Nevertheless, as in most scenarios, we can only observe their decisions or behaviors and cannot directly access decision making schemes. Indeed, participants probably do not have exact information regarding their own decision making process (Keshavarz et al., 2011). To bridge the discrepancy, we leverage the inverse optimization idea that has been proposed and received significant attention in the optimization community, which is to infer the missing information of the underlying decision models from observed data, assuming that human decision makers are making optimal decisions (Ahuja & Orlin, 2001; Iyengar & Kang, 2005; Schaefer, 2009; Wang, 2009; Keshavarz et al., 2011; Chan et al., 2014; Bertsimas et al., 2015; Aswani et al., 2018; Esfahani et al., 2018; Tan et al., 2020). This subject actually carries the data-driven concept and becomes more applicable as large amounts of data are generated and become readily available, especially those from digital devices and online transactions.\n\n1.1 RELATED WORK\n\nOur work draws inspiration from the inverse optimization problem with single objective. It seeks particular values for those parameters such that the difference between the actual observation and the expected solution to the optimization model (populated with those inferred values) is minimized. Although complicated, an inverse optimization model can often be simplified for computation through\n\n1\n\nUnder review as a conference paper at ICLR 2023\n\nusing KKT conditions or strong duality of the decision making model, provided that it is convex. Nowadays, extending from its initial form that only considers a single observation Ahuja & Orlin (2001); Iyengar & Kang (2005); Schaefer (2009); Wang (2009), inverse optimization has been further developed and applied to handle many observations Keshavarz et al. (2011); Bertsimas et al. (2015); Aswani et al. (2018); Esfahani et al. (2018). Nevertheless, a particular challenge, which is almost unavoidable for any large data set, is that the data could be inconsistent due to measurement errors or decision makers’ sub-optimality. To address this challenge, the assumption on the observations’ optimality is weakened to integrate those noisy data, and KKT conditions or strong duality is relaxed to incorporate inexactness.\n\nOur work is most related to the subject of inverse multiobjective optimization. The goal is to find multiple objective functions or constraints that explain the observed efficient solutions well. There are several recent studies related to the presented research. One is in Chan et al. (2014), which considers a single observation that is assumed to be an exact optimal solution. Then, given a set of well-defined linear functions, an inverse optimization is formulated to learn their weights. Another one is Dong & Zeng (2020), which proposes the batch learning framework to infer utility functions or constraints from multiple noisy decisions through inverse multiobjective optimization. This work can be categorized as doing inverse multiobjective optimization in batch setting. Recently, Dong & Zeng (2021) extends Dong & Zeng (2020) with distributionally robust optimization by leveraging the prominent Wasserstein metric. In contrast, we do inverse multiobjective optimization in online settings, and the proposed online learning algorithms significantly accelerate the learning process with performance guarantees, allowing us to deal with more realistic and complex preference inference problems.\n\nAlso related to our work is the line of research conducted by B ̈armann et al. (2017) and Dong et al. (2018), which develops online learning methods to infer the utility function or constraints from sequentially arrived observations. However, their approach is only possible to handle inverse optimization with a single objective. More specifically, their methods apply to situations where observations are generated by decision making problems with only one objective function. Differently, our approach does not make the single-objective assumption and only requires the convexity of the underlying decision making problem with multiple objectives. Hence, we believe that our work generalizes their methods and extends the applicability of online learning from learning single objective program to multiobjective program.\n\n1.2 OUR CONTRIBUTIONS\n\nTo the best of authors’ knowledge, we propose the first general framework of online learning for inferring decision makers’ objective functions or constraints using inverse multiobjective optimization. This framework can learn the parameters of any convex decision making problem, and can explicitly handle noisy decisions. Moreover, we show that the online learning approach, which adopts an implicit update rule, has an O( T ) regret under suitable regularity conditions when using the ideal loss function. We finally illustrate the performance of two algorithms on both a multiobjective quadratic programming problem and a portfolio optimization problem. Results show that both algorithms can learn parameters with great accuracy and are robust to noise while the second algorithm significantly accelerate the learning process over the first one.\n\n√\n\n2 PROBLEM SETTING\n\n2.1 DECISION MAKING PROBLEM WITH MULTIPLE OBJECTIVES\n\nWe consider a family of parametrized multiobjective decision making problems of the form\n\nmin x∈Rn s.t.\n\n(cid:8)f1(x, θ), f2(x, θ), . . . , fp(x, θ)(cid:9) x ∈ X(θ),\n\n(DMP)\n\nwhere p ≥ 2 and fl(x, θ) : Rn × Rnθ (cid:55)→ R for each l ∈ [p]. Assume parameter θ ∈ Θ ⊆ Rnθ . We denote the vector of objective functions by f (x, θ) = (f1(x, θ), f2(x, θ), . . . , fp(x, θ))T . Assume X(θ) = {x ∈ Rn : g(x, θ) ≤ 0, x ∈ Rn +}, where g(x, θ) = (g1(x, θ), . . . , gq(x, θ))T is another vector-valued function with gk(x, θ) : Rn × Rnθ (cid:55)→ R for each k ∈ [q].\n\n2\n\nUnder review as a conference paper at ICLR 2023\n\nDefinition 2.1 (Efficiency). For fixed θ, a decision vector x∗ ∈ X(θ) is said to be efficient if there exists no other decision vector x ∈ X(θ) such that fi(x, θ) ≤ fi(x∗, θ) for all i ∈ [p], and fk(x, θ) < fk(x∗, θ) for at least one k ∈ [p].\n\nIn the study of multiobjective optimization, the set of all efficient solutions is denoted by XE(θ) and called the efficient set. The weighting method is commonly used to obtain an efficient solution through computing the problem of weighted sum (PWS) Gass & Saaty (1955) as follows.\n\nmin wT f (x, θ) s.t. x ∈ X(θ),\n\n(PWS)\n\nwhere w = (w1, . . . , wp)T . Without loss of generality, all possible weights are restricted to a simplex, which is denoted by Wp = {w ∈ Rp + : 1T w = 1}. Next, we denote the set of optimal solutions for the (PWS) by\n\nS(w, θ) = arg min\n\nx\n\n(cid:8)wT f (x, θ) : x ∈ X(θ)(cid:9) .\n\np = {w ∈ Rp\n\nLet W + Proposition 2.1. If x ∈ S(w, θ) and w ∈ W +\n\np , then x ∈ XE(θ).\n\n++ : 1T w = 1}. Following from Theorem 3.1.2 of Miettinen (2012), we have:\n\nThe next result from Theorem 3.1.4 of Miettinen (2012) states that all the efficient solutions can be found by the weighting method for convex MOP.\n\nProposition 2.2. Assume that MOP is convex. If x ∈ X is an efficient solution, then there exists a weighting vector w ∈ Wp such that x is an optimal solution of (PWS).\n\nBy Propositions 2.1 - 2.2, we can summarize the relationship between S(w, θ) and XE(θ) as follows. Corollary 2.2.1. For convex MOP,\n\n(cid:91)\n\nw∈W +\n\np\n\nS(w, θ) ⊆ XE(θ) ⊆\n\n(cid:91)\n\nw∈Wp\n\nS(w, θ).\n\nIn the following, we make a few assumptions to simplify our understanding, which are actually mild and appear often in the literature. Assumption 2.1. Set Θ is a convex compact set. There exists D > 0 such that ∥θ∥2 ≤ D for all θ ∈ Θ. In addition, for each θ ∈ Θ, both f (x, θ) and g(x, θ) are convex in x.\n\nINVERSE MULTIOBJECTIVE OPTIMIZATION\n\n2.2 Consider a learner who has access to decision makers’ decisions, but does not know their objective functions or constraints. In our model, the learner aims to learn decision makers’ multiple objective functions or constraints from observed noisy decisions only. We denote y the observed noisy decision that might carry measurement error or is generated with a bounded rationality of the decision maker. We emphasize that this noisy setting of y reflects the real world situation rather than for analysis of regret. Throughout the paper we assume that y is a random variable distributed according to an unknown distribution Py supported on Y. As y is a noisy observation, we note that y does not necessarily belong to X(θ), i.e., it might be either feasible or infeasible with respect to X(θ).\n\nWe next discuss the construction of an appropriate loss function for the inverse multiobjective optimization problem Dong & Zeng (2020; 2021). Ideally, given a noisy decision y and a hypothesis θ, the loss function can be defined as the minimum distance between y and the efficient set XE(θ):\n\nl(y, θ) = min\n\nx∈XE (θ)\n\n∥y − x∥2 2.\n\n(loss function)\n\nFor a general MOP, however, there might exist no explicit way to characterize the efficient set XE(θ). Hence, an approximation approach to practically describe this is adopted. Following from Corollary 2.2.1, a sampling approach is adopted to generate wk ∈ Wp for each k ∈ [K] and approximate XE(θ) as (cid:83) k∈[K] S(wk, θ). Then, the surrogate loss function is defined as\n\nlK(y, θ) =\n\nmin\n\nx∈ (cid:83)\n\nS(wk,θ)\n\n∥y − x∥2 2.\n\n(surrogate loss)\n\nk∈[K]\n\n3\n\nUnder review as a conference paper at ICLR 2023\n\nBy using binary variables, this surrogate loss can be converted into the Surrogate Loss Problem.\n\nlK(y, θ) =\n\nmin zj ∈{0,1}\n\n∥y − (cid:80)\n\nzkxk∥2\n\n2\n\nk∈[K] zk = 1, xk ∈ S(wk, θ).\n\ns.t. (cid:80)\n\nk∈[K]\n\n(1)\n\nConstraint (cid:80) k∈[K] zk = 1 ensures that exactly one of the efficient solutions will be chosen to measure the distance to y. Hence, solving this optimization problem identifies some wk with k ∈ [K] such that the corresponding efficient solution S(wk, θ) is closest to y. Remark 2.1. It is guaranteed that no efficient solution will be excluded if all weight vectors in Wp are enumerated. As it is practically infeasible due to computational intractability, we can control K to balance the tradeoff between the approximation accuracy and computational efficacy. Certainly, if the computational power is strong, we would suggest to draw a large number of weights evenly in Wp to avoid any bias. In practice, for general convex MOP, we evenly sample {wk}k∈[K] from W + to ensure that S(wk, θ) ∈ XE(θ). If f (x, θ) is known to be strictly convex, we can evenly sample {wk}k∈[K] from Wp as S(wk, θ) ∈ XE(θ) by Proposition 2.1.\n\np\n\n3 ONLINE LEARNING FOR IMOP\n\nIn our online learning setting, noisy decisions become available to the learner one by one. Hence, the learning algorithm produces a sequence of hypotheses (θ1, . . . , θT +1). Here, T is the total number of rounds, and θ1 is an arbitrary initial hypothesis and θt for t > 1 is the hypothesis chosen after seeing the (t − 1)th decision. Let l(yt, θt) denote the loss the learning algorithm suffers when it tries to predict yt based on the previous observed decisions {y1, . . . , yt−1}. The goal of the learner is to minimize the regret, which is the cumulative loss (cid:80)T t=1 l(yt, θt) against the best possible loss when the whole batch of decisions are available. Formally, the regret is defined as\n\nRT =\n\nT (cid:88)\n\nt=1\n\nl(yt, θt) − min θ∈Θ\n\nT (cid:88)\n\nt=1\n\nl(yt, θ).\n\nUnlike most online learning problems that assume the loss function to be smooth Shalev-Shwartz (2011); Hazan (2016), l(y, θ) and lK(y, θ) are not necessarily smooth in our paper, due to the structures of XE(θ) and (cid:83) k∈[K] S(wk, θ). Thus, the popular gradient based online learning algorithms Bottou (1999); Kulis & Bartlett (2010) fail and our problem is significantly more difficult than most of them. To address this challenge, two online learning algorithms are developed in the next section.\n\n3.1 ONLINE IMPLICIT UPDATES Once receiving the tth noisy decision yt, the ideal way to update θt+1 is by solving the following optimization problem using the ideal loss function:\n\nθt+1 = arg min θ∈Θ\n\n1 2\n\n∥θ − θt∥2\n\n2 + ηtl(yt, θ),\n\n(2)\n\nwhere ηt is the learning rate in each round, and l(yt, θ) is defined in loss function.\n\nAs explained in the previous section, l(yt, θ) might not be computable due to the non-existence of the closed form of the efficient set XE(θ). Thus, we seek to approximate the update 2 by:\n\nθt+1 = arg min θ∈Θ\n\n1 2\n\n∥θ − θt∥2\n\n2 + ηtlK(yt, θ),\n\n(3)\n\nwhere ηt is the learning rate in each round, and lK(yt, θ) is defined in surrogate loss.\n\nThe update 3 approximates 2, and seeks to balance the tradeoff between “conservativeness” and “correctiveness”, where the first term characterizes how conservative we are to maintain the current estimation, and the second term indicates how corrective we would like to modify with the new estimation. As no closed form exists for θt+1 in general, this update method is an implicit approach.\n\n4\n\nUnder review as a conference paper at ICLR 2023\n\nAlgorithm 1 Online Learning for IMOP\n\nAlgorithm 2 Accelerated Online Learning\n\n1: Input:\n\nnoisy decisions {yt}t∈T , weights\n\n{wk}k∈K\n\n2: Initialize θ1 = 0 3: for t = 1 to T do receive yt 4: suffer loss lK(yt, θt) 5: if lK(yt, θt) = 0 then 6: 7: 8: 9: 10:\n\nθt+1 ← θt\n\nelse\n\n√\n\nset learning rate ηt ∝ 1/ update θt+1 by solving 3 directly (or equivalently solving K subproblems 4)\n\nt\n\nend if 11: 12: end for\n\n1: Input: {yt}t∈T and {wk}k∈K 2: Initialize θ1 = 0 3: for t = 1 to T do receive yt 4: suffer loss lK(yt, θt) 5: let k∗ = arg mink∈[K]∥yt − xk∥2 2, 6: where xk ∈ S(wk, θt) for k ∈ [K] if lK(yt, θt) = 0 then\n\nθt+1 ← θt\n\nset learning rate ηt ∝ 1/ update θt+1 by 4 with k = k∗\n\nt\n\n√\n\nelse\n\n7: 8: 9: 10: 11: end if 12: 13: end for\n\nTo solve 3, we can replace xk ∈ S(wk, θ) by KKT conditions for each k ∈ [K]:\n\nmin θ\n\ns.t.\n\n1\n\n2 ∥θ − θt∥2\n\n2 + ηt\n\n(cid:80)\n\nk∈[K]\n\n∥yt − θk∥2\n\n2\n\nθ ∈ Θ, \n\n \n\nk g(xk) = 0,\n\ng(xk) ≤ 0, uk ≥ 0, uT ∇xk wT 0 ≤ θk ≤ Mkzk, xk − Mk(1 − zk) ≤ θk ≤ xk,\n\n(cid:80)\n\nzk = 1,\n\nk f (xk, θ) + uk · ∇xk g(xk) = 0,\n\n\n\n  , ∀k ∈ [K],\n\n∀k ∈ [K], ∀k ∈ [K],\n\nk∈[K]\n\nxk ∈ Rn, uk ∈ Rm\n\n+ , zk ∈ {0, 1},\n\n∀k ∈ [K],\n\nwhere uk is the dual variable for gk(x, θ) ≤ 0, and Mk is a big number to linearize zkxk.\n\nAlternatively, solving 3 is equivalent to solving K independent programs defined in the following and taking the one with the least optimal value (breaking ties arbitrarily).\n\nmin θ∈Θ s.t.\n\n1\n\n2 ∥θ − θt∥2\n\n2 + ηt∥yt − x∥2\n\n2\n\nx ∈ S(wk, θ).\n\n(4)\n\nOur application of the implicit update rule to learn an MOP proceeds as outlined in Algorithm 1.\n\nRemark 3.1. (i) When choosing 4 to update θt+1, we can parallelly compute K independent problems of 4, which would dramatically improve the computational efficiency. (ii) After the completion of Algorithm 1, we can allocate every yt to the wk that minimizes lK(yt, θT +1), which provides an inference on the distribution of weights of component functions fl(x, θ) over human subjects.\n\nAcceleration of Algorithm 1: Note that we update θ and the weight sample assigned to yt in 3 simultaneously, meaning both θ and the weight sample index k are variables when solving 3. In other words, one needs to solve K subproblems 4 to get an optimal solution for 3. However, note that the increment of θ by 3 is typically small for each update. Consequently, the weight sample assigned to yt using θt+1 is roughly the same as using the previous guess of this parameter, i.e., θt. Hence, it is reasonable to approximate 3 by first assigning a weight sample to yt based on the previous updating result. Then, instead of computing K problems of 4, we simply compute a single one associated with the selected weight samples, which significantly eases the burden of solving 3. Our application of the accelerated implicit update rule proceeds as outlined in Algorithm 2.\n\n5\n\nUnder review as a conference paper at ICLR 2023\n\nMini-batches We enhance online learning by considering multiple observations per update Bottou & Cun (2004). In online IMOP, this means that computing θt+1 using |Nt| > 1 decisions:\n\nθt+1 = arg min θ∈Θ\n\n1 2\n\n∥θ − θt∥2\n\n2 +\n\nηt |Nt|\n\n(cid:88)\n\nt∈Nt\n\nlK(yt, θ),\n\n(5)\n\nHowever, we should point out that applying Mini-batches might not be suitable here as the update 5 is drastically more difficult to compute even for |Nt| = 2 than the update 3 with a single observation.\n\n3.2 ANALYSIS OF CONVERGENCE Note that the proposed online learning algorithms are generally applicable to learn the parameter of any convex MOP. In this section, we show that the average regret converges at a rate of O(1/ T ) under certain regularity conditions based on the ideal loss function l(y, θ). Namely, we consider the regret bound when using the ideally implicit update rule 2. Next, we introduce a few assumptions that are regular in literature Keshavarz et al. (2011); Bertsimas et al. (2015); Esfahani et al. (2018); Aswani et al. (2018); Dong & Zeng (2018); Dong et al. (2018).\n\n√\n\nAssumption 3.1. (a) X(θ) is closed, and has a nonempty relative interior. X(θ) is also bounded. Namely, there exists B > 0 such that ∥x∥2 ≤ B for all x ∈ X(θ). The support Y of the noisy decisions y is contained within a ball of radius R almost surely, where R < ∞. In other words, P(∥y∥2 ≤ R) = 1.\n\n(b) Each function in f is strongly convex on Rn, that is for each l ∈ [p], ∃λl > 0, ∀x, y ∈ Rn\n\n(cid:18)\n\n(cid:19)T\n\n∇fl(y, θl) − ∇fl(x, θl)\n\n(y − x) ≥ λl∥x − y∥2 2.\n\nRegarding Assumption 3.1.(a), assuming that the feasible region is closed and bounded is very common in inverse optimization. The finite support of the observations is needed since we do not hope outliers have too many impacts in our learning. Let λ = minl∈[p]{λl}. It follows that wT f (x, θ) is strongly convex with parameter λ for w ∈ Wp. Therefore, Assumption 3.1.(b) ensures that S(w, θ) is a single-valued set for each w.\n\nThe performance of the algorithm also depends on how the change of θ affects the objective values. For ∀w ∈ Wp, θ1 ∈ Θ, θ2 ∈ Θ, we consider the following function\n\nh(x, w, θ1, θ2) = wT f (x, θ1) − wT f (x, θ2).\n\nAssumption 3.2. ∃κ > 0, ∀w ∈ Wp, h(·, w, θ1, θ2) is κ-Lipschitz continuous on Y. That is,\n\n|h(x, w, θ1, θ2) − h(y, w, θ1, θ2)| ≤ κ∥θ1 − θ2∥2∥x − y∥2, ∀x, y ∈ Y.\n\nBasically, this assumption says that the objective functions will not change much when either the parameter θ or the variable x is perturbed. It actually holds in many common situations, including the multiobjective linear program and multiobjective quadratic program.\n\nFrom now on, given any y ∈ Y, θ ∈ Θ, we denote x(θ) the efficient point in XE(θ) that is closest to y. Namely, l(y, θ) = ∥y − x(θ)∥2 2. Lemma 3.1. Under Assumptions 3.1 - 3.2, the loss function l(y, θ) is uniformly 4(B+R)κ continuous in θ. That is, ∀y ∈ Y, ∀θ1, θ2 ∈ Θ, we have\n\n-Lipschitz\n\nλ\n\n|l(y, θ1) − l(y, θ2)| ≤\n\n4(B + R)κ λ\n\n∥θ1 − θ2∥2.\n\nThe key point in proving Lemma 3.1 is the observation that the perturbation of S(w, θ) due to θ is bounded by the perturbation of θ by applying Proposition 6.1 in Bonnans & Shapiro (1998). Details of the proof are given in Appendix.\n\nAssumption 3.3. For MOP, ∀y ∈ Y, ∀θ1, θ2 ∈ Θ, ∀α, β ≥ 0 s.t. α + β = 1, we have either of the following:\n\n(a) if x1 ∈ XE(θ1), and x2 ∈ XE(θ2), then αx1 + βx2 ∈ XE(αθ1 + βθ2).\n\n6\n\nUnder review as a conference paper at ICLR 2023\n\n(b) ∥αx(θ1) + βx(θ2) − x(αθ1 + βθ2)∥2 ≤ αβ∥x(θ1) − x(θ2)∥2/(2(B + R)).\n\nThe definition of x(θ1), x(θ2) and x(αθ1 + βθ2) is given before Lemma 3.1. This assumption requires the convex combination of x1 ∈ XE(θ1), and x2 ∈ XE(θ2) belongs to XE(αθ1 + βθ2). Or there exists an efficient point in XE(αθ1 + βθ2) close to the convex combination of x(θ1) and x(θ2). Examples are given in Appendix.\n\nLet θ∗ be an optimal inference to minθ∈Θ t∈[T ] l(yt, θ), i.e., an inference derived with the whole batch of observations available. Then, the following theorem asserts that under the above assumptions, the regret RT = (cid:80) T ).\n\nt∈[T ](l(yt, θt) − l(yt, θ∗)) of the online learning algorithm is of O(\n\n√\n\n(cid:80)\n\nTheorem 3.2. Suppose Assumptions 3.1 - 3.3 hold. Then, choosing ηt =\n\n√\n\n2\n\nDλ\n\n2(B+R)κ\n\n1√ t\n\n, we have\n\nRT ≤\n\n√\n\n4\n\n2(B + R)Dκ\n\n√\n\nλ\n\nT .\n\nWe establish the above regret bound by extending Theorem 3.2 in Kulis & Bartlett (2010). Our extension involves several critical and complicated analyses for the structure of the optimal solution set S(w, θ) as well as the loss function, which is essential to our theoretical understanding. Moreover, we relax the requirement of smoothness of loss function to Lipschitz continuity through a similar argument in Lemma 1 of Wang et al. (2017) and Duchi et al. (2011).\n\n4 EXPERIMENTS\n\nIn this section, we will provide a multiobjective quadratic program (MQP) and a portfolio optimization problem to illustrate the performance of the proposed online learning Algorithms 1 and 2. The mixed integer second order conic problems (MISOCPs), which are derived from using KKT conditions in 3, are solved by Gurobi Optimization (2016). All the algorithms are programmed with Julia Bezanson et al. (2017). The experiments have been run on an Intel(R) Xeon(R) E5-1620 processor that has a 3.60GHz CPU with 32 GB RAM.\n\n4.1 SYNTHETIC DATA: LEARNING THE PREFERENCES AND RESTRICTIONS FOR AN MQP Consider the following multiobjective quadratic optimization problem.\n\nmin x∈R2\n\n+\n\n(cid:18)f1(x) = 1 f2(x) = 1\n\n2 xT Q1x + cT 2 xT Q2x + cT\n\n1 x 2 x\n\n(cid:19)\n\ns.t. Ax ≤ b,\n\nwhere parameters of the objective functions and constraints are provided in Appendix.\n\nSuppose there are T decision makers. In each round, the learner would receive one noisy decision. Her goal is to learn the objective functions or restrictions of these decision makers. In round t, we suppose that the decision maker derives an efficient solution xt by solving (PWS) with weight wt, which is uniformly chosen from W2. Next, the learner receives the noisy decision yt corrupted by noise that has a jointly uniform distribution with support [−0.5, 0.5]2. Namely, yt = xt + εt, where each element of εt ∼ U (−0.5, 0.5).\n\nLearning the objective functions In the first set of experiments, the learner seeks to learn c1 and c2 given the noisy decisions that arrive sequentially in T rounds. We assume that c1 is within range [1, 6]2, c2 is within range [−6, −1]2, T = 1000 rounds of noisy decisions are generated, and K = 41 weights from W2 are evenly sampled. The learning rate is set to ηt = 5/ t. Then, we implement Algorithms 1 and 2. At each round t, we solve 4 using parallel computing with 6 workers.\n\n√\n\nTo illustrate the performance of the algorithms in a statistical way, we run 100 repetitions of the experiments. Figure 1a shows the total estimation errors of c1 and c2 in each round over the 100 repetitions for the two algorithms. We also plot the average estimation error of the 100 repetitions. As can be seen in this figure, convergence for both algorithms is pretty fast. Also, estimation errors over rounds for different repetitions concentrate around the average, indicating that our algorithm is pretty robust to noise. The estimation error in the last round is not zero because we use a finite K to approximate the efficient set. We see in Figure 1b that Algorithm 2 is much faster than Algorithm 1 especially when K is large. To further illustrate the performance of algorithms, we randomly pick one repetition using Algorithm 1 and plot the estimated efficient set in Figure 1c. We can see\n\n7\n\nUnder review as a conference paper at ICLR 2023\n\n(a)\n\n(b)\n\n(c)\n\n(d)\n\nFigure 1: Learning objective functions of an MQP over T = 1000 rounds. We run 100 repetitions of experiments. Let c = [c1, c2]. (a) We plot estimation errors at each round t for all 100 experiments and their average estimation errors with K = 41. (b) Blue and yellow bars indicate average running time and standard deviations for each K using Algorithm 1 and 2, respectively. (c) We randomly pick one repetition. The estimated efficient set after T = 1000 rounds is indicated by the red line. The real efficient set is shown by the yellow line. (d) The dotted brown line is the error bar plot of the running time over 10 repetitions in batch setting. The blue line is the error bar plot of the running time over 100 repetitions in an online setting using Algorithm 1.\n\nclearly that the estimated efficient set almost coincides with the real efficient set. Moreover, Figure 1d shows that IMOP in online settings is drastically faster than in batch setting. It is practically impossible to apply the batch setting algorithms in real-world applications.\n\nLearning the Right-hand Side In the second set of experiments, the learner seeks to learn b given the noisy decisions that arrive sequentially in T rounds. We assume that b is within [−10, 10]2. T = 1000 rounds of noisy decisions are generated. K = 81 weights from W2 are evenly sampled. The learning rate is set to ηt = 5/ t. Then, we apply Algorithms 1 and 2. To illustrate the performance of them, we run 100 repetitions of the experiments. Figure 2a shows the estimation error of b in each round over the 100 repetitions for the two algorithms. We also plot the average estimation error of the 100 repetitions. As can be seen in the figure, convergence for both algorithms is pretty fast. In addition, we see in Figure 2b that Algorithm 2 is much faster than Algorithm 1.\n\n√\n\n(a)\n\n(b)\n\nFigure 2: Learning the right-hand side of an MQP over T = 1000 rounds. We run 100 repetitions of the experiments. (a) We plot estimation errors at each round t for all 100 experiments and their average estimation errors of all repetitions with K = 41. (b) Blue and yellow bars indicate the average running times and standard deviations for each K using Algorithm 1 and 2, respectively.\n\n4.2 REAL-WORLD CASE: LEARNING EXPECTED RETURNS IN PORTFOLIO OPTIMIZATION We next consider noisy decisions arising from different investors in a stock market. More precisely, we consider a portfolio selection problem, where investors need to determine the fraction of their wealth to invest in each security to maximize the total return and minimize the total risk. The process typically involves the cooperation between an investor and a portfolio analyst, where the analyst provides an efficient frontier on a certain set of securities to the investor and then the investor selects a portfolio according to her preference to the returns and risks. The classical Markovitz meanvariance portfolio selection Markowitz (1952) in the following is used by analysts.\n\nmin\n\ns.t.\n\n(cid:18)f1(x) = −rT x f2(x) = xT Qx\n\n(cid:19)\n\n0 ≤ xi ≤ bi, n\n(cid:80)\n\nxi = 1,\n\ni=1\n\n∀i ∈ [n],\n\n8\n\n0200400600800100010-1100101Alg 1: Estimation errorAlg 1: Average errorAlg 2: Estimation errorAlg 2: Average errorK=6K=11K=21K=41020406080100120140Time (s)Alg 1Alg 201230123Nosiy decisionsReal efficient setEstimated efficient setT = 5T = 10T = 15100101102103Batching settingOnline setting0200400600800100010-1100101Alg 1: Estimation errorAlg 1: Average errorAlg 2: Estimation errorAlg 2: Average errorK=6K=11K=21K=41020406080100120140160Time(s)Alg 1Alg 2Under review as a conference paper at ICLR 2023\n\n(a)\n\n(b)\n\nFigure 3: Learning the expected return of a Portfolio optimization problem over T = 1000 rounds with K = 41. (a) The red line indicates the real efficient frontier. The blue dots indicate the estimated efficient frontier using the estimated expected return for K = 41. (b) Each bar represents the proportion of the 1000 decision makers that has the corresponding weight for f1(x).\n\nwhere r ∈ Rn + is a vector of individual security expected returns, Q ∈ Rn×n is the covariance matrix of securities returns, x is a portfolio specifying the proportions of capital to be invested in the different securities, and bi is an upper bound on the proportion of security i, ∀i ∈ [n].\n\nDataset: The dataset is derived from monthly total returns of 30 stocks from a blue-chip index which tracks the performance of top 30 stocks in the market when the total investment universe consists of thousands of assets. The true expected returns and true return covariance matrix for the first 8 securities are given in the Appendix.\n\n√\n\nDetails for generating the portfolios are provided in Appendix. The portfolios on the efficient frontier are plot in Figure 3a. The learning rate is set to ηt = 5/ t. At each round t, we solve 4 using parallel computing. In Table 1 we list the estimation error and estimated expected returns for different K. The estimation error becomes smaller when K increases, indicating that we have a better approximation accuracy of the efficient set when using a larger K. We also plot the estimated efficient frontier using the estimated ˆr for K = 41 in Figure 3a. We can see that the estimated efficient frontier is very close to the real one, showing that our algorithm works quite well in learning expected returns in portfolio optimization. We also plot our estimation on the distribution of the weight of f1(x) among the 1000 decision makers. As shown in Figure 3b, the distribution follows roughly normal distribution. We apply Chi-square goodness-of-fit tests to support our hypotheses.\n\nTable 1: Estimation Error for Different K\n\nK\n\n6\n\n11\n\n21\n\n41\n\n∥ˆr − rtrue∥2\n\n0.1270\n\n0.1270\n\n0.0420\n\n0.0091\n\n5 CONCLUSION AND FUTURE WORK\n\nIn this paper, an online learning method to learn the parameters of the multiobjective optimization problems from noisy observations is developed and implemented. We prove that this framework converges at a rate of O(1/ T ) under suitable conditions. Nonetheless, as shown in multiple experiments using both synthetic and real world datasets, even if these conditions are not satisfied, we still observe a fast convergence rate and a strong robustness to noisy observations. Thus, it would be interesting to analyze to what extent these conditions can be relaxed.\n\n√\n\nAlso, we note that our model naturally follows the contextual bandit setting. We can view the decision yt observed at time t as the context. The learner then takes the action θt and the loss is jointly determined by the context and the action. Compared to the vast majority of literature surveyed in Zhou (2015), the main technical difficulty in our model is how to set an appropriate reward (loss) given the context (yt) and the action (θt). Intuitively, we set the loss as the difference between the context (yt) and another context generated by the action. Motivated by this observation, one future work is to integrate classical contextual bandits algorithms into our model. Particularly, we think that algorithms without the Linear Realizability Assumption (the reward is linear with respect to the context), such as KernelUCB, might fit well in our problem.\n\n9\n\n0.20.220.240.260.280.30.320.34Standard Deviation of Portfolio Returns (Annualized)0.060.080.10.120.140.160.180.2Mean of Portfolio Returns (Annualized)Efficient Frontier and Estimated Efficient FrontierReal Efficient FrontierEstimated Efficient FrontierUnder review as a conference paper at ICLR 2023\n\nREFERENCES\n\nRavindra K Ahuja and James B Orlin. Inverse optimization. Operations Research, 49(5):771–783,\n\n2001.\n\nAnil Aswani, Zuo-Jun Shen, and Auyon Siddiq. Inverse optimization with noisy data. Operations\n\nResearch, 2018.\n\nAndreas B ̈armann, Sebastian Pokutta, and Oskar Schneider. Emulating the expert: Inverse optimiza-\n\ntion through online learning. In ICML, 2017.\n\nDimitris Bertsimas, Vishal Gupta, and Ioannis Ch Paschalidis. Data-driven estimation in equilibrium\n\nusing inverse optimization. Mathematical Programming, 153(2):595–633, 2015.\n\nJeff Bezanson, Alan Edelman, Stefan Karpinski, and Viral B Shah. Julia: A fresh approach to\n\nnumerical computing. SIAM Review, 59(1):65–98, 2017.\n\nJ Fr ́ed ́eric Bonnans and Alexander Shapiro. Optimization problems with perturbations: A guided\n\ntour. SIAM Review, 40(2):228–264, 1998.\n\nL ́eon Bottou. On-line learning and stochastic approximations. In On-line Learning in Neural Net-\n\nworks, pp. 9–42. Cambridge University Press, 1999.\n\nL ́eon Bottou and Yann L Cun. Large scale online learning. In NIPS, 2004.\n\nTimothy CY Chan, Tim Craig, Taewoo Lee, and Michael B Sharpe. Generalized inverse multiobjective optimization with application to cancer therapy. Operations Research, 62(3):680–695, 2014.\n\nChaosheng Dong and Bo Zeng. Inferring parameters through inverse multiobjective optimization.\n\narXiv preprint arXiv:1808.00935, 2018.\n\nChaosheng Dong and Bo Zeng. Expert learning through generalized inverse multiobjective opti-\n\nmization: Models, insights, and algorithms. In ICML, 2020.\n\nChaosheng Dong and Bo Zeng. Wasserstein distributionally robust inverse multiobjective optimiza-\n\ntion. In AAAI, 2021.\n\nChaosheng Dong, Yiran Chen, and Bo Zeng. Generalized inverse optimization through online learn-\n\ning. In NeurIPS, 2018.\n\nJohn Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and\n\nstochastic optimization. Journal of Machine Learning Research, 12(Jul):2121–2159, 2011.\n\nPeyman Mohajerin Esfahani, Soroosh Shafieezadeh-Abadeh, Grani A Hanasusanto, and Daniel Kuhn. Data-driven inverse optimization with imperfect information. Mathematical Programming, 167(1):191–234, 2018.\n\nSaul Gass and Thomas Saaty. The computational algorithm for the parametric objective function.\n\nNaval Research Logistics, 2(1-2):39–45, 1955.\n\nInc. Gurobi Optimization. Gurobi optimizer reference manual, 2016. URL http://www.\n\ngurobi.com.\n\nTrevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning.\n\nSpringer, 2001.\n\nElad Hazan. Introduction to online convex optimization. Foundations and Trends in Optimization,\n\n2(3-4):157–325, 2016.\n\nGarud Iyengar and Wanmo Kang. Inverse conic programming with applications. Operations Re-\n\nsearch Letters, 33(3):319–330, 2005.\n\nArezou Keshavarz, Yang Wang, and Stephen Boyd.\n\nImputing a convex objective function.\n\nIn\n\nIntelligent Control (ISIC), 2011 IEEE International Symposium on, pp. 613–619. IEEE, 2011.\n\n10\n\nUnder review as a conference paper at ICLR 2023\n\nBrian Kulis and Peter L Bartlett. Implicit online learning. In ICML, 2010.\n\nHarry Markowitz. Portfolio selection. The Journal of Finance, 7(1):77–91, 1952.\n\nKaisa Miettinen. Nonlinear Multiobjective Optimization, volume 12. Springer Science & Business\n\nMedia, 2012.\n\nAndrew J. Schaefer. Inverse integer programming. Optimization Letters, 3(4):483–489, 2009.\n\nShai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends®\n\nin Machine Learning, 4(2):107–194, 2011.\n\nYingcong Tan, Daria Terekhov, and Andrew Delong. Learning linear programs from optimal deci-\n\nsions. arXiv preprint arXiv:2006.08923, 2020.\n\nJialei Wang, Weiran Wang, and Nathan Srebro. Memory and communication efficient distributed stochastic optimization with minibatch prox. In Proceedings of the 2017 Conference on Learning Theory, volume 65, pp. 1882–1919, 2017.\n\nLizhi Wang. Cutting plane algorithms for the inverse mixed integer linear programming problem.\n\nOperations Research Letters, 37(2):114–116, 2009.\n\nLi Zhou. A survey on contextual multi-armed bandits. arXiv preprint arXiv:1508.03326, 2015.\n\nA APPENDIX\n\nA.1 OMITTED MATHEMATICAL REFORMULATIONS\n\nBefore giving the reformulations, we first make some discussions about the surrogate loss functions.\n\nlK(y, θ) = min\n\nzk∈{0,1}\n\n(cid:88)\n\n∥y −\n\nzkxk∥2\n\n2\n\nk∈[K]\n\n= min\n\nzk∈{0,1}\n\n(cid:88)\n\nk∈[K]\n\n∥y − zkxk∥2\n\n2 − (K − 1)∥y∥2\n\n2\n\nwhere xk ∈ S(wk, θ) and (cid:80)\n\nk∈[K] zk = 1.\n\nSince (K − 1)∥y∥2 function when solving the optimization program in the implicit update,\n\n2 is a constant, we can safely drop it and use the following as the surrogate loss\n\nlK(y, θ) = min\n\nzk∈{0,1}\n\n(cid:88)\n\n∥y − zkxk∥2\n\n2\n\nk∈[K]\n\nwhere xk ∈ S(wk, θ) and (cid:80)\n\nk∈[K] zk = 1.\n\nA.1.1 SINGLE LEVEL REFORMULATION FOR THE INVERSE MULTIOBJECTIVE\n\nOPTIMIZATION PROBLEM\n\nThe parametrized mulobjective optimization problem is\n\nmin x∈Rn s.t.\n\nf (x, θ)\n\ng(x) ≤ 0\n\nMOP\n\nwhere\n\nf (x, θ) = (f1(x, θ), f2(x, θ), . . . , fp(x, θ))T\n\ng(x) = (g1(x), . . . , gq(x))T\n\nThen, the single level reformulation for the Implicit update in the paper is given in the following\n\n11\n\nUnder review as a conference paper at ICLR 2023\n\nmin b\n\ns.t.\n\n1\n\n2 ∥θ − θt∥2\n\n2 + ηt\n\n(cid:80)\n\nk∈[K]\n\n∥yt − θk∥2\n\n2\n\nθ ∈ Θ \n\n \n\nk g(xk) = 0\n\ng(xk) ≤ 0, uk ≥ 0 uT ∇xk wT 0 ≤ θk ≤ Mkzk xk − Mk(1 − zk) ≤ θk ≤ xk\n\n(cid:80)\n\nzk = 1\n\nk f (xk, θ) + uk · ∇xk g(xk) = 0\n\n\n\n \n\n∀k ∈ [K]\n\n∀k ∈ [K] ∀k ∈ [K]\n\nk∈[K]\n\nxk ∈ Rn, uk ∈ Rm\n\n+ , tk ∈ {0, 1}m, zk ∈ {0, 1} ∀k ∈ [K]\n\nA.1.2 SINGLE LEVEL REFORMULATION FOR THE INVERSE MULTIOBJECTIVE QUADRATIC\n\nPROBLEM\n\nWhen the objective functions are quadratic and the feasible region is a polyhedron, the multiobjective optimization has the following form\n\n\n\n \n\nmin x∈Rn\n\n1 x\n\n1\n\n2 xT Q1x + cT ... 2 xT Qpx + cT\n\n1\n\np x\n\n\n\n \n\nMQP\n\ns.t. Ax ≥ b\n\nwhere Ql ∈ Sn\n\n+ (the set of symmetric positive semidefinite matrices) for all l ∈ [p]..\n\nWhen trying to learn {cl}l∈[p], the single level reformulation for the Implicit update in the paper is given in the following\n\nmin cl\n\ns.t.\n\n1 2\n\n(cid:80)\n\nl∈[p]\n\n∥cl − ct\n\nl∥2\n\n2 + ηt\n\n(cid:80)\n\nk∈[K]\n\n∥yt − θk∥2\n\n2\n\ncl ∈ (cid:101)Cl \n\n \n \n\nAxk ≥ b, uk ≥ 0 uk ≤ M tk Axk − b ≤ M (1 − tk) kQ1 + · · · + wp (w1\n\nkQp)xi + w1\n\nkc1 + · · · + wp\n\nkcp − AT uk = 0\n\n0 ≤ θk ≤ Mkzk xk − Mk(1 − zk) ≤ θk ≤ xk\n\n(cid:80)\n\nzk = 1\n\n\n\n \n \n\n∀l ∈ [p]\n\n∀k ∈ [K]\n\n∀k ∈ [K] ∀k ∈ [K]\n\nk∈[K]\n\nxk ∈ Rn, uk ∈ Rm\n\n+ , tk ∈ {0, 1}m, zk ∈ {0, 1}\n\n∀l ∈ [p] ∀k ∈ [K]\n\nwhere ct\n\nl is the estimation of cl at the tth round, and (cid:101)Cl is a convex set for each l ∈ [p].\n\nWe have a similar single level reformulation when learning the Right-hand side b. Clearly, this is a Mixed Integer Second Order Cone program(MISOCP) when learning either cl or b.\n\n12\n\nUnder review as a conference paper at ICLR 2023\n\nA.2 OMITTED PROOFS\n\nA.2.1 STRONGLY CONVEX OF wT f (x, θ) AS STATED UNDER ASSUMPTION 3.1\n\nProof. By the definition of λ,\n\n(cid:18)\n\n∇wT f (y, θ) − ∇wT f (x, θ)\n\n(cid:19)T\n\n(cid:18)\n\n(y − x) =\n\n∇\n\np (cid:80)\n\nwlfl(y, θ) − ∇\n\n(cid:19)T\n\nwlfl(x, θl)\n\n(y − x)\n\np (cid:80)\n\nl=1\n\n(cid:19)T\n\nl=1 (cid:18)\n\n=\n\n≥\n\np (cid:80)\n\nl=1 p\n(cid:80)\n\nl=1\n\nwl\n\n∇fl(y, θl) − ∇fl(x, θl)\n\n(y − x)\n\nwlλl∥x − y∥2\n\n2 ≥ η∥x − y∥2\n\n2\n\np (cid:80)\n\nl=1\n\nwl\n\n= λ∥x − y∥2 2\n\nThus, wT f (x, θ) is strongly convex for x ∈ Rn.\n\nA.2.2 PROOF OF LEMMA 3.1\n\nProof. By Assumption 3.1(b), we know that S(w, θ) is a single-valued set for each w ∈ Wp. Thus, ∀y ∈ Y, ∀θ1, θ2 ∈ Θ, ∃w1, w2 ∈ Wp, s.t.\n\nx(θ1) = S(w1, θ1), x(θ2) = S(w2, θ2)\n\nWithout of loss of generality, let lK(y, θ1) ≥ lK(y, θ2). Then,\n\n|lK(y, θ1) − lK(y, θ2)| = lK(y, θ1) − lK(y, θ2) = ∥y − x(θ1)∥2 2 − ∥y − x(θ2)∥2 = ∥y − S(w1, θ1)∥2 ≤ ∥y − S(w2, θ1)∥2 = ⟨S(w2, θ2) − S(w2, θ1), 2y − S(w2, θ1) − S(w2, θ2)⟩ ≤ 2(B + R)∥S(w2, θ2) − S(w2, θ1)∥2\n\n2 − ∥y − S(w2, θ2)∥2 2 − ∥y − S(w2, θ2)∥2\n\n2\n\n2\n\n2\n\nThe last inequality is due to Cauchy-Schwartz inequality and the Assumptions 3.1(a), that is\n\n∥2y − S(w2, θ1) − S(w2, θ2)∥2 ≤ 2(B + R)\n\n(6)\n\n(7)\n\nNext, we will apply Proposition 6.1 in Bonnans & Shapiro (1998) to bound ∥S(w2, θ2) − S(w2, θ1)∥2.\n\nUnder Assumptions 3.1 - 3.2, the conditions of Proposition 6.1 in Bonnans & Shapiro (1998) are satisfied. Therefore,\n\n∥S(w2, θ2) − S(w2, θ1)∥2 ≤\n\n2κ λ\n\n∥θ1 − θ2∥2\n\n(8)\n\nPlugging equation 7 and equation 8 in equation 6 yields the claim.\n\nA.2.3 PROOF OF THEOREM 3.2\n\nProof. We will extend Theorem 3.2 in Kulis & Bartlett (2010) to prove our theorem.\n\nLet Gt(θ) = 1\n\n2 ∥θ − θt∥2\n\n2 + ηtl(yt, θ).\n\nWe will now show the loss function is convex. The first step is to show that if Assumption 3.3 holds, then the loss function l(y, θ) is convex in θ.\n\n13\n\nUnder review as a conference paper at ICLR 2023\n\nFirst, suppose Assumption 3.3(a) hold. Then,\n\nαl(y, θ1) + βl(y, θ2) − l(y, αθ1 + βθ2)\n\n2 + β∥y − x(θ2)∥2 2 + β∥y − x(θ2)∥2\n\n2 − ∥y − x(αθ1 + βθ2)∥2 2 − ∥y − αx(θ1) − βx(θ2)∥2\n\n2\n\n2\n\n= α∥y − x(θ1)∥2 ≥ α∥y − x(θ1)∥2 = αβ∥x(θ1) − x(θ2)∥2 ≥ 0\n\n2\n\n(By Assumption 3.3(a))\n\n(9)\n\nSecond, suppose Assumption 3.3(b) holds. Then,\n\nαl(y, θ1) + βl(y, θ2) − l(y, αθ1 + βθ2)\n\n= α∥y − x(θ1)∥2 = α∥y − x(θ1)∥2\n\n2 + β∥y − x(θ2)∥2 2 + β∥y − x(θ2)∥2\n\n2 − ∥y − x(αθ1 + βθ2)∥2 2 − ∥y − αx(θ1) − βx(θ2)∥2\n\n2\n\n2\n\n+∥y − αx(θ1) − βx(θ2)∥2\n\n2 − ∥y − x(αθ1 + βθ2)∥2\n\n2\n\n= αβ∥x(θ1) − x(θ2)∥2 = αβ∥x(θ1) − x(θ2)∥2 ≥ αβ∥x(θ1) − x(θ2)∥2\n\n2 + ∥y − αx(θ1) − βx(θ2)∥2 2 − ∥y − x(αθ1 + βθ2)∥2 2 − ⟨αx(θ1) + βx(θ2) − x(αθ1 + βθ2), 2y − x(αθ1 + βθ2) − αx(θ1) − βx(θ2)⟩ 2 − ∥αx(θ1) + βx(θ2) − x(αθ1 + βθ2)∥2∥2y − x(αθ1 + βθ2) − αx(θ1) − βx(θ2)∥2\n\n2\n\n(10)\n\n(11)\n\n(12)\n\n(13)\n\n(14)\n\nThe last inequality is by Cauchy-Schwartz inequality. Note that\n\n∥αx(θ1) + βx(θ2) − x(αθ1 + βθ2)∥2∥2y − x(αθ1 + βθ2) − αx(θ1) − βx(θ2)∥2\n\n≤ 2(B + R)∥αx(θ1) + βx(θ2) − x(αθ1 + βθ2)∥2 ≤ αβ∥x(θ1) − x(θ2)∥2\n\n(By Assumption 3.3(b))\n\nPlugging equation 11 in equation 10 yields the result.\n\nUsing Theorem 3.2. in Kulis & Bartlett (2010), for αt ≤ Gt(θt+1)\n\nGt(θt) , we have\n\nRT ≤ (cid:80)T + 1 2ηt\n\nt=1\n\n1 ηt\n\n(1 − αt)ηtl(yt, θt)\n\n(∥θt − θ∗∥2\n\n2 − ∥θt+1 − θ∗∥2 2)\n\nNotice that\n\nGt(θt) − Gt(θt+1)\n\n= ηt(l(yt, θt) − l(yt, θt+1)) − 1 ≤ 4(B+R)κηt ≤ 8(B+R)2κ2η2\n\n∥θt − θt+1∥2 − 1\n\nλ\n\nt\n\nλ2\n\n2 ∥θt − θt+1∥2\n\n2\n\n2 ∥θt − θt+1∥2\n\n2\n\nThe first inequality follows by applying Lemma 3.1.\n\nLet αt = Rt(θt+1)\n\nRt(θt) . Using equation 13, we have\n\n(1 − αt)ηtl(yt, θt) = (1 − αt)Gt(θt)\n\n= Gt(θt) − Gt(θt+1) ≤ 8(B+R)2κ2η2\n\nt\n\nλ2\n\nPlug equation 14 in equation 12, and note the telescoping sum,\n\nRT ≤\n\nT (cid:88)\n\nt=1\n\n8(B + R)2κ2ηt λ2\n\n+\n\nT (cid:88)\n\nt=1\n\n1 2ηt\n\n(∥θt − θ∗∥2\n\n2 − ∥θt+1 − θ∗∥2 2)\n\n14\n\nUnder review as a conference paper at ICLR 2023\n\nDλ\n\nSetting ηt = telescopes and θ1 = 0, ∥θ∗∥2 ≤ D. The first sum simplifies using (cid:80)T the result\n\n, we can simplify the second summation to D(B+R)κ\n\n1√ t\n\n≤ 2\n\n2(B+R)κ\n\nt=1\n\n2t\n\n√\n\nλ\n\n√\n\n2\n\n√\n\nsince the sum\n\nT − 1 to obtain\n\n√\n\n4\n\nRT ≤\n\n2(B + R)Dκ\n\n√\n\nλ\n\nT .\n\nA.3 OMITTED EXAMPLES\n\nA.3.1 EXAMPLES FOR WHICH ASSUMPTION 3.3 HOLDS\n\nConsider for example the following quadratic program\n\nmin x∈Rn\n\n(cid:18)xT x − 2θT xT x − 2θT\n\n1 x 2 x\n\n(cid:19)\n\ns.t.\n\n0 ≤ x ≤ 10\n\nOne can check that Assumption 3.3 (a) is indeed satisfied. For example, let n = 1. Then, W.L.O.G, let θ1 ≤ θ2. Then, XE(θ) = [θ1, θ2]. Consider two parameters that θ1 = (θ1 2) ∈ [0, 10]2. For all α ∈ [0, 1],\n\n2), θ2 = (θ2\n\n1, θ2\n\n1, θ1\n\nXE(αθ1 + (1 − α)θ2) = [αθ1\n\n1 + (1 − α)θ2\n\n1, αθ1\n\n2 + (1 − α)θ2 2]\n\nAlthough tedious, one can check that one can check that Assumption 3.3 (a) is indeed satisfied.\n\nA.4 DATA FOR THE PORTFOLIO OPTIMIZATION PROBLEM\n\nTable 2: True Expected Return\n\nSecurity\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\nExpected Return\n\n0.1791\n\n0.1143\n\n0.1357\n\n0.0837\n\n0.1653\n\n0.1808\n\n0.0352\n\n0.0368\n\nTable 3: True Return Covariances Matrix\n\nSecurity\n\n1\n\n1 2\n3 4\n5 6\n7 8\n\n0.1641 0.0299 0.0478 0.0491 0.0580 0.0871 0.0603 0.0492\n\n2\n\n0.0299 0.0720 0.0511 0.0287 0.0527 0.0297 0.0291 0.0326\n\n3\n\n0.0478 0.0511 0.0794 0.0498 0.0664 0.0479 0.0395 0.0523\n\n4\n\n0.0491 0.0287 0.0498 0.1148 0.0336 0.0503 0.0326 0.0447\n\n5\n\n0.058 0.0527 0.0664 0.0336 0.1073 0.0483 0.0402 0.0533\n\n6\n\n0.0871 0.0297 0.0479 0.0503 0.0483 0.1134 0.0591 0.0387\n\n7\n\n0.0603 0.0291 0.0395 0.0326 0.0402 0.0591 0.0704 0.0244\n\n8\n\n0.0492 0.0326 0.0523 0.0447 0.0533 0.0387 0.0244 0.1028\n\nA.5 APPROXIMATION ERROR\n\nTheorem A.1. Under Assumption 3.1, we have that ∀y ∈ Y, ∀θ ∈ Θ,\n\n0 ≤ lK(y, θ) − l(y, θ) ≤\n\n4(B + R)ζ λ\n\n·\n\n2p Λ − 1\n\n,\n\n√\n\nwhere\n\nFurthermore,\n\nK =\n\n(Λ + p − 2)! (Λ − 1)!(p − 1)!\n\n, ζ =\n\nmax l∈[p],x∈X(θ),θ∈Θ\n\n|fl(x, θ)|.\n\n0 ≤ lK(y, θ) − l(y, θ) ≤\n\n16e(B + R)ζ λ\n\n·\n\n1\n\n1 p−1\n\nK\n\n.\n\n15\n\nUnder review as a conference paper at ICLR 2023\n\nThus, the surrogate loss function uniformly converges to the loss function at the rate of O(1/K p−1 ). Note that this rate exhibits a dependence on the number of objective functions p. As p increases, we might require (approximately) exponentially more weight samples {wK}k∈[K] to achieve an approximation accuracy. In fact, this phenomenon is a reflection of curse of dimensionality Hastie et al. (2001), a principle that estimation becomes exponentially harder as the number of dimension increases. In particular, the dimension here is the number of objective functions p. Naturally, one way to deal with the curse of dimensionality is to employ dimension reduction techniques in statistics to find a low-dimensional representation of the objective functions.\n\n1\n\nExample A.1. When p = 2, MOP is a bi-objective decision making problem. Then, Theorem A.1 shows that lK(y, θ) − l(y, θ) is of O(1/K). That is, lK(y, θ) asymptotically converges to l(y, θ) sublinearly.\n\nProof. By definition,\n\nlK(y, θ) − l(y, θ) =\n\nmin\n\nx∈ (cid:83)\n\nk∈[K]\n\nS(wk,θ)\n\n∥y − x∥2\n\n2 − min\n\n∥y − x∥2\n\n2 ≥ 0.\n\nx∈XE (θ)\n\nLet ∥y − S(wy\n\nk , θ)∥2\n\n2 =\n\nmin\n\nx∈ (cid:83)\n\nS(wk,θ)\n\n∥y − x∥2\n\n2, and ∥y − S(wy, θ)∥2\n\n2 = min\n\n∥y − x∥2\n\n2. Let\n\nx∈XE (θ)\n\nwy\n\nk′ be the closest weight sample among {wk}k∈[K] to wy. Then,\n\nk∈[K]\n\n2 − ∥y − S(wy, θ)∥2 2 − ∥y − S(wy, θ)∥2\n\nlK(y, θ) − l(y, θ) = ∥y − S(wy ≤ ∥y − S(wy = (2y − S(wy ≤ ∥2y − S(wy ≤ 2(B + R)∥S(wy, θ) − S(wy ≤ 4(B+R)ζ\n\nk , θ)∥2 k′, θ)∥2 k′, θ) − S(wy, θ))T (S(wy, θ) − S(wy k′, θ) − S(wy, θ)∥2∥S(wy, θ) − S(wy k′, θ)∥2\n\n· ∥wy − wy\n\n√\n\np\n\n2\n\n2\n\nk′∥2,\n\nλ\n\nk′, θ)) k′, θ)∥2\n\n(15)\n\nwhere ζ =\n\nmax l∈[p],x∈X(θ),θ∈Θ\n\n|fl(x, θ)|. The third inequality is due to Cauchy Schwarz inequality.\n\nUnder Assumption 3.1, we can apply Lemma 4 in Dong & Zeng (2018) to yield the last inequality. Next, we will show that ∀w ∈ Wp, the distance between w and its closest weight sample among {wk}k∈[K] is upper bounded by the function of K and p and nothing else. More precisely, we will show that\n\nsup w∈Wp\n\nmin k∈[K]\n\n∥w − wk∥2 ≤\n\nΛ − 1\n\n.\n\n(16)\n\n√\n\n2\n\nHere, Λ is the number of evenly spaced weight samples between any two extreme points of Wp. Note that {wk}k∈[K] are evenly sampled from Wp, and that the distance between any two extreme points of Wp equals to 2. Hence, the distances between any two neighboring weight samples are equal and can be calculated as the distance between any two extreme points of Wp divided by Λ − 1. Proof of equation 16 can be done by further noticing that the distance between any w and {wk}k∈[K] is upper bounded by the distances between any two neighboring weight samples.\n\n√\n\nCombining equation 15 and equation 16 yields that\n\n0 ≤ lK(y, θ) − l(y, θ) ≤\n\n4(B + R)ζ λ\n\n·\n\n√\n\n2p Λ − 1\n\n,\n\n(17)\n\nThen, we can prove that the total number of weight samples K and Λ has the following relationship:\n\nK =\n\n(cid:16)Λ + p − 2 p − 1\n\n(cid:17)\n\n(18)\n\nProof of equation 18 can be done by induction with respect to p. Obviously, equation 18 holds when p = 2 as K = Λ. Assume equation 18 holds for the ≤ p − 1 cases. For ease of notation, denote\n\nK Λ\n\np =\n\n(cid:16)Λ + p − 2 p − 1\n\n(cid:17)\n\n.\n\n16\n\nUnder review as a conference paper at ICLR 2023\n\nThen, for the p case, we note that the weight samples can be classified into two categories: wp = 0; wp > 0. For wp = 0, the number of weight samples is simply K Λ p−1. For wp > 0, the number of weight samples is K Λ−1\n\n. Thus,\n\np\n\nK = K Λ\n\np−1 + K Λ−1\n\np\n\n.\n\n(19)\n\nIteratively expanding K Λ−1\n\np\n\nthrough the same argument as equation 18 and using the fact that\n\n(cid:17)\n\n(cid:16)n k\n\n=\n\n(cid:17)\n\n(cid:16)n − 1 k − 1\n\n+\n\n(cid:17)\n\n(cid:16)n − 1 k\n\n,\n\nwe have\n\np−1 + K Λ−1\n\np\n\n= K Λ\n\np−1 + K Λ−1\n\np−1 + K Λ−2\n\np\n\np−1 + K Λ−1\n\np−1 + K 1\n\np\n\np−1 + · · · + K 2 (cid:16)Λ + p − 4 (cid:17) p − 2\n\n+\n\n(cid:17)\n\n+ · · · +\n\n(cid:17)\n\n(cid:16)p − 1 p − 2\n\n+\n\n(cid:17)\n\n(cid:16)p − 1 p − 1\n\n(20)\n\nK = K Λ ... = K Λ\n\n=\n\n(cid:16)Λ + p − 3 p − 2 = (Λ+p−2)!\n\n(Λ−1)!(p−1)!\n\nTo this end, we complete the proof of equation 18.\n\nFurthermore, we notice that\n\nK =\n\n(Λ + p − 2)! (Λ − 1)!(p − 1)!\n\n≤\n\n(Λ + p − 2)p−1 (p − 1)!\n\n<\n\n(cid:18) Λ + p − 2 p − 1\n\n(cid:19)p−1\n\n· ep−1.\n\nThen, when Λ ≥ p(K ≥ 2p−1), through simple algebraic calculation we have\n\ne\n\n1 p−1\n\nK\n\n>\n\np − 1 Λ + p − 2\n\n>\n\n1 4\n\n·\n\np Λ − 1\n\nWe complete the proof by combining equation 17 and equation 21 and noticing that\n\n(21)\n\n√\n\n2p ≤ p.\n\n17",
  "translations": [
    "# Summary Of The Paper\n\nThis paper is very technical and I'll first say I am not familiar with the literature. However, as somewhat an \"outsider\" to this problem, hopefully I can contribute by asking the right questions, which can help the author make this work more accessible.\n\nMy naive understanding of this paper is that it's basically doing reward learning (or inverse reinforcement learning). Given a black box agent with some latent reward function (of a particular form, that of min of bunch of other functions), we can observe the agent's actions to infer what the reward function is. The observations come sequentially, but we do not get to control what observation to make.\n\n# Strength And Weaknesses\n\nstrength : It tackles a new problem of multi-objective reward learning, of a particular form: min(f1(x,\\theta) ... fn(x,\\theta)). The paper was able to take this special form, along with some assumptions, to develop a set of update-rules to guess what \\theta can be as online observations come in. Even if the user (like me) does not grasp the full derivation, this algorithm can easily exist in a package to be used as black box.\n\nweakness : for me the paper is easy to follow wherever it is self-contained, but then some thm or corr. was invoked, and this \"jump\" makes the paper hard to follow. however this is unlikely to be an issue with people familiar with the field.\n\nI do have some questions, which would be great to have answered:\n\n1. when we say the agent is minimizing regret, does it mean it is sufficient agent comes up with a hypothesis that explains the data as well as the original \\theta, rather than trying to infer the original \\theta itself?\n\n2. I always find the connection between bandit-like literatures and bayesian inference related, yet the two use very different language. For me, I'd think we just put some prior over the hypothesis P(\\theta), and we do posterior inference of P(\\theta | Data) while assuming some forward data generating process P(Data | \\theta). Or more simply, we can find the maximum-likelihood estimator without the full posterior. There must be a good reason why this kind of language isn't the way to explain your work, but what is it? \n\n3. How would the problem change if you are allowed to take active samples? i.e. present the agent with a scenario as a query, and see how it respond to it in the style of active learning. Can your approach be made to work in this setting? How would you select a query? How would you select a query without making some distributional assumptions of the objective function, other than it is a min of a bunch of functions ?\n\n# Clarity, Quality, Novelty And Reproducibility\n\nclarity : it appears good -- I can follow everything until 2.2.1\n\nnovelty : the authors claims that nobody has worked on the problem of inferring parameters for the form min(f1(x,theta1)...) before, so this work is novel.\n\nquality : appears to be good\n\n# Summary Of The Review\n\nfrom a non-expert point of view, this paper can result in an artifact that can exist in scipy as a black-box, which is definitely a contribution. I would defer technical correctness to an expert.\n\nafter discussion with other reviewers, who knows the work better, I'm lowering my score to a 6.\nI still think this work is interesting though.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n4: The contributions are significant, and do not exist in prior works.\n\n# Empirical Novelty And Significance\n\nNot applicable",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework for inferring parameters in multiobjective decision-making models using sequential observations, which may include noise. It introduces inverse multiobjective optimization (IMOP) as a basis for learning, achieving a convergence rate of O(1/T) under certain conditions. Two online learning algorithms are developed to handle noisy data effectively, and the empirical evaluations on synthetic and real-world datasets demonstrate the algorithms' accuracy and robustness.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its introduction of the first general framework for online learning in multiobjective optimization, which is a significant advancement over traditional batch learning approaches. The ability to manage noisy data and the theoretical guarantees of convergence are commendable contributions. However, the paper could improve in articulating the assumptions that underpin the convergence analysis, which may hinder replicability. Additionally, while the algorithms show promising results, further exploration of their performance in more diverse real-world scenarios could strengthen the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear and well-structured, with a logical flow from problem formulation to contributions and empirical validation. The novelty of the approach lies in extending inverse optimization to an online setting, which has not been extensively explored in existing literature. However, the reproducibility of the results could be enhanced by providing more comprehensive details about the experimental setup and data generation processes. Overall, the quality of writing is high, but certain technical aspects may require additional clarification.\n\n# Summary Of The Review\nThis paper introduces a significant advancement in online learning for multiobjective optimization, providing a robust framework and algorithms that demonstrate strong empirical performance. While the contributions are substantial, particularly in handling noisy data, further clarification on assumptions and replication details would enhance the paper's overall impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework for online learning in the context of inverse multiobjective optimization (IMOP), aimed at inferring decision-making parameters from sequentially observed decisions that may be noisy or suboptimal. It introduces two online learning algorithms designed to effectively handle noise and provides a theoretical convergence analysis demonstrating a regret bound of \\(O(1/\\sqrt{T})\\) under specific regularity conditions. The empirical evaluation showcases the algorithms' performance on both synthetic and real-world datasets, revealing their capability to accurately estimate efficient sets and learn decision-maker preferences.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to IMOP and the robustness of the proposed algorithms under noise, which enhances their practical applicability. The theoretical guarantees provided for convergence and performance analysis lend credibility to the methodology. However, the reliance on specific assumptions such as Lipschitz continuity and boundedness for convergence may limit the generalizability of the results. Additionally, while the algorithms show promise, their computational complexity could pose challenges in high-dimensional or large datasets, and there is a potential risk of overfitting to noisy observations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodologies, and findings. The novelty of the framework is significant, particularly in the context of online learning for multiobjective optimization. The reproducibility is supported by detailed descriptions of the algorithms and experimental setup, although further validation across a broader range of datasets would enhance confidence in the findings.\n\n# Summary Of The Review\nOverall, this paper makes a valuable contribution to the field of multiobjective optimization by introducing a robust framework for online learning. Despite some limitations regarding assumptions and computational challenges, the findings are promising and relevant, particularly for real-world applications like portfolio optimization.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework for online learning in inverse multiobjective optimization (IMOP), aiming to learn the parameters of multiobjective decision-making models from sequentially observed decisions. The authors propose two online learning algorithms that utilize implicit update rules to handle noisy data, achieving a convergence rate of O(1/T) under certain regularity conditions. Empirical evaluations on both synthetic and real-world datasets demonstrate the algorithms' high accuracy and robustness to noise, particularly in applications such as portfolio optimization.\n\n# Strength And Weaknesses\nStrengths of the paper include its pioneering approach to applying online learning to IMOP, addressing a significant gap in the literature that has primarily focused on batch learning methods. The development of two distinct algorithms offers practical options for implementation, and the convergence analysis provides theoretical grounding for their efficacy. However, the paper could benefit from a more comprehensive exploration of potential limitations and assumptions inherent in the proposed methods, particularly regarding the types of noise considered and the robustness of the algorithms under various conditions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodologies. The exposition of complex concepts, such as the loss function and update rules, is coherent, making it accessible to readers with a background in optimization. While the theoretical results are presented convincingly, the reproducibility of the experiments could be enhanced by providing additional details regarding the implementation of the algorithms, as well as code or datasets used for validation.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of online learning in multiobjective optimization, presenting a robust framework and algorithms that effectively handle noisy data. The clarity of the presentation and the empirical results support the claims made, although some aspects regarding reproducibility could be improved.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework for inferring multiobjective decision-making parameters, which addresses a gap in optimization literature. The methodology involves two algorithms designed to handle noisy data and improve learning efficiency. Empirical findings demonstrate that the algorithms can accurately learn parameters from both synthetic and real-world datasets, with the second algorithm significantly accelerating the learning process.\n\n# Strength And Weaknesses\nThe paper offers several strengths, including the introduction of a general framework that enhances the understanding of multiobjective decision-making, and its robust performance in noisy environments, suggesting practical applicability. However, limitations such as the complexity of implementation, dependence on regularity conditions for convergence, and the potential trade-off between accuracy and speed may hinder practical adoption. Moreover, while the empirical validation is promising, the limited scope of experiments raises questions regarding the generalizability of the results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written with a well-structured presentation of algorithms, making it accessible for reproduction. The theoretical foundation is solid, with convergence proofs provided, which enhances the paper's quality. The novelty lies in the integration of contextual bandit concepts and the exploration of online settings in inverse multiobjective optimization, although some areas, such as the integration with contextual bandits, require deeper exploration.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of multiobjective optimization through its novel framework and robust algorithms. While it presents a strong theoretical basis and empirical validation, certain limitations regarding implementation complexity and the need for broader experimental scope should be addressed for greater impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents an innovative framework for adaptive multiobjective learning in online decision-making contexts, effectively addressing the issue of noisy observations. The authors introduce a novel approach that diverges from traditional inverse multiobjective optimization (IMOP) techniques, demonstrating a convergence rate of \\(O(1/\\sqrt{T})\\) under specific conditions. Key contributions include an adaptive learning framework, an implicit update mechanism, and a robust loss function designed to mitigate the effects of noise. The empirical evaluation across synthetic and real-world datasets, particularly in portfolio optimization, confirms the framework's superior performance compared to existing methods.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its novel adaptive learning framework that allows for real-time updates based on sequential decision data, which is a significant advancement over conventional batch processing methods. The introduction of an implicit update rule tailored for stochastic observations is another notable contribution. However, a potential weakness is the reliance on specific conditions for convergence, which may limit the framework's applicability in more generalized settings. Additionally, while the empirical results are promising, further investigation into the framework's performance in various contexts could strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written, with clear explanations of the proposed methodology and its theoretical underpinnings. The quality of the experiments is high, and the results are presented in a comprehensible manner. The novel aspects of the research, particularly the dynamic loss function and mini-batch processing, are articulated effectively. However, reproducibility could be enhanced by providing more detailed descriptions of experimental setups and datasets used, which would aid other researchers in replicating the results.\n\n# Summary Of The Review\nOverall, this paper makes a significant contribution to the field of multiobjective optimization by presenting a robust adaptive online learning framework. Its innovative approaches to handling noisy observations and ensuring convergence rate improvements indicate both theoretical and practical value. Future work could focus on expanding the framework's adaptability through additional algorithmic integrations.\n\n# Correctness\n4/5 - The theoretical claims regarding convergence and the robustness of the proposed methods appear sound, although some conditions for applicability could limit generalizability.\n\n# Technical Novelty And Significance\n5/5 - The introduction of adaptive learning mechanisms and implicit updates in the context of multiobjective optimization is a notable advancement that significantly shifts the paradigm from traditional methods.\n\n# Empirical Novelty And Significance\n4/5 - The empirical validation demonstrates the framework's effectiveness, yet further exploration across diverse problem domains could enhance the understanding of its broader applicability and robustness.",
    "# Summary Of The Paper\nThe paper presents a novel approach to adversarial training within the framework of multiobjective optimization (MOP). The authors introduce an online learning algorithm that leverages inverse multiobjective optimization principles to enhance the robustness of machine learning models against adversarial attacks. Key contributions include theoretical convergence guarantees, a robust response to noisy data, and extensive empirical validation demonstrating superior performance compared to existing techniques in both synthetic and real-world datasets.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative integration of multiobjective optimization into adversarial training, which is a relatively unexplored area. The rigorous theoretical foundation supports the claims regarding convergence and robustness, and the empirical results convincingly illustrate the method's effectiveness. However, the paper could improve by addressing the computational complexity of the proposed algorithms, providing additional baseline comparisons, and discussing the practical implications of the research findings in more depth.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and conveys its contributions clearly, though it could benefit from a more detailed analysis of computational aspects and a broader review of related work. The novelty is significant, as it introduces a new framework that combines two important areas in machine learning. Reproducibility is bolstered by comprehensive empirical results, yet more details regarding the implementation and computational costs could enhance this aspect.\n\n# Summary Of The Review\nThis paper makes a notable contribution to adversarial training by proposing a novel online learning framework grounded in multiobjective optimization principles. While the theoretical and empirical findings are robust and compelling, addressing computational complexity and providing additional baseline comparisons would strengthen the overall impact of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework aimed at inferring decision-making parameters in multiobjective optimization (MOO). The authors claim that their approach, which incorporates two algorithms designed to handle noisy data, is a significant advancement in the field of inverse multiobjective optimization (IMOP). They assert a convergence rate of O(1/T) and provide empirical results demonstrating their methods' performance on synthetic and real-world datasets, particularly in applications like portfolio optimization.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its ambitious attempt to address the complexities of learning parameters in MOO and its provision of empirical results that suggest robust algorithm performance. However, the weaknesses include an exaggerated claim of being the first comprehensive framework in IMOP, as previous literature has explored similar concepts. The authors' convergence rate, while presented as a significant achievement, is not unique to their work, and their claims regarding the transformative impact on real-world applications may overlook existing methodologies. Moreover, the limitations and assumptions in their approach are noted but not sufficiently explored.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its methodologies clearly, making it accessible to readers. However, the novelty of the contributions is overstated, as the framework builds on established concepts without adequate acknowledgment of prior work. Reproducibility is somewhat supported by the empirical results, but the claims of accuracy in handling noisy data could benefit from further validation.\n\n# Summary Of The Review\nWhile the paper proposes an interesting approach to online learning in multiobjective optimization, many of its claims regarding novelty and impact are overstated. The contributions, though potentially useful, do not fundamentally shift the existing landscape of MOO and are framed more as incremental improvements rather than groundbreaking advancements.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework designed to learn the parameters of multiobjective decision-making models in the presence of noisy observations. Key contributions include the introduction of algorithms that exhibit improved convergence rates of **O(1/√T)**, a notable enhancement over the previously claimed **O(1/T)**. Through extensive numerical experiments, the authors demonstrate that their algorithms achieve high accuracy and robustness in various scenarios, including synthetic data and real-world applications such as portfolio optimization.\n\n# Strength And Weaknesses\nThe paper's main strength lies in its innovative approach to online learning in multiobjective optimization, specifically addressing the challenges posed by noisy data. The performance improvements reported in the experiments are significant, demonstrating both increased accuracy and reduced computational time across multiple scenarios. However, a potential weakness is the limited discussion regarding the scalability of the proposed methods to larger, more complex datasets. Additionally, while the empirical results are promising, further exploration of their applicability across diverse real-world contexts would strengthen the paper.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodology, making it accessible to readers. The quality of the presented algorithms and the thoroughness of the experiments add to the paper's credibility. The novelty is substantial, as it introduces a general framework for online learning in multiobjective optimization. Reproducibility is enhanced by detailed experimental setups and reported results, but additional methodological details would be beneficial for independent validation.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in online learning for multiobjective optimization, with robust empirical results supporting its claims. While the contributions are valuable, further exploration of scalability and broader applicability in diverse scenarios could enhance the impact of the work.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper presents a framework for Inverse Multiobjective Optimization (IMOP), focusing on optimal decision-making processes based on the assumption that human decision-makers operate under ideal conditions. The authors propose algorithms designed to handle noisy data while ensuring convergence under certain regularity conditions. Key findings suggest that the proposed methods demonstrate effective learning outcomes, although concerns arise regarding their robustness and applicability in real-world scenarios, particularly when assumptions such as compactness, convexity, and Lipschitz continuity are not met.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to IMOP and the development of algorithms that aim to learn from multiobjective decision-making scenarios. However, significant weaknesses include the reliance on assumptions that may not hold in practical applications, such as the presumption of optimal decision-making, the handling of noisy data, and the applicability of convergence guarantees under relaxed conditions. Furthermore, the implications of using implicit update rules and the sampling strategy for weights warrant further exploration to assess their impact on the algorithm's performance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, presenting its methodology and findings clearly. However, the clarity could be enhanced by providing a more thorough justification of the assumptions and their implications on the framework's applicability. The novelty of the proposed approach is noteworthy, but the lack of extensive empirical validation raises concerns about reproducibility. A more comprehensive exploration of the algorithms under varied conditions would strengthen the paper's contributions.\n\n# Summary Of The Review\nOverall, the paper presents a promising framework for IMOP with notable contributions to the field. However, the heavy reliance on specific assumptions and the limited exploration of their robustness in real-world scenarios somewhat undermine the practical significance of the findings. Addressing these concerns could significantly enhance the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework designed to infer parameters of multiobjective decision-making models from noisy, sequential observations. It introduces two algorithms that converge at a rate of O(1/T) under certain conditions, demonstrating robustness to noise through numerical experiments. The authors focus on inverse multiobjective optimization problems (IMOPs), addressing the challenges of learning from observed decisions rather than solving for optimal solutions directly. The work establishes performance guarantees and showcases the algorithms' effectiveness in both synthetic and real-world scenarios, including applications such as portfolio optimization.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative approach to online learning in the context of IMOPs and the theoretical guarantees provided for the proposed algorithms. The contrast with traditional batch learning frameworks emphasizes its practical relevance, particularly in noisy environments. However, a potential weakness is the computational complexity introduced when incorporating mini-batches, which may limit the applicability of the proposed methods in real-time scenarios. Furthermore, while the paper presents compelling results, a deeper exploration of the assumptions made regarding decision-makers' objectives could strengthen the analysis.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodologies, and findings. The clarity of the theoretical underpinnings and experimental setups enhances the overall quality. The novelty is significant, as it extends existing inverse optimization frameworks to a multiobjective setting with an online learning perspective. Reproducibility is facilitated by the thorough descriptions of the algorithms and experimental designs, although the authors could provide additional details regarding implementation specifics to further enhance reproducibility.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in the field of multiobjective optimization through its innovative online learning framework. The theoretical and empirical contributions are well articulated, although some aspects, such as computational complexity and assumptions about decision-makers, require further consideration.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to optimizing neural network training by introducing a new adaptive learning rate algorithm, termed Adaptive Rate Adjustment (ARA). The authors claim that ARA improves convergence speed and final model performance compared to conventional learning rate schedules. The methodology involves integrating a dynamic adjustment mechanism that responds to the local gradient landscape, with empirical evaluations conducted on various benchmark datasets.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative contribution to the field of optimization in deep learning, offering a fresh perspective on learning rate adaptation. The results demonstrate significant improvements in convergence speed and model accuracy across several datasets, suggesting practical applicability. However, the paper lacks comprehensive discussions on the limitations of ARA, particularly regarding its performance on non-convex problems and potential overfitting risks. Additionally, the experimental results could be more robust with a broader range of datasets and baselines for comparison.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clearly written, with a logical flow of ideas. However, some sections could benefit from more detailed explanations, particularly regarding the algorithm's implementation and hyperparameter tuning. The novelty of the proposed algorithm is significant, as it addresses a common issue in training deep learning models. While the authors provide sufficient details for reproduction, more extensive documentation or supplementary materials would enhance reproducibility.\n\n# Summary Of The Review\nOverall, the paper offers a valuable contribution to the optimization techniques in machine learning, with promising empirical results demonstrating the effectiveness of the proposed adaptive learning rate algorithm. While the work is well-presented, there are areas requiring improvement in depth and clarity. I recommend acceptance with minor revisions to address these concerns.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework for multiobjective decision-making, particularly focusing on learning parameters from sequentially arrived decisions that may be noisy or reflect limited rationality. It introduces inverse multiobjective optimization (IMOP) as a way to extract decision-making schemes from observed behaviors, which is essential for applications in service and product design. Two algorithms are developed to handle noisy data effectively, and the results demonstrate that the proposed methods achieve a convergence rate of O(1/T), exhibiting high accuracy and robustness across both synthetic and real-world datasets.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to addressing the challenges associated with learning from noisy observations in multiobjective optimization. By framing the problem as an inverse learning task, the authors provide a fresh perspective that diverges from traditional methods that assume optimal decisions. The empirical results support the claims of robustness and accuracy, showcasing the practical applicability of the proposed algorithms. However, a notable weakness is the reliance on certain conditions for convergence, which may not always be met in real-world scenarios. Additionally, the exploration of contextual bandit integrations is mentioned but not elaborated upon, leaving potential avenues for future work somewhat underexplored.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured, presenting its contributions clearly and logically. The methodology is described in sufficient detail, allowing for reproducibility; however, the specific conditions under which the convergence rate holds could be more thoroughly discussed to enhance clarity. The novelty of framing the learning problem via IMOP is significant, contributing to advancements in the field of online learning and multiobjective optimization. Overall, the quality of the writing is high, although a deeper exploration of potential limitations would strengthen the discussion.\n\n# Summary Of The Review\nThis paper makes a noteworthy contribution to the field of online learning by addressing the challenges of learning from noisy multiobjective decision-making data. While the proposed algorithms show promise in terms of robustness and accuracy, further exploration of the conditions for convergence and contextual bandit integrations could enhance the overall impact of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework for online learning in multiobjective decision-making, focusing on inferring parameters of objective functions and constraints from sequentially arrived decisions. It utilizes inverse multiobjective optimization, proposing two robust algorithms that perform well even under noisy conditions, with convergence rates established at O(1/T). Empirical results demonstrate the algorithms' effectiveness on both synthetic and real-world datasets, highlighting their robustness and efficiency in practical applications.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to extending inverse optimization into the realm of multiobjective problems through online learning mechanisms. The methodological contributions, particularly the two proposed algorithms, are well-founded and supported by rigorous theoretical analysis, providing performance guarantees. However, a potential weakness is the limited exploration of the algorithms’ performance across diverse and more complex real-world scenarios, which could further validate their robustness and applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodologies, and findings. The clarity of the exposition allows readers to follow the development of the proposed algorithms and their theoretical underpinnings. The novelty of applying inverse optimization to multiobjective settings is significant, and the paper provides sufficient detail for reproducibility, including algorithmic specifics and empirical evaluation methods.\n\n# Summary Of The Review\nOverall, this paper makes a commendable contribution to the field of online learning and multiobjective optimization. It effectively addresses practical challenges related to noise and uncertainty in decision-making, supported by both theoretical and empirical validations. Further exploration of diverse applications could enhance the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Learning Multiobjective Program Through Online Learning\" investigates the learning of parameters in multiobjective decision-making models amidst noisy data. The authors propose a novel online learning framework leveraging inverse multiobjective optimization (IMOP) that infers decision-makers' objectives based on sequential decision observations. Key contributions include a general framework for online learning in this context, the establishment of a convergence rate of O(1/T), and empirical results demonstrating the framework's effectiveness through experiments on both synthetic and real-world datasets.\n\n# Strength And Weaknesses\nStrengths of the paper include its novel approach to integrating online learning with multiobjective optimization, highlighting its applicability in real-world decision-making scenarios. The rigorous mathematical formulation and convergence analysis substantiate the theoretical claims. However, the paper could benefit from a deeper exploration of the conditions affecting convergence and robustness, particularly in diverse noisy environments. Additionally, while the experiments are well-executed, further exploration of various real-world applications could enhance the impact of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly structured, guiding the reader through complex concepts with appropriate technical language. The methodology is described in sufficient detail to facilitate reproducibility, with clear definitions of the loss functions and algorithms used. The originality of the approach is evident, particularly in its application to multiobjective optimization under noise, which is a relatively unexplored area in the literature.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in the field of multiobjective optimization through its novel online learning framework. While the contributions are robust and well-supported by empirical evidence, further investigation into convergence conditions and broader applications would strengthen the work.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThis paper investigates parameter learning in multiobjective decision-making models using a novel online learning framework based on inverse multiobjective optimization (IMOP). The authors propose two online learning algorithms that effectively manage noisy data and demonstrate a convergence rate of \\(O(1/T)\\) under specific conditions. Empirical results reveal that these algorithms achieve high accuracy in parameter estimation and exhibit robustness against measurement noise, particularly in applications involving multiobjective quadratic programming and portfolio optimization.\n\n# Strength And Weaknesses\nThe key strengths of this paper include its innovative approach to parameter estimation in multiobjective optimization problems, which is a significant contribution to the field. The use of online learning algorithms tailored for handling noisy observations is well-motivated and offers practical implications. However, the paper could benefit from a more thorough discussion of the limitations of the proposed methodologies and the assumptions made regarding optimal decision-making. Additionally, while the empirical validation is strong, further comparisons with existing methods could enhance the robustness of the claims made.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its contributions, methodologies, and findings. The mathematical formulations are precise, aiding in the understanding of the proposed algorithms and their convergence properties. However, some sections could use more explanation, especially regarding the implications of measurement noise and bounded rationality. The novelty of the approach is notable, and the reproducibility of experiments is supported by clear descriptions of the methodologies used, though supplementary materials or code would further facilitate this.\n\n# Summary Of The Review\nOverall, this paper presents a meaningful advancement in online learning for multiobjective optimization through the introduction of robust algorithms that manage noisy data effectively. While the contributions are significant and the empirical results are promising, the paper would benefit from addressing some limitations and providing further context for the applicability of its methods.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper proposes a novel online learning framework aimed at multiobjective decision-making, leveraging concepts from inverse optimization. The authors claim that the framework can efficiently handle noisy data and provides a convergence rate of O(1/T) under specific regularity conditions. However, the methodology lacks substantial new insights and relies heavily on existing theories without adequately justifying its applicability or robustness in practical scenarios.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to address multiobjective decision-making through an online learning framework, an area of ongoing research interest. However, the reliance on established concepts in inverse optimization detracts from its originality. The convergence rate claim appears overly optimistic and lacks thorough justification, which raises questions about its realism. Furthermore, the assumption of rational decision makers undermines the framework’s practical applicability, as bounded rationality is often more representative of real-world scenarios. The vague discussion on handling noise, limited exploration of parameter impacts in experiments, and the convoluted organization of the paper significantly weaken the overall contribution.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper suffers from clarity issues, with a convoluted organization that hampers the flow of ideas and makes it difficult for readers to follow the authors' arguments. While the literature review is extensive, it does not effectively contextualize the current work, leading to a perception of selective referencing. The reproducibility of the findings is questionable due to a lack of detailed methodology, particularly regarding the claims of computational efficiency and parallelization. Overall, the paper does not provide a comprehensive or clear understanding of its contributions.\n\n# Summary Of The Review\nWhile the paper attempts to propose a significant contribution to multiobjective decision-making through an online learning framework, it ultimately reveals numerous weaknesses, including insufficient validation, lack of depth in analysis, and questionable applicability. The reliance on established concepts without novel insights and the flawed assumptions about rationality further diminish its impact.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework for inferring decision-making parameters in multiobjective optimization, marking a pioneering advancement in this field. It introduces two algorithms characterized by implicit update rules, demonstrating robustness to noisy data and achieving fast convergence rates (O(1/T)). The experiments conducted reveal that these algorithms can effectively learn from both synthetic and real-world datasets, illustrating their practical relevance in applications such as portfolio optimization and service design. The findings suggest significant potential for future integration with contextual bandit algorithms.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative contributions to online learning in inverse multiobjective optimization, which is the first of its kind. The robustness of the proposed algorithms to noise is a critical asset, enhancing their applicability in real-world scenarios. Furthermore, the rapid convergence rate is a noteworthy advantage for applications requiring quick adaptations. However, while the algorithms demonstrate impressive empirical results, further details on the computational complexity and scalability in larger datasets would strengthen the paper's overall impact.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and articulately presents its methodology, making it accessible to readers with a foundational understanding of optimization and machine learning. The quality of the experiments is commendable, showcasing both synthetic and real-world datasets, which adds to the reproducibility of the findings. The novelty is significant, particularly regarding the application of the algorithms to learn human preferences, but the paper could benefit from additional clarifications around the underlying assumptions and limitations of the proposed framework.\n\n# Summary Of The Review\nOverall, this paper represents a substantial contribution to the field of multiobjective optimization through its innovative online learning framework. The proposed algorithms show strong empirical performance and practical applicability, although further discussion on scalability and limitations would enhance the work's depth.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces a theoretical framework for learning parameters in multiobjective decision-making models through the lens of inverse multiobjective optimization (IMOP). It establishes convergence rates for the proposed algorithms, specifically O(1/T), under regularity conditions while addressing the challenges posed by noise in observations and bounded rationality in decision-making. The contributions include a novel online learning framework that allows for inferring decision-makers' objectives, alongside rigorous theoretical foundations that highlight the interplay between observed data and optimization models.\n\n# Strength And Weaknesses\nThe paper presents several strengths, including a robust theoretical foundation that extends existing inverse optimization theories to multiobjective contexts and effectively addresses the complexities introduced by noisy data. The formalization of the decision-making problem and the derivation of convergence rates under specific assumptions demonstrate a thorough understanding of the underlying optimization principles. However, the paper could benefit from more empirical validation and practical examples to illustrate the application of the proposed framework in real-world scenarios, as the focus remains predominantly theoretical.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible to readers with a background in optimization theory. The theoretical arguments are logically presented, and the notation is consistent throughout. However, the emphasis on theoretical constructs over empirical results may limit the reproducibility of the findings in practical applications. The novelty lies in the integration of online learning methodologies with inverse multiobjective optimization, although further empirical exploration would solidify its significance.\n\n# Summary Of The Review\nOverall, this paper presents a commendable theoretical framework that advances the understanding of learning in multiobjective optimization. While the theoretical contributions are substantial, the lack of empirical validation may hinder its practical applicability. Future work could focus on bridging this gap to enhance the framework's relevance in real-world decision-making contexts.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThis paper presents a novel online learning framework for multiobjective decision-making models, specifically utilizing inverse multiobjective optimization (IMOP) to manage noisy data. The authors propose two algorithms with implicit update rules, demonstrating convergence at a rate of O(1/T) under certain conditions. The proposed algorithms exhibit robustness against noise and efficiency in parameter learning, verified through extensive numerical experiments on both synthetic and real-world datasets.\n\n# Strength And Weaknesses\nThe strength of the paper lies in its innovative approach to online learning in multiobjective optimization, which addresses practical challenges such as noise in data. The development of two distinct algorithms, with one being an accelerated version that improves computational efficiency, adds depth to the contribution. However, the paper's discussion on the computational complexity of updates and the challenges associated with mini-batch updates could be expanded for further clarity. Additionally, while the experimental results are promising, further exploration of the implications of these findings in broader contexts would strengthen the contribution.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and results. The algorithms are described in detail, with sufficient information provided for reproducibility, including the use of the Gurobi Optimization software and the implementation in Julia. The novelty of combining IMOP with online learning is significant, although the paper could benefit from a more thorough discussion on potential limitations and future directions. Overall, the clarity and quality of the writing are commendable, allowing for a good understanding of the proposed methods and findings.\n\n# Summary Of The Review\nOverall, this paper presents a valuable contribution to the field of online learning in multiobjective decision-making by introducing effective algorithms that handle noisy data. While the methods are well-explained and yield promising results, a deeper exploration of certain aspects could enhance the paper's impact.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper proposes a general framework for online learning in multiobjective optimization, claiming to address issues related to noisy data and generalizability across convex decision-making problems. The authors present algorithms designed to accelerate the learning process compared to traditional batch methods, asserting that their approach is free from the single-objective assumption. They provide experimental results demonstrating the effectiveness of their framework on real-world applications, particularly in portfolio optimization.\n\n# Strength And Weaknesses\nWhile the authors present an interesting approach to online learning in multiobjective optimization, there are significant weaknesses in their claims of novelty and generalizability. The assertion that their work is the first of its kind is misleading, as similar frameworks already exist in the literature, such as those by Dong & Zeng (2020) and Bärmann et al. (2017). Additionally, the lack of comprehensive comparisons with these prior works and others addressing noise limits the perceived contribution of their methodology. The experimental results, while robust, are not adequately contextualized within the broader field, leading to a potential overstatement of their significance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and clear, but the novelty of the proposed methods is overstated due to insufficient acknowledgement of prior work. The authors do not provide a balanced view of how their contributions fit within existing literature, which affects the clarity of their claims. The reproducibility of their findings is not sufficiently supported by detailed comparisons with established methods, making it challenging for readers to assess the true value of the proposed framework.\n\n# Summary Of The Review\nOverall, while the paper introduces a framework for online learning in multiobjective optimization that is interesting and potentially useful, it suffers from an inflated sense of novelty and insufficient engagement with existing literature. The authors' failure to adequately compare their work to prior studies diminishes the clarity and significance of their contributions.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"Learning Multiobjective Programming through Online Learning\" presents a novel framework for addressing multiobjective programming (MOP) problems using online learning techniques. The authors propose an algorithm that adapts to dynamic environments, enabling efficient decision-making in scenarios where objectives may change over time. Key contributions include the formulation of an online learning algorithm for interactive multiobjective programming (IMOP) and empirical evaluations demonstrating its effectiveness compared to existing methods. The findings indicate that the proposed approach yields superior performance in adapting to objective changes while maintaining computational efficiency.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to solving MOP problems through online learning, which is a timely and relevant contribution given the increasing complexity of real-world decision-making scenarios. The methodology is well-defined, and the empirical results are promising, showcasing improvements over traditional methods. However, weaknesses include the lack of clarity in mathematical notation and inconsistencies in formatting, which could hinder understanding. Additionally, the discussions on limitations and future work could be expanded to provide clearer insights into the practical implications of the research.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is hampered by several formatting issues, including inconsistent use of mathematical symbols and unclear definitions of variables. Although the novelty of applying online learning to MOP is significant, the presentation could benefit from improved organization and readability. Reproducibility is a concern due to the insufficient detail in the algorithmic descriptions and the need for clearer explanations of the empirical setups. \n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of multiobjective programming through its innovative application of online learning techniques. However, the effectiveness of the contributions is somewhat undermined by clarity and formatting issues that affect the readability and reproducibility of the results.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel online learning framework for multiobjective optimization that aims to address decision-making under uncertainty. The authors propose algorithms that adaptively learn preferences from observations and demonstrate their approach on several benchmark problems. Key findings suggest that the proposed framework improves decision-making efficiency; however, it lacks a comprehensive exploration of its scalability and robustness under varying conditions.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its innovative approach to integrating online learning with multiobjective optimization and the empirical results demonstrating its effectiveness on benchmark datasets. However, significant weaknesses include the limited exploration of varying noise levels in observations, which raises questions about the robustness of the algorithms. Additionally, the paper does not adequately address scalability to high-dimensional problems or the integration with existing optimization techniques, which could limit its practical applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its methodology clearly. However, the novelty could be more convincingly articulated, particularly regarding the implications of the proposed framework in dynamic environments or when scaling to multiple objectives. The reproducibility of the results is hindered by insufficient detail regarding experiments and the types of datasets used, which could impact the assessment of the framework's generalizability.\n\n# Summary Of The Review\nOverall, while the paper introduces an interesting online learning framework for multiobjective optimization, it falls short in addressing critical limitations such as noise robustness, scalability, and integration with existing methods. The contributions are noteworthy but would benefit from a more thorough examination of practical implications and broader experimental validation.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a framework for online learning in multiobjective decision-making models that account for noise and measurement errors in sequential decisions. The authors propose an inverse multiobjective optimization (IMOP) approach to infer decision makers' objective functions, asserting a convergence rate of \\( O(1/\\sqrt{T}) \\) under certain regularity conditions. Through robust empirical validation using both synthetic and real datasets, the results demonstrate the algorithms' effectiveness in noisy environments, highlighting their reliability and performance metrics.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its clear articulation of a novel learning framework and the demonstration of convergence rates that are theoretically sound. The empirical analysis, bolstered by repeated trials and statistical testing, provides credibility to the findings. However, the assumptions regarding the Lipschitz continuity and strong convexity, while necessary for the proofs, may limit the model's applicability in more complex or less structured environments. Additionally, the reliance on specific statistical tests, such as the Chi-square goodness-of-fit, could benefit from broader validation techniques.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly written, making the complex methodologies accessible to readers. The quality of the empirical validation is high, with appropriate statistical analyses that enhance the reproducibility of the results. The novelty of the approach, particularly the integration of statistical error analysis in the context of multiobjective decision-making, is commendable; however, further exploration of its implications beyond the current assumptions would strengthen its impact.\n\n# Summary Of The Review\nThis paper offers a significant contribution to the field of online learning in multiobjective decision-making under noisy conditions. While it provides solid theoretical foundations and empirical validation, it would benefit from addressing its assumptions and exploring broader applications of its findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel framework for decision-making under uncertainty, proposing new algorithms that demonstrate convergence at a rate of O(1/T) under specific conditions. The methodology relies on the convexity of the underlying decision-making problem and incorporates a surrogate loss function dependent on sampled weights. The findings suggest that while the algorithms perform well in certain scenarios, there is a significant gap in addressing the impact of assumptions on observations' optimality and the robustness of the approach in non-convex settings.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative algorithms and clear demonstration of convergence under specific conditions. However, the weaknesses are pronounced, particularly in the limited exploration of the impact of assumptions regarding observations and the lack of analysis on non-convex problems. Additionally, the paper does not thoroughly investigate the computational complexity of the proposed algorithms, nor does it consider the influence of outliers in the data. The suggested future work lacks concrete strategies for integrating contextual bandit algorithms and does not delve into dimension reduction techniques or the integration of human behavior insights, which could enhance the model’s applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a clear presentation of the proposed algorithms and their theoretical foundations. However, the lack of depth in exploring various assumptions and their implications may hinder reproducibility and understanding of the framework's limitations. The novelty is present in the proposed methodology, but it is somewhat diminished by the absence of a comprehensive discussion on its applicability to real-world non-convex problems.\n\n# Summary Of The Review\nOverall, the paper introduces a promising framework for decision-making under uncertainty with convergence guarantees, but it suffers from significant limitations regarding the robustness of its assumptions, exploration of non-convexities, and practical applicability. The lack of depth in discussing future work and computational complexities further detracts from the overall impact of the contributions.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents an online learning framework for multiobjective decision-making, claiming to address challenges such as noisy data and bounded rationality. It introduces two algorithms that aim to improve the speed of learning through implicit updates, accompanied by a convergence rate of O(1/T). The authors suggest that their methods generalize existing single-objective inverse optimization techniques to multiobjective problems, although the novelty of these contributions is questionable.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its attempt to tackle multiobjective optimization in an online learning context, which is a relevant area of research. However, the weaknesses are pronounced: the contributions often feel like reiterations of established concepts, lacking true innovation. The claim of being the first to propose a general framework for online learning in multiobjective optimization seems overstated. Additionally, the experimental validation appears limited, relying on a small set of problems and lacking broader applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is written in a clear and structured manner, making it relatively easy to follow. However, the quality of the contributions is diminished by a lack of true novelty, as many ideas presented are well-established in the literature. Reproducibility could be hindered by the limited scope of the experiments, as the authors do not provide extensive details on the implementation of their algorithms or the datasets used.\n\n# Summary Of The Review\nOverall, the paper attempts to contribute to the field of online learning for multiobjective optimization but ultimately fails to deliver significant novel insights. The claims made are often unsubstantiated, and the experimental results do not convincingly demonstrate the advantages of the proposed methods over existing approaches.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents an online learning framework for multiobjective optimization, focusing on improving convergence rates and robustness to noise. It claims convergence at a rate of O(1/T) and explores various aspects of the optimization process, including mini-batch learning and the integration of contextual features. Empirical results are provided, showcasing the framework's effectiveness, although the authors primarily focus on convex problems. The paper proposes directions for future work, including potential integrations with contextual bandits and multi-agent scenarios.\n\n# Strength And Weaknesses\nThe main contribution of the paper lies in its online learning framework tailored for multiobjective optimization, which is a relevant and timely area of research. The proposed convergence guarantees and noise robustness are commendable; however, the paper lacks depth in exploring non-convex problems and could benefit from a stronger empirical validation across diverse datasets. The suggestions for future work are insightful but could have been more explicitly integrated into the current framework. Moreover, while the theoretical aspects are mentioned, they are not sufficiently elaborated.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and generally clear, although it would benefit from more detailed explanations of the methodologies employed. The novelty primarily lies in the proposed online learning framework, but further exploration of modern optimization techniques could enhance its contribution. Reproducibility is somewhat limited due to the lack of detailed experimental setups and diverse dataset validation. Including more comprehensive results could improve the paper's impact.\n\n# Summary Of The Review\nOverall, the paper introduces a promising online learning framework for multiobjective optimization, with notable strengths in convergence guarantees and robustness. However, it falls short in empirical validation and theoretical depth, particularly regarding non-convex problems. Addressing these shortcomings could significantly enhance its contributions to the field.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n3/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents a novel framework for online learning algorithms specifically designed for multiobjective quadratic optimization problems (MQP) and portfolio optimization. The authors conduct extensive numerical experiments on both synthetic and real-world datasets to evaluate the performance of their proposed algorithms, focusing on convergence rates, robustness to noise, and computation efficiency. Findings indicate that the algorithms achieve rapid convergence and low estimation errors for learning parameters, demonstrating scalability and effectiveness in real-time applications.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its thorough experimental validation and clear demonstration of the algorithms' performance metrics, such as convergence rates and robustness under noise. The comparative analysis with batch learning approaches highlights the practical advantages of online algorithms in terms of computation time and applicability in real-time scenarios. However, a potential weakness is the lack of extensive discussion on the limitations of the proposed methods and their applicability to other types of optimization problems, which could provide a more balanced view.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its findings clearly, making it accessible to readers. The methodology is detailed, allowing for reproducibility of the experiments. The novelty of the proposed online learning algorithms is noteworthy, as they significantly improve upon existing methods in terms of speed and accuracy. However, further elaboration on the theoretical underpinnings of the algorithms could enhance the understanding of their novelty and significance.\n\n# Summary Of The Review\nOverall, this paper makes a valuable contribution to the field of online learning in multiobjective optimization. It provides a robust evaluation of the proposed algorithms, demonstrating strong performance in both synthetic and real-world scenarios. While the clarity and reproducibility are commendable, a deeper exploration of the limitations would strengthen the overall presentation.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel approach to multiobjective decision-making under uncertainty, leveraging inverse optimization techniques. The authors propose a model that incorporates measurement noise and bounded rationality, providing a framework for optimizing decisions based on a sequence of choices. Key findings indicate that their method outperforms existing models in various scenarios, as evidenced by extensive empirical evaluations.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative integration of inverse optimization into the multiobjective decision-making framework, which offers practical implications for real-world applications. However, the paper suffers from issues related to clarity and organization; the introduction is dense and the contributions are not clearly enumerated. Additionally, the assumptions made in the methodology are presented in a technical manner that may confuse readers without a strong background in the subject.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the methodology is sound, the paper's clarity could be significantly improved. Complex sentences and jargon may obstruct understanding, particularly for a broader audience. The reproducibility of results could be bolstered by clearer descriptions of the algorithms and their implementations, as well as succinctly summarized contributions. Furthermore, the figures and graphs lack adequate labeling and context, which hampers their effectiveness in conveying the authors' findings.\n\n# Summary Of The Review\nOverall, the paper introduces a significant advancement in multiobjective decision-making by incorporating inverse optimization; however, it suffers from clarity and organizational issues that detract from its impact. Improving the structure and presentation of the content would greatly enhance its accessibility and effectiveness.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.6446107728977637,
    -1.7170304921027044,
    -1.7242723366283232,
    -1.6920470962795864,
    -1.9595385726451007,
    -1.7015105006495026,
    -1.7271454497286705,
    -1.925164482184704,
    -1.6941413364076223,
    -1.7556599254966723,
    -1.786696640599484,
    -1.5116691821619614,
    -1.7205433397591174,
    -1.738717265529047,
    -1.7835319973257142,
    -1.7851290899280812,
    -1.953902280703457,
    -1.9378152596132092,
    -1.7924650367443822,
    -1.7606072042184187,
    -1.8017529618258958,
    -1.55545757541538,
    -1.8076140063546549,
    -1.9132315016011674,
    -1.8177681393590108,
    -1.7187887997087863,
    -1.7714066226857668,
    -1.7096427998743096,
    -1.8953470107253576
  ],
  "logp_cond": [
    [
      0.0,
      -2.5313547231739255,
      -2.5253770265750943,
      -2.5185328962196474,
      -2.518542234289601,
      -2.5095935170270147,
      -2.5261914598714252,
      -2.5165381484173555,
      -2.5196598950694136,
      -2.5330651954338337,
      -2.5131878024941696,
      -2.5394926924478955,
      -2.536467810363205,
      -2.5415728129249673,
      -2.5085712324784346,
      -2.5426714607265595,
      -2.523815206931363,
      -2.5155341218743925,
      -2.5386796231030955,
      -2.524000383447215,
      -2.5312549626769103,
      -2.5212011892724644,
      -2.5270245381725953,
      -2.5217924807573975,
      -2.5358989668984426,
      -2.544644254642094,
      -2.5254012127776835,
      -2.5348765007043403,
      -2.5363295218297917
    ],
    [
      -1.4032244226615394,
      0.0,
      -1.2625112243655159,
      -1.234860995761375,
      -1.2830294534517248,
      -1.3341069240390109,
      -1.320652854017832,
      -1.243399874347204,
      -1.290728744957227,
      -1.3446402444951193,
      -1.207188813492393,
      -1.4557795349779485,
      -1.17051031959693,
      -1.2786164538759015,
      -1.2372584458406723,
      -1.1838842165227985,
      -1.2818484793881786,
      -1.2737439767652257,
      -1.2502614584877274,
      -1.2155599191061943,
      -1.3469467291531818,
      -1.3416056756988903,
      -1.3776773803652795,
      -1.2531946486261207,
      -1.378062450722179,
      -1.3298456254767919,
      -1.3497937475556965,
      -1.3491727375913378,
      -1.393606837189197
    ],
    [
      -1.4491313094158664,
      -1.229112237948397,
      0.0,
      -1.1839332970153962,
      -1.253818169663447,
      -1.318845920675137,
      -1.3812307452393595,
      -1.190410706471438,
      -1.3232555963553232,
      -1.298891733468742,
      -1.198213902615464,
      -1.507515787633273,
      -1.2391075976695238,
      -1.2366473020354476,
      -1.3003398333238747,
      -1.234730982047645,
      -1.3232348225312707,
      -1.2095473909483,
      -1.333894904454965,
      -1.29493661746842,
      -1.336669793796139,
      -1.4333132223689289,
      -1.374089723047478,
      -1.2857118999510992,
      -1.391768160396348,
      -1.341882859094188,
      -1.3964588768104809,
      -1.3663034115439585,
      -1.4554351223634059
    ],
    [
      -1.398156094187084,
      -1.1673097996200275,
      -1.1749072118334916,
      0.0,
      -1.2865127316083667,
      -1.2448859480403922,
      -1.3315848792726728,
      -1.1545210633176721,
      -1.2310096366567913,
      -1.2541174166444078,
      -1.1713034822865214,
      -1.3978469933872153,
      -1.2065071299128691,
      -1.2283075740811609,
      -1.2412074561216986,
      -1.1339259248338545,
      -1.2599140938947853,
      -1.1629608263003217,
      -1.271777910822434,
      -1.154380077951639,
      -1.2637132424118314,
      -1.3434782993338066,
      -1.3482002253384793,
      -1.2441175170615664,
      -1.3638080268876922,
      -1.2446230073844926,
      -1.3390030187251978,
      -1.2933599626041132,
      -1.3719486353597343
    ],
    [
      -1.5946371455542783,
      -1.468760693257599,
      -1.4554550607244103,
      -1.4734991941978135,
      0.0,
      -1.6060705810474902,
      -1.5626951629583248,
      -1.434914197916647,
      -1.5465982107128915,
      -1.5179854794242131,
      -1.4320275126050763,
      -1.6651578541308238,
      -1.4124401918381553,
      -1.4790580867295922,
      -1.5030563074964265,
      -1.502815244181697,
      -1.4811835459458316,
      -1.389896203463704,
      -1.5071098021379064,
      -1.4665060862205976,
      -1.5502484477889427,
      -1.5848065645031613,
      -1.5718870118920785,
      -1.5406161659288087,
      -1.543084629717655,
      -1.4763315096466838,
      -1.5411742315957084,
      -1.568926172504294,
      -1.6123530067641754
    ],
    [
      -1.5149218370480841,
      -1.3529139794915739,
      -1.3495203565407379,
      -1.3462567402114562,
      -1.4455659196049364,
      0.0,
      -1.4198139989309413,
      -1.3719866573576747,
      -1.3715478260651761,
      -1.4195241123986948,
      -1.3344653334269663,
      -1.5072528101552272,
      -1.3908424822873526,
      -1.3888763527434624,
      -1.3587290102499758,
      -1.3502506811134187,
      -1.4261949375665073,
      -1.3804740152490202,
      -1.3979563370730952,
      -1.3808355774469798,
      -1.4068248619215322,
      -1.4540358071906996,
      -1.431332074870062,
      -1.4026172646551005,
      -1.4615403128705386,
      -1.4341277947155702,
      -1.376951777274735,
      -1.4344790142662802,
      -1.4415941283331326
    ],
    [
      -1.3775112170249182,
      -1.211965694702966,
      -1.2534768140614478,
      -1.2355847614997337,
      -1.2489405146724668,
      -1.3504773213598813,
      0.0,
      -1.1993529093944362,
      -1.276793326738327,
      -1.2827261092095514,
      -1.2530932859311157,
      -1.4237790320186487,
      -1.2536853597566369,
      -1.265022549016272,
      -1.2648554163232526,
      -1.208370813949601,
      -1.2698186018337756,
      -1.2293164148840512,
      -1.2504469672117782,
      -1.26222722395253,
      -1.2691268081634002,
      -1.3122937208520928,
      -1.299874275078175,
      -1.2463216613730932,
      -1.324805232264685,
      -1.2867702627654203,
      -1.3012482285975189,
      -1.2813730114038138,
      -1.3559205837238555
    ],
    [
      -1.6266459248817386,
      -1.4292941532058823,
      -1.3563478817545087,
      -1.3817771272157926,
      -1.4767609483161173,
      -1.5594290617812898,
      -1.5739614813813796,
      0.0,
      -1.530242010529315,
      -1.5254413603352208,
      -1.3984654421796137,
      -1.7228070776885194,
      -1.4371705840888016,
      -1.4659357012656253,
      -1.5198471950979626,
      -1.4270753269675533,
      -1.5193352248624519,
      -1.4008000773794094,
      -1.508679308971139,
      -1.5057199679104227,
      -1.4802235217615667,
      -1.637969413399398,
      -1.620886226887534,
      -1.4835016260624985,
      -1.5750784883955788,
      -1.4867634914749777,
      -1.6064903346056356,
      -1.5668600707081741,
      -1.6642011167010426
    ],
    [
      -1.4102041613302032,
      -1.2256370448877918,
      -1.2659247920688408,
      -1.2531446406426054,
      -1.2395587798840582,
      -1.274927387723868,
      -1.2847663240684328,
      -1.2170089239224584,
      0.0,
      -1.3082163523337231,
      -1.1667175403182035,
      -1.3337957207419011,
      -1.2797904817214532,
      -1.2784621593630119,
      -1.2646030122891998,
      -1.2767567574823835,
      -1.303396150583483,
      -1.195817324216781,
      -1.2612959123550973,
      -1.2630991041156547,
      -1.275801070408272,
      -1.3528437110660538,
      -1.2918344274537699,
      -1.2992179672374857,
      -1.3218782961824918,
      -1.268673744541902,
      -1.289624533443805,
      -1.2789668733692774,
      -1.3130485912006122
    ],
    [
      -1.4508418018745528,
      -1.3361099821108327,
      -1.2879098550053463,
      -1.275336023684732,
      -1.3776555066454517,
      -1.4044882198604898,
      -1.377873992782257,
      -1.305728266116646,
      -1.4067773922379017,
      0.0,
      -1.3284230606128835,
      -1.4781012792278567,
      -1.3077032436119969,
      -1.3389432767494176,
      -1.4056380054339206,
      -1.3547120882107582,
      -1.3218987126462631,
      -1.2851729906621416,
      -1.3610642364762973,
      -1.3378600042482307,
      -1.3635175330187763,
      -1.4017955653203609,
      -1.3211209351235993,
      -1.3452789093610913,
      -1.3188264498827296,
      -1.3356014715665272,
      -1.3916724472499569,
      -1.3586403190047263,
      -1.4220814573410645
    ],
    [
      -1.437837844813941,
      -1.3386135430356365,
      -1.3147725227176275,
      -1.3111895783482144,
      -1.3309019472071315,
      -1.4095896224329059,
      -1.4243402010622708,
      -1.3318736949711643,
      -1.341196445241521,
      -1.4045391399680431,
      0.0,
      -1.5034883105940202,
      -1.4165930608656412,
      -1.365941389072125,
      -1.3852817537776256,
      -1.3213830721649449,
      -1.3972838352917583,
      -1.3042052221696845,
      -1.3649762482251369,
      -1.352672770518677,
      -1.404732832251672,
      -1.441423063763612,
      -1.4459969979346692,
      -1.3907615297764295,
      -1.4704766618235336,
      -1.4068945494050276,
      -1.4048230878135333,
      -1.4350521907755707,
      -1.470570963643991
    ],
    [
      -1.275923187977013,
      -1.2203143533966099,
      -1.1955151103567982,
      -1.185737629544358,
      -1.166626097430592,
      -1.2034224909354745,
      -1.2049095874933162,
      -1.2130786152881419,
      -1.1719459885212282,
      -1.2174064269276708,
      -1.182862580306315,
      0.0,
      -1.2159895632071585,
      -1.2268918668167814,
      -1.169248227216973,
      -1.2249586184802197,
      -1.1727385768385352,
      -1.1696462808358665,
      -1.2323890606577212,
      -1.196610636500468,
      -1.1931150372906123,
      -1.136551155625581,
      -1.210626875644988,
      -1.2195312429117888,
      -1.20908657638214,
      -1.21543986020375,
      -1.1857850154418874,
      -1.2065193854618708,
      -1.1295005806090685
    ],
    [
      -1.4629278629956657,
      -1.248951545716542,
      -1.30214266865246,
      -1.2647715258101686,
      -1.3469039995293801,
      -1.4420954723804669,
      -1.3909602682049613,
      -1.288993288148129,
      -1.3871457798520694,
      -1.3866676443119181,
      -1.305727467097185,
      -1.472226357572371,
      0.0,
      -1.3220408676417938,
      -1.3704993070522156,
      -1.277186174863284,
      -1.356254920108136,
      -1.278251923111372,
      -1.3638052223965103,
      -1.265796266731409,
      -1.3854325891148487,
      -1.4095696332437984,
      -1.4111131169331057,
      -1.354096147084306,
      -1.3530494666715516,
      -1.3496278063919265,
      -1.3552755663766003,
      -1.3839124399025005,
      -1.4824200856533936
    ],
    [
      -1.4284783089026276,
      -1.1964215408403842,
      -1.148475716655741,
      -1.1961470984440619,
      -1.2825609278065229,
      -1.3341770235392267,
      -1.30178138506635,
      -1.2511897447683582,
      -1.2752496753635285,
      -1.3097272677550593,
      -1.1791097360213263,
      -1.4082432409611307,
      -1.1779858675117696,
      0.0,
      -1.2187352959933524,
      -1.1958386279613005,
      -1.2855795488463535,
      -1.1677599653240527,
      -1.2541628119119466,
      -1.1589420130980468,
      -1.311025913679461,
      -1.338249108896902,
      -1.328962850863198,
      -1.217880088812371,
      -1.3254879155482309,
      -1.3086222834197587,
      -1.327223489812827,
      -1.2984485695361527,
      -1.3806569443241403
    ],
    [
      -1.5014309052623707,
      -1.2780171615396345,
      -1.3265853894690065,
      -1.3184737937464677,
      -1.3664119247625246,
      -1.35522080701201,
      -1.3818466175089381,
      -1.3450669078407762,
      -1.3162630505060238,
      -1.4065470741943482,
      -1.3144539848110528,
      -1.4522753797658228,
      -1.289001730967477,
      -1.329659222591583,
      0.0,
      -1.3039941778283308,
      -1.3611617656583237,
      -1.3479995814437724,
      -1.2889642957119418,
      -1.3416044240991187,
      -1.4243013962435904,
      -1.432223868664177,
      -1.4311407842390618,
      -1.2877035785042896,
      -1.4372059952058813,
      -1.3813421397504482,
      -1.3839022747285028,
      -1.4199192540306287,
      -1.401802085212148
    ],
    [
      -1.503400883804272,
      -1.274720074725178,
      -1.3149395567166504,
      -1.270257331520431,
      -1.3687132777241615,
      -1.4200717085851833,
      -1.3989924855427087,
      -1.2996841612080956,
      -1.3857350919020206,
      -1.357745068284482,
      -1.2824091358167595,
      -1.4812330679490449,
      -1.2954565408623337,
      -1.365615385869806,
      -1.3230130896672307,
      0.0,
      -1.3294205700517603,
      -1.3397279193821647,
      -1.3316531019309852,
      -1.2842304927574608,
      -1.4272284710810814,
      -1.425233633051748,
      -1.44224216218505,
      -1.3594984463407187,
      -1.4040949467849275,
      -1.3749653322800712,
      -1.4351533924628226,
      -1.397565253775218,
      -1.4295978435214358
    ],
    [
      -1.6788877295510278,
      -1.5676297668479393,
      -1.560875390637209,
      -1.571324966197772,
      -1.580701800851008,
      -1.6362167128697784,
      -1.629263830664651,
      -1.580199638403174,
      -1.635521018887506,
      -1.606426421387598,
      -1.5619130008776059,
      -1.7111407227331124,
      -1.5740768022269953,
      -1.6063150598267375,
      -1.6250903104354815,
      -1.5731483979465823,
      0.0,
      -1.5696285910403245,
      -1.5659828089966001,
      -1.5752548258871142,
      -1.6165536344135152,
      -1.653868296990152,
      -1.6268332474094067,
      -1.5832112803955491,
      -1.6183119904512429,
      -1.562265334288464,
      -1.6488441176641173,
      -1.6327437431231533,
      -1.6525399757164911
    ],
    [
      -1.6319936540571915,
      -1.448023451454227,
      -1.4316651347580205,
      -1.4162002729820686,
      -1.4662240965494446,
      -1.5763239217606697,
      -1.5694498190929491,
      -1.4099125552375729,
      -1.5086993299276623,
      -1.5198549715105094,
      -1.426375452983373,
      -1.6813898799821052,
      -1.454255808237408,
      -1.500786426918194,
      -1.5301945542469593,
      -1.4926673078030601,
      -1.5445359531406513,
      0.0,
      -1.4949427600298844,
      -1.4492721009751528,
      -1.5396382838253995,
      -1.6033436418840785,
      -1.6066530930440874,
      -1.5256566627281742,
      -1.5826179119287374,
      -1.5412615695007865,
      -1.5588309293170894,
      -1.5458374046001948,
      -1.622934063504759
    ],
    [
      -1.4795201057652496,
      -1.3085202499841668,
      -1.3449825010531749,
      -1.355415612828851,
      -1.3821868897418121,
      -1.422400137212421,
      -1.4485677324049995,
      -1.3345096554062352,
      -1.3758788867969285,
      -1.3830469192820818,
      -1.2970050727108033,
      -1.5476487213672292,
      -1.332615262113268,
      -1.375914665172695,
      -1.350600756401108,
      -1.3392988626906461,
      -1.3097024140416005,
      -1.3507426700012015,
      0.0,
      -1.3521488241656865,
      -1.421168311925223,
      -1.432879234891208,
      -1.423837636695699,
      -1.299348229296813,
      -1.3856231406670045,
      -1.370033932307191,
      -1.4254515712704907,
      -1.3921848298061914,
      -1.4943218335370552
    ],
    [
      -1.5026956744795843,
      -1.2563691707030682,
      -1.3723701068073197,
      -1.2872593537042274,
      -1.3670882537797124,
      -1.3848768920447467,
      -1.402036461471415,
      -1.3288394347017152,
      -1.3530531906436805,
      -1.3630793731286968,
      -1.288712221916291,
      -1.4715544037063304,
      -1.2666802174074918,
      -1.3670731687134712,
      -1.316380628747777,
      -1.2438368569248257,
      -1.3392682463817216,
      -1.3228921670664775,
      -1.33673913476124,
      0.0,
      -1.4032932623584882,
      -1.4605770185918907,
      -1.4488043709010539,
      -1.3203146816954034,
      -1.4253603919682163,
      -1.365783488877638,
      -1.3923861227407208,
      -1.3920973958218474,
      -1.4365335452932961
    ],
    [
      -1.529929994326972,
      -1.4279235791197948,
      -1.40072167443799,
      -1.4106849765919725,
      -1.436902319296011,
      -1.5356995856153242,
      -1.5026847146001177,
      -1.3489669712086092,
      -1.45786192140437,
      -1.4547806578674622,
      -1.4155082745620655,
      -1.5758120111135991,
      -1.4752982431794601,
      -1.4323175445897094,
      -1.489348729170056,
      -1.439806586192197,
      -1.4352393222225717,
      -1.4075050675499203,
      -1.426239702981098,
      -1.4193867037101668,
      0.0,
      -1.5124947839981846,
      -1.4856551003184488,
      -1.4497051058392931,
      -1.464669793595389,
      -1.3846636902986613,
      -1.5205248153575006,
      -1.454582802736354,
      -1.5258103173855688
    ],
    [
      -1.2733179564836892,
      -1.1886496015409527,
      -1.194876480899941,
      -1.1852716075115144,
      -1.188886209332593,
      -1.2514728336938403,
      -1.1711648084543975,
      -1.162486110662115,
      -1.2004891944399392,
      -1.1609234698615398,
      -1.2039460369195711,
      -1.2231208639340947,
      -1.1825434315291263,
      -1.1833820123581016,
      -1.1809542040621528,
      -1.1850235470022294,
      -1.1585630965359999,
      -1.1874203008320072,
      -1.1895062234957046,
      -1.1571977376344493,
      -1.1690137959556168,
      0.0,
      -1.1646281224746489,
      -1.1872626371591894,
      -1.181241014251634,
      -1.1998854663853118,
      -1.1784190411905562,
      -1.1899412349318832,
      -1.1630765423513627
    ],
    [
      -1.4769950910836394,
      -1.353334149562677,
      -1.3234746060957816,
      -1.3150519604305215,
      -1.31085902569181,
      -1.4237762757280927,
      -1.3834071122587965,
      -1.2959658131020608,
      -1.3760280394448832,
      -1.3062564026223442,
      -1.3212845113821514,
      -1.438475021828797,
      -1.3459366963472061,
      -1.3690423729772245,
      -1.387088871875771,
      -1.3841472127753842,
      -1.3112320585833954,
      -1.3161023820659887,
      -1.382038459127285,
      -1.3671952759992718,
      -1.3641961716221191,
      -1.3741756327357317,
      0.0,
      -1.3881394068384625,
      -1.316060145382484,
      -1.3483122021939242,
      -1.3531778747675405,
      -1.3581239117501092,
      -1.4059696296302866
    ],
    [
      -1.5894949966119758,
      -1.47279319175896,
      -1.468904953523658,
      -1.4764481921187285,
      -1.5030436494775035,
      -1.5813810383009588,
      -1.52581066068935,
      -1.4548651790249092,
      -1.5635023557088739,
      -1.4790719848352196,
      -1.4521549005027494,
      -1.6679277687206222,
      -1.4507300844026318,
      -1.4845827407881471,
      -1.4937914298705475,
      -1.4542973288038221,
      -1.5238590201415456,
      -1.5018734863667902,
      -1.476186106063226,
      -1.4649286978893528,
      -1.5461351653323807,
      -1.5707122457222487,
      -1.5664189304795761,
      0.0,
      -1.5384462106621744,
      -1.5689080936977435,
      -1.5630829483261683,
      -1.5344467683524532,
      -1.5800511129758084
    ],
    [
      -1.5699156126618408,
      -1.4912272640453546,
      -1.4766707067189622,
      -1.5013161249955334,
      -1.488363844760461,
      -1.5448702803717511,
      -1.5094378391939378,
      -1.5000482373805313,
      -1.508169337809289,
      -1.482191807721219,
      -1.4661696853688393,
      -1.6018540365651348,
      -1.4619163797060217,
      -1.500844064440072,
      -1.5695365175151301,
      -1.4882036390770106,
      -1.490772648061661,
      -1.434912756771438,
      -1.5230957142074266,
      -1.507100791701763,
      -1.4957417005701696,
      -1.555114642894391,
      -1.5078071655891925,
      -1.5087411150588816,
      0.0,
      -1.4985221047765798,
      -1.5046586460047395,
      -1.497602004933458,
      -1.5707444223778513
    ],
    [
      -1.4195454531087583,
      -1.2170348557445554,
      -1.2834211592182696,
      -1.2227320509807353,
      -1.284191729176097,
      -1.3444370877884018,
      -1.3160594115185735,
      -1.2147744073476112,
      -1.3078896848971775,
      -1.2837162832299944,
      -1.209302515035068,
      -1.4490926180437447,
      -1.2609259576181218,
      -1.248166183318133,
      -1.318340016275881,
      -1.2247100213744697,
      -1.2164053458536943,
      -1.2291304148567894,
      -1.2233725948798684,
      -1.2078839664057068,
      -1.2905405114330941,
      -1.337023890693586,
      -1.3283183078176302,
      -1.2849456136959863,
      -1.322897559960836,
      0.0,
      -1.312501323784688,
      -1.3321229509507344,
      -1.3770986212084277
    ],
    [
      -1.5464328026466891,
      -1.4478716128804812,
      -1.4244655691411467,
      -1.4527968307778412,
      -1.4486414718799356,
      -1.4067183868501512,
      -1.4689950485059082,
      -1.4100040104533373,
      -1.3823893688941011,
      -1.460928452551451,
      -1.4124518826970784,
      -1.4796128266388717,
      -1.446657872526463,
      -1.4700302552411626,
      -1.450513061653841,
      -1.4684249105107137,
      -1.3958685441750864,
      -1.411755457052089,
      -1.452524711019823,
      -1.4384466471164,
      -1.430446737131479,
      -1.4976054723944991,
      -1.4480274888651834,
      -1.4295332012009512,
      -1.3935886543125489,
      -1.4214685456699805,
      0.0,
      -1.4428777142460842,
      -1.4266962079142922
    ],
    [
      -1.4400508505893708,
      -1.2795229590064172,
      -1.2969030382739202,
      -1.242426943614131,
      -1.341873230110875,
      -1.3951601548859258,
      -1.3175356132469516,
      -1.294106836662182,
      -1.3194577047972849,
      -1.3170093221428631,
      -1.2580621972374857,
      -1.4005834592479585,
      -1.322437960759909,
      -1.3173719199665852,
      -1.3666331254179735,
      -1.2760319685203922,
      -1.330027576935394,
      -1.2837252732191202,
      -1.3065917208796305,
      -1.2742000703234284,
      -1.277217074519665,
      -1.3207714553310348,
      -1.3087205290574457,
      -1.3097560307593898,
      -1.3545521227999435,
      -1.314924985903309,
      -1.3388541977155868,
      0.0,
      -1.3673370718888151
    ],
    [
      -1.5780271027191874,
      -1.464556038828275,
      -1.4882669028859588,
      -1.4760165864971313,
      -1.518588805810731,
      -1.4542347741884138,
      -1.4651508425580653,
      -1.4763424719538445,
      -1.4642417582918343,
      -1.4766852312520407,
      -1.4943846137134857,
      -1.5080914881921497,
      -1.4669416825581547,
      -1.4680725643302543,
      -1.4553248874024765,
      -1.4557785892716355,
      -1.4566683047082436,
      -1.4909895928366206,
      -1.499649236432506,
      -1.4947620193738091,
      -1.5405609387222268,
      -1.5109613692542596,
      -1.5345415308000552,
      -1.4610526600445792,
      -1.5511462458991203,
      -1.4992695222874335,
      -1.471392897595084,
      -1.521046352282369,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.11325604972383818,
      0.11923374632266937,
      0.12607787667811632,
      0.12606853860816258,
      0.13501725587074898,
      0.11841931302633846,
      0.12807262448040824,
      0.12495087782835013,
      0.11154557746393001,
      0.13142297040359407,
      0.10511808044986815,
      0.10814296253455868,
      0.10303795997279641,
      0.13603954041932909,
      0.10193931217120422,
      0.12079556596640062,
      0.12907665102337118,
      0.10593114979466822,
      0.1206103894505488,
      0.11335581022085339,
      0.1234095836252993,
      0.11758623472516838,
      0.12281829214036621,
      0.10871180599932107,
      0.09996651825566971,
      0.11920956012008022,
      0.10973427219342335,
      0.10828125106797204
    ],
    [
      0.31380606944116507,
      0.0,
      0.45451926773718854,
      0.48216949634132944,
      0.4340010386509796,
      0.38292356806369354,
      0.3963776380848725,
      0.4736306177555005,
      0.4263017471454775,
      0.3723902476075851,
      0.5098416786103115,
      0.2612509571247559,
      0.5465201725057744,
      0.4384140382268029,
      0.47977204626203207,
      0.5331462755799059,
      0.43518201271452583,
      0.44328651533747876,
      0.466769033614977,
      0.5014705729965101,
      0.3700837629495226,
      0.3754248164038141,
      0.3393531117374249,
      0.4638358434765837,
      0.3389680413805254,
      0.38718486662591256,
      0.36723674454700794,
      0.3678577545113666,
      0.32342365491350744
    ],
    [
      0.2751410272124568,
      0.4951600986799263,
      0.0,
      0.5403390396129271,
      0.4704541669648763,
      0.4054264159531862,
      0.34304159138896373,
      0.5338616301568853,
      0.40101674027300005,
      0.42538060315958126,
      0.5260584340128593,
      0.21675654899505026,
      0.4851647389587994,
      0.48762503459287565,
      0.42393250330444854,
      0.48954135458067816,
      0.40103751409705257,
      0.5147249456800231,
      0.3903774321733582,
      0.4293357191599032,
      0.3876025428321843,
      0.29095911425939436,
      0.35018261358084524,
      0.438560436677224,
      0.33250417623197515,
      0.3823894775341352,
      0.3278134598178424,
      0.35796892508436473,
      0.26883721426491736
    ],
    [
      0.2938910020925023,
      0.5247372966595589,
      0.5171398844460948,
      0.0,
      0.4055343646712197,
      0.4471611482391942,
      0.3604622170069136,
      0.5375260329619143,
      0.4610374596227951,
      0.4379296796351786,
      0.520743613993065,
      0.2942001028923711,
      0.48553996636671726,
      0.4637395221984255,
      0.4508396401578878,
      0.5581211714457319,
      0.4321330023848011,
      0.5290862699792647,
      0.4202691854571523,
      0.5376670183279473,
      0.428333853867755,
      0.3485687969457798,
      0.3438468709411071,
      0.44792957921802,
      0.3282390693918942,
      0.4474240888950938,
      0.3530440775543886,
      0.39868713367547315,
      0.32009846091985206
    ],
    [
      0.3649014270908224,
      0.4907778793875017,
      0.5040835119206903,
      0.4860393784472872,
      0.0,
      0.35346799159761044,
      0.3968434096867759,
      0.5246243747284536,
      0.4129403619322092,
      0.44155309322088754,
      0.5275110600400243,
      0.29438071851427683,
      0.5470983808069454,
      0.4804804859155085,
      0.4564822651486742,
      0.4567233284634036,
      0.4783550266992691,
      0.5696423691813968,
      0.4524287705071943,
      0.49303248642450304,
      0.409290124856158,
      0.3747320081419394,
      0.3876515607530222,
      0.418922406716292,
      0.41645394292744564,
      0.48320706299841687,
      0.41836434104939224,
      0.39061240014080667,
      0.3471855658809253
    ],
    [
      0.18658866360141846,
      0.3485965211579287,
      0.3519901441087647,
      0.35525376043804635,
      0.2559445810445662,
      0.0,
      0.2816965017185613,
      0.32952384329182793,
      0.3299626745843265,
      0.2819863882508078,
      0.36704516722253633,
      0.19425769049427544,
      0.31066801836214997,
      0.31263414790604016,
      0.34278149039952677,
      0.3512598195360839,
      0.2753155630829953,
      0.32103648540048235,
      0.3035541635764074,
      0.3206749232025228,
      0.2946856387279704,
      0.24747469345880302,
      0.2701784257794406,
      0.2988932359944021,
      0.23997018777896395,
      0.26738270593393243,
      0.32455872337476754,
      0.2670314863832224,
      0.25991637231637
    ],
    [
      0.34963423270375227,
      0.5151797550257045,
      0.4736686356672226,
      0.4915606882289367,
      0.47820493505620365,
      0.37666812836878916,
      0.0,
      0.5277925403342343,
      0.45035212299034355,
      0.444419340519119,
      0.47405216379755477,
      0.3033664177100217,
      0.4734600899720336,
      0.46212290071239837,
      0.46229003340541786,
      0.5187746357790695,
      0.45732684789489486,
      0.49782903484461927,
      0.4766984825168923,
      0.4649182257761404,
      0.4580186415652703,
      0.4148517288765776,
      0.42727117465049536,
      0.48082378835557726,
      0.4023402174639854,
      0.4403751869632502,
      0.4258972211311516,
      0.4457724383248567,
      0.37122486600481497
    ],
    [
      0.2985185573029654,
      0.4958703289788218,
      0.5688166004301953,
      0.5433873549689114,
      0.4484035338685868,
      0.3657354204034142,
      0.35120300080332445,
      0.0,
      0.39492247165538896,
      0.3997231218494832,
      0.5266990400050904,
      0.20235740449618467,
      0.48799389809590243,
      0.4592287809190787,
      0.4053172870867414,
      0.4980891552171507,
      0.40582925732225217,
      0.5243644048052947,
      0.41648517321356504,
      0.4194445142742813,
      0.44494096042313735,
      0.287195068785306,
      0.3042782552971701,
      0.44166285612220557,
      0.3500859937891252,
      0.4384009907097264,
      0.3186741475790684,
      0.3583044114765299,
      0.2609633654836614
    ],
    [
      0.2839371750774191,
      0.46850429151983053,
      0.42821654433878154,
      0.4409966957650169,
      0.45458255652356416,
      0.4192139486837543,
      0.4093750123391895,
      0.4771324124851639,
      0.0,
      0.3859249840738992,
      0.5274237960894188,
      0.3603456156657212,
      0.41435085468616917,
      0.41567917704461044,
      0.4295383241184225,
      0.41738457892523884,
      0.3907451858241393,
      0.4983240121908412,
      0.432845424052525,
      0.4310422322919676,
      0.41834026599935026,
      0.3412976253415685,
      0.40230690895385246,
      0.3949233691701366,
      0.37226304022513057,
      0.42546759186572025,
      0.4045168029638173,
      0.41517446303834493,
      0.3810927452070101
    ],
    [
      0.30481812362211946,
      0.4195499433858396,
      0.467750070491326,
      0.4803239018119403,
      0.3780044188512206,
      0.3511717056361825,
      0.3777859327144153,
      0.4499316593800262,
      0.3488825332587706,
      0.0,
      0.42723686488378876,
      0.27755864626881555,
      0.4479566818846754,
      0.41671664874725467,
      0.3500219200627517,
      0.4009478372859141,
      0.43376121285040914,
      0.47048693483453063,
      0.394595689020375,
      0.41779992124844156,
      0.39214239247789595,
      0.3538643601763114,
      0.434538990373073,
      0.410381016135581,
      0.4368334756139427,
      0.42005845393014507,
      0.3639874782467154,
      0.397019606491946,
      0.33357846815560777
    ],
    [
      0.3488587957855429,
      0.44808309756384745,
      0.4719241178818565,
      0.4755070622512696,
      0.45579469339235246,
      0.3771070181665781,
      0.3623564395372132,
      0.4548229456283197,
      0.4455001953579629,
      0.3821575006314408,
      0.0,
      0.28320833000546375,
      0.3701035797338428,
      0.42075525152735893,
      0.40141488682185833,
      0.4653135684345391,
      0.3894128053077257,
      0.4824914184297995,
      0.4217203923743471,
      0.434023870080807,
      0.3819638083478121,
      0.3452735768358719,
      0.3406996426648148,
      0.39593511082305444,
      0.3162199787759503,
      0.3798020911944564,
      0.3818735527859507,
      0.3516444498239133,
      0.316125676955493
    ],
    [
      0.23574599418494846,
      0.29135482876535157,
      0.3161540718051632,
      0.3259315526176034,
      0.34504308473136946,
      0.30824669122648696,
      0.3067595946686452,
      0.2985905668738196,
      0.3397231936407332,
      0.2942627552342907,
      0.32880660185564636,
      0.0,
      0.295679618954803,
      0.28477731534518,
      0.34242095494498836,
      0.28671056368174175,
      0.3389306053234262,
      0.3420229013260949,
      0.2792801215042402,
      0.3150585456614934,
      0.31855414487134914,
      0.3751180265363805,
      0.3010423065169734,
      0.2921379392501726,
      0.30258260577982155,
      0.2962293219582115,
      0.32588416672007403,
      0.3051497967000907,
      0.3821686015528929
    ],
    [
      0.25761547676345176,
      0.47159179404257534,
      0.41840067110665746,
      0.45577181394894883,
      0.3736393402297373,
      0.27844786737865057,
      0.3295830715541561,
      0.43155005161098847,
      0.333397559907048,
      0.3338756954471993,
      0.4148158726619324,
      0.24831698218674636,
      0.0,
      0.3985024721173236,
      0.3500440327069019,
      0.44335716489583343,
      0.36428841965098147,
      0.4422914166477454,
      0.3567381173626072,
      0.45474707302770834,
      0.33511075064426876,
      0.3109737065153191,
      0.30943022282601174,
      0.3664471926748114,
      0.36749387308756587,
      0.37091553336719096,
      0.36526777338251715,
      0.336630899856617,
      0.23812325410572388
    ],
    [
      0.3102389566264194,
      0.5422957246886628,
      0.5902415488733059,
      0.5425701670849852,
      0.4561563377225242,
      0.4045402419898203,
      0.43693588046269705,
      0.48752752076068884,
      0.46346759016551853,
      0.4289899977739877,
      0.5596075295077207,
      0.3304740245679163,
      0.5607313980172774,
      0.0,
      0.5199819695356946,
      0.5428786375677466,
      0.45313771668269354,
      0.5709573002049944,
      0.4845544536171005,
      0.5797752524310003,
      0.42769135184958595,
      0.4004681566321451,
      0.40975441466584894,
      0.520837176716676,
      0.4132293499808162,
      0.4300949821092883,
      0.41149377571622003,
      0.4402686959928943,
      0.3580603212049067
    ],
    [
      0.28210109206334355,
      0.5055148357860797,
      0.4569466078567077,
      0.46505820357924654,
      0.4171200725631896,
      0.42831119031370424,
      0.4016853798167761,
      0.438465089484938,
      0.46726894681969044,
      0.376984923131366,
      0.4690780125146614,
      0.33125661755989144,
      0.49453026635823716,
      0.4538727747341311,
      0.0,
      0.4795378194973834,
      0.4223702316673905,
      0.4355324158819418,
      0.4945677016137724,
      0.4419275732265955,
      0.3592306010821238,
      0.35130812866153716,
      0.35239121308665244,
      0.4958284188214246,
      0.3463260021198329,
      0.40218985757526604,
      0.3996297225972114,
      0.3636127432950855,
      0.3817299121135662
    ],
    [
      0.2817282061238091,
      0.5104090152029033,
      0.47018953321143075,
      0.5148717584076501,
      0.41641581220391966,
      0.3650573813428979,
      0.38613660438537245,
      0.48544492871998557,
      0.39939399802606057,
      0.4273840216435991,
      0.5027199541113216,
      0.3038960219790363,
      0.4896725490657474,
      0.41951370405827526,
      0.4621160002608504,
      0.0,
      0.4557085198763209,
      0.44540117054591644,
      0.453475987997096,
      0.5008985971706204,
      0.35790061884699975,
      0.35989545687633306,
      0.3428869277430311,
      0.42563064358736247,
      0.38103414314315365,
      0.41016375764800994,
      0.3499756974652586,
      0.3875638361528633,
      0.35553124640664535
    ],
    [
      0.2750145511524291,
      0.38627251385551764,
      0.3930268900662479,
      0.382577314505685,
      0.37320047985244886,
      0.3176855678336785,
      0.324638450038806,
      0.37370264230028294,
      0.31838126181595094,
      0.3474758593158589,
      0.3919892798258511,
      0.2427615579703446,
      0.37982547847646164,
      0.34758722087671945,
      0.3288119702679755,
      0.3807538827568746,
      0.0,
      0.38427368966313247,
      0.3879194717068568,
      0.37864745481634277,
      0.33734864628994177,
      0.30003398371330503,
      0.32706903329405024,
      0.3706910003079078,
      0.3355902902522141,
      0.3916369464149929,
      0.30505816303933964,
      0.32115853758030366,
      0.3013623049869658
    ],
    [
      0.3058216055560177,
      0.48979180815898227,
      0.5061501248551887,
      0.5216149866311406,
      0.4715911630637646,
      0.3614913378525395,
      0.3683654405202601,
      0.5279027043756364,
      0.4291159296855469,
      0.4179602881026998,
      0.5114398066298362,
      0.256425379631104,
      0.48355945137580125,
      0.43702883269501513,
      0.40762070536624995,
      0.4451479518101491,
      0.39327930647255793,
      0.0,
      0.44287249958332486,
      0.4885431586380564,
      0.39817697578780975,
      0.3344716177291307,
      0.3311621665691218,
      0.412158596885035,
      0.35519734768447186,
      0.3965536901124227,
      0.3789843302961198,
      0.3919778550130144,
      0.3148811961084501
    ],
    [
      0.31294493097913256,
      0.48394478676021535,
      0.44748253569120733,
      0.43704942391553114,
      0.41027814700257004,
      0.3700648995319611,
      0.3438973043393827,
      0.45795538133814695,
      0.4165861499474537,
      0.4094181174623004,
      0.49545996403357884,
      0.24481631537715298,
      0.4598497746311141,
      0.4165503715716872,
      0.4418642803432742,
      0.45316617405373605,
      0.4827626227027817,
      0.44172236674318066,
      0.0,
      0.4403162125786957,
      0.3712967248191592,
      0.3595858018531741,
      0.3686274000486831,
      0.49311680744756914,
      0.40684189607737764,
      0.4224311044371911,
      0.36701346547389146,
      0.4002802069381908,
      0.298143203207327
    ],
    [
      0.25791152973883436,
      0.5042380335153505,
      0.3882370974110989,
      0.47334785051419126,
      0.3935189504387062,
      0.3757303121736719,
      0.35857074274700373,
      0.4317677695167035,
      0.4075540135747382,
      0.3975278310897219,
      0.4718949823021277,
      0.28905280051208826,
      0.49392698681092684,
      0.3935340355049475,
      0.4442265754706416,
      0.516770347293593,
      0.42133895783669706,
      0.43771503715194116,
      0.4238680694571786,
      0.0,
      0.3573139418599305,
      0.30003018562652795,
      0.3118028333173648,
      0.4402925225230152,
      0.33524681225020236,
      0.39482371534078076,
      0.36822108147769783,
      0.3685098083965712,
      0.3240736589251225
    ],
    [
      0.2718229674989239,
      0.373829382706101,
      0.40103128738790583,
      0.3910679852339234,
      0.36485064252988475,
      0.2660533762105717,
      0.2990682472257782,
      0.45278599061728664,
      0.34389104042152585,
      0.3469723039584336,
      0.3862446872638303,
      0.2259409507122967,
      0.3264547186464357,
      0.36943541723618645,
      0.31240423265583983,
      0.3619463756336989,
      0.36651363960332417,
      0.3942478942759755,
      0.3755132588447978,
      0.382366258115729,
      0.0,
      0.28925817782771124,
      0.316097861507447,
      0.3520478559866027,
      0.3370831682305069,
      0.4170892715272345,
      0.2812281464683952,
      0.34717015908954174,
      0.275942644440327
    ],
    [
      0.2821396189316909,
      0.36680797387442743,
      0.36058109451543907,
      0.3701859679038657,
      0.3665713660827872,
      0.3039847417215398,
      0.3842927669609826,
      0.39297146475326517,
      0.3549683809754409,
      0.3945341055538403,
      0.35151153849580896,
      0.3323367114812854,
      0.37291414388625377,
      0.3720755630572785,
      0.3745033713532273,
      0.37043402841315065,
      0.39689447887938023,
      0.3680372745833729,
      0.36595135191967554,
      0.39825983778093077,
      0.38644377945976327,
      0.0,
      0.39082945294073124,
      0.36819493825619065,
      0.374216561163746,
      0.3555721090300683,
      0.3770385342248239,
      0.3655163404834969,
      0.3923810330640174
    ],
    [
      0.3306189152710155,
      0.4542798567919779,
      0.48413940025887325,
      0.49256204592413333,
      0.49675498066284485,
      0.3838377306265621,
      0.4242068940958583,
      0.511648193252594,
      0.4315859669097717,
      0.5013576037323106,
      0.48632949497250344,
      0.3691389845258579,
      0.4616773100074487,
      0.4385716333774303,
      0.42052513447888384,
      0.42346679357927064,
      0.49638194777125944,
      0.4915116242886661,
      0.4255755472273699,
      0.44041873035538304,
      0.4434178347325357,
      0.4334383736189231,
      0.0,
      0.41947459951619237,
      0.4915538609721708,
      0.45930180416073063,
      0.4544361315871144,
      0.4494900946045457,
      0.40164437672436826
    ],
    [
      0.3237365049891916,
      0.44043830984220733,
      0.4443265480775094,
      0.43678330948243893,
      0.41018785212366393,
      0.3318504633002086,
      0.3874208409118174,
      0.4583663225762582,
      0.34972914589229354,
      0.4341595167659478,
      0.46107660109841797,
      0.2453037328805452,
      0.46250141719853555,
      0.4286487608130203,
      0.4194400717306199,
      0.4589341727973453,
      0.3893724814596218,
      0.4113580152343772,
      0.4370453955379414,
      0.44830280371181463,
      0.3670963362687867,
      0.34251925587891874,
      0.34681257112159125,
      0.0,
      0.37478529093899304,
      0.34432340790342386,
      0.35014855327499905,
      0.3787847332487142,
      0.33318038862535904
    ],
    [
      0.24785252669717006,
      0.3265408753136563,
      0.34109743264004866,
      0.3164520143634775,
      0.3294042945985498,
      0.2728978589872597,
      0.308330300165073,
      0.31771990197847955,
      0.30959880154972175,
      0.33557633163779177,
      0.35159845399017153,
      0.21591410279387602,
      0.3558517596529891,
      0.3169240749189388,
      0.2482316218438807,
      0.32956450028200024,
      0.32699549129734984,
      0.3828553825875729,
      0.2946724251515842,
      0.3106673476572479,
      0.3220264387888412,
      0.2626534964646199,
      0.30996097376981835,
      0.3090270243001292,
      0.0,
      0.31924603458243106,
      0.3131094933542713,
      0.32016613442555286,
      0.24702371698115955
    ],
    [
      0.29924334660002794,
      0.5017539439642309,
      0.4353676404905167,
      0.49605674872805094,
      0.43459707053268937,
      0.3743517119203845,
      0.40272938819021276,
      0.5040143923611751,
      0.4108991148116088,
      0.43507251647879186,
      0.5094862846737183,
      0.2696961816650416,
      0.4578628420906645,
      0.4706226163906533,
      0.40044878343290535,
      0.49407877833431657,
      0.502383453855092,
      0.48965838485199686,
      0.4954162048289179,
      0.5109048333030795,
      0.42824828827569217,
      0.3817649090152002,
      0.3904704918911561,
      0.43384318601280003,
      0.3958912397479504,
      0.0,
      0.4062874759240982,
      0.3866658487580519,
      0.34169017850035854
    ],
    [
      0.22497382003907762,
      0.3235350098052856,
      0.34694105354462,
      0.3186097919079256,
      0.3227651508058311,
      0.3646882358356156,
      0.30241157417985853,
      0.3614026122324294,
      0.38901725379166563,
      0.3104781701343158,
      0.3589547399886883,
      0.29179379604689504,
      0.3247487501593038,
      0.30137636744460417,
      0.3208935610319257,
      0.3029817121750531,
      0.37553807851068033,
      0.3596511656336778,
      0.3188819116659438,
      0.33295997556936685,
      0.3409598855542877,
      0.2738011502912676,
      0.32337913382058336,
      0.3418734214848156,
      0.3778179683732179,
      0.3499380770157863,
      0.0,
      0.3285289084396825,
      0.34471041477147457
    ],
    [
      0.2695919492849388,
      0.43011984086789234,
      0.4127397616003894,
      0.4672158562601785,
      0.36776956976343467,
      0.31448264498838374,
      0.392107186627358,
      0.4155359632121276,
      0.3901850950770247,
      0.3926334777314464,
      0.45158060263682387,
      0.3090593406263511,
      0.3872048391144005,
      0.39227087990772436,
      0.343009674456336,
      0.4336108313539173,
      0.3796152229389156,
      0.42591752665518934,
      0.40305107899467907,
      0.43544272955088115,
      0.43242572535464463,
      0.38887134454327477,
      0.4009222708168638,
      0.3998867691149197,
      0.35509067707436603,
      0.3947178139710006,
      0.3707886021587228,
      0.0,
      0.3423057279854944
    ],
    [
      0.31731990800617016,
      0.4307909718970826,
      0.40708010783939885,
      0.4193304242282263,
      0.3767582049146265,
      0.44111223653694376,
      0.43019616816729234,
      0.4190045387715131,
      0.43110525243352327,
      0.41866177947331695,
      0.40096239701187186,
      0.38725552253320794,
      0.4284053281672029,
      0.42727444639510326,
      0.44002212332288115,
      0.4395684214537221,
      0.438678706017114,
      0.404357417888737,
      0.3956977742928516,
      0.40058499135154846,
      0.35478607200313084,
      0.384385641471098,
      0.36080547992530243,
      0.4342943506807784,
      0.3442007648262373,
      0.3960774884379241,
      0.42395411313027354,
      0.37430065844298865,
      0.0
    ]
  ],
  "row_avgs": [
    0.11742249180489484,
    0.4173264853695189,
    0.40682833925856193,
    0.4319260896410035,
    0.4420637761849226,
    0.2961022148973979,
    0.4487462312371188,
    0.4077462626915201,
    0.41574805837359297,
    0.39848946028000054,
    0.39643192346855155,
    0.3133702311511426,
    0.36276314641811486,
    0.46703430261246914,
    0.41837058406506245,
    0.41646486043580244,
    0.34658908724916027,
    0.413545937756766,
    0.4090523703323453,
    0.395751660099192,
    0.3438699264948649,
    0.3675053046338029,
    0.4470480665723784,
    0.3934511715601629,
    0.30864138609905944,
    0.4306966377010494,
    0.32977184608049576,
    0.3892197500952742,
    0.40453468891500244
  ],
  "col_avgs": [
    0.2895184633727413,
    0.43404374171147486,
    0.4277669975205893,
    0.4374540167778923,
    0.39405769098050974,
    0.35274025324121544,
    0.35660346040585356,
    0.43583123985496613,
    0.38506199571764077,
    0.381654851109969,
    0.44434255687974117,
    0.27450855484523007,
    0.4254427134471847,
    0.3974643012216917,
    0.3898212500139345,
    0.42693389974994467,
    0.4008601383817876,
    0.43599500092398624,
    0.39702700955740716,
    0.4224943302921453,
    0.37274235424131286,
    0.33398674236091186,
    0.34326209083277304,
    0.39965958494270876,
    0.35488470647431797,
    0.3829629982320862,
    0.3590605476950433,
    0.36162794994865904,
    0.3187028507455104
  ],
  "combined_avgs": [
    0.20347047758881806,
    0.4256851135404969,
    0.4172976683895756,
    0.43469005320944787,
    0.41806073358271617,
    0.3244212340693067,
    0.40267484582148616,
    0.4217887512732431,
    0.40040502704561687,
    0.39007215569498477,
    0.42038724017414636,
    0.29393939299818633,
    0.3941029299326498,
    0.43224930191708044,
    0.40409591703949843,
    0.42169938009287355,
    0.3737246128154739,
    0.4247704693403761,
    0.40303968994487627,
    0.40912299519566864,
    0.3583061403680889,
    0.3507460234973574,
    0.3951550787025757,
    0.39655537825143583,
    0.33176304628668873,
    0.4068298179665678,
    0.34441619688776953,
    0.37542385002196665,
    0.3616187698302564
  ],
  "gppm": [
    586.3995317107943,
    577.4324563357243,
    579.7068887214034,
    576.281853104742,
    592.1416062534441,
    602.8020029222174,
    609.4734110378653,
    574.1850900690944,
    596.9689859341664,
    597.6660315704223,
    571.2205038152971,
    644.1091041648266,
    578.2850866144915,
    593.3947470688029,
    594.327156436628,
    579.0705244883263,
    585.7602250655481,
    573.4235543989874,
    591.0335070892072,
    580.8184770371241,
    599.5876772840722,
    619.2750271323812,
    614.2942972036687,
    588.4534827071266,
    606.0160875395146,
    599.0940463613812,
    605.8466737110282,
    606.6056622972811,
    623.0344805178994
  ],
  "gppm_normalized": [
    1.3063181068817722,
    1.390651288616786,
    1.3999133021279437,
    1.3848708794185094,
    1.4201878123972715,
    1.4428338138243741,
    1.4608312891656294,
    1.372615767917653,
    1.4277397788288104,
    1.4294825300601304,
    1.3662121187611285,
    1.5340578295960783,
    1.392435746153654,
    1.4205102599677097,
    1.4218262817758127,
    1.386801382865866,
    1.4015069460678187,
    1.3782860096297755,
    1.413069467065106,
    1.3967387800291464,
    1.4295758868158952,
    1.4722706927066296,
    1.4619519918387032,
    1.4063708276335625,
    1.4474359814074929,
    1.4291662472366915,
    1.4459410771094767,
    1.4495247999225678,
    1.4790220623599315
  ],
  "token_counts": [
    277,
    515,
    611,
    479,
    483,
    468,
    529,
    403,
    449,
    451,
    404,
    473,
    494,
    442,
    447,
    417,
    443,
    473,
    430,
    500,
    413,
    401,
    405,
    424,
    448,
    408,
    436,
    450,
    391,
    303,
    497,
    433,
    459,
    752,
    459,
    495,
    438,
    433,
    410,
    431,
    387,
    410,
    444,
    431,
    438,
    393,
    372,
    470,
    373,
    439,
    420,
    389,
    490,
    384,
    410,
    374,
    372,
    394,
    324,
    414,
    458,
    484,
    436,
    428,
    501,
    399,
    399,
    381,
    466,
    408,
    398,
    376,
    425,
    390,
    398,
    422,
    389,
    407,
    452,
    424,
    401,
    424,
    397,
    379,
    413,
    401,
    344,
    781,
    392,
    394,
    392,
    352,
    525,
    360,
    385,
    392,
    397,
    413,
    380,
    455,
    358,
    381,
    399,
    424,
    396,
    397,
    404,
    410,
    394,
    346,
    390,
    420,
    367,
    398,
    386,
    349
  ],
  "response_lengths": [
    3605,
    2308,
    2293,
    2274,
    2106,
    3141,
    2162,
    2205,
    2275,
    2309,
    2490,
    2222,
    2618,
    2134,
    2232,
    2407,
    2462,
    2378,
    2443,
    2310,
    2332,
    2374,
    2118,
    2235,
    2394,
    2027,
    2262,
    2262,
    2007
  ]
}