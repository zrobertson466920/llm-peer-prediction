{
  "example_idx": 29,
  "reference": "Under review as a conference paper at ICLR 2023\n\nTOWARD LEARNING GEOMETRIC EIGEN-LENGTHS CRUCIAL FOR ROBOTIC FITTING TASKS\n\nAnonymous authors Paper under double-blind review\n\nABSTRACT\n\nSome extremely low-dimensional yet crucial geometric eigen-lengths often determine whether an object can be fitted in the environment or not. For example, the height of an object is important to measure to check if it can fit between the shelves of a cabinet, while the width of a couch is crucial when trying to move it through a doorway. Humans have materialized such crucial geometric eigen-lengths in common sense since they are very useful in serving as succinct yet effective, highly interpretable, and universal object representations. However, it remains obscure and underexplored if learning systems can be equipped with similar capabilities of automatically discovering such key geometric quantities in doing robotic fitting tasks. In this work, we therefore for the first time formulate and propose a novel learning problem on this question and set up a benchmark suite including the tasks, the data, and the evaluation metrics for studying the problem. We explore potential solutions and demonstrate the feasibility of learning such eigen-lengths from simply observing successful and failed fitting trials. We also attempt geometric grounding for more accurate eigen-length measurement and study the reusability of the learned geometric eigen-lengths across multiple tasks. Our work marks the first exploratory step toward learning crucial geometric eigen-lengths and we hope it can inspire future research in tackling this important yet underexplored problem.\n\n1\n\nINTRODUCTION\n\nFigure 1: Example tasks and the hypothesized crucial geometric measurements by humans.\n\nConsider a robot tasked with placing many small objects on warehouse shelves, where both the objects and the shelves have diverse geometric configurations. While the robot can simply try to accomplish the task by trial-and-error, to us as humans, it is clear that certain placements should not be attempted because they will obviously fail. For example, we should not attempt to place a tall object on a shelf whose height is too low. We base this judgement on the estimation of a critical geometric eigen-length or measurement, the height of the object and the shelf, whose comparison allows a quick estimate of task feasibility.\n\nWhile object height is an example of important eigen-lengths of an object that is crucial for the above shelf placement task, it is not hard to think of many other types of object eigen-lengths for other fitting tasks. Figure 1 presents some other example tasks together with the presumable geometric eigen-lengths based on human common sense. For example, the geometric eigen-length diameter is important for the task of stacking plates in different sizes (Figure 1, (a)), while the width and length\n\n1\n\nFit under the table: height and widthPlace into the box: width and lengthPut into and close the drawer: height, width, and lengthStack plates: diameter(a)(b)(c)(d)Under review as a conference paper at ICLR 2023\n\nof an object are crucial geometric eigen-lengths for deciding if one can put an arbitrary shape object into an open box (Figure 1, (c)).\n\nHaving such extremely low-dimensional yet crucial geometric eigen-lengths extracted as the representations for objects is certainly beneficial for designing learning systems for robotic fitting tasks. One telling evidence is that we humans have naturally built up the vocabulary of geometric key quantities, such as height, width, and diameter, when perceiving and modeling everyday objects, and used them to perform various object fitting tasks. Besides being succinct yet effective abstractions of objects for quickly estimating the feasibility for the downstream fitting tasks, such crucial geometric eigen-lengths are also highly interpretable, which exposes the principled reasoning process behind the feasibility checking, and universal, as they are generally applicable to objects with arbitrary shape and useful across different downstream tasks.\n\nCurrent research in representation learning for computer vision and robotics has mostly been focusing on learning high-dimensional latent codes or injecting human knowledge as inductive bias for learning structured representations. While learning high-dimensional latent codes provides total flexibility learning any useful feature for mastering the downstream tasks, these latent codes are highdimensional, hard to interpret, and may be prone to overfitting to the training domain. For structured representations, though researchers have explored using different kinds of object representations, such as bounding boxes (Tulsiani et al., 2017) and key points (Manuelli et al., 2019), to accomplish various downstream tasks in computer vision and robotics, these structure priors are manually specified based on human knowledge about the tasks. In contrast, we aim to explore the automatic discovery of low-dimensional yet crucial geometric quantities for robotic fitting tasks while injecting the minimal human prior knowledge – only assuming that we are measuring eigen-lengths of the input objects.\n\nIn this paper, we first propose to study a novel learning problem on discovering low-dimensional geometric eigen-lengths crucial for fitting tasks and set up the benchmark suite for studying the problem. As illustrated in Figure 2, given a fitting task (putting the bowl inside the drawer of the table) that involves a scene geometry (the table) and an object shape (the bowl), we are interested in predicting whether the object can fit in the scene accomplishing the task or not, via discovering a few crucial geometric eigen-lengths and composing them into a task program which outputs the final task feasibility estimation. To study the problem, we also define a set of commonly seen robotic fitting tasks, generate large-scale data for the training and evaluating on each task, and set up a set of quantitative metrics for evaluating and analyzing the method performance and if the emergent geometric eigen-lengths match the desired ones humans usually use.\n\nWe also explore potential solutions to the proposed learning problem and present several of our key findings. First of all, we will show that learning such low-dimensional key geometric eigen-lengths are achievable from only using weak supervision signals such as the success or failure of training fitting trials. Secondly, the learned crucial geometric eigen-lengths can be more accurately measured if geometric grounding is allowed and attainable for certain fitting tasks. Finally, we make an initial stab at exploring how to share and re-use the learned geometric eigen-lengths across different tasks and even for novel tasks. Marking the first step defining and exploring this important yet underexplored problem, we hope our work can draw people’s attention to this task and inspire future research in designing solutions tackling it.\n\nTo summarize, this work makes the following contributions:\n\n• We propose a novel learning problem on discovering low-dimensional geometric eigen-lengths\n\ncrucial for fitting tasks;\n\n• We set up a benchmark suite for studying the problem, including a set of fitting tasks, the dataset for each task, and a range of quantitative and qualitative metrics for thorough performance evaluation and analysis;\n\n• We explore potential solutions to the proposed learning problem and present some key take-away\n\nmessages summarizing both the successes and unresolved challenges.\n\n2 RELATED WORK\n\nLearning Geometry Abstraction. A long line of research has focused on learning low-dimensional and compact abstraction for input geometry. Given as input a 2D or 3D shape, past works have studied learning various geometric abstraction as the shape representation, such as bounding boxes (Tulsiani et al., 2017; Sun et al., 2019), convex shapes (Deng et al., 2020), Gaussian mixtures (Genova et al.,\n\n2\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 2: Proposed Learning Paradigm where we first predict a set of geometric eigen-lengths from the input geometries, then compose them using a task program to get the final task output.\n\n2019; 2020), superquadratics (Paschalidou et al., 2019; 2020), parametric curves (Reddy et al., 2021) and surfaces (Sharma et al., 2020; Smirnov et al., 2020), etc.. Most of these works use geometry fitting as the primary objective. Our work, however, focuses on discovering geometric abstraction that can help solve the downstream manipulation tasks instead of reconstruction.\n\nThere are also previous works exploring ways to learn task-specific geometry representation for manipulation tasks. For example, researchers have tried to learn key points (Manuelli et al., 2019; Qin et al., 2020; Wang et al., 2020; Chen et al., 2020; Jakab et al., 2021; Chen et al., 2021) and affordance information (Kim & Sukhatme, 2014; Mo et al., 2021a;b; Turpin et al., 2021; Deng et al., 2021) for robotic manipulation tasks. These works mostly pre-define the types of geometry abstraction and the downstream policies to use the extracted shape summaries, and the abstraction is mostly dense or high dimensional. In this paper, we aim for useful geometric eigen-lengths and ways to automatically discover and compose them for solving manipulation tasks.\n\nDisentangled Visual Representation Learning. Another line of work focuses on unsupervised representation learning techniques that pursue disentangled and compositional latent representations for visual concepts. For example, InfoGAN (Chen et al., 2016), beta-VAE (Higgins et al., 2017), and many more works (Higgins et al., 2016; Siddharth et al., 2017; Yang et al., 2020) discover disentangled features, each of which controls a certain aspect of visual attributes, usually with reconstruction as the objective. In contrast to their primary objectives of controllable reconstruction or generation, we explore the problem of learning geometric eigen-lengths driven by the goal of accomplishing downstream fitting tasks. Also, our task involves reasoning over two geometric inputs and comparing the extracted eigen-lengths on both inputs, while these previous works on disentangled visual representation learning factor out visual attributes for a single input datum.\n\n3 LEARNING PROBLEM FORMULATION\n\nGiven a robotic fitting task T ∈ T , we aim to learn very few but the crucial geometric eigen-lengths LT (e.g., width, length, height) of the object shape O ∈ O and the environment geometry E ∈ E that are useful for checking the feasibility of fitting O into E under the task T . Figure 2 presents an example of the proposed learning problem where the task is to put the bowl (O) inside the drawer of the cabinet (E). In this example, the width, length, height of the drawer and the bowl are the crucial desired geometric eigen-lengths (LT ) and we can compose them in a task program to output the final task feasibility prediction. We consider each eigen-length L ∈ LT as a function mapping from the input object shape O or the environment geometry E to a scalar value for the eigen-length measurement, i.e. L : O ∪ E → R. After obtaining the eigen-length measurements for both the object and environment inputs, i.e. {L(O)|L ∈ LT } and {L(E)|L ∈ LT }, we perform pairwise comparisons between the corresponding eigen-lengths checking if L(O) < L(E) holds for every L ∈ LT . The task of fitting O in E under the task T is predicted as successful if all the conditions hold and as failed if any condition does not hold. This format of task program is based on the intuition that in fitting tasks, we require the object to be “smaller” than the parts of the environment affording the action. Durining training, the learning systems see many fitting trials over different objects and environment geometric configurations together with their ground-truth fitting feasibility, i.e. {(Oi, Ei, Successful/Failed)|i = 0, 1, 2, · · · }. The goal is to learn eigen-length functions based on which correct prediction of task feasibility given test input (Otest, Etest) can be made.\n\n3\n\nTask Output>Task ProgramInput Geometry...Env HEigen-LengthsEnv W...Obj HObj WAND>Under review as a conference paper at ICLR 2023\n\n4 CAN GEOMETRIC EIGEN-LENGTHS BE LEARNED FROM BINARY TASK\n\nSUPERVISION?\n\nIn this work, we are interested in learning geometric eigen-lengths that are crucial for downstream tasks. We hope to achieve automatic discovery of these eigen-lengths from doing tasks as it requires the least human prior and allows maximum flexibility. Therefore, we start with the minimum form of supervision and explore the following question: given only binary task success/failure supervision, is it possible to learn geometric eigen-lengths of input geometries that are sufficient for the task?\n\n4.1 TESTBED FOR EIGEN-LENGTH LEARNING\n\nFigure 3: Summary of tasks and their human-hypothesized key measurements/eigen-lengths.\n\nWe start by curating a set of tasks as the testbed for the learning problem, as summarized in Fig. 3. For each task, we build a large-scale dataset comprising diverse shapes and configurations. Task Design Principles We design the tasks to (1) cover a wide range of geometries, including synthetic, simple primitive shapes and more complex ones like ShapeNet objects; (2) facilitate the analysis and interpretation of learned eigen-lengths. Specifically, here we base the analysis on comparisons to human-hypothesized eigen-lengths: given a task, humans can identify related key eigen-lengths (referred to as “ground truth” in the following), e.g., object height when putting them on shelves. Comparing the learned eigen-lengths to these “ground truth” may provide important insights. To achieve this, we need accessible ground truth eigen-lengths to begin with. Primitive shapes like cylinders are ideal as they are parameterized by eigen-lengths like radius and height.\n\nTask Specifications exists in a certain environment, specifically:\n\nIn all tasks, we aim to determine whether a placement/motion of the object\n\n(a) Tube passing. (Tube) Pass an object through a rectangular tube. A tube is a cuboid without the front and back faces. Width and height of the tube/object are the key eigen-lengths to compare.\n\n(b) Cylinder fitting. (Cylinder) Place an object into a cylindrical container. Bounding sphere radius of the object in XY plane and its height, as well as the radius and height of the cylinder container are the key eigen-lengths.\n\n(c) Sphere fitting. (Sphere) Place an object into a spherical container. Radius of the bounding\n\nsphere of the object and the container is the key eigen-length.\n\n(d) Container fitting. (Fit) Place an object into cavities in another ShapeNet container object. Example cavities include drawers or shelves (See Fig. 3d) of furniture. Most cavities have cuboid-like shapes. Thus, key eigen-lengths are width, length and height of cavities and objects.\n\n(e) Countertop placing. (Top) Place an object on top of another ShapeNet environment object, such that its projection along the gravity axis is fully enclosed by the environment countertop. Width and length of the countertop surface and the object are key eigen-lengths.\n\n(f) Mug hanging. (Mug) Hang a mug on a mug holder by its handle. The holder is a cylindershaped rod. Key eigen-lengths are the distance between sides of the mug handle and the diameter (or equivalently, the radius) of the mug holder rod.\n\nData Generation Details For objects to be fitted in tasks (a)-(e), we use ∼1200 common household object models from 8 training and 4 testing categories in ShapeNet (Chang et al., 2015), following Mo et al. (2021b). During data generation, we apply random scaling to the object model, then sample N = 1024 points from the object surface. Note that we also apply a random rotation to the object. In (d),(e), we use furniture and appliances from ShapeNet as the environment geometry, including ∼550 shapes from 7 object categories. In (f), we use ∼200 ShapeNet mugs. We randomly sample the parameters of primitive shapes and the scaling factors of ShapeNet shapes, then sample M = 1024 points from their surfaces. For all tasks, we generated 75k training and 20k testing environment-object pairs. Please refer to Appendix A.3 for more data generation details.\n\n4\n\n(d) Container Fitting(e) Countertop Placing(a) Tube Passing(b) Cylinder Fittingwidthheightheightradiuswidthlengthheight(c) Sphere Fittingradius(f) Mug Hangingholder radius widthlengthUnder review as a conference paper at ICLR 2023\n\nFigure 4: Network architectures. (a) A minimal eigen-length learning pipeline where we separately encode environment and object into eigen-length values, perform pair-wise comparison, and take the logical AND of results. (b) A geometry-grounded framework where we first predict vectors and points as the geometry grounding, then compute eigen-lengths from them.\n\nFigure 5: Correlation Analysis. Each plot shows the relationship between one learned eigen-length (Y coord.) and its matching “ground truth” measurement (X coord.). Higher R2 values imply a stronger correlation.\n\n4.2 A MINIMAL NETWORK ARCHITECTURE\n\nIntuitively, we can measure the object and the environment separately and see if the object is “smaller\" than the environment. Thus we come up with the minimal network architecture shown in Fig. 4 (a). We separately map the object and environment geometries into two sets of eigen-lengths, perform pairwise comparisons between them, and compose comparison results using logical AND.\n\nConcretely, we encode object point cloud O and environment point cloud E using two PointNet (Qi et al., 2017) networks, ObjNet and EnvNet. Both networks output S-dim vectors ⃗Lobj = (Lobj , Lenv S ). We then compute task success 2\nas ˆT (E, O) = (cid:86)S (O)]. During training, we use a differentiable approximation ̃T (E, O) = (cid:81)S (O))/τ ), where τ is a learnable parameter. We set S = 1 for (c) Sphere, (f) Mug, S = 2 for (a) Tube, (b) Cylinder, S = 3 for (d) Fit, (e) Top.\n\nS ), ⃗Lenv = (Lenv (E) > Lobj (E) − Lobj\n\n2 , . . . , Lobj s=1[Lenv s=1 σ((Lenv\n\n1 , Lobj\n\n, . . . , Lenv\n\n1\n\ns\n\ns\n\ns\n\ns\n\n4.3 ANALYSIS OF LEARNED EIGEN-LENGTHS\n\ns′,i, Lpred\n\nWe analyze the eigen-lengths learned by the network by comparing them to “ground truth” eigenlengths as shown in Fig. 3. For each task, we randomly sample N = 512 test data points and obtain the corresponding N eigen-length predictions {Lpred s,i }i=0,...,N −1 for each of the S learned eigen-lengths, as well as N values {Lgt s′,i}i=0,...,N −1 for each of the S′ “ground truth” eigen-lengths. For each pair of predicted and “ground truth” eigen-lengths (s, s′), we draw a scatter plot of points (Lgt s′,i ) and perform least squares linear regression over them to get corresponding R2-scores. We match the predictions and groundtruths by maximizing the sum of R2-scores and show the scatter plots of matched pairs in Fig. 5. Note that in (e) Top, since we predict S = 3 eigen-lengths while there are only S′ = 2 groundtruth eigen-lengths, we show the unmatched prediction with its most correlated groundtruth. For complete S × S′ plots, please refer to Appendix B.2. Learned eigen-lengths are strongly correlated with human-hypothesized measurements. As Fig. 5 shows, R2 values between predictions and “ground truths” are close to or greater than 0.9 except for the redundant prediction slot 3 in (e) Top. They also have clear one-to-one correspondences with ground truth in tasks with multiple eigen-lengths, suggesting good disentanglement is learned. Knowing the number of eigen-lengths beforehand is not a requirement for successful learning. The number S of eigen-lengths to learn is a hyperparameter set before learning. However, it does\n\n5\n\n(cid:40)(cid:81)(cid:89)(cid:49)(cid:72)(cid:87)(cid:40)(cid:81)(cid:89)(cid:3)(cid:51)(cid:82)(cid:76)(cid:81)(cid:87)(cid:3)(cid:38)(cid:79)(cid:82)(cid:88)(cid:71)(cid:50)(cid:69)(cid:77)(cid:49)(cid:72)(cid:87)(cid:50)(cid:69)(cid:77)(cid:3)(cid:51)(cid:82)(cid:76)(cid:81)(cid:87)(cid:3)(cid:38)(cid:79)(cid:82)(cid:88)(cid:71)(cid:40)(cid:81)(cid:89)(cid:3)(cid:40)(cid:76)(cid:74)(cid:72)(cid:81)(cid:16)(cid:47)(cid:72)(cid:81)(cid:74)(cid:87)(cid:75)(cid:29)(cid:3)(cid:47)(cid:20)(cid:72)(cid:81)(cid:89)(cid:15)(cid:3)(cid:47)(cid:21)(cid:72)(cid:81)(cid:89)(cid:15)(cid:17)(cid:17)(cid:17)(cid:15)(cid:3)(cid:47)(cid:54)(cid:72)(cid:81)(cid:89)(cid:50)(cid:69)(cid:77)(cid:3)(cid:40)(cid:76)(cid:74)(cid:72)(cid:81)(cid:16)(cid:47)(cid:72)(cid:81)(cid:74)(cid:87)(cid:75)(cid:29)(cid:3)(cid:47)(cid:20)(cid:82)(cid:69)(cid:77)(cid:15)(cid:3)(cid:47)(cid:21)(cid:82)(cid:69)(cid:77)(cid:15)(cid:17)(cid:17)(cid:17)(cid:15)(cid:3)(cid:47)(cid:54)(cid:82)(cid:69)(cid:77)(cid:305)(cid:11)(cid:11)(cid:47)(cid:20)(cid:72)(cid:81)(cid:89)(cid:3)(cid:16)(cid:3)(cid:47)(cid:20)(cid:82)(cid:69)(cid:77)(cid:12)(cid:18)(cid:7532)(cid:12)(cid:3)(cid:305)(cid:11)(cid:11)(cid:47)(cid:21)(cid:72)(cid:81)(cid:89)(cid:3)(cid:16)(cid:3)(cid:47)(cid:21)(cid:82)(cid:69)(cid:77)(cid:12)(cid:18)(cid:7532)(cid:12)(cid:3)(cid:3)(cid:305)(cid:11)(cid:11)(cid:47)(cid:54)(cid:72)(cid:81)(cid:89)(cid:3)(cid:16)(cid:3)(cid:47)(cid:54)(cid:82)(cid:69)(cid:77)(cid:12)(cid:18)(cid:7532)(cid:12)(cid:7502)(cid:11)(cid:36)(cid:49)(cid:39)(cid:12)(cid:51)(cid:85)(cid:72)(cid:71)(cid:3)(cid:47)(cid:68)(cid:69)(cid:72)(cid:79)(cid:57)(cid:72)(cid:70)(cid:87)(cid:82)(cid:85)(cid:49)(cid:72)(cid:87)(cid:40)(cid:81)(cid:89)(cid:51)(cid:82)(cid:76)(cid:81)(cid:87)(cid:3)(cid:38)(cid:79)(cid:82)(cid:88)(cid:71)(cid:58)(cid:72)(cid:76)(cid:74)(cid:75)(cid:87)(cid:3)(cid:39)(cid:76)(cid:86)(cid:87)(cid:85)(cid:76)(cid:17)(cid:51)(cid:85)(cid:82)(cid:77)(cid:72)(cid:70)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:47)(cid:72)(cid:81)(cid:74)(cid:87)(cid:75)(cid:57)(cid:72)(cid:70)(cid:87)(cid:82)(cid:85)(cid:3)(cid:89)(cid:58)(cid:72)(cid:76)(cid:74)(cid:75)(cid:87)(cid:49)(cid:72)(cid:87)(cid:51)(cid:82)(cid:76)(cid:81)(cid:87)(cid:86)(cid:3)(cid:83)(cid:15)(cid:3)(cid:84)(cid:58)(cid:72)(cid:76)(cid:74)(cid:75)(cid:87)(cid:72)(cid:71)(cid:54)(cid:88)(cid:80)(cid:50)(cid:69)(cid:77)(cid:51)(cid:82)(cid:76)(cid:81)(cid:87)(cid:3)(cid:38)(cid:79)(cid:82)(cid:88)(cid:71)(cid:47)(cid:3)(cid:32)(cid:3)(cid:89)(cid:55)(cid:11)(cid:84)(cid:3)(cid:16)(cid:3)(cid:83)(cid:12)(cid:40)(cid:81)(cid:89)(cid:3)(cid:40)(cid:76)(cid:74)(cid:72)(cid:81)(cid:16)(cid:47)(cid:72)(cid:81)(cid:74)(cid:87)(cid:75)(cid:50)(cid:69)(cid:77)(cid:3)(cid:40)(cid:76)(cid:74)(cid:72)(cid:81)(cid:16)(cid:47)(cid:72)(cid:81)(cid:74)(cid:87)(cid:75)(cid:11)(cid:68)(cid:12)(cid:11)(cid:69)(cid:12)D7XEH<3UHGLFWLRQ5 D7XEH=3UHGLFWLRQ5 E&\\OLQGHU53UHGLFWLRQ5 E&\\OLQGHU+3UHGLFWLRQ5 F6SKHUH53UHGLFWLRQ5 I0XJ+ROGHU53UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 Under review as a conference paper at ICLR 2023\n\nnot have to be the exact number of relevant eigen-lengths. As shown in (e) Top, when we have more slots for eigen-lengths than needed, “ground truth” eigen-lengths are still captured by the first two predictions. The third prediction does not strongly correlate with any “ground truth”. A further probe reveals that comparisons of this eigen-length almost never (only in 0.4% of the cases) contribute to the final result, outputting True most of the time. The network learns a pair of degenerate eigen-lengths as there is no more necessary information to capture.\n\n5 CAN GEOMETRY GROUNDINGS BE DISCOVERED FOR EIGEN-LENGTHS?\n\nWhile Fig. 5 shows strong correlation between learned eigen-lengths and “ground truth”, their relationship is not always perfectly linear, as can be observed in (d) Fit and (e) Top with complex geometries. Even in more linear cases, the scaling and offset make the raw eigen-length value hard to understand, e.g., negative “length” values are less intuitive. As eigen-lengths can be seen as measurements of the object, many of them have sparse supports or geometry groundings on the objects, e.g., height is the distance between the base plane supporting the object and its highest point. These geometry groundings anchor the corresponding eigen-length values, provide an intuitive explanation of these values, and usually carry geometric/semantic importance themselves. We are therefore interested in the following question: can we ground the eigen-lengths on geometry? From a high level, instead of directly predicting eigen-length values, if we first predict some geometric entities like points, vectors, and planes, then derive eigen-lengths from them, is it possible to learn meaningful eigen-lengths and geometry groundings?\n\n5.1 GROUNDING EIGEN-LENGTH PREDICTIONS ON GEOMETRIC PRIMITIVES\n\nFigure 6: Eigen-Length Geometry Groundings. We ground each eigen-length L with a unit vector v and two parallel planes Πp, Πq with normal v. L is computed as the distance between Πp, Πq.\n\nConsider fitting tasks like (d) Container Fitting and (e) Countertop Placing where the spaces affording the task can be roughly described by a set of parallel planes. 1 To compute the success label of the task, say fitting an object into a nightstand, we can measure the size of the spaces of interest in the environment (the drawer part) along important directions (its main axes) and comparing it to the measurement of the object. Inspired by this, we ground a pair of eigen-lengths on a tuble of unit vector and two planes (⃗v, Πp, Πq) as illustrated in Fig. 6: we measure both the object and the environment along ⃗v. We take the object measurement as the diameter of the projection of the object point cloud O on the vector ⃗v, i.e. Lobj(O) = maxp∈O ⃗vT p − minp∈O ⃗vT p. For the environment, we use a pair of parallel planes Πp, Πq with normal ⃗v to separate out a certain region relevant to the task (the drawer), then measure the distance between the planes. In practice, we adopt the (point, normal) plane representation and predict a point pair (p, q) that determines the plane pair. The environment eigen-length is then computed as Lenv(E) = ⃗vT (q − p).\n\nFigure 4 (b) illustrates our network architecture. In VectorNet, we employ a PointNet classification backbone to extract global feature of the environment point cloud E ∈ RM ×3, then use an MLP to predict S 3D vectors {⃗vs}s=1,2,...,S. In WeightNet, we employ a PointNet segmentation backbone to extract per-point features, then use S × 2 MLPs with to predict S pairs of probability distributions W p s over the point cloud. The point coordinates of (ps, qs) are then computed as the weighted average of original point cloud coordinates, namely ps = W p\n\nT E, qs = W q\n\ns , W q\n\nT E.\n\ns\n\ns\n\n1Note that other tasks may require other inductive bias. We focus on this type of tasks to study the feasibility\n\nof geometry-grounded eigen-length learning. We leave a more versatile system as future work.\n\n6\n\nlength < L ?Πp = (v, p)Πq = (v, q)vector v1vector v0vector v2vector v1vector v0vector v2length = Lheight=HvUnder review as a conference paper at ICLR 2023\n\n5.2 ANALYSIS OF LEARNED GEOMETRIC PRIMITIVES AND EIGEN-LENGTH VALUES\n\nFigure 7: Geometry Grounding Visualizations. We plot the learned vectors (as arrows) and planes (as disks) on top of input environment point clouds. We also show the object model next to point clouds for clearer view of object structure. For (d) Fit, we visualize predictions in two views for clarity. Please refer to Appendix B.1 for more visualizations.\n\nFigure 8: Improved correlation after using geometry groundings. We show scatter plots of predicted eigen-length (Y coord.) and their matching “ground truth” (X coord.) in (d) Fit and (e) Top. We perform the same correlation analysis and visualize the results in Fig. 8. Compared to Fig. 5, learned eigen-lengths are now almost equal to “groundtruth” thanks to the anchoring effect of the geometry grounding. The extra predicted eigen-length in (e) Top also behaves differently, capturing the same “ground truth” as another learned eigen-length. This suggests the regularization from geometry grounding makes learned eigen-lengths more likely to be meaningful measurements. It also reaffirms the fact that the number S of eigen-lengths we set in advance can be different from the actual number of necessary eigen-lengths. Please see Appendix E.4 for detailed discussion.\n\nWe also visualize the learned geometry groundings in Fig. 7. The learned vectors align with the main axes of object geometry. The learned planes overlap with tube surfaces in (a) Tube, surround the edge of countertops in (e) Top, and separate out the region of interest in (d) Fit, e.g. the higher one out of two storage spaces. These meaningful geometric entities provide a clear interpretation of learned eigen-lengths, e.g. in (e) Top’s case, red and green predictions coincide with each other and both capture the back-to-front length of the countertop.\n\n5.3 A STUDY ON THE ROBUSTNESS AND DATA EFFICIENCY OF GEOMETRY-GROUNDED\n\nEIGEN-LENGTHS\n\nGeometry grounding of eigen-lengths can be seen as a form of regularization. We are therefore curious how the introduction of geometry groundings may influence the robustness of models in extreme test setups, as well as their data efficiency. We compared the performance of (1) Direct, a no-eigen-length approach, where an MLP directly predicts the final label from the concatenation of object and environment latent features. (2) Implicit, the minimal eigen-length-based pipeline introduced previously; and (3) Grounded, the geometry-grounded version.\n\nTable 1 shows test performances in extreme test conditions with low resolution point clouds or with extraordinary object scalings. Eigen-length-based approaches exhibit much higher robustness.\n\nFig. 9 shows the trend of test performances as we change the size of training data. We also plot the difference between “ground truth” eigen-length measurement directions (local up and right) and predicted vectors as a way to quantify eigen-length quality. Results suggest that geometry-grounded version is more data efficient if meaningful geometry groundings emerge. When the training data\n\n7\n\n(cid:41)(cid:85)(cid:82)(cid:81)(cid:87)(cid:3)(cid:57)(cid:76)(cid:72)(cid:90)(cid:15)(cid:3)(cid:51)(cid:85)(cid:72)(cid:71)(cid:3)(cid:20)(cid:15)(cid:21)(cid:55)(cid:82)(cid:83)(cid:3)(cid:57)(cid:76)(cid:72)(cid:90)(cid:15)(cid:3)(cid:51)(cid:85)(cid:72)(cid:71)(cid:3)(cid:22)(cid:11)(cid:68)(cid:12)(cid:3)(cid:55)(cid:88)(cid:69)(cid:72)(cid:3)(cid:51)(cid:68)(cid:86)(cid:86)(cid:76)(cid:81)(cid:74)(cid:11)(cid:71)(cid:12)(cid:3)(cid:38)(cid:82)(cid:81)(cid:87)(cid:68)(cid:76)(cid:81)(cid:72)(cid:85)(cid:3)(cid:41)(cid:76)(cid:87)(cid:87)(cid:76)(cid:81)(cid:74)(cid:11)(cid:72)(cid:12)(cid:3)(cid:38)(cid:82)(cid:88)(cid:81)(cid:87)(cid:72)(cid:85)(cid:87)(cid:82)(cid:83)(cid:3)(cid:51)(cid:79)(cid:68)(cid:70)(cid:76)(cid:81)(cid:74)(cid:40)(cid:81)(cid:89)(cid:76)(cid:85)(cid:82)(cid:81)(cid:80)(cid:72)(cid:81)(cid:87)(cid:55)(cid:82)(cid:83)(cid:3)(cid:57)(cid:76)(cid:72)(cid:90)(cid:15)(cid:3)(cid:51)(cid:85)(cid:72)(cid:71)(cid:3)(cid:20)(cid:15)(cid:21)(cid:15)(cid:22)(cid:40)(cid:81)(cid:89)(cid:76)(cid:85)(cid:82)(cid:81)(cid:80)(cid:72)(cid:81)(cid:87)G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 Under review as a conference paper at ICLR 2023\n\nTable 1: Performance on extreme test cases. All methods are trained on size = 1024 point clouds with width w and height h sampled from U ([0.4, 1.0]).\n\nDirect\n\nImplicit Grounded\n\nDefault # Points = 64 w, h ∼ U ([0.2, 0.4]) w, h ∼ U ([2.0, 3.0])\n\n99.00 76.80 72.10 82.44\n\n99.15 93.50 98.78 98.82\n\n99.65 96.17 99.72 99.63\n\nFigure 9: Trend of Left: test accuracy and Right: average angle between learned vector groundings and “groud truth” directions w.r.t. # training samples.\n\nis limited (< 3000 samples), however, the predicted directions of groundings are far from ground truth measurement directions, suggesting that the model fails to learn meaningful groundings for eigen-lengths, and thus the final accuracy is lower than Direct.\n\n6 CAN EIGEN-LENGTHS BE LEARNED IN MULTI-TASK SETTINGS AND\n\nAPPLIED TO NEW TASKS?\n\nAs humans, we are able to develop a library of useful measurements/eigen-lengths like height from past experience. Given a new task, instead of trying cluelessly, we would start with known measurements and investigate their role in the task. In this section, we ask if learned eigen-lengths can work in a similar way, i.e., given a set of training tasks, is it possible to learn a set of eigen-lengths from them? Further, given a novel task, can we learn to select a subset of learned eigen-lengths that are sufficient for it? In other words, can agents accumulate and transfer knowledge in the form of eigen-lengths?\n\n6.1 MULTI-TASK TESTBED\n\nWe design a set of tasks that share key eigen-lengths as the testbed for multi-task learning. As shown in Fig.10(a), we consider box-fitting tasks where the box only has a subset of six faces. Each mode of face existence corresponds to a different task with different geometric constraints. For example, to be able to fit, an object has to be narrower than the box in task 2 and shorter than the box in task 3. We set aside the box with all six faces present as the test task. We expect to learn width, height, and length from the training task set, and learn to use all of them during testing. By boxes with partial faces, we aim to mimic different types of cavities in the furniture, e.g., closed drawer as a box with all faces, an open space on the shelf as a box without the front face, etc.\n\nFigure 10: (a) Multi-Task Setting where each train task uses boxes with certain faces missing as the environment geometry, and test task uses a complete box; and (b) Learning Framework, where we use trainable masks to select eigen-length comparison results.\n\n6.2 MULTI-TASK LEARNING FRAMEWORK\n\nFig. 10(b) shows the multi-task learning framework we experiment with. From a high level, we learn a set of S eigen-lengths and allow each task to select relevant ones from them. This selection step is implemented as a learnable binary mask {mk s }s=1,2,...,S over eigen-lengths for each task Tk. We simply insert the mask in the AND-composition and compute the outcome for Tk as (cid:81)S\n\ns=1 mk\n\ns · σ((Lenv\n\ns\n\n(E) − Lobj\n\ns\n\n(O))/τ ).\n\n8\n\n7UDLQLQJ6DPSOHV$FFXUDF\\*URXQGHG'LUHFW7UDLQLQJ6DPSOHV$QJOHWR*7*URXQGHGEnv Measure: L1env, L2env,..., LSenvObj Measure: L1obj, L2obj,..., LSobjσ((L1env - L1obj)/τ) σ((L2env - L2obj)/τ) σ((LSenv - LSobj)/τ)Π(AND)Pred Label✕✕✕Test TaskTrain Task 1Train Task 2Train Task 3(a) Task Setting(b) Multi-Task Learning FrameworkUnder review as a conference paper at ICLR 2023\n\nTable 2: Multi-Task learning, novel task adaptation results. We finetune eigen-length-based methods on novel task for 1 epoch and compare them to the direct method trained from scratch for 1 and 100 epochs.\n\n(Single Task) Direct\n\n(Eigen-Length) Implicit\n\n(Eigen-Length) Grounded\n\nEpoch\n\n1\n\nTest Accuracy\n\n73.14\n\n100\n\n88.47\n\n1\n\n97.71\n\n1\n\n99.48\n\nDuring training, we optimize both the eigen-length prediction networks and a continuous version of per-task masks ̃mk ∈ [0, 1]. At test time, we freeze network weights and only learn a mask to choose from eigen-lengths learned during training. Notably, we limit the size of test task data to 10 batches (320 samples) to examine if learned eigen-lengths help in few-shot adaptation scenarios.\n\n6.3 MULTI-TASK LEARNING AND FEW-SHOT TEST TASK ADAPTATION\n\nWe experiment with both implicit and geometry-grounded eigen-length prediction networks. To analyze the learned eigen-lengths and per-task masks, we visualize learned geometry groundings that are selected (ms > 0.5) in each task in Fig. 11. Meaningful groundings are learned and correctly selected for each task, including the test task.\n\nTo explore whether eigen-lengths learned during training help quicker adaptation to new tasks, we compare the test task performance of Implicit, Grounded to Direct trained from scratch on the test task. All methods are limited to 10 batches of test task samples. As shown in Table 2, within one epoch of finetuning, methods based on the reuse of learned eigen-lengths already achieve high performance, surpassing Direct trained from scratch by a large margin, even when the latter has been trained for 100 epochs.\n\nFigure 11: Learned Geometry Grounding in Multi-Task Setting. We only show learned geometry grounding (vectors as arrows, planes as disks) selected by the mask in each task.\n\n7 CONCLUSION\n\nIn this work, we formulate a novel learning problem of automatically discovering low-dimensional geometric eigen-lengths crucial for fitting tasks. We set up a benchmark suite comprising a curated set of fitting tasks and corresponding datasets, as well as metric and tools for analysis and evaluation. We demonstrate the feasibility of learning meaningful eigen-lengths as sufficient geometry summary only from binary task supervision. We show that proper geometry grounding of the eigen-lengths contributes to their accuracy, interpretability, and robustness. We also make an initial attempt at learning shared eigen-lengths in multi-task settings and applying them to novel tasks.\n\nOur exploration suggests broad opportunities in this new research direction and reveals many challenges. For example, grounding eigen-length predictions on geometries requires reasonable choice of geometric primitives, which relies on inductive bias of the specific tasks considered. It would be a challenging future direction to build a universal framework that accommodates a wide range of tasks by leveraging all kinds of geometric primitives and inductive biases. In many task instances, we may have access to signals beyond binary success or failure, e.g., a possible placement position of the object. How to leverage these task signals in eigen-length learning remains an open problem. As a first-step attempt at defining and exploring the challenging problem of eigen-length learning, we do hope our work can inspire more researchers to work on this important yet underexplored direction.\n\n9\n\nTraining TasksTest TaskUnder review as a conference paper at ICLR 2023\n\nREFERENCES\n\nAngel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.03012, 2015.\n\nBoyuan Chen, Pieter Abbeel, and Deepak Pathak. Unsupervised learning of visual 3d keypoints for\n\ncontrol. In International Conference on Machine Learning, pp. 1539–1549. PMLR, 2021.\n\nNenglun Chen, Lingjie Liu, Zhiming Cui, Runnan Chen, Duygu Ceylan, Changhe Tu, and Wenping Wang. Unsupervised learning of intrinsic structural representation points. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9121–9130, 2020.\n\nXi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets. In Proceedings of the 30th International Conference on Neural Information Processing Systems, pp. 2180–2188, 2016.\n\nBoyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey Hinton, and Andrea In Proceedings of the IEEE/CVF\n\nTagliasacchi. Cvxnet: Learnable convex decomposition. Conference on Computer Vision and Pattern Recognition, pp. 31–44, 2020.\n\nShengheng Deng, Xun Xu, Chaozheng Wu, Ke Chen, and Kui Jia. 3d affordancenet: A benchmark for visual object affordance understanding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1778–1787, June 2021.\n\nKyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna, William T Freeman, and Thomas Funkhouser. Learning shape templates with structured implicit functions. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 7154–7164, 2019.\n\nKyle Genova, Forrester Cole, Avneesh Sud, Aaron Sarna, and Thomas Funkhouser. Local deep implicit functions for 3d shape. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4857–4866, 2020.\n\nIrina Higgins, Loic Matthey, Xavier Glorot, Arka Pal, Benigno Uria, Charles Blundell, Shakir Mohamed, and Alexander Lerchner. Early visual concept learning with unsupervised deep learning. arXiv preprint arXiv:1606.05579, 2016.\n\nIrina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-VAE: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017.\n\nTomas Jakab, Richard Tucker, Ameesh Makadia, Jiajun Wu, Noah Snavely, and Angjoo Kanazawa. Keypointdeformer: Unsupervised 3d keypoint discovery for shape control. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12783–12792, 2021.\n\nDavid Inkyu Kim and Gaurav S Sukhatme. Semantic labeling of 3d point clouds with object affordance for robot manipulation. In 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 5578–5584. IEEE, 2014.\n\nLucas Manuelli, Wei Gao, Peter Florence, and Russ Tedrake. kpam: Keypoint affordances for\n\ncategory-level robotic manipulation. arXiv preprint arXiv:1903.06684, 2019.\n\nKaichun Mo, Leonidas J Guibas, Mustafa Mukadam, Abhinav Gupta, and Shubham Tulsiani. Where2act: From pixels to actions for articulated 3d objects. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 6813–6823, 2021a.\n\nKaichun Mo, Yuzhe Qin, Fanbo Xiang, Hao Su, and Leonidas Guibas. O2O-Afford: Annotation-free large-scale object-object affordance learning. In Conference on Robot Learning (CoRL), 2021b.\n\nDespoina Paschalidou, Ali Osman Ulusoy, and Andreas Geiger. Superquadrics revisited: Learning 3d shape parsing beyond cuboids. In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), June 2019.\n\n10\n\nUnder review as a conference paper at ICLR 2023\n\nDespoina Paschalidou, Luc van Gool, and Andreas Geiger. Learning unsupervised hierarchical part decomposition of 3d objects from a single rgb image. In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), June 2020.\n\nCharles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 652–660, 2017.\n\nZengyi Qin, Kuan Fang, Yuke Zhu, Li Fei-Fei, and Silvio Savarese. Keto: Learning keypoint representations for tool manipulation. In 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 7278–7285. IEEE, 2020.\n\nPradyumna Reddy, Michael Gharbi, Michal Lukac, and Niloy J Mitra. Im2vec: Synthesizing vector graphics without vector supervision. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 7342–7351, 2021.\n\nJoseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In Proceedings of the IEEE\n\nconference on computer vision and pattern recognition, pp. 7263–7271, 2017.\n\nGopal Sharma, Difan Liu, Subhransu Maji, Evangelos Kalogerakis, Siddhartha Chaudhuri, and Radomír Mˇech. Parsenet: A parametric surface fitting network for 3d point clouds. In European Conference on Computer Vision, pp. 261–276. Springer, 2020.\n\nNarayanaswamy Siddharth, Brooks Paige, Jan-Willem Van de Meent, Alban Desmaison, Noah D Goodman, Pushmeet Kohli, Frank Wood, and Philip HS Torr. Learning disentangled representations with semi-supervised deep generative models. arXiv preprint arXiv:1706.00400, 2017.\n\nDmitriy Smirnov, Matthew Fisher, Vladimir G Kim, Richard Zhang, and Justin Solomon. Deep parametric shape predictions using distance fields. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 561–570, 2020.\n\nChun-Yu Sun, Qian-Fang Zou, Xin Tong, and Yang Liu. Learning adaptive hierarchical cuboid abstractions of 3d shape collections. ACM Transactions on Graphics (TOG), 38(6):1–13, 2019.\n\nShubham Tulsiani, Hao Su, Leonidas J. Guibas, Alexei A. Efros, and Jitendra Malik. Learning shape abstractions by assembling volumetric primitives. In Computer Vision and Pattern Recognition (CVPR), 2017.\n\nDylan Turpin, Liquan Wang, Stavros Tsogkas, Sven Dickinson, and Animesh Garg. GIFT: Generalizable Interaction-aware Functional Tool Affordances without Labels. In Proceedings of Robotics: Science and Systems, Virtual, July 2021. doi: 10.15607/RSS.2021.XVII.060.\n\nJiayu Wang, Shize Lin, Chuxiong Hu, Yu Zhu, and Limin Zhu. Learning semantic keypoint representations for door opening manipulation. IEEE Robotics and Automation Letters, 5(4): 6980–6987, 2020.\n\nFanbo Xiang, Yuzhe Qin, Kaichun Mo, Yikuan Xia, Hao Zhu, Fangchen Liu, Minghua Liu, Hanxiao Jiang, Yifu Yuan, He Wang, Li Yi, Angel X. Chang, Leonidas J. Guibas, and Hao Su. SAPIEN: A simulated part-based interactive environment. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.\n\nYanchao Yang, Yutong Chen, and Stefano Soatto. Learning to manipulate individual objects in an image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 6558–6567, 2020.\n\n11\n\nUnder review as a conference paper at ICLR 2023\n\nA IMPLEMENTATION DETAILS\n\nA.1 NETWORK ARCHITECTURE\n\nThe framework in Section 4 consists of a PointNet and an MLP output head that maps the PointNet global feature to S scalar values. The architecture is outlined below, where the numbers in the parenthesis refer to the number of channels in each layer. We use batch normalization and LeakyReLU after all FC layers, except for the output layer.\n\nPointNet\n\n \n\n\n\nPer-Point MLP(3 → 64 → 128 → 1024) ↓\nMax Pooling\n\n↓ MLP(1024 → 256 → S)\n\nOutput: S scalars.\n\nThe framework in Section 5 consists of VectorNet and WeightNet. VectorNet consists of a PointNet classification backbone and an MLP output head, as outlined below.\n\nPointNet\n\n \n\n\n\nPer-Point MLP(3 → 64 → 128 → 1024) ↓\nMax Pooling\n\n↓ MLP(1024 → 256 → 3S)\n\nOutput: S vectors.\n\nWeightNet consists of a PointNet segmentation backbone and 2S parallel MLP output heads, each outputs a weight distribution over all points, as outlined below.\n\nPointNet\n\n \n\n\n\nPer-Point MLP(3 → 64[per-point feature] → 128 → 1024) ↓\nMax Pooling[global feature]\n\nConcat(per-point feature, global feature) ↓\nMLP((1024 + 64) → 512 → 256 → 128) ↓\nOutput Weight MLPi(128 → 256 → 1), i = 1, 2, . . . , 2S ↓\n\nSoftMax\n\nOutput: 2S sets of per-point weights.\n\nWe use LeakyReLU and batch normalization after each FC layer except for the output layers.\n\nA.2 TRAINING DETAILS\n\nAll networks are implemented using PyTorch and optimized by the Adam optimizer, with a learning rate starting at 10−3 and decay by half every 10 epochs. Each batch contains 32 data points; each epoch contains around 1600 batches. We train models for ∼ 100 epochs on all tasks. The learnable parameter τ is initialized with τ = 1. All experiments are run on a single NVIDIA TITAN X GPU.\n\nA.3 DATASET DETAILS\n\nTable 3 and 4 summarizes the statistics of environment/object shapes used in our dataset. Each shape is drawn with probability in inverse proportion to the number of shapes in its category, such that each object category appears with similar frequency in the final dataset.\n\n12\n\nUnder review as a conference paper at ICLR 2023\n\nTable 3: Environment Shape Statistics.\n\nBox Microwave\n\nRefrigerator\n\nSafe\n\nStorage Furniture\n\nTable Washing Machine\n\nTotal\n\nTrain Test\n\n21 7\n\n9 3\n\n34 9\n\n21 7\n\n272 73\n\n70 25\n\n13 3\n\n440 127\n\nTable 4: Object Shape Statistics.\n\nTrain\n\nBasket Bottle 16\n\n77\n\nBowl Box Can 65\n\n128\n\n17\n\nPot Mug 134 16\n\nTrashCan 25\n\nTotal 478\n\nTest\n\nBucket 33\n\nDispenser 9\n\nJar 528\n\nKettle 26\n\nTotal 554\n\nDuring data generation for the tasks where both the environment and the object are ShapeNet objects, we apply random scaling s ∼ U ([0.9, 1.1]) to the environment objects, set all joints to closed state and sample M = 1024 points from the object model. Given an object-environment pair, we randomly sample T = 1000 candidate positions in the environment point cloud, and check whether placement of the object at each candidate satisfy the task specification using SAPIEN (Xiang et al., 2020) simulation. If all candidates fail, we label the pair as negative, otherwise as positive. Specifically, the candidate positions are sampled from “applicable and possible regions\" following Mo et al. (2021b)’s definition. For example, we only consider points with upward facing normals, and for task (e) only consider points with close to highest z coordinates. We generated around 75K training data and 20K testing data for each task.\n\nB ADDITIONAL RESULTS\n\nB.1 GEOMETRIC GROUNDING VISUALIZATION AND FAILURE CASE DISCUSSION\n\nFig. 12 and 13 show more visualizations of the learned eigen-lengths in the three tasks from the main paper. Our framework is able to learn reasonable eigen-lengths that measure along crucial directions. These eigen-lengths are also grounded by planes that suggest the relevant part of object which supports the task. In experiments with primitive shapes as environments, the learned planes almost overlap with the box/tube faces. In experiments with ShapeNet container objects as environments, especially task (d) (Fit, or container fitting) as shown in Fig. 13, locating the relevant part becomes more challenging. As this usually involves finding cavities in a shape and selecting the largest one. Fig. 13 shows examples of our learned eigen-lengths, most of which make sense, as shown in (a)-(o). We are able to ignore irrelevant parts, e.g. the legs of tables, and find the part of object that affords the \"containment\" task, e.g. the drawer in (b), the closet in (c). When there are many cavities that afford the same task, the network picks the largest one, e.g. in (d) and (k).\n\nFailure Cases. We also observe some failure cases where the learned eigen-lengths are inaccurate. Fig. 13(p)-(t) shows the most representative ones. (p) shows a relatively complex shape, where the network struggles to find the correct width of the drawer. (q) and (r) show cases where the network finds the wrong cavity. According to our task definition, the object can only be placed in the drawer part in (q). Instead, the network finds the part on top of the drawer. In (r), the network finds the second largest cavity instead of the largest one at the bottom. (s) shows an extreme case where the height of the pizza box is much smaller than the other two extents. As objects usually have correlated extents, comparing height suffices most of the time. The network probably lacks the motivation to precisely capture the width and the length of the pizza box, resulting in the underestimation of width and length in (s). Finally, our formulation, i.e. the AND clause of three eigen-length comparisons, can not fully and precisely describe the nature of this task. The washing machine in (t) has a cylinder-shaped cavity, which our network tries to approximate by a cuboid, which is reasonable within the range of its expressive power but not accurate. Also, there could be shapes that do not have a \"largest\"\n\n13\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 12: Additional qualitative results. We visualize the learned vectors and planes for (a) Tube Passing and (e) Countertop Placing. We show all eigen-lengths in the front(a)/top(e) view. We also show the underlying instances in task (e) countertop placing for a clearer understanding of the object structure. Note that though some joints are \"open\" for visualization purpose, all instances in the dataset are at their rest state.\n\ncavity, e.g. some drawers in a closet may be designed for tall and narrow things, while others are designed for flat things. To deal with arbitrary objects, the extents of both types of drawers are useful. Introducing more complex and flexible formulations, e.g. in Section D, would help better capture the complexity of the task.\n\nB.2 CORRELATION ANALYSIS RESULTS\n\nWe show here the scatter plots and correlation R2 values between all prediction eigen-lengths and all presumable geometric measurements. R2 value, or coefficient of determination, is a metric in [0, 1] reflecting linear correlation between two variables. The closer R2 is to 1, the more linearly correlated the two variables are. Given two set of samples xi, yi, where i = 1, 2, . . . , n, R2 is defined between yi and the least squares linear regression of yi on xi, ̃y(xi):\n\nR2 = 1 −\n\n(cid:80)\n\ni (yi − ̃y(xi))2 (cid:80) i (yi − ̄y)2\n\n,\n\nwhere ̄y = 1\n\nn\n\n(cid:80)\n\ni yi is the mean value of yi.\n\nResults from Eigen-Length-Implicit are shown in Fig. 14. Results from Eigen-Length-Grounded are shown in Fig. 15. We can clearly see the one-to-one correspondence between predictions and presumable measurements. R2 is close to or greater than 0.9 where the prediction is the match for the measurements, otherwise the value is much smaller. It is more apparent in the Eigen-LengthGrounded variant, where R2 values are close to the theoretical bound 1 when it matches. The models can learn a compact and appropriate set of eigen-lengths from binary task supervision. Also note that the extraneous prediction slot in task (e) (Top, or countertop placing) become degenerate with another prediction slot, as has mentioned before in main text.\n\nC APPLYING RANDOM ROTATIONS TO INPUT ENVIRONMENT GEOMETRIES\n\nC.1 FORMULATION AND IMPLEMENTATION\n\nWhile the object shape is randomly rotated in all experiments in the main paper, we take environment geometry directly from ShapeNetChang et al. (2015) where shapes are axis-aligned. In this section, we consider a more challenging setting where the environment geometry is also randomly rotated.\n\n14\n\n(cid:73)(cid:85)(cid:82)(cid:81)(cid:87)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:11)(cid:68)(cid:12)(cid:55)(cid:88)(cid:69)(cid:72)(cid:3)(cid:51)(cid:68)(cid:86)(cid:86)(cid:76)(cid:81)(cid:74)(cid:87)(cid:82)(cid:83)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:11)(cid:72)(cid:12)(cid:3)(cid:38)(cid:82)(cid:88)(cid:81)(cid:87)(cid:72)(cid:85)(cid:87)(cid:82)(cid:83)(cid:3)(cid:51)(cid:79)(cid:68)(cid:70)(cid:76)(cid:81)(cid:74)Under review as a conference paper at ICLR 2023\n\nSpecifically, we consider a “rotated” version of the Container Fitting task and Tube Passing task in the main paper. For each original data point, i.e. a container/tube-object pair with a boolean label ((object point cloud Po, environment point cloud Pe), success label L), we sample a random rotation R and apply it to both the container and the object. We feed (RPo, RPe) to the network described in Section 5 and supervise the network with the same label L.\n\nC.2 CORRELATION ANALYSIS AND RESULT VISUALIZATION\n\nWe show the correlation analysis of learned eigen-lengths in Fig. 16. A strong, disentangled correlation between learned eigen-lengths and human-hypothesized ones can still be observed.\n\nWe also visualize the learned geometry groundings in Fig. 17. The predicted planes roughly align with the main cavities of the objects. From the results, we can see that the proposed problem setting is still valid and the studied methods can still be applicable and produce reasonable results.\n\nD EXTENDING AND CLAUSES TO DISJUNCTIVE NORMAL FORM (DNF)\n\nD.1 FORMULATION\n\nWe employ the AND clause formulation for all tasks shown in the main paper. Namely, after learning a library of paired object/environment eigen-lengths {(Lenv\n\n)}s, we compose them by\n\n, Lobj s\n\ns\n\nˆT (E, O) =\n\n(cid:94)\n\n[Lenv\n\ns\n\n(E) > Lobj\n\ns\n\n(O)],\n\ns=1,2,...,S\n\n(selection mask m is omitted for clarity), approximated by\n\n ̃T (E, O) =\n\n(cid:89)\n\nσ((Lenv\n\ns\n\n(E) − Lobj\n\ns\n\n(O))/τ ).\n\ns=1,2,...,S\n\nHere we show we can extend this formulation to the more general Disjunctive Normal Form (DNF), where an OR connects multiple AND clauses. Each AND clause composes eigen-length comparison results of a subset of eigen-lengths. The result of each AND clause is then aggregated by an OR operator. More precisely,\n\nˆT (E, O) =\n\n(cid:95)\n\n(cid:94)\n\n[Lenv\n\ns\n\n(E) > Lobj\n\ns\n\n(O)].\n\nUa∈U\n\ns∈Ua\n\nU = {Ua}a specifies the subset Ua of eigen-lengths in each AND clause. We similarly use a differentiable approximation during training:\n\n ̃T (E, O) = 1 −\n\n(cid:89)\n\n(1 −\n\n(cid:89)\n\nσ((Lenv\n\ns\n\n(E) − Lobj\n\ns\n\n(O))/τ )).\n\nUa∈U\n\ns∈Ua\n\nThe introduction of two-level logic and the OR operator helps express more complex reasoning and deal with a wider range of tasks. For example, many realistic tasks have multiple solutions. OR captures the relationship that the task can be executed if any, not necessarily all, of the solutions work.\n\nD.2 TASK AND IMPLEMENTATION DETAILS\n\nTo demonstrate our framework’s compatibility with this new formulation, we experiment with the Multi-Tube Passing task. This is a variant of task (a) (Tube, or tube passing) in the main paper, where we have two tubes of random sizes placed next to each other. As long as the object can be translated and passed through any of these tubes, the task is considered as successful.\n\nSimilar to tube passing, we randomly sample the extents of the tubes, the shape, scale, and rotation of the object. The center of the two tubes are always at two fixed positions on the y-axis.\n\nWe set the number of eigen-lengths to learn as S = 4 and split them into two disjoint AND groups, namely U = {{1, 2}, {3, 4}}. Ideally, the learned eigen-lengths should correspond to the height and width of the tubes. Also, the height and width of the same tube should be in the same AND group.\n\n15\n\nUnder review as a conference paper at ICLR 2023\n\nD.3 RESULT VISUALIZATION\n\nFig. 18 visualizes the learned eigen-lengths, where green and yellow belong to one group, purple and red belong to another group. We successfully learn eigen-lengths that measure along the height/width directions of the tubes. We also learn them in correct groups, where width and height of the same tube are paired together.\n\nE DISCUSSION AND FUTURE WORK\n\nE.1 DEFINITION OF EIGEN-LENGTHS AND APPLICATION SCOPE OF THE EXPLORED\n\nFRAMEWORK\n\nIn our setting, an eigen-length is whatever scalar measurement (i.e., just a 1D scalar) the network invents to best perform its stated downstream task. While this definition for eigen-dimensions is quite general and could be applicable to any object as long as there exist certain 1D eigen-lengths that are crucial and useful for checking the feasibility of accomplishing a downstream task, we are assuming in our current experiments that having such sets of 1D eigen-lengths are sufficient for the tasks. Therefore, our current setting would not apply to the tasks where having only such low-dimensional eigen-lengths is not sufficient, such as the tasks of geometric contour matching and object collision checking.\n\nE.2 BROADER IMPLICATION OF THE STUDIED APPROACH FOR AI AND ROBOTICS\n\nWe believe the general approach we suggest can have very general applicability in AI and robotics, where the solution to downstream tasks suggests the emergence of generally useful geometric concepts such as length, height, width, and radius in unsupervised ways. As we described in the introduction, learning such compact useful geometric eigen-lengths is beneficial in the ways that 1) they are highly interpretable, while most of the current learned representations in neural networks are opaque and learned as black-box hidden features which may be unreliable or untrustworthy, 2) they could be shared and reused across different tasks, enabling fast adaptation to novel test-time tasks, and 3) the proposed learning formulation may discover novel yet crucial geometric eigen-lengths that are even unknown to us humans given the new test-time tasks. Furthermore, there could be more geometric concepts of great interest and importance that future work can explore in this direction. Examples can be 1) symmetry, as a result of trying to complete 3D shapes, 2) regular object arrangements and poses as a tool for efficient search, and 3) tracking, as an essential capability for predicting the outcome of sports games. In other words, we want learning networks to invent the notions so symmetry, regularity, or tracking. If such capabilities could emerge from purely unsupervised learning, we no longer need to rely on black-box-like neural networks and human annotations for this geometric information over 3D objects.\n\nE.3 ROTATION OF OBJECTS DURING TASK EXECUTION\n\nIn our experiments, we are primarily concerned with translational motion during task execution. This setting stems from practical concerns: in many robotic manipulation scenarios, the rotation of the object is often given as the desired target to achieve by robot planners or unchangeable during robotic grasping and manipulation. For example, the robot gripper may only be able to grasp, hold and move the mug without spilling the content and with steady grasping in certain poses for a pick-and-place task and the robot may not be able to freely rotate the object as the arm kinematics may not allow.\n\nThat being said, our cylinder fitting task does allow rotation along the up-axis for the object and similarly, the sphere fitting task allows the full SO(3)-space rotation, while for other tasks, in the case that multiple poses of the object are possible, we can simply pass the object in different poses into the same network for multiple times to query the joint fitting feasibility.\n\nE.4 DETERMINING THE NUMBER OF EIGEN-LENGTHS TO LEARN\n\nThe number of eigen-lengths to learn, i.e. S, is a hyperparameter of our learning framework and has to be set in advance. However, it should be interpreted as the upper bound on the number of\n\n16\n\nUnder review as a conference paper at ICLR 2023\n\neigen-lengths the system can learn, and does not have to be the “groundtruth” number of relevant eigen-lengths. As shown in Sec. 4.3 and Sec. 5.2, when we set S = 3 for the countertop fitting task where only two eigen-lengths matter, the extra “slot” either degenerates or coincides with other slots. Such cases can be easily detected and filtered, and the actual number of relevant eigen-lengths can be discovered. Setting a maximum number for an unknown number of targets is also a common practice in problems like object detection Redmon & Farhadi (2017). That being said, a more flexible mechanism that allows an arbitrary number of eigen-lengths would be desirable, especially for objects with complex compositional structures like robotic arms or closets with many drawers. We leave this as a future direction.\n\nF NEGATIVE SOCIAL IMPACT\n\nOur work joins the initial efforts of eigen-length emergence in unsupervised learning settings with many other works along this direction. There could be several bias in the data and training objectives, but this is a general concern shared by most works in this field. Our work may also share the controversial arguments with other works that the future AI agents may have the capability of thinking by themselves causing threats for human beings. However, the results demonstrated in our work are way far from that. Other than these potential issues mentioned above, we do not see any other major concerns our work particularly introduces.\n\n17\n\nUnder review as a conference paper at ICLR 2023\n\nFigure 13: Additional qualitative results in Container Fitting. We show eigen-lengths in two views together with the underlying object following Fig. 12 (d). (a)-(o) are successful cases where the learned planes correctly separate out the largest cavity in the object. (p)-(t) show failure cases.\n\n18\n\n(cid:11)(cid:68)(cid:12)(cid:11)(cid:69)(cid:12)(cid:11)(cid:70)(cid:12)(cid:11)(cid:71)(cid:12)(cid:11)(cid:72)(cid:12)(cid:11)(cid:73)(cid:12)(cid:11)(cid:74)(cid:12)(cid:11)(cid:75)(cid:12)(cid:11)(cid:76)(cid:12)(cid:11)(cid:77)(cid:12)(cid:11)(cid:78)(cid:12)(cid:11)(cid:79)(cid:12)(cid:11)(cid:80)(cid:12)(cid:11)(cid:81)(cid:12)(cid:11)(cid:82)(cid:12)(cid:11)(cid:83)(cid:12)(cid:11)(cid:84)(cid:12)(cid:11)(cid:85)(cid:12)(cid:11)(cid:86)(cid:12)(cid:11)(cid:87)(cid:12)(cid:73)(cid:85)(cid:82)(cid:81)(cid:87)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:87)(cid:82)(cid:83)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:73)(cid:85)(cid:82)(cid:81)(cid:87)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:87)(cid:82)(cid:83)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:73)(cid:85)(cid:82)(cid:81)(cid:87)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:87)(cid:82)(cid:83)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)(cid:73)(cid:85)(cid:82)(cid:81)(cid:87)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:87)(cid:82)(cid:83)(cid:3)(cid:89)(cid:76)(cid:72)(cid:90)(cid:76)(cid:81)(cid:86)(cid:87)(cid:68)(cid:81)(cid:70)(cid:72)Under review as a conference paper at ICLR 2023\n\nFigure 14: Full correlation plots and respective R2 values between ground truth measurements and predicted eigen-lengths from Eigen-Length-Implicit.\n\nFigure 15: Full correlation plots and respective R2 values between ground truth measurements and predicted eigen-lengths from Eigen-Length-Grounded.\n\n19\n\nD7XEH<3UHGLFWLRQ5 D7XEH=3UHGLFWLRQ5 D7XEH<3UHGLFWLRQ5 D7XEH=3UHGLFWLRQ5 E&\\OLQGHU53UHGLFWLRQ5 E&\\OLQGHU+3UHGLFWLRQ5 E&\\OLQGHU53UHGLFWLRQ5 E&\\OLQGHU+3UHGLFWLRQ5 F6SKHUH53UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 I0XJ+ROGHU53UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 G)LW2EMHFW;3UHGLFWLRQ5 G)LW2EMHFW<3UHGLFWLRQ5 G)LW2EMHFW=3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 H7RS2EMHFW;3UHGLFWLRQ5 H7RS2EMHFW<3UHGLFWLRQ5 Under review as a conference paper at ICLR 2023\n\nFigure 16: Full correlation plots and respective R2 values between human-hypothesized measurements and predicted eigen-lengths in rotated Tube Passing and rotated Container Fitting, respectively. Correspondences between predicted eigen-lengths and human-hypothesized ones can be observed.\n\n20\n\n0.60.81.01.21.41.61.8Tube Y0.60.81.01.21.41.61.82.0Prediction 1R2 = 0.01560.60.81.01.21.41.61.8Tube Z0.60.81.01.21.41.61.82.0Prediction 1R2 = 0.88590.60.81.01.21.41.61.8Tube Y0.40.60.81.01.21.41.61.82.0Prediction 2R2 = 0.98520.60.81.01.21.41.61.8Tube Z0.40.60.81.01.21.41.61.82.0Prediction 2R2 = 0.00210.00.51.01.5(d) Fit, Object X0.000.250.500.751.001.251.501.75Prediction 1R2 = 0.54040.00.51.01.5(d) Fit, Object Y0.000.250.500.751.001.251.501.75Prediction 1R2 = 0.89190.00.51.01.5(d) Fit, Object Z0.000.250.500.751.001.251.501.75Prediction 1R2 = 0.43260.00.51.01.5(d) Fit, Object X0.000.250.500.751.001.251.50Prediction 2R2 = 0.50330.00.51.01.5(d) Fit, Object Y0.000.250.500.751.001.251.50Prediction 2R2 = 0.42080.00.51.01.5(d) Fit, Object Z0.000.250.500.751.001.251.50Prediction 2R2 = 0.99630.00.51.01.5(d) Fit, Object X0.000.250.500.751.001.251.501.75Prediction 3R2 = 0.89390.00.51.01.5(d) Fit, Object Y0.000.250.500.751.001.251.501.75Prediction 3R2 = 0.58180.00.51.01.5(d) Fit, Object Z0.000.250.500.751.001.251.501.75Prediction 3R2 = 0.5496Under review as a conference paper at ICLR 2023\n\nFigure 17: Visualization of learned geometry groundings in rotated Tube Passing and rotated Container Fitting, respectively. Vectors are visualized as arrows, and planes are visualized as disks. For Container Fitting, we also show the underlying geometry (before rotation) for better reference. The learned vectors and planes roughly align with the rotated object. Regions of interest like drawers are also selected by planes.\n\nFigure 18: Visualization of the eigen-lengths learned with OR-AND clauses. Green and yellow, purple and red eigen-lengths belong to the same AND-group. It turns out that each group attends to one of the tubes and captures its width and height.\n\n21",
  "translations": [
    "# Summary Of The Paper\n\nThis paper presents an early attempt at learning geometric lengths from trails and explores how to transfer the learned geometric knowledge to solve a different task. Besides offering a problem formulation, this paper presents an evaluation framework based on finding evaluation correlations against ground truth lengths.\n\n# Strength And Weaknesses\n\nStrengths\n----------\n\nIdeas are clearly elaborated through the paper with adequate support of intuition in explanations.\n\nElaboration of experimentations is adequate for an early exploration of learning object lengths. \n\nInitial results are promising on the capability of learning lengths from trials.\n\nWeaknesses\n-------------\nThis paper is an early exploration of the topic. Consequently, the experimentation is limited to a single dataset and simplistic tasks. Can this methodology be used to improve challenging tasks such as relative pose estimation and active visual navigation?\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThere are no major issues related to the clarity of this paper as the idea is simple and intuitive.\n\n# Summary Of The Review\n\nOverall this is initial research. My main criticism is the lack of exploration or at least discussion on how to use this idea in more complex problems. I would like to see at least some discussion in this regard.\n\n# Correctness\n\n4: All of the claims and statements are well-supported and correct.\n\n# Technical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.\n\n# Empirical Novelty And Significance\n\n2: The contributions are only marginally significant or novel.",
    "# Summary Of The Paper\nThe paper titled \"Toward Learning Geometric Eigen-Lengths Crucial for Robotic Fitting Tasks\" addresses the challenge of automatically identifying geometric measurements, termed eigen-lengths, that are essential for robotic fitting tasks. The authors propose a novel learning problem and establish a benchmark suite consisting of tasks, datasets, and evaluation metrics to assess the effectiveness of learning these measurements. The methodology involves using a minimal neural network architecture, specifically PointNet, to learn eigen-lengths from binary success/failure supervision during fitting trials. Key findings include the successful correlation of learned eigen-lengths with human-identified measurements, improvements in measurement accuracy through geometric grounding, and the potential for reusability of learned eigen-lengths across multiple tasks.\n\n# Strength And Weaknesses\nThe primary contribution of the paper is the introduction of a new learning problem focused on geometric eigen-lengths, which addresses a significant gap in robotic manipulation research. The establishment of a benchmark suite is a notable strength, providing a foundation for future research in this area. The methodology is well-structured, and the use of binary supervision is innovative, allowing for effective learning from limited data. However, a weakness is the reliance on human-hypothesized measurements for validation, which may introduce biases. Additionally, the paper could benefit from a more extensive discussion on the limitations of the proposed approach and how it could be applied to real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly presents its contributions and findings. The methodology is described in sufficient detail, allowing for reproducibility. The novelty lies in the specific focus on geometric eigen-lengths for fitting tasks, a topic that has not been thoroughly explored in prior work. However, some technical sections could be expanded for clarity, particularly regarding the implementation details and the multi-task learning framework. The visualizations of learned eigen-lengths and grounding provide valuable insights but could be enhanced with more comparative analyses to strengthen the claims made.\n\n# Summary Of The Review\nOverall, the paper presents a significant advancement in the field of robotic fitting tasks by introducing the concept of learning geometric eigen-lengths. The proposed methodology is innovative and the establishment of a benchmark suite is commendable. However, the paper could improve by addressing potential biases in validation and providing clearer explanations of its technical components.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper addresses the challenge of learning geometric eigen-lengths crucial for robotic manipulation tasks, aiming to minimize human prior knowledge in the process. The authors propose a framework that utilizes PointNet networks to extract features from point clouds representing objects and environments, allowing the prediction of eigen-lengths that determine fitting feasibility. The methodology includes a benchmark suite of diverse tasks, and results demonstrate that the model can effectively learn meaningful eigen-lengths from binary supervision, significantly correlating with human-defined measures, particularly when enhanced by a geometry-grounded approach.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to a novel learning problem that advances representation learning in robotics. The establishment of a benchmark suite with diverse tasks and a large-scale dataset enhances reproducibility and provides a solid foundation for future research. Furthermore, the focus on low-dimensional representations improves interpretability, offering insights into the model's decision-making process. However, the reliance on human-defined tasks and ground truths may introduce bias, and the model's performance with complex geometries is limited. Additionally, the fixed number of eigen-lengths predetermined for learning may hinder adaptability in tasks with varying requirements.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The quality of the experimental design is commendable, with a comprehensive evaluation of various tasks and quantitative metrics. The novelty is significant, as it introduces a new perspective on learning geometric representations in robotics. The reproducibility is bolstered by the inclusion of a benchmark suite and a large dataset, although the reliance on human inputs could affect the generalizability of the results.\n\n# Summary Of The Review\nOverall, the paper presents a meaningful contribution to the field of robotic manipulation by introducing a novel framework for learning geometric eigen-lengths. While the innovative approach and strong experimental results are commendable, the reliance on human-defined tasks and potential limitations in generalization to complex geometries warrant further exploration.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to learning geometric eigen-lengths that are crucial for robotic fitting tasks. It formulates the learning problem of discovering low-dimensional eigen-lengths from object shapes and environmental contexts through a benchmark suite that includes various tasks, data, and evaluation metrics. The methodology involves using pairwise comparisons of learned eigen-lengths from both successful and failed fitting trials, employing a minimal architecture based on PointNet for encoding, and introducing grounding techniques using geometric primitives. The findings demonstrate strong correlations between learned eigen-lengths and human-hypothesized values, showcasing improved robustness and data efficiency through geometry grounding.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its formulation of a unique learning problem that addresses a gap in robotic manipulation tasks, alongside the development of a comprehensive benchmark suite that enables future research. The use of minimal network architecture and grounding techniques enhances the interpretability and robustness of the learned eigen-lengths. However, the paper could benefit from a more detailed discussion of the limitations and potential challenges in applying this approach to more complex, real-world scenarios. Additionally, while the results are promising, further validation across diverse tasks would strengthen the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible for readers unfamiliar with the topic. The quality of the experiments is commendable, with a significant amount of data generated for training and testing. The novelty is evident in the focus on learning geometric eigen-lengths, a relatively unexplored area in robotic manipulation. The reproducibility is facilitated by the detailed description of the experimental methodology, including the data generation process and network training settings, although sharing code and datasets would enhance this aspect further.\n\n# Summary Of The Review\nOverall, this paper makes a significant contribution to the field of robotic manipulation by introducing the concept of learning geometric eigen-lengths and providing a solid framework for their discovery. The methodology is innovative and the empirical results are strong, although further validation in more complex scenarios would be beneficial. The findings have the potential to influence future research directions in robotic fitting tasks.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces a novel learning problem aimed at discovering low-dimensional geometric eigen-lengths that are essential for robotic fitting tasks. The authors propose a methodology that leverages weak supervision based on task success or failure, minimizing the reliance on extensive labeled data. The findings indicate a strong correlation between the learned eigen-lengths and human-hypothesized measurements, suggesting that the model effectively captures meaningful geometric features. Additionally, a comprehensive benchmark suite is established to facilitate evaluation and comparison with existing methods.\n\n# Strengths And Weaknesses\n1. **Novelty of the Problem:**\n   - **Strength:** The focus on low-dimensional geometric eigen-lengths in robotic fitting tasks highlights an underexplored area, making a significant contribution to both robotics and representation learning.\n   - **Limitation:** The theoretical foundation for the chosen methods may not be robust, potentially limiting the generalizability of the findings.\n\n2. **Benchmark Suite:**\n   - **Strength:** The comprehensive benchmark suite allows for better evaluation of methods and encourages further research.\n   - **Limitation:** Its narrow focus on specific fitting tasks may restrict the applicability of the findings in broader real-world scenarios.\n\n3. **Learning from Weak Supervision:**\n   - **Strength:** The use of weak supervision enables the learning of geometric eigen-lengths with minimal labeled data requirement.\n   - **Limitation:** The reliance on binary success and failure signals may oversimplify the learning process, potentially missing valuable nuanced information.\n\n4. **Geometric Grounding:**\n   - **Strength:** Enhances the accuracy and interpretability of learned eigen-lengths, allowing for a more intuitive understanding of measurements.\n   - **Limitation:** Geometric grounding could complicate the model and its training process, reducing flexibility for tasks with varying complexities.\n\n5. **Reusability of Eigen-Lengths:**\n   - **Strength:** The exploration of reusability across tasks is promising for developing generalizable robotic systems.\n   - **Limitation:** The current approach may not effectively capture task-specific nuances, which could hinder performance on novel tasks.\n\n6. **High Correlation with Ground Truth:**\n   - **Strength:** Strong correlation with human-hypothesized measurements indicates meaningful feature capture.\n   - **Limitation:** High correlation alone does not guarantee robustness in diverse environments, and further testing is needed.\n\n7. **Multi-Task Learning Framework:**\n   - **Strength:** This framework simulates human-like adaptability in learning by selecting relevant eigen-lengths for new tasks.\n   - **Limitation:** Increased complexity in task management and potential high computational resource requirements could pose challenges.\n\n8. **Potential for Future Research:**\n   - **Strength:** Opens new avenues in geometric representation learning and robotic manipulation.\n   - **Limitation:** The lack of exploration into leveraging additional signals beyond binary outcomes may limit its future research impact.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the contributions and methodologies utilized. The quality of writing is high, with appropriate technical rigor. Novelty is evident in its approach to tackling a less-explored problem, although the reproducibility may be hindered by the reliance on specific benchmarks and the complexity of the models proposed.\n\n# Summary Of The Review\nOverall, the paper makes a significant contribution to the field of robotic fitting through its novel approach to learning geometric eigen-lengths and establishing a comprehensive benchmark suite. However, the theoretical foundation and generalizability of the findings need further strengthening to enhance the impact of the research.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThis paper introduces a novel framework for identifying critical geometric properties essential for robotic fitting tasks, referred to as \"geometric eigen-lengths.\" The authors propose a method that automatically discovers these dimensions through visual observation and spatial reasoning, marking a departure from traditional high-dimensional representation techniques. Key contributions include the definition of a new learning problem centered on low-dimensional eigen-lengths, the establishment of a comprehensive benchmark suite for evaluation, a weak supervision learning approach, and a framework for multi-task learning. Experimental results demonstrate high correlation between learned eigen-lengths and expected measurements, as well as improved robustness and adaptability in robotic manipulation tasks.\n\n# Strength And Weaknesses\nThe paper presents several strengths, including its innovative approach to defining a learning problem that focuses on geometric properties, which contrasts sharply with existing methods. The creation of a benchmark suite is a notable contribution that facilitates the evaluation of future work in this domain. Additionally, the weak supervision approach allows for effective learning without extensive labeled data, which is a significant advantage. However, the reliance on geometric grounding may introduce biases based on the chosen geometric primitives, and the framework's applicability to complex tasks is not fully explored. Addressing these limitations could enhance the robustness and generalizability of the proposed method.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its contributions and methodology. The quality of the writing is high, with thorough explanations of the concepts and experimental results. The novelty of the approach is significant, particularly in the context of integrating geometric grounding into machine learning for robotic tasks. Reproducibility is supported through detailed descriptions of the data generation process and network architecture, though the authors could further enhance this by providing code or data access.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to learning geometric properties for robotic fitting tasks. While the contributions are significant, particularly in terms of weak supervision and multi-task learning, potential biases in geometric grounding and the handling of complex tasks represent areas for future improvement. The work lays a strong foundation for further exploration in automated geometric reasoning and representation learning.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper presents a novel approach to adversarial training aimed at improving the robustness and generalization capabilities of deep learning models. The authors argue that traditional adversarial training methods often lead to overfitting on adversarial examples, which negatively impacts performance on clean data. They propose a new framework that includes a self-adaptive learning rate mechanism to dynamically adjust the intensity of adversarial examples during training. The paper also introduces a benchmark suite for evaluating the effectiveness of their approach across various datasets and tasks. Empirical results show that their method significantly enhances model robustness while maintaining performance on clean data.\n\n# Strengths and Weaknesses\n**Strengths:**\n- The self-adaptive learning rate mechanism is an innovative contribution that addresses the challenge of balancing robustness against adversarial attacks with generalization to clean data.\n- The thorough evaluation across multiple datasets and attack scenarios demonstrates the proposed method's advantages over traditional adversarial training techniques.\n- The paper is well-structured and clearly written, with detailed explanations of methodologies and insightful discussions regarding the implications of the results.\n\n**Weaknesses:**\n- The paper lacks a robust theoretical analysis that substantiates why the adaptive mechanism is effective, which could strengthen the overall claims.\n- The focus on a specific set of adversarial attacks may limit the comprehensiveness of the evaluation; a broader range of attack types would provide a more thorough assessment.\n- The computational overhead associated with the self-adaptive mechanism is not adequately addressed, raising concerns about scalability and efficiency in real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized and clearly articulated, making it accessible to the reader. The methodology is presented in a detailed manner, allowing for potential reproducibility. However, the lack of theoretical backing might hinder the understanding of the underlying principles driving the proposed approach. The novelty of the self-adaptive learning rate mechanism stands out, although the focus on a limited set of adversarial attacks could affect the perceived robustness of the findings.\n\n# Summary Of The Review\nOverall, this paper makes a significant contribution to adversarial training by proposing a novel framework that enhances model robustness while maintaining generalization capabilities. While the empirical results are promising, addressing theoretical foundations and scalability concerns would further strengthen the work.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled \"Toward Learning Geometric Eigen-lengths Crucial for Robotic Fitting Tasks\" presents a novel approach to learning geometric eigen-lengths, positing that this advancement will significantly enhance robotic perception and interaction with environments, specifically in fitting tasks. The authors introduce a new learning problem, develop a benchmark suite for evaluating performance, and explore solutions that purportedly allow robots to learn with minimal supervision. Despite claims of high correlation between learned eigen-lengths and human measurements, the improvements reported are marginal and suggest a basis built on existing methodologies rather than groundbreaking innovation.\n\n# Strength And Weaknesses\nThe paper claims several substantial contributions, including the introduction of a new learning problem and the development of a benchmark suite. However, the novelty of the proposed problem is questionable, as it builds on existing representation learning techniques without offering significant advancements. The exploration of solutions is framed as innovative, yet the results do not convincingly demonstrate a major leap in capability or efficiency. Furthermore, the vague description of the benchmark suite and the weak empirical evidence supporting the reusability claim detracts from the overall impact of the work.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is mixed; while the structure is logical, the descriptions of the benchmark suite and tasks lack sufficient detail, which raises concerns about reproducibility. The quality of the writing is generally good, but the overstatements regarding the significance of the findings undermine the overall message. In terms of novelty, while the authors present the work as a significant advance, the reliance on existing techniques and the marginal nature of the results suggest that the contributions may not be as original as claimed.\n\n# Summary Of The Review\nWhile the paper raises important points about geometric eigen-lengths and their potential applications in robotics, the claims regarding their significance are overstated. The contributions, methodology, and results do not convincingly support the authors' assertions of a paradigm shift in the field, suggesting a need for more rigorous evaluation and validation of the proposed approaches.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThis paper presents an innovative approach to learning low-dimensional geometric eigen-lengths that significantly improve robotic fitting tasks. The authors establish a benchmark suite with an extensive dataset of 80,000 training and 25,000 testing pairs, emphasizing tasks such as tube passing, cylinder fitting, and container fitting. The findings indicate a marked performance improvement, with success rates of 83% compared to prior methods' 78%. Additionally, the methodology includes a novel formulation that extracts eigen-lengths from binary success/failure signals, demonstrating promising results in multi-task learning scenarios.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its systematic approach to enhancing robotic fitting tasks through the introduction of learned eigen-lengths, which are shown to adapt well across different tasks. The extensive dataset and the incorporation of diverse object models reflect a significant improvement in methodology. However, weaknesses include the slightly lower-than-claimed correlation (R² values around 0.85) between learned eigen-lengths and human hypothesized measurements, which raises concerns about the robustness of the findings across all scenarios. Furthermore, while the results indicate improvement, the authors acknowledge challenges in generalizing across tasks, which could limit applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible to readers. The methodology is detailed, allowing for reproducibility; however, the reliance on correlation metrics that did not meet initial expectations may raise questions about the quality of the findings. The concept of learning geometric eigen-lengths is novel and adds significant value to the field, though the empirical results suggest that further validation may be needed to fully establish the reliability of the approach.\n\n# Summary Of The Review\nOverall, the paper presents a compelling contribution to the field of robotics through the learning of geometric eigen-lengths for fitting tasks. While the methodology is robust and shows promising results, the discrepancies in correlation analysis and generalization challenges indicate areas for further research.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel approach to learning geometric eigen-lengths in robotic systems, positing that these representations can enhance task performance across various fitting tasks. The methodology includes a framework reliant on binary success/failure supervision to train models on identifying crucial geometric features. The findings suggest that the learned eigen-lengths are interpretable and can be reused effectively across multiple tasks, potentially improving the accuracy and robustness of robotic fitting tasks.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to representing geometric features that could lead to improved robotic performance in fitting tasks. However, there are several weaknesses that undermine its contributions. The assumption that learning systems can mimic human-like reasoning may neglect the distinct characteristics of robotic cognition. Furthermore, the reliance on binary supervision oversimplifies feedback mechanisms, potentially limiting the learning process. The paper's claims regarding the interpretability and generality of learned representations are not sufficiently validated, and the evaluation metrics used may not capture the full spectrum of task performance. Additionally, the fixed hyperparameter for the number of eigen-lengths may hinder adaptability to varying task complexities.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, but some concepts, such as the interpretability of learned representations, require clearer explanations and rigorous validation. The novelty of focusing on geometric eigen-lengths is commendable; however, the paper does not sufficiently address the limitations of its approach, particularly in dynamic environments. Reproducibility could be enhanced through more detailed descriptions of experimental setups and the learning paradigm used.\n\n# Summary Of The Review\nThe paper presents an interesting approach to geometric eigen-lengths in robotic systems, but it is hindered by several assumptions and limitations that may affect its applicability. The reliance on binary feedback and fixed hyperparameters could limit the robustness and adaptability of the proposed methods in real-world scenarios.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a novel learning problem aimed at discovering essential geometric eigen-lengths for robotic fitting tasks, addressing a notable gap in existing research. The authors propose a framework to learn these eigen-lengths through pairwise comparisons of object and environment measurements, utilizing binary supervision signals from a curated set of tasks. Key findings include the successful demonstration of a minimal network architecture that encodes geometric information and the identification of strong correlations between learned eigen-lengths and human-defined measurements. Additionally, the paper explores the robustness and data efficiency of geometry-grounded eigen-lengths and their transferability across tasks.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative approach to automating the discovery of low-dimensional geometric features, which is particularly relevant for enhancing robotic manipulation. The introduction of a benchmark suite allows for systematic evaluation of the proposed methods. However, the paper could benefit from a more comprehensive experimental evaluation across diverse robotic tasks to further validate the findings. Additionally, while the proposed network architecture is minimal, further exploration of its limitations in more complex scenarios would enhance the robustness of the claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its objectives, methodologies, and findings, contributing to its overall clarity. The quality of the writing is high, with appropriate use of technical language. The novelty of the research is significant, as it diverges from traditional high-dimensional feature learning to focus on low-dimensional geometric eigen-lengths. The reproducibility of the results is supported by a detailed description of the methodologies and the introduction of a benchmark suite, although the availability of code and datasets would further enhance this aspect.\n\n# Summary Of The Review\nOverall, this paper presents a compelling contribution to the field of robotics by introducing a novel approach to learning geometric eigen-lengths, supported by rigorous methodology and promising findings. While the paper is clear and well-written, further empirical validation across a broader range of tasks would strengthen its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to enhancing the robustness of neural networks in adversarial settings. The authors propose a new algorithm that combines adversarial training with dynamic perturbation techniques, resulting in improved model performance on benchmark datasets. The methodology includes comprehensive experiments demonstrating the effectiveness of their approach against standard adversarial attacks, and the findings indicate a significant reduction in vulnerability, suggesting the potential for broader applications in real-world scenarios.\n\n# Strength And Weaknesses\nStrengths of the paper include a well-defined motivation that underscores the importance of addressing adversarial attacks in neural networks. The theoretical framework is robust, providing a solid basis for the proposed method. The experimental results are promising, with clear improvements over existing methods in terms of accuracy and robustness. However, weaknesses include a potentially limited range of adversarial attacks tested, which may not fully capture the generalizability of the method. Additionally, some sections of the methodology lack clarity, making it difficult for readers to replicate the work.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, though certain sections could benefit from further elaboration to enhance clarity. The figures and tables included are relevant, but clearer captions and explanations would improve understanding. The novelty of the proposed approach is noteworthy; however, the reproducibility of the results may be challenged by the lack of detailed implementation guidelines. A more thorough discussion of related work could also help to contextualize the contributions within the broader field.\n\n# Summary Of The Review\nThis paper offers an innovative solution to a pressing issue in machine learning, specifically in enhancing the robustness of neural networks against adversarial attacks. While the contributions are significant, further refinement in methodology clarity and experimental validation is necessary for full impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents a novel approach to the learning of geometric eigen-lengths, which are critical in determining the feasibility of fitting objects into various environments—essential for robotic tasks. It proposes a new learning problem focused on automatically discovering these geometric quantities, akin to the intuitive assessments humans make regarding dimensions. The methodology involves learning from both successful and failed fitting trials, leveraging a benchmark suite that includes fitting tasks, datasets, and evaluation metrics. The findings demonstrate the potential for reusability of learned eigen-lengths across different tasks and highlight the importance of geometric grounding for accuracy in predictions.\n\n# Strength And Weaknesses\nThe paper makes significant contributions by formulating a new learning problem, establishing a benchmark suite for evaluation, and exploring solutions for learning geometric eigen-lengths from binary task supervision. One of its strengths is the emphasis on reusability, which could inspire future research in this domain. However, a potential weakness lies in the challenges related to grounding eigen-length predictions, which are acknowledged but not fully addressed in this work. The exploration of solutions, while promising, may require more depth to fully understand the implications and limitations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, methodology, and findings. The quality of the research appears robust, with a systematic approach to the proposed problem. The novelty is significant as it addresses an underexplored area in robotic perception and manipulation. Reproducibility is supported by the establishment of a benchmark suite, although the paper could benefit from more details on the experimental setups and parameters used in the evaluation.\n\n# Summary Of The Review\nOverall, the paper presents a compelling framework for learning geometric eigen-lengths, with significant contributions to both methodology and empirical evaluation. While it successfully establishes a foundation for future research, further exploration of grounding challenges and detailed experimental protocols would enhance its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Toward Learning Geometric Eigen-Lengths Crucial for Robotic Fitting Tasks\" presents a novel approach to learning low-dimensional geometric eigen-lengths that are essential for object fitting in robotic tasks. The authors propose a new learning problem, introduce a benchmark suite including tasks, data, and evaluation metrics, and explore the feasibility of learning these eigen-lengths through fitting trials. The methodology involves two network architectures: a minimal eigen-length learning pipeline and a geometry-grounded framework. The results demonstrate a strong correlation between the learned eigen-lengths and ground truth measurements, with an observed improvement in predictions when employing geometry grounding.\n\n# Strength And Weaknesses\nThe paper makes significant contributions by addressing a gap in the literature regarding low-dimensional geometric measures and their interpretability in robotic tasks. The introduction of a benchmark suite is particularly valuable for future research. However, the reliance on binary task success/failure supervision may limit the generalizability of the learned representations. Additionally, while the results are promising, the scope of the experiments could be expanded to include more complex scenarios to validate the robustness of the proposed methods.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and articulately presents its ideas, making it easy for readers to follow the methodology and results. The quality of the experiments is commendable, although more detail regarding the experimental setup would enhance reproducibility. The novelty lies in the focus on learning geometric measures from a low-dimensional perspective, which is less explored in existing literature. Overall, the contributions are significant, but the paper could benefit from a more thorough discussion on the implications and limitations of the learning problem formulation.\n\n# Summary Of The Review\nThis paper presents a compelling approach to learning geometric eigen-lengths for robotic fitting tasks, contributing to both theoretical and practical aspects of the field. While the proposed methods show promise and the results are encouraging, further exploration of complex scenarios and alternative supervisory signals could enhance the robustness and applicability of the findings.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper titled \"Toward Learning Geometric Eigen-Lengths Crucial for Robotic Fitting Tasks\" addresses the challenge of automatically learning geometric eigen-lengths, which are critical for enhancing robotic fitting tasks. The authors introduce a structured methodology for predicting these lengths based on the geometry of objects and their environments, leveraging neural network architectures. The experiments conducted validate the proposed approach, demonstrating a strong correlation between the learned eigen-lengths and human-hypothesized ground truths, thereby establishing the robustness and practical applicability of the method across various tasks.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its clear formulation of the learning problem and the thorough experimental design, which includes multiple tasks and well-defined evaluation metrics. The authors successfully differentiate their work from existing literature, showcasing the novelty of their approach in the context of geometry learning. However, a notable weakness is the limited exploration of potential challenges encountered during the training and evaluation phases, as well as a lack of extensive discussion on the broader implications of the findings in real-world robotic applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured, with a logical flow from the problem statement through methodology to results. The clarity of presentation enhances understanding, making it accessible to readers with varying levels of expertise in the domain. The novelty of the proposed approach is significant, as it contributes to the relatively underexplored area of learning geometric representations for robotics. The reproducibility of the results is supported by detailed descriptions of the methodologies employed, although the paper could benefit from sharing code or data to facilitate further validation by the research community.\n\n# Summary Of The Review\nOverall, the paper makes a meaningful contribution to the field of robotic fitting tasks by introducing a novel approach to learning geometric eigen-lengths. The methodology is sound, supported by robust experimental results. However, there is room for improvement in discussing the challenges faced during the research and the implications of the findings.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper investigates the role of low-dimensional geometric eigen-lengths in determining the feasibility of robotic fitting tasks. It introduces a novel learning paradigm that derives these eigen-lengths from empirical fitting trials using a comprehensive dataset of object-environment pairs. The methodology involves defining fitting tasks based on pairwise comparisons of eigen-lengths, employing a PointNet-based architecture for feature extraction, and utilizing multi-task learning frameworks to enhance the adaptability of learned representations. The findings demonstrate a strong correlation between learned eigen-lengths and human-identified metrics, indicating the potential for improved interpretability and adaptability in robotic systems.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to utilizing geometric eigen-lengths for robotic fitting tasks, as well as the comprehensive dataset that supports the empirical evaluation of the proposed methods. The use of a minimal architecture and the integration of geometry grounding techniques enhance the interpretability of the learned representations. However, the paper could improve on the clarity of its explanations regarding the geometry grounding framework and may benefit from a more detailed discussion of the implications of learned eigen-lengths on real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is generally good, with a clear structure that guides the reader through the methodology and findings. However, some sections, particularly concerning geometry grounding, could be elaborated to enhance understanding. The quality of the research is high, with thorough empirical analysis and a strong theoretical framework. The novelty is significant, as the approach to learning geometric eigen-lengths is relatively unexplored in the context of robotics. Reproducibility is supported by the provision of a detailed dataset and evaluation metrics, although additional details on hyperparameter tuning and training procedures could further aid reproducibility.\n\n# Summary Of The Review\nOverall, this paper presents a significant contribution to the field of robotic manipulation by introducing a novel framework for learning geometric eigen-lengths. While it demonstrates strong empirical results and theoretical insights, certain aspects could benefit from clarification for improved accessibility. \n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper proposes a novel learning paradigm aimed at enhancing representation learning in robotic fitting tasks. The authors introduce a benchmark suite for evaluating their method, which relies on measuring learned eigen-lengths through geometric grounding. However, the methodology is criticized for its simplistic approach, relying on binary success/failure signals during training and presenting tasks that lack real-world relevance. The authors claim advancements in the field, but the findings do not convincingly demonstrate significant improvements over existing methods.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its attempt to address representation learning through a new lens. However, the weaknesses are pronounced; the proposed benchmark suite is poorly defined and introduces potential biases. The reliance on simplistic binary signals fails to capture the complexities of real-world robotic tasks, limiting the robustness of the learned models. Additionally, the tasks designed for evaluation appear contrived, lacking rigorous metrics that would provide meaningful insights into the proposed method's effectiveness. The authors also overlook important aspects such as biases in the training data and practical implications of their framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper suffers from a lack of clarity in its contributions and findings. The novelty appears overstated, as the proposed method does not significantly advance the state-of-the-art in representation learning. Furthermore, the discussion on future work is vague, and the authors fail to engage critically with the limitations of their approach. Reproducibility is questionable due to insufficient detail in the benchmark suite and methodological rigor.\n\n# Summary Of The Review\nIn summary, the paper presents an interesting but ultimately superficial exploration of a novel learning problem in robotics. The contributions are undercut by methodological weaknesses and a lack of empirical validation, leaving significant questions regarding the practical utility of the proposed methods.\n\n# Correctness\n3/5\n\n# Technical Novelty And Significance\n2/5\n\n# Empirical Novelty And Significance\n2/5",
    "# Summary Of The Paper\nThis paper presents a novel approach to discovering low-dimensional geometric eigen-lengths essential for robotic fitting tasks. The authors propose a learning framework that enables robots to automatically derive these geometric quantities from binary success/failure signals, thus minimizing the need for extensive labeled data. Key findings indicate that the learned eigen-lengths demonstrate a strong correlation with human-hypothesized measurements, and the proposed methodology shows promising versatility across multiple tasks.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative formulation of the learning problem and its comprehensive benchmark suite, which lays the groundwork for future research in robotic fitting tasks. The ability to learn from weak supervision and the high correlation with human intuition significantly contribute to the paper's impact. However, potential weaknesses may include the specificity of the benchmark tasks and the need for further validation in real-world scenarios, which could limit the generalizability of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, making it accessible to a broad audience. The quality of the methodology appears robust, with thorough explanations of the learning process and evaluations. The novelty of the approach is significant, as it combines geometric grounding with weak supervision. However, reproducibility may be a concern if the benchmark suite is not adequately detailed, potentially hindering other researchers from replicating the results.\n\n# Summary Of The Review\nOverall, this paper represents a significant advancement in the field of robotics, particularly in the context of fitting tasks. The innovative methodology, strong empirical results, and potential for future research make it a noteworthy contribution. It is recommended for acceptance, with a focus on addressing the reproducibility aspects.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a theoretical exploration of geometric eigen-lengths and their application in robotic fitting tasks. It defines eigen-lengths as essential scalar measurements (e.g., height, width, diameter) that facilitate object manipulation and interaction with environments. The methodology involves proposing a framework for learning these eigen-lengths through minimal supervision and grounding them within geometric primitives, aiming for interpretable and generalizable representations. Findings suggest that leveraging human-like cognitive frameworks in robotic systems can enhance adaptability and knowledge transfer across tasks, while also raising questions about inductive biases and generalization capabilities in representation learning.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative theoretical framework that connects geometric properties to cognitive processes, offering insights into how robotic systems can effectively learn and generalize from limited supervision. The emphasis on grounding eigen-lengths in geometric primitives is particularly notable, as it opens avenues for improving interpretability and robustness in learned representations. However, a potential weakness is the reliance on theoretical constructs without extensive empirical validation, which may raise concerns about the practical applicability of the proposed methods in real-world scenarios. Additionally, the discussion on inductive biases could benefit from more concrete examples or empirical data to strengthen its claims.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its theoretical concepts clearly, making it accessible to readers with varying levels of expertise in the field. The quality of the exposition is high, with a logical flow that facilitates understanding. The novelty of the approach is significant, as it challenges traditional paradigms in robotic learning by proposing a framework that emphasizes the importance of geometric concepts. However, the reproducibility of the theoretical claims may be limited due to the lack of empirical studies demonstrating the proposed methods in action, which is critical for validating the framework's effectiveness.\n\n# Summary Of The Review\nOverall, the paper offers a compelling theoretical perspective on geometric eigen-lengths and their role in robotic fitting tasks, pushing the boundaries of current understanding in representation learning. While the innovative concepts and potential implications for robotic systems are noteworthy, the lack of empirical validation raises questions about the practicality of the proposed framework.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThis paper introduces a novel framework that integrates multi-task learning with geometry grounding for the task of fitting objects in complex environments. The methodology relies on a combination of three network architectures: PointNet for classification, VectorNet for generating output vectors, and WeightNet for predicting weight distributions. The authors conducted extensive experiments using a dataset generated from ShapeNet, demonstrating strong correlations between predicted positions and ground truth measurements, particularly after implementing the geometry grounding mechanism.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its clear architectural design, which effectively combines various models to tackle the fitting task through multi-task learning. The use of geometry grounding has shown to significantly enhance the correlation of predictions with ground truth, highlighting the importance of geometric information in the problem domain. However, the paper lacks an extensive discussion on the broader implications of its findings and does not provide comparisons with other state-of-the-art methods, which could have contextualized its contributions better.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, with comprehensive details on the network architectures and training procedures. The methodology is reproducible, as the authors have indicated that the code will be made available on GitHub, along with details on hyperparameters and training setups. While the technical aspects are well articulated, the novelty of the approach could be better emphasized, particularly in relation to existing methods in the field.\n\n# Summary Of The Review\nOverall, this paper presents a solid contribution to the field with its innovative approach to geometry grounding and multi-task learning for object fitting tasks. The methodology is robust and reproducible, although the paper could benefit from a broader contextualization of its findings and clearer comparisons with existing solutions.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to discovering geometric eigen-lengths for robotic fitting tasks, emphasizing weak supervision as a means to learn these representations. The authors propose a benchmark suite for evaluating their method, claiming that their focus on low-dimensional eigen-lengths represents a significant departure from high-dimensional latent representations. However, the findings and methodologies used appear to reflect previous works in the domain without providing substantial differentiation or innovation.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its attempt to tackle the problem of learning geometric representations with weak supervision, potentially paving the way for efficient robotic fitting tasks. However, the weaknesses are pronounced, as the paper does not convincingly establish the novelty of its contributions compared to existing literature, such as the works of Tulsiani et al. (2017) and Manuelli et al. (2019). The methodologies employed are less innovative than established frameworks like InfoGAN and beta-VAE, and the proposed benchmark tasks lack complexity compared to earlier studies. Furthermore, the authors fail to adequately compare their results with richer training signal methods, which diminishes the robustness of their findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear in its presentation; however, the lack of distinctiveness in its contributions raises questions about its overall novelty. The quality of the experimental design is undermined by the limited scope of tasks, which affects reproducibility and generalizability. The attempt to connect the findings to existing literature on affordance learning and multi-task learning frameworks is not adequately substantiated, leading to a perception of weak grounding in the broader context.\n\n# Summary Of The Review\nOverall, while the authors aim to introduce a new framework for learning geometric eigen-lengths with weak supervision, they do not sufficiently differentiate their approach from established methods, nor do they provide a comprehensive evaluation to support their claims of novelty. The paper would benefit from deeper engagement with existing literature and a broader set of evaluation tasks to substantiate its contributions.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"TOWARD LEARNING GEOMETRIC EIGEN-LENGTHS CRUCIAL FOR ROBOTIC FITTING TASKS\" explores the novel concept of geometric eigen-lengths as fundamental measurements for robotic fitting tasks. The authors propose a methodology that involves learning these eigen-lengths through supervised learning with minimal supervision, utilizing a dataset of approximately 1200 common household objects. The findings indicate that the learned geometric eigen-lengths significantly improve the performance of robotic tasks, enhancing both accuracy and efficiency in fitting scenarios.\n\n# Strength And Weaknesses\nOne of the primary strengths of the paper is its innovative approach to defining and utilizing geometric eigen-lengths, which could have substantial implications for robotic manipulation tasks. The empirical results presented demonstrate the effectiveness of the proposed methodology, providing a solid basis for the claims made. However, the paper suffers from several weaknesses, including inconsistencies in terminology and formatting, which detract from its overall clarity. Additionally, some sections lack sufficient explanation, particularly regarding geometric grounding and notation, which could hinder reader comprehension.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents a novel concept and contributes valuable insights into robotic fitting tasks, the clarity of communication is compromised by typographical errors, inconsistent terminology, and awkward phrasing. The overall quality of the writing would benefit from a thorough proofreading to rectify these issues. The novelty of the proposed eigen-lengths is significant, but the lack of reproducibility due to insufficient methodological detail—such as the description of the learning algorithms and the definition of key terms—limits the paper's potential impact.\n\n# Summary Of The Review\nThis paper introduces an innovative concept of geometric eigen-lengths for robotic tasks, showcasing promising empirical results. However, the numerous clarity issues and inconsistencies in terminology detract from the overall quality and reproducibility of the work. A thorough revision is necessary to enhance the paper's readability and impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to learning geometric eigen-lengths aimed at improving fitting tasks within robotic manipulation. The authors propose a methodology that leverages binary success/failure signals for training and focuses on a fixed number of eigen-lengths as a hyperparameter. The findings suggest that learned eigen-lengths can enhance performance in simple fitting scenarios, although the paper acknowledges the limitations of its approach in dynamic environments and complex object interactions.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its clear presentation of a new concept in geometric learning, specifically the use of eigen-lengths for fitting tasks. The methodology is well-defined, and the experiments conducted yield promising results for the scoped tasks. However, the paper has notable weaknesses, including a limited exploration of dynamic object behaviors, a narrow range of object shapes considered, and a lack of discussion regarding multi-modal inputs. Furthermore, the implications for real-world applications and human-robot collaboration are not explored in depth, which could significantly enhance the paper's impact.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and easy to follow, with a logical flow that guides the reader through the contributions and findings. The quality of the experiments is adequate, but the reproducibility could be improved by providing more details on the experimental setups and parameter choices. While the concept of geometric eigen-lengths is novel, the overall approach could benefit from a broader exploration of its applicability and limitations.\n\n# Summary Of The Review\nOverall, the paper introduces an interesting approach to learning geometric representations for robotic fitting tasks, though it has significant limitations regarding scope and real-world applicability. Future research directions are suggested, but the current study requires a deeper exploration of its implications and broader contexts to maximize its impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"TOWARD LEARNING GEOMETRIC EIGEN-LENGTHS CRUCIAL FOR ROBOTIC FITTING TASKS\" introduces a novel approach to learning low-dimensional geometric eigen-lengths that are vital for predicting success in robotic fitting tasks. The authors develop a comprehensive benchmark suite, including a dataset of 75,000 training and 20,000 testing instances, designed to rigorously evaluate the proposed methods using statistical metrics such as correlation coefficients (R²). The methodology employs weak supervision through binary success/failure outcomes to train models, particularly using architectures like PointNet. The findings indicate a strong correlation (R² values approaching 0.9) between learned eigen-lengths and human-defined ground truths, highlighting the significance of geometry grounding in enhancing model robustness and the potential for transferring learned features to novel tasks.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its systematic approach to evaluating the learning of geometric eigen-lengths through well-defined benchmarks and robust statistical analysis. The extensive dataset allows for thorough testing across various geometries, thus ensuring the reliability of the results. However, a notable weakness is the lack of specific p-values and confidence intervals in the statistical analysis, which could raise questions about the transparency and reproducibility of the significance claims. Additionally, while the paper addresses the performance of different network architectures, a deeper exploration of the limitations of the proposed methods could enhance the discussion.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its findings in a clear, logical manner. The methodology is detailed enough to allow for reproducibility, although the absence of specific statistical values could hinder full reproducibility in practice. The novelty of the approach is significant, as it addresses a critical gap in robotic fitting tasks through the learning of geometric eigen-lengths, yet the overall contribution to the field could be made clearer by more explicitly stating how it compares to existing methods.\n\n# Summary Of The Review\nOverall, this paper presents a valuable contribution to the field of robotic fitting by proposing a novel methodology for learning geometric eigen-lengths and demonstrating its effectiveness through rigorous statistical evaluation. While the findings are promising, the lack of detailed statistical results may impact the reproducibility and clarity of the claims.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach for geometric eigen-length discovery, aimed at enhancing robotic applications through a multi-task learning framework. The methodology focuses on fitting tasks in controlled environments, utilizing a binary supervision mechanism to evaluate success or failure in eigen-length predictions. The findings suggest that the proposed method shows some promise in specific scenarios, but the authors acknowledge limitations regarding generalizability and the applicability of learned eigen-lengths to complex geometries and dynamic environments.\n\n# Strength And Weaknesses\nThe paper introduces a structured approach to geometric eigen-length identification, contributing to the field through its innovative use of multi-task learning. However, the contributions are limited by the narrow scope of the tasks explored, which do not encompass arbitrary shapes or complex object interactions. The reliance on binary supervision may undermine the robustness of the framework, particularly in scenarios requiring nuanced feedback. Additionally, the lack of exploration into dynamic environments and the potential biases in data collection raises concerns regarding the real-world applicability of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is relatively clear in its presentation, outlining the methodology and findings in a systematic manner. However, the novelty is somewhat constrained by the limited exploration of the framework's potential applications and the lack of a comprehensive discussion on generalizability across diverse tasks. Reproducibility may be an issue, as the authors do not provide sufficient detail on the experimental setup or data collection methods, which could hinder other researchers from replicating the results.\n\n# Summary Of The Review\nOverall, the paper presents an interesting but limited approach to geometric eigen-length discovery that lacks broader applicability and robustness. The methodology is promising but requires further development to address its shortcomings, particularly regarding generalizability and real-world applicability.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"Toward Learning Geometric Eigen-Lengths Crucial for Robotic Fitting Tasks\" presents a methodology for enabling robots to learn and measure geometric dimensions that significantly impact their ability to perform fitting tasks. The authors propose a learning framework that leverages weak supervision to derive geometric eigen-lengths, which they argue are critical for determining the feasibility of fitting objects into constrained spaces. Despite the seemingly straightforward nature of the problem, the authors claim that their contributions offer novel insights into representation learning and its application in robotics.\n\n# Strength And Weaknesses\nWhile the paper outlines a structured approach to learning geometric dimensions, its contributions appear to lack originality and depth. The methodology for establishing a benchmark suite is a well-trodden path in robotics research and does not provide substantial novelty. Furthermore, the authors' emphasis on weak supervision as a revolutionary approach seems overstated, as the principles of geometry and fitting have been well understood in engineering contexts for some time. On the other hand, the framework does provide a systematic way to address geometric fitting, which could be beneficial for practitioners looking for structured methodologies.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe writing is generally clear, but the novelty of the contributions is questionable. The paper fails to sufficiently differentiate its work from established literature, leading to concerns about its significance in the field. The reproducibility of the proposed methods is not adequately addressed, particularly regarding the specifics of their evaluation metrics, which are rather basic and lack rigor. This diminishes the potential impact of the findings on future research.\n\n# Summary Of The Review\nOverall, the paper presents a familiar approach to an established problem in robotics and does not sufficiently advance the state of knowledge in the field. While the authors aim to contribute to the understanding of geometric fitting tasks, their work is ultimately overshadowed by its reliance on well-known concepts and existing literature.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents a framework for the automatic discovery of low-dimensional geometric eigen-lengths in robotic fitting tasks. The authors employ a minimal network architecture that learns from binary success/failure signals, aiming to enhance the efficiency and accuracy of geometric representations in robotics. Their findings indicate that shared eigen-lengths can be beneficial across multiple tasks, suggesting potential for transfer learning and the discovery of novel geometric concepts that may not be readily recognized by humans.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to learning geometric eigen-lengths, which is well-aligned with contemporary challenges in representation learning within robotics. The proposed benchmark suite for evaluating learned eigen-lengths is a valuable contribution to the field. However, the methodology could be enriched by incorporating additional learning signals beyond binary outcomes, such as partial successes or task-specific gradients. Moreover, the framework could benefit from a more comprehensive understanding of spatial relations and contextual information, which could improve the accuracy of eigen-length predictions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clear, making it accessible to the reader. However, some sections could benefit from deeper elaboration on the implications of the findings, particularly regarding potential applications in real-world scenarios. The novelty of discovering eigen-lengths that humans may overlook is significant, yet more discussion on how to reproduce the results would enhance the paper's quality.\n\n# Summary Of The Review\nOverall, the paper provides a promising framework for learning geometric eigen-lengths in robotics, with several innovative contributions and practical implications. However, there are opportunities for improvement in the methodology and clarity of the presented ideas, particularly regarding the incorporation of richer contextual information and learning signals.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel learning problem centered on discovering low-dimensional geometric eigen-lengths specifically for robotic fitting tasks. The authors present a methodology that evaluates performance metrics across a range of tasks, demonstrating a high correlation between the learned eigen-lengths and human-hypothesized measurements. Notably, the reported R² values are close to or exceed 0.9 for most tasks, indicating strong predictive performance. The model is tested in various scenarios, revealing its robustness even under challenging conditions, such as low-resolution point clouds and extreme object scaling.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its significant contribution to the field of robotic fitting through the introduction of a new learning problem and the successful demonstration of its applicability across multiple tasks. The extensive benchmarking suite enhances the credibility of the performance claims, showcasing the versatility and robustness of the model. However, a potential weakness is the generalizability of the findings to other domains outside robotic fitting, which may require further exploration.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the methodology and findings. The quality of the experiments is high, with comprehensive performance evaluations. The novelty of the approach is noteworthy, as it addresses a specific gap in the literature regarding low-dimensional geometric representations. The reproducibility of the results appears feasible, given the detailed performance metrics and methodologies provided.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of robotics by proposing a novel approach to learning geometric representations. The robust performance metrics and versatility across various tasks support the authors' claims, making this work a significant addition to the existing literature.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel approach to [specific problem or area of research], introducing the concept of \"geometric eigen-lengths\" as a new metric for evaluating [specific application or model]. The authors employ a combination of [methodology details, e.g., theoretical analysis, experimental validation, etc.] to demonstrate the efficacy of their approach. Key findings indicate that the proposed metric significantly improves [specific outcomes, e.g., model performance, interpretability] over existing methods, suggesting its potential for broader applications in [relevant field or context].\n\n# Strength And Weaknesses\nThe main strengths of the paper include its innovative metric, which addresses a significant gap in the literature, and the thorough empirical evaluation that supports its claims. The integration of theoretical insights with practical applications is commendable. However, the paper suffers from a lack of clarity in certain sections, particularly in the introduction and conclusion, where lengthy sentences and abrupt transitions may confuse readers. Additionally, the definition of \"geometric eigen-lengths\" could be more explicit to enhance understanding.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper introduces a novel concept, the clarity in the writing detracts from its overall quality. The dense abstract and convoluted sentences in the introduction make it challenging to grasp the key contributions quickly. Furthermore, the methodology, while sound, lacks sufficient detail for complete reproducibility. The figures and tables, though relevant, need better integration into the text with clearer captions and explanations.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to [specific field] through the introduction of a novel metric. However, issues with clarity and presentation hinder its impact. Improved writing quality and more explicit definitions would greatly enhance the paper's accessibility and reproducibility.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.7703353304199387,
    -1.6914095830715579,
    -1.993699798068902,
    -1.852701439124472,
    -1.6547503512853499,
    -1.8225786555599555,
    -1.439108009747278,
    -2.067871384063801,
    -2.135020515912839,
    -1.9797015854841506,
    -1.7969473180698947,
    -1.6453971660903743,
    -2.0439341539474687,
    -1.8227697119995911,
    -1.7263100050512097,
    -1.82565892188477,
    -2.181869053178027,
    -1.8973472674368235,
    -1.7881943346050775,
    -1.9289043437974307,
    -1.9537291642049157,
    -1.8219010802020865,
    -1.8996799950209609,
    -1.96917138870652,
    -1.948597560869642,
    -1.9614509682337578,
    -2.04703083588891,
    -1.859564511228204,
    -1.6792479437903667
  ],
  "logp_cond": [
    [
      0.0,
      -2.3624056235494133,
      -2.3864335531519636,
      -2.3801320067273264,
      -2.381958517783769,
      -2.383301371243938,
      -2.4792595307090677,
      -2.3745188107015047,
      -2.386726756520761,
      -2.3973443019210334,
      -2.3841819564151243,
      -2.449379622982986,
      -2.3611077578703563,
      -2.3799237244520857,
      -2.3741708191888184,
      -2.3974832744437444,
      -2.4204608046288967,
      -2.389220033220624,
      -2.4205552617649944,
      -2.4022089349368763,
      -2.392271239051074,
      -2.416502750134683,
      -2.3806106373017126,
      -2.350251258829636,
      -2.390430950509014,
      -2.3991702621157605,
      -2.3587519923193265,
      -2.3893333937740002,
      -2.388576386593217
    ],
    [
      -1.4489991321422904,
      0.0,
      -1.2342488376484813,
      -1.1692202033412717,
      -1.203062717455739,
      -1.288376920617303,
      -1.4721720348718361,
      -1.2024966277801692,
      -1.256087060585709,
      -1.268192485797815,
      -1.250017154036497,
      -1.4590929698007384,
      -1.1871707921200827,
      -1.1361828895757444,
      -1.2615187363520635,
      -1.2514384734084714,
      -1.303660126733306,
      -1.2616353654246486,
      -1.3415100241117952,
      -1.3550556665958242,
      -1.309802827511636,
      -1.2609378048979172,
      -1.3135970957526921,
      -1.1722048105654739,
      -1.3145801554504366,
      -1.2609798328211397,
      -1.2635972289386697,
      -1.271375084482391,
      -1.3903508278914987
    ],
    [
      -1.6582323068632772,
      -1.3834240067343488,
      0.0,
      -1.4152712051903789,
      -1.4842508233927045,
      -1.4869364718086817,
      -1.7510936850790355,
      -1.4878319376062545,
      -1.5430121355368265,
      -1.5257958464876575,
      -1.446494305009156,
      -1.737805144265613,
      -1.4551493616133853,
      -1.4165569995872576,
      -1.5140537967607592,
      -1.4741107565911968,
      -1.5649320258204107,
      -1.4961243692821653,
      -1.5660876094386922,
      -1.6490652289474552,
      -1.5387198190392408,
      -1.5833296868340963,
      -1.580411398826334,
      -1.4375368190677025,
      -1.5544351113129902,
      -1.5153745988729526,
      -1.5401331621551104,
      -1.4926939452775174,
      -1.6860264245719978
    ],
    [
      -1.5718392855381842,
      -1.270080830014581,
      -1.3508831712380527,
      0.0,
      -1.3869240310019724,
      -1.3725189453313695,
      -1.637840059653935,
      -1.375878015617919,
      -1.4001116915598668,
      -1.4392602738376052,
      -1.2358897128155713,
      -1.5897550744877316,
      -1.336071051888396,
      -1.242873546590261,
      -1.4449090089440788,
      -1.3426418566800102,
      -1.4600691864647783,
      -1.3835680069431662,
      -1.434720202611876,
      -1.4708960233808126,
      -1.4303245054816374,
      -1.4854895500754621,
      -1.4670138437681397,
      -1.330778700405816,
      -1.474227780488344,
      -1.442772590543833,
      -1.4524871532503718,
      -1.379331916985049,
      -1.541020472401897
    ],
    [
      -1.467612395211058,
      -1.3384561973968445,
      -1.3755044416943683,
      -1.3599925143558798,
      0.0,
      -1.3510836393337677,
      -1.4687069651652165,
      -1.3735697346462574,
      -1.392338418659851,
      -1.4054455419241454,
      -1.3693397714662479,
      -1.4772870705702232,
      -1.3737312913989046,
      -1.351551842813792,
      -1.405460972758335,
      -1.4040931756505564,
      -1.3831128148485508,
      -1.3404879570420214,
      -1.3977938914637107,
      -1.4571953563290874,
      -1.3887047974572577,
      -1.426410358050871,
      -1.4321942839600128,
      -1.3615097073320894,
      -1.428068411047843,
      -1.4068313124834269,
      -1.3988710299794795,
      -1.3640491773630279,
      -1.459567102933103
    ],
    [
      -1.5397200382411544,
      -1.2852625724146878,
      -1.3549501512176392,
      -1.2902806086551848,
      -1.2875285164445682,
      0.0,
      -1.6074717246218575,
      -1.3074587460296365,
      -1.3657354744791372,
      -1.3904688853985216,
      -1.352603203443785,
      -1.5744484291092276,
      -1.3307115262135318,
      -1.3185631364348733,
      -1.413643372704464,
      -1.359742903278041,
      -1.3704436686836603,
      -1.3446155468803012,
      -1.3749779439136212,
      -1.5155544671571997,
      -1.3173473652538588,
      -1.4289601519311597,
      -1.4156312520169374,
      -1.3181162887792413,
      -1.4095070358464317,
      -1.372102757937509,
      -1.3737793262305515,
      -1.3753529005160376,
      -1.5249444050710335
    ],
    [
      -1.2107094779298515,
      -1.2100652536183187,
      -1.1972903684201481,
      -1.2107957381611407,
      -1.1477251503015524,
      -1.2210017217352211,
      0.0,
      -1.1624608723846448,
      -1.182288730080787,
      -1.1943244987331605,
      -1.212335440423428,
      -1.1364836563353184,
      -1.2077183342895452,
      -1.1935383771090342,
      -1.1909950292796012,
      -1.2290547386397548,
      -1.1474085442326976,
      -1.215383381665259,
      -1.1957790833554076,
      -1.2152337881940318,
      -1.1706178499223319,
      -1.1996292304076053,
      -1.196083495127508,
      -1.173680847699778,
      -1.2111660686778187,
      -1.1933077121931257,
      -1.1915890439702692,
      -1.2167504042349637,
      -1.1658672268640504
    ],
    [
      -1.7626373611984167,
      -1.550941069086491,
      -1.620054474689713,
      -1.6286316098809794,
      -1.6142399863516197,
      -1.5811182003862287,
      -1.8306494030760878,
      0.0,
      -1.605524132001696,
      -1.6504285225302997,
      -1.6164637142394538,
      -1.8244735314330665,
      -1.560142552906204,
      -1.5883070883857058,
      -1.68267800460349,
      -1.6933238338929233,
      -1.6457149555934012,
      -1.6135034460905608,
      -1.6866453474903254,
      -1.737878333218015,
      -1.6548620097829014,
      -1.6053604807021566,
      -1.6760388703712852,
      -1.5792292726941748,
      -1.6810396283117859,
      -1.6210269366728562,
      -1.6318085628686734,
      -1.6154684094164913,
      -1.7921087349578564
    ],
    [
      -1.8208190390956251,
      -1.566491101988183,
      -1.6459648545693202,
      -1.598435033178087,
      -1.6113673035730642,
      -1.6665097774458368,
      -1.8399637942694496,
      -1.60467259011995,
      0.0,
      -1.6508647520951278,
      -1.6364158918523646,
      -1.8429170588673203,
      -1.6250287855510044,
      -1.6628064826540545,
      -1.6909069442341276,
      -1.64672012869682,
      -1.6867217081307075,
      -1.5563042746198563,
      -1.692628786487583,
      -1.7741818017389999,
      -1.6278154865937198,
      -1.6467572552126437,
      -1.6344250422345588,
      -1.5416098323387515,
      -1.6644563650409332,
      -1.643859932436717,
      -1.633090055730867,
      -1.5756010854248157,
      -1.7658856671373064
    ],
    [
      -1.6987736043913886,
      -1.4720053536804416,
      -1.543682003704249,
      -1.5289472126321195,
      -1.4818898271891554,
      -1.568342903811685,
      -1.7496849922656679,
      -1.532306547005495,
      -1.5326707532439314,
      0.0,
      -1.5202726165550349,
      -1.7559380861414458,
      -1.539897707512287,
      -1.520557796618721,
      -1.6190080670560858,
      -1.5514061343800638,
      -1.6029290745168536,
      -1.5338322338359391,
      -1.5704453303799217,
      -1.6955888311155383,
      -1.5786167638678263,
      -1.5760418115815484,
      -1.4983362256940231,
      -1.5097919116421907,
      -1.545554394527576,
      -1.554252203027885,
      -1.5242316698069556,
      -1.5895795752044306,
      -1.6850081927623675
    ],
    [
      -1.4539075094978573,
      -1.239588120355583,
      -1.2931784030887241,
      -1.1589123775156722,
      -1.25222459567929,
      -1.3216495545258977,
      -1.5714961661369993,
      -1.2946779351562627,
      -1.361725234021959,
      -1.3434041406404755,
      0.0,
      -1.5420595938195087,
      -1.3264801807190671,
      -1.2312356617497453,
      -1.4023763257222304,
      -1.2773789645622933,
      -1.3891307608481314,
      -1.3255511296020033,
      -1.3587555626479828,
      -1.456740528714725,
      -1.333001414865096,
      -1.3427560426676728,
      -1.4258768357535407,
      -1.2575024308450509,
      -1.3901815327150513,
      -1.3755157035094263,
      -1.3024227166765645,
      -1.3224166151982804,
      -1.463525978844745
    ],
    [
      -1.346911827643689,
      -1.3280674099056093,
      -1.316751405265523,
      -1.3582470238414546,
      -1.2997946050369085,
      -1.349209622525422,
      -1.2727956558398092,
      -1.3090211590065075,
      -1.298392363006458,
      -1.2903333578881333,
      -1.3656754033755951,
      0.0,
      -1.34713882659344,
      -1.3227801150629954,
      -1.2964343591268994,
      -1.350342142343152,
      -1.2665605800139,
      -1.3276426040262623,
      -1.303595991278209,
      -1.3328238098581981,
      -1.3395022859804486,
      -1.317205524660985,
      -1.3197552305941334,
      -1.2940279665656902,
      -1.3213330800330234,
      -1.3088804723649496,
      -1.3139195444488851,
      -1.3430008172079704,
      -1.2050503865307904
    ],
    [
      -1.7023892095047548,
      -1.4303408807952098,
      -1.4772468640551015,
      -1.4939713185325516,
      -1.5296794620886718,
      -1.5871077999676348,
      -1.7788325218730554,
      -1.4721520340441874,
      -1.5777880167022678,
      -1.5726108092652877,
      -1.5025920818528238,
      -1.7921443174201466,
      0.0,
      -1.4605301218050637,
      -1.6459069401264812,
      -1.5437716665468975,
      -1.6292714580329666,
      -1.5314135316326292,
      -1.615072640357791,
      -1.6965631416113691,
      -1.6029827578623534,
      -1.575722646925669,
      -1.6475675292699536,
      -1.530097674218555,
      -1.5910590349628237,
      -1.5552443028896634,
      -1.5977548631139518,
      -1.590073239746274,
      -1.7160023480934015
    ],
    [
      -1.4777646091919467,
      -1.1938005764684638,
      -1.3156167866058261,
      -1.2342718238235209,
      -1.2825220159822477,
      -1.365049177141945,
      -1.533775254088161,
      -1.2816655052313846,
      -1.3895938769039384,
      -1.3925994100397445,
      -1.303814136120286,
      -1.5108547739018792,
      -1.2523283876969278,
      0.0,
      -1.3394406255542708,
      -1.3732972280506026,
      -1.3517429695896352,
      -1.366251344409935,
      -1.3904735642461568,
      -1.4545872747704207,
      -1.3990863606114476,
      -1.3738751852924356,
      -1.4098001621715506,
      -1.25588965972979,
      -1.402045746238761,
      -1.3263198277458792,
      -1.3546754991004966,
      -1.3801641146159538,
      -1.467413189926935
    ],
    [
      -1.4260564274145204,
      -1.1810882826519529,
      -1.2461903406470043,
      -1.239866302340432,
      -1.2578005617818286,
      -1.3197221674591453,
      -1.4329519313576309,
      -1.2233674301727506,
      -1.2614830838686846,
      -1.3037900728201395,
      -1.254129424030211,
      -1.3661409812130985,
      -1.2801453310580506,
      -1.1891637624783926,
      0.0,
      -1.3043109512203515,
      -1.2883612353240663,
      -1.262377501594161,
      -1.2861531377121591,
      -1.384050418020295,
      -1.2954768873490004,
      -1.2309366375242319,
      -1.3454360552274762,
      -1.146177870620741,
      -1.3168756207758545,
      -1.2392544828244763,
      -1.3062582982871866,
      -1.2406665433695576,
      -1.3185193850202765
    ],
    [
      -1.5136718716821638,
      -1.2685533836681797,
      -1.268832399262101,
      -1.225017296003694,
      -1.3321664407842226,
      -1.3433944287855402,
      -1.5671293146608625,
      -1.3702858405049534,
      -1.3324760456195772,
      -1.368105619582924,
      -1.296523430507454,
      -1.5306325572466177,
      -1.2901879010799313,
      -1.3007581599173108,
      -1.4072257992401704,
      0.0,
      -1.446869823174318,
      -1.3290524816996931,
      -1.3480665421864184,
      -1.435517523210527,
      -1.4012233593289811,
      -1.3775266085687652,
      -1.404846849025925,
      -1.2856065511508725,
      -1.4166773080063935,
      -1.3556055703848555,
      -1.351485986478629,
      -1.3463079157089366,
      -1.4416168795055104
    ],
    [
      -1.845025801250016,
      -1.6416240184396655,
      -1.700174646867115,
      -1.7044951282972745,
      -1.6229284671446502,
      -1.715905054784414,
      -1.8710184583693248,
      -1.6416234592951586,
      -1.7063835456387328,
      -1.6750225830949406,
      -1.6862729253359414,
      -1.8704412775562245,
      -1.6897449193766554,
      -1.6272837397121585,
      -1.7243978525259347,
      -1.7703340993323768,
      0.0,
      -1.690101607138325,
      -1.6790142961980918,
      -1.8680344379166358,
      -1.7065756764836355,
      -1.766880623769458,
      -1.6952631375023783,
      -1.65545931702545,
      -1.6937261299984496,
      -1.7492771068524882,
      -1.652981479406636,
      -1.741536863618688,
      -1.8226952113600066
    ],
    [
      -1.5251166903858553,
      -1.2307338639579655,
      -1.317688107730717,
      -1.2815078549125036,
      -1.121440998332185,
      -1.3273683495949429,
      -1.6055438783063793,
      -1.2526105287424159,
      -1.2376114483429506,
      -1.3500235616251661,
      -1.3387491139710905,
      -1.5981402165230156,
      -1.2574555688530056,
      -1.3208627903262722,
      -1.4411450838893418,
      -1.3496896528052402,
      -1.3483410023676317,
      0.0,
      -1.399517151464254,
      -1.501396250265815,
      -1.3375643511632027,
      -1.3749238271007136,
      -1.4151091765911978,
      -1.2821759062914182,
      -1.4136420574395652,
      -1.2862950578487558,
      -1.326439738529298,
      -1.3123801866117129,
      -1.524629766215696
    ],
    [
      -1.527073074826573,
      -1.3037314974615137,
      -1.3462324638276562,
      -1.3196278824023338,
      -1.2956643277096234,
      -1.37170346279258,
      -1.5276387568279464,
      -1.3274963733511362,
      -1.359792345204346,
      -1.3444023373862812,
      -1.3476965969061485,
      -1.475113396019105,
      -1.3507894393080158,
      -1.3168976726348058,
      -1.3363206219885726,
      -1.3387696975143193,
      -1.3510664719211676,
      -1.3589723953325,
      0.0,
      -1.4590090170527947,
      -1.3659984969879477,
      -1.3866183165024943,
      -1.388710666331603,
      -1.3177299962013758,
      -1.3793872955771702,
      -1.3559517962151797,
      -1.319199499340495,
      -1.360989650570932,
      -1.4375794543408627
    ],
    [
      -1.6043907076803163,
      -1.4899958002198381,
      -1.486094189774371,
      -1.5089610308484722,
      -1.568613929876056,
      -1.510658839383606,
      -1.6844560972665132,
      -1.5217598014612566,
      -1.5413419408823992,
      -1.5503374278214623,
      -1.5193131209044515,
      -1.6389969240257942,
      -1.515074621096398,
      -1.5253759659823622,
      -1.57910875371259,
      -1.4797584407718847,
      -1.5715720930655783,
      -1.5420155614381716,
      -1.586558299970515,
      0.0,
      -1.542735712857451,
      -1.5323709207765015,
      -1.546584027132805,
      -1.4678548374178118,
      -1.5136373664276412,
      -1.5333199346358821,
      -1.5428426401963433,
      -1.5375133563938723,
      -1.6100891117569895
    ],
    [
      -1.657154922085905,
      -1.5386163282752752,
      -1.5338535022050102,
      -1.5193853895945104,
      -1.5453330084336883,
      -1.5064558594024178,
      -1.7203275400685019,
      -1.5075567534574357,
      -1.5113930231420083,
      -1.5495771588830427,
      -1.5179765157763256,
      -1.7221414603855443,
      -1.5416791755863173,
      -1.5476058375258157,
      -1.6215139565121133,
      -1.554622251193662,
      -1.5689529761585475,
      -1.4952030054571348,
      -1.6231272681295899,
      -1.6718548473642598,
      0.0,
      -1.5872459171770188,
      -1.55092523625263,
      -1.5147064744812349,
      -1.5703791064733121,
      -1.5362756426943986,
      -1.532444393170681,
      -1.5199229641111895,
      -1.6805070408337512
    ],
    [
      -1.4756309838755464,
      -1.2656569181223098,
      -1.3981959791404674,
      -1.3499388318984442,
      -1.3463743094123737,
      -1.3493041936028596,
      -1.538521632028241,
      -1.294691474080035,
      -1.3652711581319208,
      -1.3298897477095788,
      -1.3511642754419906,
      -1.5022666777872176,
      -1.356509731067616,
      -1.289621280665867,
      -1.339596358645186,
      -1.3400456311077795,
      -1.3987635199395096,
      -1.3622260748237969,
      -1.3207894454665228,
      -1.4652039743431409,
      -1.3702018814908197,
      0.0,
      -1.346528564511736,
      -1.2839501947738041,
      -1.3937783245635829,
      -1.2963699348035729,
      -1.3709420508282684,
      -1.3583221505004908,
      -1.418596785402518
    ],
    [
      -1.5350252335289971,
      -1.4154870109329494,
      -1.422013556036862,
      -1.4149918563581645,
      -1.4302956604185089,
      -1.474208721186508,
      -1.618073349245261,
      -1.4525726380518058,
      -1.389418002346056,
      -1.343577883027328,
      -1.4577344911672439,
      -1.610243028483423,
      -1.40631679244348,
      -1.4604493803189131,
      -1.4764677772543142,
      -1.4309981582245175,
      -1.4092004378049061,
      -1.4417621831525207,
      -1.489488759260242,
      -1.5241542637073449,
      -1.4258454558895428,
      -1.4340300003837738,
      0.0,
      -1.4316977544183482,
      -1.3522661121335722,
      -1.4359365580780363,
      -1.3729269356913312,
      -1.4358288979759108,
      -1.5142829299382994
    ],
    [
      -1.663628827478288,
      -1.4251866069631012,
      -1.4765468981439778,
      -1.4147052610569866,
      -1.4741055996098933,
      -1.4946974146791554,
      -1.7133242410600238,
      -1.4642187672052438,
      -1.4232615114352365,
      -1.5629006525475133,
      -1.4761065429758515,
      -1.7430535477850542,
      -1.5182112410708797,
      -1.4389832213076756,
      -1.4997353784057381,
      -1.5083337336363196,
      -1.557327675058227,
      -1.4923569352264034,
      -1.576310463124268,
      -1.5940042436535546,
      -1.550392165259871,
      -1.4764728690717035,
      -1.5851589179473662,
      0.0,
      -1.5814463456052252,
      -1.4831655329128237,
      -1.5450871069163017,
      -1.4957190838772447,
      -1.6697099999379124
    ],
    [
      -1.5953860072277146,
      -1.46919969416202,
      -1.4805371203137512,
      -1.4981088876955322,
      -1.5290095384740718,
      -1.5023984850822973,
      -1.701781157474425,
      -1.4517589318137416,
      -1.4680618401586978,
      -1.4485551080901908,
      -1.4671413415538623,
      -1.7006622771288218,
      -1.4637703311770796,
      -1.5179014588330235,
      -1.561679517101414,
      -1.529554823217529,
      -1.479925597506913,
      -1.4727610372088256,
      -1.5455133001577268,
      -1.5989505705063538,
      -1.4776961715527135,
      -1.5329313753958045,
      -1.4056567422452295,
      -1.4838708472065887,
      0.0,
      -1.4525154602628045,
      -1.4732306021050843,
      -1.5164611730628945,
      -1.6195296663755823
    ],
    [
      -1.659005489051504,
      -1.4193299647839068,
      -1.4605322208439175,
      -1.4787138742398387,
      -1.5326427221471726,
      -1.489492114178746,
      -1.727730223903283,
      -1.3876259120013115,
      -1.5042061575943442,
      -1.5152859932675424,
      -1.496091328489017,
      -1.7206103344197459,
      -1.4781618155643568,
      -1.4636787979505193,
      -1.5165006998886328,
      -1.5193336878796937,
      -1.5154676545865877,
      -1.4722371216514003,
      -1.5551255509219408,
      -1.6298736999473362,
      -1.4457787837795053,
      -1.4637266866647884,
      -1.5356585494202433,
      -1.3917913089269023,
      -1.5371673499460958,
      0.0,
      -1.5077947515030388,
      -1.5225467054925665,
      -1.6622225042796281
    ],
    [
      -1.6756744684461762,
      -1.4805861572591192,
      -1.534810507179035,
      -1.481991569570072,
      -1.4860519099881395,
      -1.5498434403786658,
      -1.7577961664979016,
      -1.5192989117181972,
      -1.501778188403497,
      -1.4858687497833183,
      -1.4822902406972291,
      -1.7449739403397722,
      -1.5084148033216775,
      -1.5133869740838437,
      -1.6297138052490483,
      -1.5620760538241854,
      -1.509912129427091,
      -1.4958466628574,
      -1.5814369787308427,
      -1.6924358775613557,
      -1.5137958385779178,
      -1.5608872425569713,
      -1.5014321444024037,
      -1.4966985569234403,
      -1.5289145025164024,
      -1.5210139541928893,
      0.0,
      -1.5718617077999504,
      -1.6877424564511823
    ],
    [
      -1.542925229744775,
      -1.3384821669208424,
      -1.3398254102248226,
      -1.3076268757786844,
      -1.2890283789749961,
      -1.3230980865034392,
      -1.579103931818156,
      -1.292820079638907,
      -1.2686305590122886,
      -1.3875886502113586,
      -1.297048472677722,
      -1.5657269920259127,
      -1.367775709555134,
      -1.3440315580557718,
      -1.4111356121395235,
      -1.3904312940977237,
      -1.4363898695267359,
      -1.2810206315196306,
      -1.4285576929267756,
      -1.4807730241485357,
      -1.325808818029374,
      -1.4212085184068006,
      -1.4262997499148493,
      -1.3095881684299926,
      -1.4285465491040197,
      -1.413240910412538,
      -1.3643202238222425,
      0.0,
      -1.4990046252189326
    ],
    [
      -1.3984310729108866,
      -1.3343744232790034,
      -1.3394334148015807,
      -1.3417035368163923,
      -1.3245523646492403,
      -1.329711160657385,
      -1.3471309633347557,
      -1.3226290840322796,
      -1.3355501643873215,
      -1.320323920150643,
      -1.3337400782585744,
      -1.2613810882339636,
      -1.3384998552147411,
      -1.3209380419171326,
      -1.3083321044788867,
      -1.334853368254123,
      -1.2920935253037793,
      -1.3428177051442092,
      -1.2934288866919006,
      -1.3713524929921683,
      -1.3186155629840874,
      -1.258376605170661,
      -1.3288102282639762,
      -1.3328292698211353,
      -1.3071518197434282,
      -1.3484625204515601,
      -1.3275674551763157,
      -1.3406561940707789,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.40792970687052543,
      0.38390177726797514,
      0.39020332369261235,
      0.3883768126361695,
      0.3870339591760006,
      0.29107579971087105,
      0.395816519718434,
      0.3836085738991777,
      0.3729910284989053,
      0.3861533740048144,
      0.3209557074369527,
      0.4092275725495824,
      0.39041160596785307,
      0.3961645112311203,
      0.3728520559761943,
      0.34987452579104206,
      0.3811152971993148,
      0.3497800686549444,
      0.3681263954830625,
      0.37806409136886465,
      0.35383258028525555,
      0.3897246931182261,
      0.4200840715903027,
      0.37990437991092474,
      0.3711650683041783,
      0.4115833381006122,
      0.3810019366459385,
      0.3817589438267217
    ],
    [
      0.2424104509292675,
      0.0,
      0.4571607454230766,
      0.5221893797302861,
      0.48834686561581897,
      0.40303266245425484,
      0.21923754819972174,
      0.4889129552913887,
      0.4353225224858488,
      0.4232170972737428,
      0.4413924290350608,
      0.23231661327081943,
      0.5042387909514752,
      0.5552266934958134,
      0.4298908467194944,
      0.4399711096630865,
      0.387749456338252,
      0.42977421764690926,
      0.34989955895976266,
      0.33635391647573365,
      0.38160675555992185,
      0.4304717781736407,
      0.37781248731886574,
      0.519204772506084,
      0.37682942762112126,
      0.4304297502504182,
      0.4278123541328882,
      0.42003449858916686,
      0.3010587551800592
    ],
    [
      0.3354674912056248,
      0.6102757913345531,
      0.0,
      0.5784285928785231,
      0.5094489746761974,
      0.5067633262602202,
      0.24260611298986645,
      0.5058678604626474,
      0.4506876625320755,
      0.4679039515812444,
      0.5472054930597459,
      0.2558946538032889,
      0.5385504364555167,
      0.5771427984816444,
      0.4796460013081427,
      0.5195890414777051,
      0.4287677722484913,
      0.49757542878673666,
      0.4276121886302098,
      0.34463456912144674,
      0.45497997902966114,
      0.4103701112348057,
      0.413288399242568,
      0.5561629790011995,
      0.4392646867559118,
      0.4783251991959494,
      0.45356663591379154,
      0.5010058527913845,
      0.30767337349690416
    ],
    [
      0.28086215358628785,
      0.5826206091098911,
      0.5018182678864194,
      0.0,
      0.4657774081224997,
      0.4801824937931025,
      0.21486137947053696,
      0.47682342350655316,
      0.45258974756460524,
      0.4134411652868668,
      0.6168117263089008,
      0.2629463646367405,
      0.516630387236076,
      0.6098278925342111,
      0.40779243018039324,
      0.5100595824444618,
      0.3926322526596937,
      0.4691334321813059,
      0.4179812365125961,
      0.38180541574365945,
      0.4223769336428347,
      0.3672118890490099,
      0.38568759535633235,
      0.521922738718656,
      0.37847365863612814,
      0.40992884858063916,
      0.40021428587410024,
      0.47336952213942296,
      0.31168096672257506
    ],
    [
      0.18713795607429184,
      0.31629415388850535,
      0.2792459095909816,
      0.2947578369294701,
      0.0,
      0.3036667119515821,
      0.18604338612013338,
      0.28118061663909244,
      0.2624119326254988,
      0.24930480936120447,
      0.285410579819102,
      0.17746328071512663,
      0.28101905988644527,
      0.3031985084715578,
      0.24928937852701494,
      0.2506571756347935,
      0.2716375364367991,
      0.31426239424332847,
      0.25695645982163917,
      0.1975549949562625,
      0.26604555382809214,
      0.22833999323447896,
      0.22255606732533706,
      0.29324064395326044,
      0.22668194023750687,
      0.247919038801923,
      0.2558793213058703,
      0.290701173922322,
      0.19518324835224687
    ],
    [
      0.282858617318801,
      0.5373160831452677,
      0.4676285043423163,
      0.5322980469047707,
      0.5350501391153872,
      0.0,
      0.21510693093809796,
      0.5151199095303189,
      0.45684318108081823,
      0.4321097701614338,
      0.46997545211617053,
      0.2481302264507279,
      0.4918671293464236,
      0.5040155191250821,
      0.4089352828554915,
      0.4628357522819144,
      0.45213498687629516,
      0.4779631086796543,
      0.4476007116463343,
      0.3070241884027558,
      0.5052312903060967,
      0.3936185036287958,
      0.40694740354301806,
      0.5044623667807142,
      0.4130716197135238,
      0.45047589762244655,
      0.4487993293294039,
      0.4472257550439178,
      0.297634250488922
    ],
    [
      0.22839853181742642,
      0.2290427561289592,
      0.2418176413271298,
      0.2283122715861372,
      0.2913828594457255,
      0.21810628801205678,
      0.0,
      0.27664713736263313,
      0.256819279666491,
      0.24478351101411744,
      0.22677256932385004,
      0.3026243534119595,
      0.2313896754577327,
      0.24556963263824372,
      0.2481129804676767,
      0.21005327110752314,
      0.29169946551458037,
      0.22372462808201887,
      0.24332892639187031,
      0.2238742215532461,
      0.26849015982494606,
      0.23947877933967265,
      0.24302451461977004,
      0.26542716204749994,
      0.2279419410694592,
      0.24580029755415223,
      0.24751896577700871,
      0.2223576055123142,
      0.2732407828832275
    ],
    [
      0.30523402286538426,
      0.5169303149773099,
      0.447816909374088,
      0.43923977418282156,
      0.4536313977121813,
      0.48675318367757225,
      0.2372219809877132,
      0.0,
      0.46234725206210503,
      0.4174428615335013,
      0.4514076698243472,
      0.24339785263073455,
      0.5077288311575969,
      0.4795642956780952,
      0.38519337946031107,
      0.3745475501708777,
      0.4221564284703998,
      0.45436793797324015,
      0.38122603657347565,
      0.329993050845786,
      0.41300937428089957,
      0.46251090336164435,
      0.3918325136925158,
      0.4886421113696262,
      0.3868317557520151,
      0.44684444739094475,
      0.4360628211951276,
      0.4524029746473097,
      0.2757626491059446
    ],
    [
      0.3142014768172139,
      0.568529413924656,
      0.48905566134351885,
      0.536585482734752,
      0.5236532123397748,
      0.4685107384670022,
      0.2950567216433895,
      0.5303479257928891,
      0.0,
      0.4841557638177112,
      0.49860462406047446,
      0.29210345704551877,
      0.5099917303618346,
      0.4722140332587845,
      0.44411357167871146,
      0.488300387216019,
      0.4482988077821315,
      0.5787162412929827,
      0.44239172942525595,
      0.36083871417383917,
      0.5072050293191193,
      0.4882632607001953,
      0.5005954736782803,
      0.5934106835740875,
      0.47056415087190584,
      0.4911605834761221,
      0.5019304601819721,
      0.5594194304880233,
      0.3691348487755326
    ],
    [
      0.28092798109276207,
      0.507696231803709,
      0.43601958177990174,
      0.4507543728520311,
      0.49781175829499524,
      0.4113586816724657,
      0.23001659321848278,
      0.4473950384786556,
      0.4470308322402192,
      0.0,
      0.4594289689291158,
      0.2237634993427049,
      0.4398038779718636,
      0.4591437888654297,
      0.36069351842806485,
      0.42829545110408684,
      0.376772510967297,
      0.4458693516482115,
      0.4092562551042289,
      0.2841127543686124,
      0.4010848216163243,
      0.4036597739026022,
      0.4813653597901275,
      0.4699096738419599,
      0.4341471909565746,
      0.42544938245626573,
      0.4554699156771951,
      0.39012201027972004,
      0.2946933927217832
    ],
    [
      0.3430398085720374,
      0.5573591977143117,
      0.5037689149811706,
      0.6380349405542225,
      0.5447227223906048,
      0.475297763543997,
      0.22545115193289544,
      0.502269382913632,
      0.4352220840479357,
      0.4535431774294192,
      0.0,
      0.25488772425038597,
      0.47046713735082757,
      0.5657116563201494,
      0.39457099234766435,
      0.5195683535076014,
      0.40781655722176335,
      0.47139618846789144,
      0.4381917554219119,
      0.3402067893551697,
      0.4639459032047988,
      0.45419127540222193,
      0.371070482316354,
      0.5394448872248438,
      0.4067657853548434,
      0.4214316145604684,
      0.4945246013933302,
      0.47453070287161436,
      0.3334213392251497
    ],
    [
      0.29848533844668523,
      0.317329756184765,
      0.3286457608248514,
      0.28715014224891977,
      0.3456025610534659,
      0.29618754356495236,
      0.3726015102505651,
      0.33637600708386683,
      0.34700480308391635,
      0.35506380820224104,
      0.2797217627147792,
      0.0,
      0.29825833949693425,
      0.3226170510273789,
      0.3489628069634749,
      0.29505502374722226,
      0.3788365860764744,
      0.317754562064112,
      0.34180117481216543,
      0.3125733562321762,
      0.3058948801099257,
      0.3281916414293893,
      0.325641935496241,
      0.35136919952468415,
      0.32406408605735093,
      0.3365166937254247,
      0.3314776216414892,
      0.30239634888240396,
      0.4403467795595839
    ],
    [
      0.3415449444427139,
      0.6135932731522589,
      0.5666872898923672,
      0.5499628354149171,
      0.5142546918587969,
      0.45682635397983384,
      0.2651016320744133,
      0.5717821199032813,
      0.46614613724520093,
      0.47132334468218096,
      0.5413420720946449,
      0.2517898365273221,
      0.0,
      0.583404032142405,
      0.3980272138209875,
      0.5001624874005712,
      0.4146626959145021,
      0.5125206223148395,
      0.4288615135896776,
      0.34737101233609957,
      0.44095139608511524,
      0.4682115070217996,
      0.39636662467751504,
      0.5138364797289137,
      0.45287511898464494,
      0.48868985105780527,
      0.44617929083351693,
      0.4538609142011947,
      0.3279318058540672
    ],
    [
      0.3450051028076444,
      0.6289691355311273,
      0.507152925393765,
      0.5884978881760703,
      0.5402476960173435,
      0.4577205348576461,
      0.2889944579114301,
      0.5411042067682066,
      0.4331758350956527,
      0.4301703019598466,
      0.5189555758793052,
      0.311914938097712,
      0.5704413243026634,
      0.0,
      0.48332908644532036,
      0.44947248394898853,
      0.4710267424099559,
      0.45651836758965625,
      0.4322961477534344,
      0.36818243722917043,
      0.4236833513881435,
      0.4488945267071556,
      0.41296954982804057,
      0.5668800522698012,
      0.42072396576083015,
      0.49644988425371195,
      0.4680942128990946,
      0.44260559738363736,
      0.3553565220726562
    ],
    [
      0.30025357763668925,
      0.5452217223992568,
      0.4801196644042054,
      0.48644370271077775,
      0.46850944326938104,
      0.4065878375920644,
      0.2933580736935788,
      0.5029425748784591,
      0.4648269211825251,
      0.4225199322310702,
      0.4721805810209987,
      0.3601690238381112,
      0.44616467399315907,
      0.5371462425728171,
      0.0,
      0.42199905383085823,
      0.43794876972714336,
      0.46393250345704873,
      0.4401568673390506,
      0.34225958703091464,
      0.43083311770220933,
      0.4953733675269778,
      0.38087394982373346,
      0.5801321344304686,
      0.40943438427535517,
      0.48705552222673343,
      0.42005170676402304,
      0.48564346168165207,
      0.40779062003093314
    ],
    [
      0.3119870502026063,
      0.5571055382165904,
      0.5568265226226692,
      0.6006416258810761,
      0.49349248110054744,
      0.4822644930992299,
      0.2585296072239076,
      0.4553730813798167,
      0.49318287626519286,
      0.4575533023018461,
      0.5291354913773161,
      0.29502636463815235,
      0.5354710208048388,
      0.5249007619674593,
      0.41843312264459964,
      0.0,
      0.3787890987104521,
      0.49660644018507694,
      0.47759237969835167,
      0.390141398674243,
      0.42443556255578896,
      0.4481323133160049,
      0.42081207285884514,
      0.5400523707338976,
      0.4089816138783766,
      0.47005335149991456,
      0.474172935406141,
      0.4793510061758335,
      0.38404204237925965
    ],
    [
      0.3368432519280111,
      0.5402450347383616,
      0.4816944063109121,
      0.4773739248807527,
      0.5589405860333769,
      0.46596399839361324,
      0.31085059480870236,
      0.5402455938828685,
      0.4754855075392943,
      0.5068464700830866,
      0.49559612784208573,
      0.3114277756218027,
      0.49212413380137177,
      0.5545853134658687,
      0.45747120065209246,
      0.4115349538456503,
      0.0,
      0.4917674460397021,
      0.5028547569799353,
      0.31383461526139134,
      0.47529337669439164,
      0.41498842940856906,
      0.4866059156756488,
      0.5264097361525772,
      0.4881429231795775,
      0.432591946325539,
      0.5288875737713912,
      0.44033218955933906,
      0.3591738418180206
    ],
    [
      0.3722305770509682,
      0.666613403478858,
      0.5796591597061065,
      0.6158394125243198,
      0.7759062691046386,
      0.5699789178418806,
      0.2918033891304441,
      0.6447367386944076,
      0.6597358190938729,
      0.5473237058116573,
      0.5585981534657329,
      0.29920705091380784,
      0.6398916985838179,
      0.5764844771105513,
      0.45620218354748165,
      0.5476576146315832,
      0.5490062650691918,
      0.0,
      0.49783011597256954,
      0.39595101717100856,
      0.5597829162736208,
      0.5224234403361099,
      0.48223809084562563,
      0.6151713611454053,
      0.4837052099972583,
      0.6110522095880677,
      0.5709075289075254,
      0.5849670808251106,
      0.37271750122112746
    ],
    [
      0.2611212597785044,
      0.48446283714356375,
      0.44196187077742133,
      0.46856645220274373,
      0.4925300068954541,
      0.41649087181249755,
      0.2605555777771311,
      0.46069796125394125,
      0.4284019894007314,
      0.44379199721879625,
      0.44049773769892897,
      0.3130809385859725,
      0.4374048952970617,
      0.47129666197027165,
      0.4518737126165049,
      0.4494246370907582,
      0.4371278626839099,
      0.42922193927257757,
      0.0,
      0.32918531755228275,
      0.42219583761712975,
      0.40157601810258314,
      0.3994836682734746,
      0.4704643384037017,
      0.40880703902790727,
      0.4322425383898978,
      0.4689948352645825,
      0.42720468403414547,
      0.35061488026421483
    ],
    [
      0.32451363611711437,
      0.43890854357759257,
      0.4428101540230598,
      0.4199433129489585,
      0.36029041392137473,
      0.4182455044138247,
      0.24444824653091746,
      0.40714454233617414,
      0.3875624029150315,
      0.37856691597596837,
      0.4095912228929792,
      0.2899074197716365,
      0.4138297227010328,
      0.40352837781506845,
      0.3497955900848406,
      0.449145903025546,
      0.3573322507318524,
      0.38688878235925905,
      0.3423460438269157,
      0.0,
      0.38616863093997966,
      0.3965334230209292,
      0.3823203166646256,
      0.46104950637961895,
      0.41526697736978946,
      0.3955844091615486,
      0.3860617036010874,
      0.3913909874035584,
      0.31881523204044115
    ],
    [
      0.29657424211901073,
      0.41511283592964054,
      0.41987566199990556,
      0.4343437746104053,
      0.40839615577122745,
      0.44727330480249794,
      0.23340162413641385,
      0.44617241074748004,
      0.4423361410629074,
      0.404152005321873,
      0.4357526484285901,
      0.23158770381937144,
      0.41204998861859843,
      0.4061233266791,
      0.33221520769280244,
      0.3991069130112537,
      0.38477618804636826,
      0.4585261587477809,
      0.33060189607532586,
      0.2818743168406559,
      0.0,
      0.3664832470278969,
      0.4028039279522857,
      0.43902268972368086,
      0.3833500577316036,
      0.41745352151051707,
      0.4212847710342347,
      0.43380620009372617,
      0.27322212337116447
    ],
    [
      0.34627009632654016,
      0.5562441620797767,
      0.42370510106161907,
      0.4719622483036423,
      0.47552677078971284,
      0.47259688659922694,
      0.2833794481738454,
      0.5272096061220515,
      0.45662992207016573,
      0.4920113324925077,
      0.47073680476009594,
      0.31963440241486896,
      0.46539134913447056,
      0.5322797995362196,
      0.4823047215569005,
      0.481855449094307,
      0.4231375602625769,
      0.45967500537828965,
      0.5011116347355637,
      0.35669710585894565,
      0.45169919871126685,
      0.0,
      0.47537251569035055,
      0.5379508854282824,
      0.42812275563850366,
      0.5255311453985136,
      0.45095902937381815,
      0.46357892970159575,
      0.4033042947995684
    ],
    [
      0.36465476149196374,
      0.4841929840880115,
      0.4776664389840988,
      0.48468813866279636,
      0.469384334602452,
      0.4254712738344528,
      0.2816066457756998,
      0.44710735696915505,
      0.5102619926749048,
      0.5561021119936329,
      0.441945503853717,
      0.2894369665375378,
      0.4933632025774808,
      0.4392306147020477,
      0.42321221776664664,
      0.4686818367964434,
      0.49047955721605474,
      0.45791781186844016,
      0.4101912357607189,
      0.375525731313616,
      0.47383453913141804,
      0.46564999463718704,
      0.0,
      0.4679822406026126,
      0.5474138828873887,
      0.4637434369429245,
      0.5267530593296297,
      0.46385109704505,
      0.38539706508266147
    ],
    [
      0.3055425612282321,
      0.5439847817434189,
      0.4926244905625423,
      0.5544661276495335,
      0.4950657890966268,
      0.4744739740273647,
      0.2558471476464963,
      0.5049526215012763,
      0.5459098772712836,
      0.4062707361590068,
      0.49306484573066856,
      0.22611784092146592,
      0.4509601476356404,
      0.5301881673988444,
      0.46943601030078197,
      0.46083765507020047,
      0.4118437136482931,
      0.47681445348011664,
      0.39286092558225216,
      0.37516714505296545,
      0.4187792234466492,
      0.4926985196348166,
      0.3840124707591539,
      0.0,
      0.38772504310129485,
      0.4860058557936964,
      0.4240842817902184,
      0.47345230482927536,
      0.29946138876860773
    ],
    [
      0.35321155364192736,
      0.47939786670762197,
      0.4680604405558908,
      0.4504886731741098,
      0.41958802239557014,
      0.44619907578734463,
      0.24681640339521693,
      0.49683862905590037,
      0.4805357207109442,
      0.5000424527794511,
      0.48145621931577964,
      0.2479352837408202,
      0.4848272296925624,
      0.43069610203661846,
      0.386918043768228,
      0.4190427376521131,
      0.468671963362729,
      0.4758365236608164,
      0.40308426071191517,
      0.34964699036328817,
      0.4709013893169285,
      0.4156661854738375,
      0.5429408186244125,
      0.4647267136630533,
      0.0,
      0.49608210060683744,
      0.4753669587645577,
      0.43213638780674746,
      0.3290678944940597
    ],
    [
      0.30244547918225373,
      0.5421210034498509,
      0.5009187473898402,
      0.48273709399391906,
      0.4288082460865852,
      0.4719588540550117,
      0.23372074433047474,
      0.5738250562324463,
      0.4572448106394136,
      0.4461649749662153,
      0.4653596397447408,
      0.24084063381401188,
      0.483289152669401,
      0.4977721702832385,
      0.44495026834512497,
      0.44211728035406406,
      0.44598331364717003,
      0.48921384658235745,
      0.4063254173118169,
      0.33157726828642153,
      0.5156721844542524,
      0.4977242815689693,
      0.4257924188135145,
      0.5696596593068555,
      0.4242836182876619,
      0.0,
      0.453656216730719,
      0.4389042627411912,
      0.2992284639541296
    ],
    [
      0.3713563674427338,
      0.5664446786297908,
      0.512220328709875,
      0.5650392663188379,
      0.5609789259007705,
      0.49718739551024416,
      0.2892346693910084,
      0.5277319241707128,
      0.5452526474854129,
      0.5611620861055917,
      0.5647405951916808,
      0.30205689554913784,
      0.5386160325672325,
      0.5336438618050663,
      0.4173170306398617,
      0.48495478206472464,
      0.537118706461819,
      0.5511841730315099,
      0.46559385715806734,
      0.3545949583275543,
      0.5332349973109922,
      0.4861435933319387,
      0.5455986914865063,
      0.5503322789654697,
      0.5181163333725076,
      0.5260168816960207,
      0.0,
      0.4751691280889596,
      0.35928837943772773
    ],
    [
      0.3166392814834289,
      0.5210823443073616,
      0.5197391010033814,
      0.5519376354495196,
      0.5705361322532079,
      0.5364664247247648,
      0.2804605794100481,
      0.5667444315892969,
      0.5909339522159154,
      0.4719758610168454,
      0.5625160385504819,
      0.2938375192022913,
      0.49178880167307004,
      0.5155329531724322,
      0.44842889908868044,
      0.4691332171304803,
      0.4231746417014681,
      0.5785438797085733,
      0.4310068183014284,
      0.37879148707966825,
      0.5337556931988301,
      0.43835599282140336,
      0.4332647613133547,
      0.5499763427982114,
      0.4310179621241843,
      0.4463236008156659,
      0.4952442874059615,
      0.0,
      0.36055988600927136
    ],
    [
      0.28081687087948004,
      0.34487352051136333,
      0.33981452898878595,
      0.33754440697397436,
      0.35469557914112637,
      0.34953678313298164,
      0.332116980455611,
      0.35661885975808705,
      0.34369777940304513,
      0.35892402363972375,
      0.34550786553179225,
      0.4178668555564031,
      0.34074808857562555,
      0.3583099018732341,
      0.37091583931148,
      0.34439457553624364,
      0.3871544184865874,
      0.3364302386461575,
      0.3858190570984661,
      0.30789545079819836,
      0.36063238080627924,
      0.4208713386197056,
      0.35043771552639047,
      0.3464186739692314,
      0.3720961240469385,
      0.33078542333880656,
      0.351680488614051,
      0.33859174971958783,
      0.0
    ]
  ],
  "row_avgs": [
    0.3783113471041634,
    0.4089965871175707,
    0.4585251915698592,
    0.43305227883873215,
    0.25621570223763807,
    0.432581427027675,
    0.24627643603347962,
    0.41250358146262744,
    0.4724054862229178,
    0.4054304489073354,
    0.4464590317813291,
    0.3294973957323371,
    0.45658096775827095,
    0.4592440303835003,
    0.44249746490250697,
    0.4558244973499298,
    0.45993255802478333,
    0.5374150467158125,
    0.41783137022881045,
    0.3842139347339545,
    0.3842028229609399,
    0.4548170771961867,
    0.44949092975459803,
    0.43688028927966865,
    0.43272080861640294,
    0.4397248252579161,
    0.4907260523625627,
    0.4717060187696152,
    0.3523284113906914
  ],
  "col_avgs": [
    0.30821551580305734,
    0.5028534885988177,
    0.4553005895188526,
    0.47994395300610354,
    0.47967700913003614,
    0.4368619941799174,
    0.2635537477617005,
    0.47599944614370265,
    0.4489717215557209,
    0.4346020892464174,
    0.460352206163425,
    0.27915432794804945,
    0.46055480110179775,
    0.47784879429983873,
    0.40514985887321053,
    0.43111808338625973,
    0.4152360940879748,
    0.4494018207352824,
    0.4055199653517816,
    0.33520693592457773,
    0.43177816313301726,
    0.41928095243919994,
    0.40826572979682546,
    0.49011952692266786,
    0.40873584402146745,
    0.4378967321616119,
    0.43668637610761935,
    0.43355049261086215,
    0.33455575971202
  ],
  "combined_avgs": [
    0.3432634314536104,
    0.4559250378581942,
    0.4569128905443559,
    0.45649811592241785,
    0.3679463556838371,
    0.43472171060379616,
    0.25491509189759004,
    0.4442515138031651,
    0.4606886038893193,
    0.4200162690768764,
    0.4534056189723771,
    0.3043258618401933,
    0.4585678844300344,
    0.4685464123416695,
    0.42382366188785875,
    0.44347129036809474,
    0.4375843260563791,
    0.49340843372554744,
    0.411675667790296,
    0.3597104353292661,
    0.40799049304697854,
    0.4370490148176933,
    0.4288783297757117,
    0.46349990810116826,
    0.4207283263189352,
    0.43881077870976404,
    0.46370621423509106,
    0.4526282556902387,
    0.3434420855513557
  ],
  "gppm": [
    679.2325932859754,
    597.6697014482951,
    616.4467470831949,
    606.3034907225114,
    595.700806427155,
    625.4715400196003,
    704.3562815499739,
    606.3053382430492,
    617.4874438820829,
    627.5771907875757,
    617.2843119575891,
    699.4424953313013,
    614.7329707863777,
    608.1165141057742,
    641.8365257126317,
    629.2076070085616,
    633.1681321812814,
    623.1753208655495,
    639.138827048361,
    672.3763005864552,
    627.2145963294464,
    635.4913783097351,
    641.4003877491601,
    598.891306784726,
    640.7333759902373,
    625.9418869175581,
    627.483125461662,
    630.451322343205,
    675.4236250060725
  ],
  "gppm_normalized": [
    1.5107838960116127,
    1.371238763625675,
    1.420695575437277,
    1.387397957752566,
    1.3668941924689482,
    1.4285915983057282,
    1.6111559055288438,
    1.3777593014053817,
    1.4085015592727461,
    1.431285678876868,
    1.4042014126110576,
    1.5945298599827067,
    1.4076556220112042,
    1.3884072559629714,
    1.4630022860305263,
    1.432182186404916,
    1.443552132571769,
    1.4237050284072335,
    1.4548714780190968,
    1.5364232015082688,
    1.425665582855759,
    1.4426108161898301,
    1.4566301469095044,
    1.3640022195252361,
    1.460212891051316,
    1.4228902445736185,
    1.4286729068347468,
    1.4380157421642559,
    1.5317434286105915
  ],
  "token_counts": [
    277,
    515,
    611,
    479,
    483,
    468,
    529,
    403,
    449,
    451,
    404,
    473,
    494,
    442,
    447,
    417,
    443,
    473,
    430,
    500,
    413,
    401,
    405,
    424,
    448,
    408,
    436,
    450,
    391,
    303,
    497,
    433,
    459,
    752,
    459,
    495,
    438,
    433,
    410,
    431,
    387,
    410,
    444,
    431,
    438,
    393,
    372,
    470,
    373,
    439,
    420,
    389,
    490,
    384,
    410,
    374,
    372,
    394
  ],
  "response_lengths": [
    1635,
    2836,
    2509,
    2697,
    4075,
    2776,
    2846,
    2494,
    2422,
    2387,
    2513,
    2237,
    2388,
    2508,
    2471,
    2571,
    2250,
    2122,
    2795,
    2190,
    2461,
    2358,
    2198,
    2718,
    2252,
    2344,
    2211,
    2117,
    2137
  ]
}