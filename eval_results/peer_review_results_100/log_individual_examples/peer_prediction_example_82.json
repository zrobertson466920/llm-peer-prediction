{
  "example_idx": 82,
  "reference": "THE DARK SIDE OF AUTOML: TOWARDS ARCHITECTURAL BACKDOOR SEARCH\n\nRen Pang† Changjiang Li† Ting Wang† Zhaohan Xi† †Pennsylvania State University, {rbp5354, cbl5583, zxx5113, ting}@psu.edu ‡Zhejiang University, sji@zju.edu.cn\n\nShouling Ji‡\n\nABSTRACT\n\nThis paper asks the intriguing question: is it possible to exploit neural architecture search (NAS) as a new attack vector to launch previously improbable attacks? Specifically, we present EVAS, a new attack that leverages NAS to find neural architectures with inherent backdoors and exploits such vulnerability using input-aware triggers. Compared with existing attacks, EVAS demonstrates many interesting properties: (i) it does not require polluting training data or perturbing model parameters; (ii) it is agnostic to downstream fine-tuning or even re-training from scratch; (iii) it naturally evades defenses that rely on inspecting model parameters or training data. With extensive evaluation on benchmark datasets, we show that EVAS features high evasiveness, transferability, and robustness, thereby expanding the adversary’s design spectrum. We further characterize the mechanisms underlying EVAS, which are possibly explainable by architecture-level “shortcuts” that recognize trigger patterns. This work showcases that NAS can be exploited in a harmful way to find architectures with inherent backdoor vulnerability. The code is available at https://github.com/ain-soph/nas_backdoor.\n\n1\n\nINTRODUCTION\n\nAs a new paradigm of applying ML techniques in practice, automated machine learning (AutoML) automates the pipeline from raw data to deployable models, which covers model design, optimizer selection, and parameter tuning. The use of AutoML greatly simplifies the ML development cycles and propels the trend of ML democratization. In particular, neural architecture search (NAS), one primary AutoML task, aims to find performant deep neural network (DNN) arches1 tailored to given datasets. In many cases, NAS is shown to find models remarkably outperforming manually designed ones (Pham et al., 2018; Liu et al., 2019; Li et al., 2020).\n\nIn contrast to the intensive research on improving the capability of NAS, its security implications are largely unexplored. As ML models are becoming the new targets of malicious attacks (Biggio & Roli, 2018), the lack of understanding about the risks of NAS is highly concerning, given its surging popularity in security-sensitive domains (Pang et al., 2022). Towards bridging this striking gap, we pose the intriguing yet critical question:\n\nIs it possible for the adversary to exploit NAS to launch previously improbable attacks?\n\nThis work provides an affirmative answer to this question. We present exploitable and vulnerable arch search (EVAS), a new backdoor attack that leverages NAS to find neural arches with inherent, exploitable vulnerability. Conventional backdoor attacks typically embed the malicious functions (“backdoors”) into the space of model parameters. They often assume strong threat models, such as polluting training data (Gu et al., 2017; Liu et al., 2018; Pang et al., 2020) or perturbing model parameters (Ji et al., 2018; Qi et al., 2022), and are thus subject to defenses based on model inspection (Wang et al., 2019; Liu et al., 2019) and data filtering (Gao et al., 2019). In EVAS, however, as the backdoors are carried in the space of model arches, even if the victim trains the models using clean data and operates them in a black-box manner, the backdoors are still retained. Moreover, due\n\n1In the following, we use “arch” for short of “architecture”.\n\nPublished as a conference paper at ICLR 2023\n\nto its independence of model parameters or training data, EVAS is naturally robust against defenses such as model inspection and input filtering.\n\nTo realize EVAS, we define a novel metric based on neural tangent kernel (Chen et al., 2021), which effectively indicates the exploitable vulnerability of a given arch; further, we integrate this metric into the NAS-without-training framework (Mellor et al., 2021; Chen et al., 2021). The resulting search method is able to efficiently identify candidate arches without requiring model training or backdoor testing. To verify EVAS’s empirical effectiveness, we evaluate EVAS on benchmark datasets and show: (i) EVAS successfully finds arches with exploitable vulnerability, (ii) the injected backdoors may be explained by arch-level “shortcuts” that recognize trigger patterns, and (iii) EVAS demonstrates high evasiveness, transferability, and robustness against defenses. Our findings show the feasibility of exploiting NAS as a new attack vector to implement previously improbable attacks, raise concerns about the current practice of NAS in security-sensitive domains, and point to potential directions to develop effective mitigation.\n\n2 RELATED WORK\n\nNext, we survey the literature relevant to this work.\n\nNeural arch search. The existing NAS methods can be categorized along search space, search strategy, and performance measure. Search space – early methods focus on the chain-of-layer structure (Baker et al., 2017), while recent work proposes to search for motifs of cell structures (Zoph et al., 2018; Pham et al., 2018; Liu et al., 2019). Search strategy – early methods rely on either random search (Jozefowicz et al., 2015) or Bayesian optimization (Bergstra et al., 2013), which are limited in model complexity; recent work mainly uses the approaches of reinforcement learning (Baker et al., 2017) or neural evolution (Liu et al., 2019). Performance measure – one-shot NAS has emerged as a popular performance measure. It considers all candidate arches as different sub-graphs of a super-net (i.e., the one-shot model) and shares weights between candidate arches (Liu et al., 2019). Despite the intensive research on NAS, its security implications are largely unexplored. Recent work shows that NAS-generated models tend to be more vulnerable to various malicious attacks than manually designed ones (Pang et al., 2022; Devaguptapu et al., 2021). This work explores another dimension: whether it can be exploited as an attack vector to launch new attacks, which complements the existing studies on the security of NAS.\n\nBackdoor attacks and defenses. Backdoor attacks inject malicious backdoors into the victim’s model during training and activate such backdoors at inference, which can be categorized along attack targets – input-specific (Shafahi et al., 2018), class-specific (Tang et al., 2020), or any-input (Gu et al., 2017), attack vectors – polluting training data (Liu et al., 2018) or releasing infected models (Ji et al., 2018), and optimization metrics – attack effectiveness (Pang et al., 2020), transferability (Yao et al., 2019), or attack evasiveness(Chen et al., 2017). To mitigate such threats, many defenses have also been proposed, which can be categorized according to their strategies (Pang et al., 2022): input filtering purges poisoning samples from training data (Tran et al., 2018); model inspection determines whether a given model is backdoored(Liu et al., 2019; Wang et al., 2019), and input inspection detects trigger inputs at inference time (Gao et al., 2019). Most attacks and defenses above focus on backdoors implemented in the space of model parameters. Concurrent to this work, Bober-Irizar et al. (2022) explore using neural arches to implement backdoors by manually designing “trigger detectors” in the arches and activating such detectors using poisoning data during training. This work investigates using NAS to directly search for arches with exploitable vulnerability, which represents a new direction of backdoor attacks.\n\n3 EVAS\n\nNext, we present EVAS, a new backdoor attack leveraging NAS to find neural arches with exploitable vulnerability. We begin by introducing the threat model.\n\n3.1 THREAT MODEL\n\nA backdoor attack injects a hidden malicious function (“backdoor”) into a target model (Pang et al., 2022). The backdoor is activated once a pre-defined condition (“trigger”) is present, while the model\n\n2\n\nPublished as a conference paper at ICLR 2023\n\nFigure 1: Attack framework of EVAS. (1) The adversary applies NAS to search for arches with exploitable vulnerability; (2) such vulnerability is retained even if the models are trained using clean data; (3) the adversary exploits such vulnerability by generating trigger-embedded inputs.\n\nbehaves normally otherwise. In a predictive task, the backdoor is often defined as classifying a given input to a class desired by the adversary, while the trigger can be defined as a specific perturbation applied to the input. Formally, given input x and trigger r = (m, p) in which m is a mask and p is a pattern, the trigger-embedded input is defined as:\n\n− Let f be the backdoor-infected model. The backdoor attack implies that for given input-label pair (x, y), f (x) = y and f ( ̃x) = t with high probability, where t is the adversary’s target class.\n\n⊙\n\n⊙\n\n ̃x = x\n\n(1\n\nm) + p\n\nm\n\n(1)\n\nThe conventional backdoor attacks typically follow two types of threat models: (i) the adversary directly trains a backdoor-embedded model, which is then released to and used by the victim user (Liu et al., 2018; Pang et al., 2020; Ji et al., 2018); or (ii) the adversary indirectly pollutes the training data or manipulate the training process (Gu et al., 2017; Qi et al., 2022) to inject the backdoor into the target model. As illustrated in Figure 1, in EVAS, we assume a more practical threat model in which the adversary only releases the exploitable arch to the user, who may choose to train the model from scratch using clean data or apply various defenses (e.g., model inspection or data filtering) before or during using the model. We believe this represents a more realistic setting: due to the prohibitive computational cost of NAS, users may opt to use performant model arches provided by third parties, which opens the door for the adversary to launch the EVAS attack.\n\nHowever, realizing EVAS represents non-trivial challenges including (i) how to define the trigger patterns? (ii) how to define the exploitable, vulnerable arches? and (iii) how to search for such arches efficiently? Below we elaborate on each of these key questions.\n\n3.2\n\nINPUT-AWARE TRIGGERS\n\nMost conventional backdoor attacks assume universal triggers: the same trigger is applied to all the inputs. However, universal triggers can be easily detected and mitigated by current defenses (Wang et al., 2019; Liu et al., 2019). Moreover, it is shown that implementing universal triggers at the arch level requires manually designing “trigger detectors” in the arches and activating such detectors using poisoning data during training (Bober-Irizar et al., 2022), which does not fit our threat model.\n\nInstead, as illustrated in Figure 1, we adopt input-aware triggers (Nguyen & Tran, 2020), in which a trigger generator g (parameterized by θ) generates trigger rx specific to each input x. Compared with universal triggers, it is more challenging to detect or mitigate input-aware triggers. Interestingly, because of the modeling capacity of the trigger generator, it is more feasible to implement input-aware triggers at the arch level (details in § 4). For simplicity, below we use ̃x = g(x; θ) to denote both generating trigger rx for x and applying rx to x to generate the trigger-embedded input ̃x.\n\n3.3 EXPLOITABLE ARCHES\n\nIn EVAS, we aim to find arches with backdoors exploitable by the trigger generator, which we define as the following optimization problem.\n\n3\n\ntrigger inputmalfunctionEVAS searchTraininginfected modeladversary<latexit sha1_base64=\"6tRDbU4fHUw4V+FYXA6UDbMIt7M=\">AAACenicbZHJahtBEIZb4yy2sng7+jJYCiQExIxxlqNJLjk6ENnGbiFqemqsRr0M3TWOhmHeItfkvfIuPqS1QCI5BQ0/VV8V1X9lpZKekuR3J9p69PjJ0+2d7rPnL17u7u0fXHhbOYFDYZV1Vxl4VNLgkCQpvCodgs4UXmbTz/P65R06L635RnWJIw23RhZSAIXUdb8Yc1DlBPrjvV4ySBYRPxTpSvTYKs7H+51rnltRaTQkFHh/kyYljRpwJIXCtssrjyWIKdziTZAGNPpRs1i5jV+FTB4X1oVnKF5k/+1oQHtf6yyQGmji12qz5ZBNfg7+l8/0OutJg6tdvrEjFR9HjTRlRWjEcsWiUjHZeO5cnEuHglQdBAgnwy9jMQEHgoK/XW7wu7Bag8kbLoR0om34FJ1JBu9wxu9EsAldwyeZnTV97sOEkjzVCvkc7rftX7rthmukm94/FBcng/T94PTrSe/s0+ou2+yIHbPXLGUf2Bn7ws7ZkAlm2A/2k/3q3EfH0Zvo7RKNOqueQ7YW0ekf6UHEXg==</latexit>f↵vulnerable archclean dataset<latexit sha1_base64=\"T8eDilDKIBvB/kBIsNFdPp63CI0=\">AAACi3icbZHbahRBEIZ7x1NcjdnolXgzuCvEm2UmHlEvgiJ4GcFNgull6ampyTTbh6G7Nu4wDD6Nt/o8vo29B9DdWNDwU/V1UfVXVinpKUl+d6Jr12/cvLVzu3vn7u69vd7+/RNvZw5wBFZZd5YJj0oaHJEkhWeVQ6EzhafZ9MOifnqJzktrvlBd4ViLCyMLCYJCatJ7OCgmXKiqFAcccktvY04lkng6mPT6yTBZRnxVpGvRZ+s4nux3vvLcwkyjIVDC+/M0qWjcCEcSFLZdPvNYCZiKCzwP0giNftwsd2jjJyGTx4V14RmKl9l/fzRCe1/rLJBaUOk3avNVk21+Af6Xz/Qm60kLV7t8a0YqXo8baaoZoYHViMVMxWTjhZVxLh0CqToIAU6GLWMohRNAwfAuN/gNrNbC5A0HkA7ahk/RmWT4Auf8EoJN6BpeZnbeDLgPHSryVCvkC3jQtn/pthuukW57f1WcHA7Tl8Pnnw/7R+/Xd9lhj9hjdsBS9oodsU/smI0YsO/sB/vJfkW70bPoTfRuhUad9Z8HbCOij38AZM/JSg==</latexit>f↵(·;✓)AdversaryInputTrigger InputgeneratorVictimMalicious ArchTrainingMalicious ModelMalfunctionClean Datasettrigger<latexit sha1_base64=\"etNJS7l+dTsiatOJk/gBHafVGRg=\">AAACe3icbZHbahRBEIZ7x1NcD0n00pvBXUFElplg1MugN7mMkE2C20voqanNNtuHobsm7tDMY3irz+XDCOk9gNmNBQ0/VV8V1X8VlZKesuxPJ7l3/8HDRzuPu0+ePnu+u7f/4szb2gEOwSrrLgrhUUmDQ5Kk8KJyKHSh8LyYfV3Uz6/ReWnNKTUVjrW4MnIiQVBMjfqcpCoxzNv+5V4vG2TLSO+KfC16bB0nl/ud77y0UGs0BEp4P8qzisZBOJKgsO3y2mMlYCaucBSlERr9OCx3btM3MVOmE+viM5Qus7c7gtDeN7qIpBY09Ru1+WrINr8A/8sXepP1pIVrXLm1I00+j4M0VU1oYLXipFYp2XRhXVpKh0CqiUKAk/GXKUyFE0DR4C43+AOs1sKUgQNIB23gM3QmGxzinF9DtAld4NPCzkOf+zihIk+NQr6A+237j2678Rr5tvd3xdnBIP84+PDtoHf0ZX2XHfaKvWZvWc4+sSN2zE7YkAGz7Cf7xX53/ia95F3yfoUmnXXPS7YRyeENiu/FHw==</latexit> ̃x<latexit sha1_base64=\"u8LfjtMONkwFfmrCZNwbPOUOgNk=\">AAACh3icbZFLb9NAEMc35tWGVwrixMUiQSqXYFfQVuJS4MKxSKSt6EbRejxJVtmHtTtOY1n+MFzhE/Ft2DwkSMpIK/0185vR7H+yQklPSfK7Fd25e+/+g7399sNHj5887Rw8u/C2dIADsMq6q0x4VNLggCQpvCocCp0pvMxmn5f1yzk6L635RlWBQy0mRo4lCAqpUedFb3LIIbf0IeZz4WiKJN70Rp1u0k9WEd8W6UZ02SbORwet7zy3UGo0BEp4f50mBQ3rMFGCwqbNS4+FgJmY4HWQRmj0w3q1fxO/Dpk8HlsXnqF4lf23oxba+0pngdSCpn6rtlgP2eWX4H/5TG+znrRwlct3dqTx6bCWpigJDaxXHJcqJhsvbYxz6RBIVUEIcDL8MoapcAIomN3mBm/Aai1MXnMA6aCp+QydSfrvccHnEGxCV/NpZhd1j/swoSBPlUK+hHtN85du2uEa6a73t8XFUT897r/7etQ9+7S5yx57yV6xQ5ayE3bGvrBzNmDAavaD/WS/ov3obXQcna7RqLXpec62Ivr4B6lsx6s=</latexit>g(·;#)<latexit sha1_base64=\"hSKFqIO+R8AL5Cb/Diu2KTFCWl4=\">AAACc3icbZFLb9NAEMc3pkBJebRw7MVqjMSFyK54HSu4cCxq01btRtV6PElW2Ye1Oy6xLH8ErvDZ+CDc2TykNmlHWumvmd+MZv+Tl0p6StO/nejR1uMnT7efdXeev3j5anfv9Zm3lQMcgFXWXeTCo5IGByRJ4UXpUOhc4Xk+/Tavn9+g89KaU6pLHGoxNnIkQVBInSSz5Hq3l/bTRcT3RbYSPbaK4+u9ziUvLFQaDYES3l9laUnDRjiSoLDt8spjKWAqxngVpBEa/bBZ7NrGb0OmiEfWhWcoXmTvdjRCe1/rPJBa0MSv1WbLIZv8HHyQz/U660kLV7tiY0cafRk20pQVoYHliqNKxWTjuWVxIR0CqToIAU6GX8YwEU4ABWO73OBPsFoLUzQcQDpoGz5FZ9L+R5zxGwg2oWv4JLezJuE+TCjJU62Qz+GkbW/pthuukW16f1+cHfazT/0PPw57R19Xd9lm++yAvWMZ+8yO2Hd2zAYM2Jj9Yr/Zn86/aD86iJIlGnVWPW/YWkTv/wNTOMFp</latexit>xgeneratorclean input123(3)\n\n(4)\n\nPublished as a conference paper at ICLR 2023\n\nSpecifically, let α and θ respectively denote f ’s arch and model parameters. We define f ’s training as minimizing the following loss:\n\ntrn(θ, α) ≜ E(x,y)∼Dl(fα(x; θ), y)\n\nL\n\n(2)\n\nwhere fα denotes the model with arch fixed as α and dependent on α, we define:\n\nis the underlying data distribution. As θ is\n\nD\n\nθα ≜ arg min\n\ntrn(θ, α)\n\nθ L\n\nFurther, we define the backdoor attack objective as:\n\natk(α, θ) ≜ E(x,y)∼D [l(fα(x; θα), y) + λl(fα(g(x; θ); θα), t)]\n\nL\n\nwhere the first term specifies that f works normally on clean data, the second term specifies that f classifies trigger-embedded inputs to target class t, and the parameter λ balances the two factors. Note that we assume the testing data follows the same distribution\n\nas the training data.\n\nOverall, we consider an arch α∗ having exploitable vulnerability if it is possible to find a trigger generator θ∗, such that\n\natk(α∗, θ∗) is below a certain threshold.\n\nD\n\nL\n\n3.4 SEARCH WITHOUT TRAINING\n\nL\n\nSearching for exploitable archs by directly optimizing Eq. 4 is challenging: the nested optimization requires recomputing θ (i.e., re-training model f ) in trn whenever α is updated; further, as α and θ are coupled in\n\natk, it requires re-training generator g once α is changed.\n\nL\n\nMotivated by recent work (Mellor et al., 2021; Wu et al., 2021; Abdelfattah et al., 2021; Ning et al., 2021) on NAS using easy-to-compute metrics as proxies (without training), we present a novel method of searching for exploitable arches based on neural tangent kernel (NTK) (Jacot et al., 2018) without training the target model or trigger generator. Intuitively, NTK describes model training dynamics by gradient descent (Jacot et al., 2018; Chizat et al., 2019; Lee et al., 2019). In the limit of infinite-width DNNs, NTK becomes constant, which allows closed-form statements to be made about model training. Recent work (Chen et al., 2021; Mok et al., 2022) shows that NTK serves as an effective predictor of model “trainability” (i.e., how fast the model converges at early training stages). Formally, considering model f (parameterized by θ) mapping input x to a probability vector f (x; θ) (over different classes), the NTK is defined as the product of the Jacobian matrix:\n\nΘ(x, θ) ≜\n\n(cid:20) ∂f (x; θ) ∂θ\n\n(cid:21) (cid:20) ∂f (x; θ)\n\n(cid:21)⊺\n\n∂θ\n\n(5)\n\nLet λmin (λmax) be the smallest (largest) eigenvalue of the empirical NTK ˆΘ(θ) ≜ E(x,y)∼DΘ(x, θ). The condition number κ ≜ λmax/λmin serves as a metric to estimate model trainability (Chen et al., 2021), with a smaller conditional number indicating higher trainability.\n\nFigure 2: The conditional number of NTK versus the model performance (ACC) and vulnerability (ASR).\n\nIn our context, we consider the trigger generator and the target model as an end-to-end model and measure the empirical NTK of the trigger generator under randomly initialized θ: (cid:21)⊺\n\n(cid:21) (cid:20) ∂f (g(x; θ; θ)\n\nˆΘ(θ) ≜ E(x,y)∼D,θ∼Pθ◦\n\n(cid:20) ∂f (g(x; θ); θ) ∂θ\n\n∂θ\n\n(6)\n\n4\n\nASR (%)40608010020608010040ACC (%)1234Conditional Number of NTK ( )Published as a conference paper at ICLR 2023\n\nwhere Pθ◦ represents the initialization distribution of θ. Here, we emphasize that the measure should be independent of θ’s initialization.\n\nIntuitively, ˆΘ(θ) measures the trigger generator’s trainability with respect to a randomly initialized target model. The generator’s trainability indicates the easiness of effectively generating input-aware triggers, implying the model’s vulnerability to input-aware backdoor attacks. To verify the hypothesis, on the CIFAR10 dataset with the generator configured as in Appendix § A, we measure ˆΘ(θ) with respect to 900 randomly generated arches as well as the model accuracy (ACC) on clean inputs and the attack success rate (ASR) on trigger-embedded inputs. Specifically, for each arch α, we first train the model fα to measure ACC and then train the trigger generator g with respect to fα on the same dataset to measure ASR, with results shown in Figure 2. Observe that the conditional number of ˆΘ(θ) has a strong negative correlation with ASR, with a smaller value indicating higher attack vulnerability; meanwhile, it has a limited correlation with ACC, with most of the arches having ACC within the range from 80% to 95%.\n\nLeveraging the insights above, we present a simple yet effective algorithm that searches for exploitable arches without training, which is a variant of regularized evolution (Real et al., 2019; Mellor et al., of n arches randomly sampled 2021). As sketched in Algorithm 1, it starts from a candidate pool ′ of m arches from , randomly from a pre-defined arch space; at each iteration, it samples a subset mutates the best candidate (i.e., with the lowest score), and replaces the oldest arch in with this newly mutated arch. In our implementation, the score function is defined as the condition number of Eq. 6; the arch space is defined to be the NATS-Bench search space (Dong & Yang, 2020), which consists of 5 atomic operators {none, skip connect, conv 1 3}; and the mutation function is defined to be randomly substituting one operator with another.\n\n3, and avg pooling 3\n\n1, conv 3\n\nA A\n\nA\n\nA\n\n×\n\n×\n\n×\n\nAlgorithm 1: EVAS Attack Input: n – pool size; m – sample size; score – score function; sample – subset sampling function; mutate\n\n– arch mutation function;\n\nOutput: exploitable arch\n\n1 A, S, T = [], [], [] ; 2 for i ← 1 to n do\n\n// candidate archs, scores, timestamps\n\n3\n\nA[i] ← randomly generated arch, S[i] ← score(A[i]), T [i] ← 0;\n\n7\n\n6\n\n4 best ← 0; 5 while maximum iterations not reached yet do i ← arg mink∈sample(A,m) S[k] ; j ← arg maxk∈A T [k] ; A[j] ← mutate(A[i]) ; S[j] ← score(A[j]) ; T ← T + 1, T [j] ← 0 ; if S[j] < S[best] then best ← j;\n\n8\n\n9\n\n10\n\n11\n\n// best candidate // oldest candidate // mutate candidate // update score // update timestamps\n\n12 return A[best];\n\n4 EVALUATION\n\nWe conduct an empirical evaluation of EVAS on benchmark datasets under various scenarios. The experiments are designed to answer the following key questions: (i) does it work? – we evaluate the performance and vulnerability of the arches identified by EVAS; (ii) how does it work? – we explore the dynamics of EVAS search as well as the characteristics of its identified arches; and (ii) how does it differ? – we compare EVAS with conventional backdoors in terms of attack evasiveness, transferability, and robustness.\n\n4.1 EXPERIMENTAL SETTING\n\nDatasets. In the evaluation, we primarily use three datasets that have been widely used to benchmark NAS methods (Chen et al., 2019; Li et al., 2020; Liu et al., 2019; Pham et al., 2018; Xie et al., 2019): CIFAR10 (Krizhevsky & Hinton, 2009), which consists of 32 32 color images drawn from 10 classes; CIFAR100, which is similar to CIFAR10 but includes 100 finer-grained classes; and\n\n×\n\n5\n\nPublished as a conference paper at ICLR 2023\n\nFigure 3: Sample arch identified by EVAS in comparison of two randomly generated arches.\n\n×\n\nImageNet16, which is a subset of the ImageNet dataset (Deng et al., 2009) down-sampled to images of size 16\n\n16 in 120 classes.\n\nSearch space. We consider the search space defined by NATS-Bench ( Dong et al. (2021)), which consists of 5 operators {none, skip connect, conv 1 3} defined among 4 nodes, implying a search space of 15,625 candidate arches.\n\n3, and avg pooling 3\n\n1, conv 3\n\n×\n\n×\n\n×\n\nBaselines. We compare the arches found by EVAS with ResNet18 (He et al., 2016), a manually designed arch. For completeness, we also include two arches randomly sampled from the NATSBench space, which are illustrated in Figure 3. By default, for each arch α, we assume the adversary trains a model fα and then trains the trigger generator g with respect to fα on the same dataset. We consider varying settings in which the victim directly uses fα, fine-tunes fα, or only uses α and re-trains it from scratch (details in § 4.4).\n\nMetrics. We mainly use two metrics, attack success rate (ASR) and clean data accuracy (ACC). Intuitively, ASR is the target model’s accuracy in classifying trigger inputs to the adversary’s target class during inference, which measures the attack effectiveness, while ACC is the target model’s accuracy in correctly classifying clean inputs, which measures the attack evasiveness.\n\nThe default parameter setting and the trigger generator configuration are deferred to Appendix § A.\n\n4.2 Q1: DOES EVAS WORK?\n\nFigure 3 illustrates one sample arch identified by EVAS on the CIFAR10 dataset. We use this arch throughout this set of experiments to show that its vulnerability is at the arch level and universal across datasets. To measure the vulnerability of different arches, we first train each arch using clean data, then train a trigger generator specific to this arch, and finally measure its ASR and ACC.\n\nTable 1 reports the results. We have the following observations. First, the ASR of EVAS is significantly higher than ResNet18 and the other two random arches. For instance, on CIFAR10, EVAS is 21.8%, 28.3%, and 34.5% more effective than ResNet18 and random arches, respectively. Second, EVAS has the highest ASR across all the datasets. Recall that we use the same arch throughout different datasets. This indicates that the attack vulnerability probably resides at the arch level and is insensitive to concrete datasets, which corroborates with prior work on NAS: one performant arch found on one dataset often transfers across different datasets (Liu et al., 2019). This may be explained as follows. An arch α essentially defines a function family ; θ) is an ·\ninstance in or exploitable by a trigger generator). Third, all the arches show higher ASR on simpler datasets such as CIFAR10. This may be explained by that more complex datasets (e.g., more classes, higher resolution) imply more intricate manifold structures, which may interfere with arch-level backdoors.\n\nFα (e.g., effective to extract important features\n\nFα, thereby carrying the characteristics of\n\nFα, while a trained model fα(\n\nTable 1. Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS, ResNet18, and two random arches.\n\narchitecture\n\ndataset\n\nEVAS\n\nResNet18\n\nRandom I\n\nRandom II\n\nACC\n\nASR\n\nACC\n\nASR\n\nACC\n\nASR\n\nACC\n\nASR\n\nCIFAR10 94.26% 81.51% 96.10% 59.73% 91.91% 53.21% 92.05% 47.04% CIFAR100 71.54% 60.97% 78.10% 53.53% 67.09% 42.41% 67.15% 47.17% ImageNet16 45.92% 55.83% 47.62% 42.28% 39.33% 37.45% 39.48% 32.15%\n\nTo understand the attack effectiveness of EVAS on individual inputs, we illustrate sample clean inputs and their trigger-embedded variants in Figure 4. Further, using GradCam (Selvaraju et al., 2017), we show the model’s interpretation of clean and trigger inputs with respect to their original and target\n\n6\n\n021302130213Conv 1×1Conv 3×3Avg Pool 3×3Skip Connect(i) EVAS(ii) Random 1(iii) Random 2Published as a conference paper at ICLR 2023\n\nclasses. Observe that the trigger pattern is specific to each input. Further, even though the two trigger inputs are classified into the same target class, the difference in their heatmaps shows that the model pays attention to distinct features, highlighting the effects of input-aware triggers.\n\nFigure 4: Sample clean and trigger-embedded inputs as well as their GradCam interpretation by the target model.\n\n4.3 Q2: HOW DOES EVAS WORK?\n\nNext, we explore the dynamics of how EVAS searches for exploitable arches. For simplicity, given the arch identified by EVAS in Figure 3, we consider the set of candidate arches with the operators on the 0-3 (skip connect) and 0-1 (conv 3 3) connections replaced by others. We measure the ACC and ASR of all these candidate arches and illustrate the landscape of their scores in Figure 5. Observe that the exploitable arch features the lowest score among the surrounding arches, suggesting the existence of feasible mutation paths from random arches to reach exploitable arches following the direction of score descent.\n\n×\n\nFigure 5: Landscape of candidate arches surrounding exploitable arches with their ASR, ACC, and scores.\n\n1 and 3\n\nFurther, we ask the question: what makes the arches found by EVAS exploitable? Observe that the arch in Figure 3 uses the conv 1 3 operators on a number of connections. We thus generate arches by enumerating all the possible combinations of conv 1 3 on these connections and measure their performance, with results summarized in Appendix § B. Observe that while all these arches show high ASR, their vulnerability varies greatly from about 50% to 90%. We hypothesize that specific combinations of conv 1 3 create arch-level “shortcuts” for recognizing trigger patterns. We consider exploring the causal relationships between concrete arch characteristics and attack vulnerability as our ongoing work.\n\n1 and conv 3\n\n1 and 3\n\n×\n\n×\n\n×\n\n×\n\n×\n\n×\n\n4.4 Q3: HOW DOES EVAS DIFFER?\n\nTo further understand the difference between EVAS and conventional backdoors, we compare the arches found by EVAS and other arches under various training and defense scenarios.\n\n7\n\nclean input“bird”trigger input“airplane”“deer”“airplane”noneskip connectconv 1x1conv 3x3avg pool 3x3noneskip connectconv 1x1conv 3x3avg pool 3x3ASR: 30.01ACC: 90.34Score: 12.54ASR: 62.35ACC: 92.89Score: 4.49ASR: 41.21ACC: 91.53Score: 9.84ASR: 36.99ACC: 92.53Score: 11.82ASR: 53.83ACC: 91.00Score: 4.22ASR: 52.52ACC: 91.67Score: 19.43ASR: 52.25ACC: 92.62Score: 6.55ASR: 50.22ACC: 92.47Score: 12.28ASR: 38.47ACC: 92.11Score: 10.87ASR: 44.48ACC: 91.63Score: 5.98ASR: 29.64ACC: 91.19Score: 19.21ASR: 46.76ACC: 91.97Score: 3.68ASR: 50.71ACC: 92.54Score: 20.51ASR: 48.66ACC: 92.86Score: 15.55ASR: 42.76ACC: 91.58Score: 5.87ASR: 27.01ACC: 91.52Score: 23.35ASR: 81.51ACC: 94.26Score: 3.48ASR: 51.19ACC: 93.22Score: 9.24ASR: 32.66ACC: 93.22Score: 21.89ASR: 45.59ACC: 92.55Score: 6.80ASR: 39.99ACC: 90.30Score: 13.88ASR: 56.35ACC: 92.62Score: 8.31ASR: 43.13ACC: 92.36Score: 32.61ASR: 51.55ACC: 92.59Score: 19.37ASR: 60.71ACC: 91.30Score: 8.18510152025300-3 connection0-1 connectionPublished as a conference paper at ICLR 2023\n\nFine-tuning with clean data. We first consider the scenario in which, with the trigger generator fixed, the target model is fine-tuned using clean data (with concrete setting deferred to Appendix § A). Table 2 shows the results evaluated on CIFAR10 and CIFAR100. Observe that fine-tuning has a marginal impact on the ASR of all the arches. Take Random I as an example, compared with Table 1, its ASR on CIFAR10 drops only by 7.40% after fine-tuning. This suggests that the effectiveness of fine-tuning to defend against input-aware backdoor attacks may be limited.\n\nTable 2. Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS, ResNet18, and two random arches after fine-tuning.\n\narchitecture\n\ndataset\n\nEVAS\n\nResNet18\n\nRandom I\n\nRandom II\n\nACC\n\nASR\n\nACC\n\nASR\n\nACC\n\nASR\n\nACC\n\nASR\n\nCIFAR10 90.33% 74.40% 92.22% 53.87% 85.62% 45.81% 87.02% 45.16% CIFAR100 72.52% 53.50% 79.02% 50.42% 58.89% 38.91% 60.18% 25.41%\n\nRe-training from scratch. Another common scenario is that the victim user re-initializes the target model and re-trains it from scratch using clean data. We simulate this scenario as follows. After the trigger generator and target model are trained, we fix the generator, randomly initialize (using different seeds) the model, and train it on the given dataset. Table 3 compares different arches under this scenario. It is observed that EVAS significantly outperforms ResNet18 and random arches in terms of ASR (with comparable ACC). For instance, it is 33.4%, 24.9%, and 19.6% more effective than the other arches respectively. This may be explained by two reasons. First, the arch-level backdoors in EVAS are inherently more agnostic to model re-training than the model-level backdoors in other arches. Second, in searching for exploitable arches, EVAS explicitly enforces that such vulnerability should be insensitive to model initialization (cf. Eq. 4). Further, observe that, as expected, re-training has a larger impact than fine-tuning on the ASR of different arches; however, it is still insufficient to mitigate input-aware backdoor attacks.\n\nTable 3. Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS, ResNet18, and two random arches after re-training from scratch.\n\narchitecture\n\ndataset\n\nEVAS\n\nResNet18\n\nRandom I\n\nRandom II\n\nACC\n\nASR\n\nACC\n\nASR\n\nACC\n\nASR\n\nACC\n\nASR\n\nCIFAR10 94.18% 64.57% 95.62% 31.15% 91.91% 39.72% 92.09% 45.02% CIFAR100 71.54% 49.47% 78.53% 44.39% 67.09% 35.80% 67.01% 39.24%\n\nFine-tuning with poisoning data. Further, we explore the setting in which the adversary is able to poison a tiny portion of the fine-tuning data, which assumes a stronger threat model. To simulate this scenario, we apply the trigger generator to generate trigger-embedded inputs and mix them with the clean fine-tuning data. Figure 6 illustrates the ASR and ACC of the target model as functions of the fraction of poisoning data in the fine-tuning dataset. Observe that, even with an extremely small poisoning ratio (e.g., 0.01%), it can significantly boost the ASR (e.g., 100%) while keeping the ACC unaffected. This indicates that arch-level backdoors can be greatly enhanced by combining with other attack vectors (e.g., data poisoning).\n\nFigure 6: Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS as a function of poisoning ratio.\n\n8\n\n7580859095100ASRACCpoisoning ratio (10-5)0246810Published as a conference paper at ICLR 2023\n\nBackdoor defenses. Finally, we evaluate EVAS against three categories of defenses, model inspection, input filtering, and model sanitization.\n\nModel inspection determines whether a given model f is infected with backdoors. We use NeuralCleanse (Wang et al., 2019) as a representative defense. Intuitively, it searches for potential triggers in each class. If a class is trigger-embedded, the minimum perturbation required to change the predictions of inputs from other classes to this class is abnormally small. It detects anomalies using median absolute deviation (MAD) and all classes with MAD scores larger than 2 are regarded as infected. As shown in Table 4, the MAD scores of EVAS’s target classes on three datasets are all below the threshold. This can be explained by that NeuralCleanse is built upon the universal trigger assumption, which does not hold for EVAS.\n\nTable 4. Detection results of NeuralCleanse and STRIP for EVAS. NeuralCleanse shows the MAD score and STRIP shows the AUROC score of binary classification.\n\ndataset CIFAR10 CIFAR100 ImageNet16\n\nNeuralCleanse STRIP\n\n0.895 0.618 0.674\n\n0.49 0.51 0.49\n\nInput filtering detects at inference time whether an incoming input is embedded with a trigger. We use STRIP (Gao et al., 2019) as a representative defense in this category. It mixes a given input with a clean input and measures the self-entropy of its prediction. If the input is trigger-embedded, the mixture remains dominated by the trigger and tends to be misclassified, resulting in low self-entropy. However, as shown in Table 4, the AUROC scores of STRIP in classifying trigger-embedded inputs by EVAS are all close to random guess (i.e., 0.5). This can also be explained by that EVAS uses input-aware triggers, where each trigger only works for one specific input and has a limited impact on others. Table 5. Model performance on clean inputs (ACC) and attack performance on trigger-embedded inputs (ASR) of EVAS and ResNet18 after Fine-Pruning.\n\narchitecture\n\ndataset\n\nEVAS\n\nResNet18\n\nACC\n\nASR\n\nACC\n\nASR\n\n90.53% 72.56% 94.11% 50.95% CIFAR10 CIFAR100 64.92% 54.55% 73.35% 38.54% ImageNet16 40.28% 32.57% 42.53% 27.59%\n\nModel sanitization, before using a given model, sanitizes it to mitigate the potential backdoors, yet without explicitly detecting whether the model is tampered. We use Fine-Pruning (Liu et al., 2018) as a representative. It uses the property that the backdoor attack typically exploits spare model capacity. It thus prunes rarely-used neurons and then applies fine-tuning to defend against pruning-aware attacks. We apply Fine-Pruning on the EVAS and ResNet18 models from Table 1, with results shown in Table 5. Observe that Fine-Pruning has a limited impact on the ASR of EVAS (even less than ResNet18). This may be explained as follows. The activation patterns of input-aware triggers are different from that of universal triggers, as each trigger may activate a different set of neurons. Moreover, the arch-level backdoors in EVAS may not concentrate on individual neurons but span over the whole model structures.\n\n5 CONCLUSION\n\nThis work studies the feasibility of exploiting NAS as an attack vector to launch previously improbable attacks. We present a new backdoor attack that leverages NAS to efficiently find neural network architectures with inherent, exploitable vulnerability. Such architecture-level backdoors demonstrate many interesting properties including evasiveness, transferability, and robustness, thereby greatly expanding the design spectrum for the adversary. We believe our findings raise concerns about the current practice of NAS in security-sensitive domains and point to potential directions to develop effective mitigation.\n\n9\n\nPublished as a conference paper at ICLR 2023\n\nACKNOWLEDGMENTS\n\nWe thank anonymous reviewers and shepherd for valuable feedback. This work is partially supported by the National Science Foundation under Grant No. 2212323, 2119331, 1951729, and 1953893. Any opinions, findings, and conclusions or recommendations are those of the authors and do not necessarily reflect the views of the National Science Foundation. S. Ji is partly supported by the National Key Research and Development Program of China under No. 2022YFB3102100, and NSFC under No. 62102360 and U1936215.\n\nREFERENCES\n\nMohamed S Abdelfattah, Abhinav Mehrotra, Łukasz Dudziak, and Nicholas Donald Lane. ZeroCost Proxies for Lightweight NAS. In Proceedings of International Conference on Learning Representations (ICLR), 2021.\n\nBowen Baker, Otkrist Gupta, Nikhil Naik, and Ramesh Raskar. Designing Neural Network Architectures using Reinforcement Learning. In Proceedings of International Conference on Learning Representations (ICLR), 2017.\n\nJ. Bergstra, D. Yamins, and D. D. Cox. Making a Science of Model Search: Hyperparameter In Proceedings of IEEE\n\nOptimization in Hundreds of Dimensions for Vision Architectures. Conference on Machine Learning (ICML), 2013.\n\nBattista Biggio and Fabio Roli. Wild Patterns: Ten Years after The Rise of Adversarial Machine\n\nLearning. Pattern Recognition, 84:317–331, 2018.\n\nMikel Bober-Irizar, Ilia Shumailov, Yiren Zhao, Robert Mullins, and Nicolas Papernot. Architectural\n\nBackdoors in Neural Networks. ArXiv e-prints, 2022.\n\nWuyang Chen, Xinyu Gong, and Zhangyang Wang. Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective. In Proceedings of International Conference on Learning Representations (ICLR), 2021.\n\nWuyang Chen, Xinyu Gong, and Zhangyang Wang. Neural Architecture Search on ImageNet in Four GPU Hours: A Theoretically Inspired Perspective. In Proceedings of International Conference on Learning Representations (ICLR), 2021.\n\nXin Chen, Lingxi Xie, Jun Wu, and Qi Tian. Progressive Differentiable Architecture Search: Bridging the Depth Gap between Search and Evaluation. In Proceedings of IEEE International Conference on Computer Vision (ICCV), 2019.\n\nXinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted Backdoor Attacks on Deep\n\nLearning Systems Using Data Poisoning. ArXiv e-prints, 2017.\n\nLenaic Chizat, Edouard Oyallon, and Francis Bach. On Lazy Training in Differentiable Programming.\n\nIn Proceedings of Advances in Neural Information Processing Systems (NeurIPS), 2019.\n\nJ. Deng, W. Dong, R. Socher, L. Li, Kai Li, and Li Fei-Fei. ImageNet: A Large-scale Hierarchical Image Database. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2009.\n\nChaitanya Devaguptapu, Devansh Agarwal, Gaurav Mittal, Pulkit Gopalani, and Vineeth N Balasubramanian. On Adversarial Robustness: A Neural Architecture Search perspective. In RobustML Workshop of International Conference on Learning Representations, 2021.\n\nXuanyi Dong and Yi Yang. NAS-Bench-201: Extending the Scope of Reproducible Neural Architecture Search. In Proceedings of International Conference on Learning Representations (ICLR), 2020.\n\nXuanyi Dong, Lu Liu, Katarzyna Musial, and Bogdan Gabrys. NATS-Bench: Benchmarking NAS Algorithms for Architecture Topology and Size. In Proceeddings of IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021.\n\n10\n\nPublished as a conference paper at ICLR 2023\n\nYansong Gao, Chang Xu, Derui Wang, Shiping Chen, Damith Ranasinghe, and Surya Nepal. STRIP:\n\nA Defence Against Trojan Attacks on Deep Neural Networks. In ArXiv e-prints, 2019.\n\nTianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. BadNets: Identifying Vulnerabilities in the\n\nMachine Learning Model Supply Chain. ArXiv e-prints, 2017.\n\nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image Recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.\n\nArthur Jacot, Franck Gabriel, and Clément Hongler. Neural Tangent Kernel: Convergence and Generalization in Neural Networks. In Proceedings of IEEE Conference on Machine Learning (ICML), 2018.\n\nYujie Ji, Xinyang Zhang, Shouling Ji, Xiapu Luo, and Ting Wang. Model-Reuse Attacks on Deep Learning Systems. In Proceedings of ACM SAC Conference on Computer and Communications (CCS), 2018.\n\nRafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever. An Empirical Exploration of Recurrent Network Architectures. In Proceedings of IEEE Conference on Machine Learning (ICML), 2015.\n\nAlex Krizhevsky and Geoffrey Hinton. Learning Multiple Layers of Features from Tiny Images.\n\nTechnical report, University of Toronto, 2009.\n\nJaehoon Lee, Lechao Xiao, Samuel S. Schoenholz, Yasaman Bahri, Roman Novak, Jascha SohlDickstein, and Jeffrey Pennington. Wide Neural Networks of Any Depth Evolve as Linear Models under Gradient Descent. In Proceedings of Advances in Neural Information Processing Systems (NeurIPS), 2019.\n\nGuohao Li, Guocheng Qian, Itzel C. Delgadillo, Matthias Müller, Ali Thabet, and Bernard Ghanem. SGAS: Sequential Greedy Architecture Search. In Proceedings of International Conference on Learning Representations (ICLR), 2020.\n\nHanxiao Liu, Karen Simonyan, and Yiming Yang. DARTS: Differentiable Architecture Search. In\n\nProceedings of International Conference on Learning Representations (ICLR), 2019.\n\nK. Liu, B. Dolan-Gavitt, and S. Garg. Fine-Pruning: Defending Against Backdooring Attacks on\n\nDeep Neural Networks. ArXiv e-prints, 2018.\n\nYingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. Trojaning Attack on Neural Networks. In Proceedings of Network and Distributed System Security Symposium (NDSS), 2018.\n\nYingqi Liu, Wen-Chuan Lee, Guanhong Tao, Shiqing Ma, Yousra Aafer, and Xiangyu Zhang. ABS: Scanning Neural Networks for Back-Doors by Artificial Brain Stimulation. In Proceedings of ACM SAC Conference on Computer and Communications (CCS), 2019.\n\nJoseph Mellor, Jack Turner, Amos Storkey, and Elliot J. Crowley. Neural Architecture Search without\n\nTraining. In Proceedings of IEEE Conference on Machine Learning (ICML), 2021.\n\nJisoo Mok, Byunggook Na, Ji-Hoon Kim, Dongyoon Han, and Sungroh Yoon. Demystifying the Neural Tangent Kernel from a Practical Perspective: Can it be trusted for Neural Architecture Search without training? In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022.\n\nTuan Anh Nguyen and Tuan Anh Tran. Input-Aware Dynamic Backdoor Attack. In Proceedings of\n\nAdvances in Neural Information Processing Systems (NIPS), 2020.\n\nXuefei Ning, Changcheng Tang, Wenshuo Li, Zixuan Zhou, Shuang Liang, Huazhong Yang, and Yu Wang. Evaluating Efficient Performance Estimators of Neural Architectures. In Proceedings of Advances in Neural Information Processing Systems (NIPS), 2021.\n\nRen Pang, Hua Shen, Xinyang Zhang, Shouling Ji, Yevgeniy Vorobeychik, Xiapu Luo, Alex Liu, and Ting Wang. A Tale of Evil Twins: Adversarial Inputs versus Poisoned Models. In Proceedings of ACM SAC Conference on Computer and Communications (CCS), 2020.\n\n11\n\nPublished as a conference paper at ICLR 2023\n\nRen Pang, Zhaohan Xi, Shouling Ji, Xiapu Luo, and Ting Wang. On the Security Risks of AutoML.\n\nIn Proceedings of USENIX Security Symposium (SEC), 2022.\n\nRen Pang, Zheng Zhang, Xiangshan Gao, Zhaohan Xi, Shouling Ji, Peng Cheng, and Ting Wang. TrojanZoo: Towards Unified, Holistic, and Practical Evaluation of Neural Backdoors. In Proceedings of IEEE European Symposium on Security and Privacy (Euro S&P), 2022.\n\nHieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, and Jeff Dean. Efficient Neural Architecture Search via Parameter Sharing. In Proceedings of IEEE Conference on Machine Learning (ICML), 2018.\n\nXiangyu Qi, Tinghao Xie, Ruizhe Pan, Jifeng Zhu, Yong Yang, and Kai Bu. Towards Practical Deployment-Stage Backdoor Attack on Deep Neural Networks. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022.\n\nEsteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized Evolution for Image Classifier Architecture Search. In Proceedings of AAAI Conference on Artificial Intelligence (AAAI), 2019.\n\nR. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra. Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization. In Proceedings of IEEE International Conference on Computer Vision (ICCV), 2017.\n\nAli Shafahi, W. Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, and Tom Goldstein. Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks. In Proceedings of Advances in Neural Information Processing Systems (NeurIPS), 2018.\n\nDi Tang, XiaoFeng Wang, Haixu Tang, and Kehuan Zhang. Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection. In Proceedings of USENIX Security Symposium (SEC), 2020.\n\nBrandon Tran, Jerry Li, and Aleksander Madry. Spectral Signatures in Backdoor Attacks.\n\nIn\n\nProceedings of Advances in Neural Information Processing Systems (NeurIPS), 2018.\n\nB. Wang, Y. Yao, S. Shan, H. Li, B. Viswanath, H. Zheng, and B. Y. Zhao. Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks. In Proceedings of IEEE Symposium on Security and Privacy (S&P), 2019.\n\nMeng-Ting Wu, Hung-I Lin, and Chun-Wei Tsai. A Training-Free Genetic Neural Architecture In Proceedings of ACM International Conference on Intelligent Computing and its\n\nSearch. Emerging (ICEA), 2021.\n\nSirui Xie, Hehui Zheng, Chunxiao Liu, and Liang Lin. SNAS: Stochastic Neural Architecture Search.\n\nIn Proceedings of International Conference on Learning Representations (ICLR), 2019.\n\nYuanshun Yao, Huiying Li, Haitao Zheng, and Ben Y. Zhao. Latent Backdoor Attacks on Deep Neural Networks. In Proceedings of ACM SAC Conference on Computer and Communications (CCS), 2019.\n\nBarret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. Learning Transferable Architectures for Scalable Image Recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.\n\nA EXPERIMENTAL SETTING\n\nA.1 PARAMETER SETTING\n\nTable 6 summarizes the default parameter setting.\n\nA.2 GENERATOR ARCHITECTURE\n\nTable 7 lists the architecture of the trigger generator.\n\n12\n\nPublished as a conference paper at ICLR 2023\n\nTable 6. Default parameter setting.\n\nType\n\nParameter Setting\n\nMask generator training epochs 25 Mark generator training epochs 10 Backdoor probability ρb 0.1 Cross-trigger probability ρc 0.1\n\nBackdoor attack\n\nOptimizer Adam\n\nInitial learning rate 0.01\n\nBatch size 96\n\nTraining epochs 50\n\nOptimizer SGD Initial learning rate 0.01\n\nLR scheduler Cosine annealing\n\nBatch size 96\n\nPool size n 50 Sample size m 10\n\nMutation function random substitution\n\nIterations 4,000\n\nFine-tuning\n\nArch search\n\nBlock\n\nblock 1\n\nEncoder\n\nblock 2\n\nblock 3\n\nMiddle\n\nTable 7. Generator network architecture.\n\nLayer Setting\n\nConvBNReLU 3x3 Cin = 3, Cout = 32 ConvBNReLU 3x3 Cin = Cout = 32\n\nMax Pooling kernel_size = 2 ConvBNReLU 3x3 Cin = 32, Cout = 64 ConvBNReLU 3x3 Cin = Cout = 64\n\nMax Pooling kernel_size = 2 ConvBNReLU 3x3 Cin = 64, Cout = 128 ConvBNReLU 3x3 Cin = Cout = 128 Max Pooling kernel_size = 2 ConvBNReLU 3x3 Cin = Cout = 128\n\nUpsample\n\nscale_factor = 2\n\nblock 1\n\nConvBNReLU 3x3 Cin = Cout = 128 ConvBNReLU 3x3 Cin = 128, Cout = 64\n\nDecoder\n\nblock 2\n\nUpsample\n\nscale_factor = 2\n\nConvBNReLU 3x3 Cin = Cout = 64 ConvBNReLU 3x3 Cin = 64, Cout = 32\n\nUpsample\n\nscale_factor = 2\n\nblock 2\n\nConvBNReLU 3x3 Cin = Cout = 32\n\nConvBN 3x3 Cin = 32, Cout = mask_generator ? 1 : 3\n\nB ADDITIONAL RESULTS\n\nB.1 NTK OF TARGET MODEL\n\nHere, we measure the NTK conditional number of the target model f under random initialization using the implementation of (Chen et al., 2021) and its corresponding ASR and ACC. Figure 7 shows their correlation. Observed that the NTK conditional number is negatively correlated with ACC (with Kendall’s coefficient τ = 0.385) and has a very weak correlation with ASR (with τ = 0.100), which is consistent with (Chen et al., 2021).\n\n−\n\nThe difference between Figure 2 and Figure 7 can be explained as follows. Figure 2 measures the NTK conditional number κg of the trigger generator g (with respect to the randomly initialized target model f ), which indicates g’s trainability (or f ’s vulnerability). As backdoor attacks embed two functions (one classifying clean inputs and the other classifying trigger inputs) into the same model, there tends to exist a natural trade-off between ASR and ACC. Therefore, κg shows a negative correlation with ASR and a weak positive correlation with ACC. Meanwhile, Figure 7 measures the\n\n13\n\nPublished as a conference paper at ICLR 2023\n\nFigure 7: The NTK conditional number of target model versus the model performance (ACC) and vulnerability (ASR).\n\nNTK conditional number κf of the target model f , which indicates f ’s trainability. Therefore, κf shows a negative correlation with ACC but a very weak correlation with ASR.\n\nB.2 ASR-ACC TRADE-OFF\n\nFigure 8 shows the correlation between the ASR and ACC of sampled arches (with Kendall’s coefficient τ = 0.390). Intuitively, as backdoor attacks embed two functions (one classifying clean inputs and the other classifying trigger inputs) into the same model, there tends to exist a natural trade-off between ASR and ACC. This trade-off also implies that it is feasible to properly optimize ASR only to find performant but vulnerable arches.\n\n−\n\nFigure 8: Trade-off between model performance (ACC) and vulnerability (ASR).\n\nB.3\n\nINTERPRETABILITY VERSUS VULNERABILITY\n\nTo understand the possible correlation between the attack vulnerability of an arch α and its interpretability, we compare the interpretation of each model fα regarding 100 clean inputs using GradCam (Selvaraju et al., 2017). Figure 9 illustrates sample inputs and their interpretation by different models.\n\nFurther, to quantitatively measure the similarity of interpretation, we use the intersection-over-union (IoU) score, which is widely used in object detection to compare model predictions with ground-truth bounding boxes. Formally, the IoU score of a binary-valued heatmap m with respect to another map m′ is defined as their Jaccard similarity:\n\nIoU(m) = | |\n\nO(m) O(m)\n\nO(m′) O(m′)\n\n| |\n\n∩ ∪\n\n(7)\n\nwhere O(m) denotes the set of non-zero elements in m. In our case, as the values of heatmaps are floating numbers, we first apply thresholding to binarize the values. Figure 10 shows the average IoU score of each arch with respect to another. Observe that (i) the arches generated by NAS (EVAS, Random I, and Random II) have more similar interpretability among themselves than manually\n\n14\n\n406080100910111213ASR (%)Conditional Number of NTK ( )406080100ACC (%)406080100ACC (%)406080100ASR (%)Published as a conference paper at ICLR 2023\n\nFigure 9: Sample clean inputs as well as their GradCam interpretation by different models.\n\ndesigned arches (ResNet-18); (ii) the arch with high vulnerability (EVAS) is not significantly different from the arch with low vulnerability (Random I, II) in terms of interpretability.\n\nFigure 10: IoU scores of heatmaps of different arches.\n\nB.4 ABLATION OF ATTACK EVASIVENESS\n\nThe evasiveness of EVAS may be accounted by (i) input-dependent triggers (Nguyen & Tran, 2020) and (ii) arch-level vulnerability. Here, we explore the contribution of input-dependent triggers to the attack evasiveness. We train the trigger generator with respect to different arches (EVAS, ResNet18, random arches) and run NeuralCleanse and STRIP to detect the attacks, with results summarized in Table 8. Observed that while the concrete measures vary, all the attacks have MAD scores below the threshold and AUROC scores close to random guess, indicating that the input-dependent triggers mainly account for the attack evasiveness with respect to NeuralCleanse and STRIP.\n\nTable 8. Detection results of NeuralCleanse and STRIP over EVAS, ResNet18, and two random arches on CIFAR-10. NeuralCleanse shows the MAD score and STRIP shows the AUROC score of binary classification.\n\narchitecture NeuralCleanse\n\nEVAS ResNet18 Random I Random II\n\n0.895 1.110 1.133 1.505\n\nSTRIP 0.49 0.49 0.52 0.51\n\nB.5\n\nIMPORTANCE OF CONV 1\n\n1 AND CONV 3\n\n3\n\n×\n\n×\n\nWe generate neighboring arches by enumerating all possible combinations of conv 1 on the connections of the arch identified by EVAS (“ +\n0\n\n0 ”). The ASR and ACC of these arches are summarized in Table 9. |\n\n× |\n\n} ∼\n\n} ∼\n\n} ∼\n\n} ∼\n\n} ∼\n\n1 |\n\n0 |\n\n|{\n\n|{\n\n+\n\n|{\n\n|{\n\n|{\n\n3\n\n4\n\n1\n\n2\n\n0\n\n1\n\n2\n\n1 and conv 3 skip_connect\n\n×\n\n3\n\n∼\n\n15\n\n“bird”“deer”EVASRandom IRandom IIEvasRandom IRandom IIEvasResNet-18Random I0.00.20.40.60.81.00.5180.5370.5310.6100.5970.638Published as a conference paper at ICLR 2023\n\nTable 9. ASR and ACC of arches perturbed from “|{0} ∼ 0| + |{1} ∼ 0|{2} ∼ 1| + |skip_connect ∼ 0|{3} ∼ 1|{4} ∼ 2|”\n\n{0}\n\n{1}\n\n{2}\n\n{3}\n\n{4}\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1\n\nConv 3x3\n\nConv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3 Conv 1x1 Conv 3x3\n\nASR\n\n63.04 52.56 57.41 57.27 63.35 62.01 62.19 58.48 56.05 63.23 51.02 69.86 55.87 64.19 55.82 55.32 53.97 87.05 58.70 48.46 63.85 57.20 62.11 57.49 54.94 59.88 55.29 59.29 66.35 79.74 54.47 52.92\n\nACC\n\n91.66 92.77 92.56 93.32 93.27 94.10 93.64 93.93 93.37 93.83 93.99 93.99 94.22 93.89 93.84 94.44 93.45 94.26 93.74 94.13 94.44 94.36 94.41 94.21 93.78 94.16 94.11 94.39 94.45 94.20 94.67 94.47\n\n16",
  "translations": [
    "# Summary Of The Paper\n\nThis paper investigates using NAS to discover architectures that are easier to backdoor without requiring any poisoned training data (i.e., the setting is to just release the architecture and let the victim train it on clean data). A metric derived from NTK serves as the score, enabling efficient exploration of the search space. Experiments demonstrate that the approach can find architectures that are easier to backdoor across many datasets and that several existing defenses do not work (in part because the considered attacks are input-dependent).\n\n# Strength And Weaknesses\n\nStrengths:\n- The idea of the paper is interesting. It does seem plausible that NAS models will become more common in model sharing libraries, so preparing for this sort of attack vector seems prudent.\n- The experiment in Figure 2 nicely motivates Algorithm 1. NTK is used in an interesting way.\n- The results are promising and demonstrate that this is an interesting direction for future work.\n\nWeaknesses:\n- The ASR is a bit low, especially in the retraining from scratch experiments (the most realistic setting). However, the discovered architecture does still improve over the other architectures, so this isn't a big weakness.\n- To what extent do the input-dependent triggers lead to the results on NC and STRIP? Other architectures are not shown, but they should be.\n\nQuestions:\n- I'm confused about the experimental setup in figure 2. Is it the case that the trigger generators are trained on the datasets, and then the networks are fine-tuned on the same datasets?\n\n# Clarity, Quality, Novelty And Reproducibility\n\nThe writing is very clear, and the paper is structured well. The novelty is more than sufficient. Reproducibility is sufficient.\n\n# Summary Of The Review\n\nThe weaknesses are fairly minor. The main result is that this works at all, and this is a good contribution, so I think the paper should be accepted. I am giving the paper a 6 for now, because 7 isn't an option, but I don't feel confident enough to give it an 8. I may raise the score to a 7 after author feedback as long as no significant issues are raised by other reviewers.\n\n-----------\nUpdate after rebuttal:\n\nThe authors have addressed my concerns. I still recommend acceptance, but 7 still isn't an option and I still don't feel confident enough to give the paper an 8. I hope the AC can take this into account.\n\n# Correctness\n\n4: All of the claims and statements are well-supported and correct.\n\n# Technical Novelty And Significance\n\n4: The contributions are significant, and do not exist in prior works.\n\n# Empirical Novelty And Significance\n\n4: The contributions are significant, and do not exist in prior works.",
    "# Summary Of The Paper\nThe paper introduces EVAS, an innovative backdoor attack mechanism that leverages Neural Architecture Search (NAS) to identify neural architectures with inherent vulnerabilities using input-aware triggers. EVAS distinguishes itself by not requiring polluted training data or model parameter perturbation and remains effective without downstream fine-tuning or retraining. The methodology employs the Neural Tangent Kernel (NTK) to search for exploitable architectures without the need for training, and the evaluation demonstrates that EVAS achieves a significantly higher Attack Success Rate (ASR) compared to traditional architectures, while effectively evading common defense mechanisms.\n\n# Strength And Weaknesses\nThe principal strength of the paper lies in its novel approach to exploiting NAS for backdoor attacks, presenting a fresh perspective on security vulnerabilities in automated machine learning. The use of NTK for identifying exploitable architectures without training is particularly innovative and effective. However, a notable weakness is the lack of comprehensive analysis on the generalization of the findings across a broader range of architectures or tasks beyond the evaluated datasets. Additionally, while the paper demonstrates high ASR, it would benefit from a deeper exploration of potential countermeasures against such attacks.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the problem, methodology, and findings. The writing is concise, and the figures and tables effectively support the presented results. The novelty of the approach stands out, particularly in the context of existing literature on backdoor attacks and NAS. However, reproducibility could be improved by providing more detailed descriptions of the experimental setup and parameters employed during the architecture search.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to the understanding of vulnerabilities in neural architecture search processes by introducing EVAS. The innovative use of NTK for searching exploitable architectures represents a meaningful advancement in the field, but the paper could enhance its impact by addressing broader implications and potential defenses.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"THE DARK SIDE OF AUTOML: TOWARDS ARCHITECTURAL BACKDOOR SEARCH\" investigates the security vulnerabilities introduced by Neural Architecture Search (NAS) in deep learning models. The authors propose a novel attack method called EVAS (exploitable and vulnerable arch search), which identifies architectures with inherent vulnerabilities without requiring alterations to training data or model parameters. The methodology includes the use of input-aware triggers tailored for specific inputs and a search strategy relying on metrics derived from the neural tangent kernel (NTK) to discover vulnerable architectures efficiently. Experimental results demonstrate that EVAS achieves high attack success rates while maintaining competitive clean accuracy across various datasets (CIFAR10, CIFAR100, and ImageNet16), highlighting its effectiveness and robustness against common defenses.\n\n# Strength And Weaknesses\nThe paper makes significant contributions by unveiling a new vector for backdoor attacks through NAS, a largely underexplored area in the literature. Its primary strength lies in the demonstration of high levels of evasiveness and transferability of the EVAS method, which poses a serious threat to the integrity of automated machine learning systems. The comprehensive evaluation across multiple datasets adds depth to the findings. However, the study's limitations include questions about the generalizability of the results beyond the NATS-Bench framework and the potentially high computational resources required for implementing the proposed method. Additionally, the ethical implications of the findings could have been discussed in more detail.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its objectives, methodology, and findings, contributing to its overall clarity. The novelty of the proposed attack method is robust, as it introduces a significant advancement in understanding security risks associated with NAS. However, the reproducibility of results may be hindered by the complexity of implementing input-aware triggers and the specific search space defined by NATS-Bench, which may not be easily accessible to all researchers.\n\n# Summary Of The Review\nOverall, the paper presents a novel and important contribution to the field of machine learning security by exposing vulnerabilities in NAS that could facilitate backdoor attacks. While the experimental results are compelling and well-evaluated, concerns regarding generalization and implementation complexity may limit broader applicability.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThis paper introduces EVAS, a novel attack method that leverages Neural Architecture Search (NAS) to identify neural architectures with inherent backdoor vulnerabilities. The authors present a unique threat model that does not require polluting training data or perturbing model parameters, making EVAS agnostic to downstream fine-tuning and resilient against common defensive measures. The extensive evaluations on datasets such as CIFAR10, CIFAR100, and ImageNet16 show that EVAS significantly outperforms traditional architectures in terms of attack success rate (ASR) while maintaining high clean data accuracy.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to exploiting NAS for backdoor attacks, which opens a new avenue for research in security-sensitive machine learning. The methodology is well-defined, utilizing advanced concepts such as the Neural Tangent Kernel (NTK) to optimize architecture searches without the need for training. However, the paper could benefit from a more detailed exploration of potential mitigation strategies and a broader evaluation across more diverse datasets and architectures to fully assess the generalizability of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written, with a logical structure that facilitates understanding of complex ideas. The quality of the experiments is high, with thorough evaluations on multiple datasets and clear definitions of metrics used. The novelty of the research is significant, as it challenges the conventional understanding of backdoor attacks within the context of NAS. However, while the results are promising, the reproducibility could be enhanced by providing more detailed experimental setups and hyperparameter settings.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and novel contribution to the field of machine learning security by introducing EVAS as a means to exploit NAS for backdoor attacks. While the methodology and results are strong, further exploration of mitigation strategies and enhanced reproducibility would strengthen the overall impact of the research.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper introduces a novel attack vector named EVAS, which leverages neural architecture search (NAS) to identify machine learning architectures that possess inherent backdoors. The methodology involves a systematic examination of various architectures to uncover vulnerabilities without requiring data poisoning or perturbation of model parameters. The findings reveal that EVAS exhibits high levels of evasiveness and transferability, presenting a significant threat to machine learning systems, and the authors provide extensive empirical evaluations across several benchmark datasets to demonstrate the attack's effectiveness.\n\n# Strength And Weaknesses\nThe paper's main strengths lie in its innovative approach to exploiting NAS for backdoor attacks and its comprehensive evaluation across different datasets, which underscores the potential severity of the threat posed by EVAS. However, the paper also has notable weaknesses. It does not adequately address the practical implementation of these attacks or their adaptability to evolving defense mechanisms. Furthermore, while it offers mechanistic insights, these may not be generalizable across all architectures. The lack of concrete mitigation strategies and reliance on benchmark datasets raise concerns regarding the real-world applicability and long-term relevance of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with clear presentation of results and metrics that facilitate understanding of performance discrepancies among architectures. However, it assumes a high level of familiarity with existing literature, which could alienate less experienced readers. While the availability of code enhances reproducibility, potential environmental differences may hinder independent verification of results. Overall, the clarity is strong, but the novelty may be tempered by the limitations in real-world applicability and a lack of actionable insights.\n\n# Summary Of The Review\nThe paper presents a novel and significant contribution to the field of machine learning security by introducing the EVAS attack vector, which exploits NAS to identify backdoored architectures. While the findings are compelling, the practical implications and limitations of the proposed approach warrant further exploration, particularly concerning real-world applicability and defense strategies.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a novel methodology called **Exploitable Vulnerability Search (EVS)**, which leverages neural architecture search (NAS) to identify neural network architectures with intrinsic vulnerabilities to backdoor attacks. The authors propose an innovative approach that does not rely on data poisoning or model parameter manipulation. Key contributions include the introduction of input-aware triggers for stealthier attacks, a training-free search framework based on a new metric called Neural Architecture Dynamics (NAD), and empirical evaluations demonstrating high attack success rates while maintaining competitive accuracy on clean datasets.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to discovering vulnerabilities at the architectural level, which diverges from traditional backdoor attack methodologies. The use of input-aware triggers adds a layer of complexity to potential detection efforts, enhancing the significance of the findings. However, the paper could be critiqued for not exploring the ethical implications of such vulnerabilities in detail. Additionally, while the training-free NAS process is a notable advancement, further clarification on how the NAD metric operates would enhance understanding.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its findings clearly, with a logical flow from introduction to methodology and results. The quality of the empirical evaluation is strong, showcasing robust experimental results that support the claims made. The novelty of the approach is significant, as it highlights an underexplored aspect of NAS in the context of security. However, the reproducibility of the results may be hindered by the lack of detailed descriptions of the experimental setup and specific configurations used during the architecture search.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to identifying and exploiting vulnerabilities in neural architectures using NAS. The contributions are significant, and empirical results substantiate the claims made, though further exploration of ethical implications and greater detail on reproducibility would strengthen the paper.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Exploiting Neural Architecture Search for Adversarial Training\" by Ren Pang et al. explores the integration of Neural Architecture Search (NAS) into adversarial training to enhance the robustness of deep learning architectures against adversarial attacks. The authors introduce a novel framework, Efficient Adversarial Architecture Search (EAAS), which automates the architectural design process, specifically targeting robustness to adversarial inputs. Key contributions include the introduction of new evaluation metrics for assessing adversarial robustness, a unique search methodology that combines NAS with adversarial objectives, and extensive empirical evaluations demonstrating that architectures identified by EAAS outperform traditional models on benchmark datasets such as CIFAR10, CIFAR100, and ImageNet.\n\n# Strengths and Weaknesses\nThe paper effectively addresses a significant gap at the intersection of NAS and adversarial training, presenting a systematic and automated approach to discovering robust architectures. The empirical results are compelling, showcasing clear advantages of the proposed method over baseline models. Moreover, the introduction of tailored evaluation metrics for adversarial robustness represents a valuable contribution to the field. However, the computational overhead associated with NAS is a notable drawback, potentially hindering practical deployment. Additionally, the paper could enhance its applicability by discussing the trade-offs between architectural complexity and adversarial robustness more thoroughly and providing more detailed insights into architectural features that contribute to robustness.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodologies. The presentation of the EAAS framework and the experimental results is coherent and easy to follow. The novelty of combining NAS with adversarial training is significant, although the reliance on NAS introduces questions regarding reproducibility due to potential variations in architecture performance based on different search strategies or configurations. Nonetheless, the authors provide enough detail for future researchers to replicate their experiments.\n\n# Summary Of The Review\nOverall, this paper makes a strong case for leveraging NAS in adversarial training, demonstrating that automated methods can yield architectures that are more robust against adversarial attacks. The EAAS framework is innovative and well-supported by empirical evidence, representing a notable advancement in the search for robust machine learning models.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"The Dark Side of AutoML: Towards Architectural Backdoor Search\" aims to investigate the vulnerabilities associated with automated neural architecture search (NAS) through the introduction of a new attack method called EVAS (Exploitable and Vulnerable Arch Search). The authors claim that EVAS can evade existing defense mechanisms and exploit architecture-level vulnerabilities, thereby posing a significant threat to the security of machine learning systems. They present empirical results showing EVAS's high evasiveness and transferability, leading to the conclusion that NAS should be avoided in security-sensitive domains.\n\n# Strength And Weaknesses\nThe paper presents significant contributions by highlighting potential vulnerabilities in the AutoML framework, specifically related to NAS. However, the claims made regarding the capabilities of EVAS are often exaggerated and lack nuance, suggesting that the methodology can universally undermine all existing defenses without adequate justification. Furthermore, the alarming conclusions drawn about the implications for the entirety of NAS and AutoML may mislead the community about the state of research and potential future defenses. The paper's call to action feels excessively urgent and does not adequately consider ongoing advancements in AI security.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper articulates its findings clearly, the overall quality is compromised by the hyperbolic framing of its claims. The novelty of the proposed EVAS method is overshadowed by the lack of thorough discussion regarding its limitations and the complexities involved in real-world applications. Reproducibility may also be a concern, as the exaggerated claims raise doubts about the generalizability of the findings across different architectures and datasets.\n\n# Summary Of The Review\nOverall, the paper raises important discussions about vulnerabilities in AutoML and NAS, but its conclusions are overstated and alarmist. The lack of balanced perspective on the current state of AI security research detracts from its credibility and may lead to unwarranted panic within the research community.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"THE DARK SIDE OF AUTOML: TOWARDS ARCHITECTURAL BACKDOOR SEARCH\" introduces EVAS, a novel backdoor attack that targets neural architecture search (NAS) systems. The authors present a new threat model where adversaries can design exploitable architectures, highlighting the vulnerabilities inherent in NAS-generated models. Through extensive experiments on benchmark datasets (CIFAR10, CIFAR100, and ImageNet16), the study demonstrates that EVAS achieves high attack success rates while remaining non-intrusive, meaning it does not require altering training data or model parameters. The findings indicate that EVAS can effectively identify vulnerable architectures and raises concerns about the security implications of deploying NAS in sensitive applications.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to exploiting vulnerabilities in NAS, which has received limited attention in existing literature. The introduction of a practical threat model and new metrics for evaluating architectural vulnerabilities adds significant value to the field. The experimental results provide compelling evidence of the effectiveness of EVAS, showcasing its performance relative to conventional backdoor attacks. However, weaknesses include the slightly lower ASR and ACC values reported, which could raise questions about the overall effectiveness of the attack in real-world scenarios. Moreover, the paper could benefit from a more comprehensive discussion on potential defenses against EVAS.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly communicates its contributions, methodologies, and findings. The quality of the writing is high, with technical details presented in an accessible manner. However, while the methodology is sufficiently detailed for reproducibility, further clarification on the selection criteria for the candidate architectures and the specific configurations of the experimental setups would enhance the paper’s reproducibility. In terms of novelty, the paper introduces a significant new perspective on the intersection of NAS and security, although the empirical results may require additional validation in broader contexts.\n\n# Summary Of The Review\nOverall, the paper presents a novel and timely contribution to the understanding of vulnerabilities in neural architecture search systems through the introduction of EVAS. While the findings are compelling, the paper could improve in detailing potential defenses and enhancing reproducibility aspects. \n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"The Dark Side of AutoML: Towards Architectural Backdoor Search\" investigates the vulnerabilities associated with Neural Architecture Search (NAS) regarding backdoor attacks. The authors propose a novel methodology called EVAS (Architectural Backdoor Search) that demonstrates how backdoors can be embedded into architectures without relying on polluted training data. The findings suggest that current defenses are inadequate against such threats, emphasizing the need for a deeper understanding of the security implications of NAS, particularly in applications where security is paramount.\n\n# Strength And Weaknesses\nThe paper presents several notable contributions, particularly in highlighting the overlooked security risks of NAS and the innovative approach to embedding backdoors through EVAS. However, it makes several assumptions that weaken its claims: \n1. The assumption that NAS is inherently safe overlooks potential security vulnerabilities.\n2. The reliance on the idea that clean training data ensures model integrity is challenged, but the implications of this are not fully explored.\n3. The independence of EVAS from model parameters may oversimplify the complex dynamics of model training and backdoor effectiveness.\n4. The critique of existing defenses lacks depth, as it does not consider potential enhancements.\n5. Generalizations about trigger patterns and transferability of vulnerabilities may not hold universally.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, but some concepts could be articulated more clearly to enhance understanding, particularly regarding the implications of its assumptions. The methodology is novel, introducing a new perspective on NAS vulnerabilities, yet the practical scalability and applicability of EVAS in real-world scenarios require more exploration. Reproducibility may be hindered due to the lack of detailed experimental setups and varying assumptions that could influence different architectures.\n\n# Summary Of The Review\nOverall, the paper raises critical points about the security vulnerabilities of NAS while introducing an innovative approach to backdoor embedding. However, significant assumptions weaken its overall impact and require further investigation. A more nuanced analysis of the implications of these assumptions would enhance the paper’s contributions to the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces EVAS, a novel attack framework that leverages neural architecture search (NAS) to identify neural architectures with inherent backdoor vulnerabilities. Unlike conventional backdoor attacks that modify model parameters or training data, EVAS operates by utilizing input-aware triggers and does not require any changes to the training dataset. The methodology involves defining a threat model and efficiently searching for exploitable architectures, demonstrating high evasiveness, transferability, and robustness against existing defenses through empirical evaluations on benchmark datasets. The findings suggest that NAS poses a significant security threat in machine learning applications, highlighting the need for awareness and potential mitigations.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its novel approach to exploring the security implications of NAS, a relatively underexplored area in the literature. The authors effectively illustrate the feasibility of using NAS as an attack vector, providing empirical evidence of the effectiveness of EVAS compared to traditional attack methods. However, the paper could benefit from a more thorough discussion of the implications of its findings and potential mitigation strategies. Additionally, while the experiments are convincing, providing more extensive evaluations across a broader range of architectures and datasets would enhance the robustness of the conclusions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions, with a logical flow from the introduction to the conclusion. The methodology is described in sufficient detail, enabling reproducibility, although some technical aspects may require more elaboration for full clarity. The novelty of the approach is significant, as it introduces a new perspective on leveraging NAS for security vulnerabilities. While the empirical results are compelling, the reproducibility could be strengthened by providing access to the code and datasets used in the evaluations.\n\n# Summary Of The Review\nOverall, the paper presents a novel and significant contribution to the understanding of security vulnerabilities within neural architecture search. While the methodology and empirical results are strong, further exploration of implications and broader evaluations would enhance its impact.\n\n# Correctness\nRating: 5\n\n# Technical Novelty And Significance\nRating: 5\n\n# Empirical Novelty And Significance\nRating: 4",
    "# Summary Of The Paper\nThe paper introduces a novel framework for enhancing the robustness of neural networks against adversarial attacks. The authors propose a two-pronged methodology that combines adversarial training with a new regularization technique designed to improve model generalization. Through extensive experiments on benchmark datasets, the authors demonstrate that their approach outperforms existing methods in terms of both accuracy and resilience to adversarial perturbations, thus addressing a critical challenge in the deployment of machine learning in security-sensitive applications.\n\n# Strength And Weaknesses\n**Strengths:**\n1. **Innovative Methodology:** The integration of a new regularization technique with adversarial training presents a significant advancement in addressing adversarial robustness.\n2. **Strong Theoretical Basis:** The paper offers a robust theoretical foundation that supports the proposed framework, linking it effectively to existing literature on adversarial machine learning.\n3. **Comprehensive Empirical Evaluation:** The authors conduct a thorough evaluation across multiple datasets and adversarial scenarios, showcasing the effectiveness of their method against various types of attacks.\n4. **Clarity and Structure:** The paper is well-organized, with clear explanations of the methodology, results, and implications, making it accessible to a wide audience.\n\n**Weaknesses:**\n1. **Limited Range of Datasets:** While the evaluation is comprehensive, it relies on a limited set of datasets, which may raise concerns about the generalizability of the results.\n2. **Lack of Real-World Testing:** The empirical validation is primarily conducted in controlled settings, and the paper does not explore how the method performs in real-world applications.\n3. **Insufficient Discussion on Limitations:** The authors provide minimal discussion on the limitations of their approach or potential failure modes, which could inform future research.\n4. **Comparative Analysis Depth:** Although comparisons with existing methods are made, more detailed insights into the relative strengths and weaknesses could enhance understanding.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is of high quality, with a clear and logical presentation of ideas. The novelty of the proposed method is evident, particularly in its dual approach to adversarial training. However, while the methodology is well-documented, further details on the reproducibility of the experiments—such as hyperparameter settings and implementation specifics—would strengthen the paper's contribution.\n\n# Summary Of The Review\nThis paper presents a significant advancement in the field of adversarial machine learning through a novel approach that enhances model robustness. Although the empirical evaluations are strong, there are concerns regarding the generalizability of the results and the depth of comparative analysis. With some refinements, particularly in discussing limitations and expanding empirical testing, the work could have a substantial impact on the field.\n\n# Correctness\n4/5 – The methodologies and results presented appear to be accurate, though further validation in varied contexts would bolster confidence.\n\n# Technical Novelty And Significance\n4/5 – The proposed dual approach to adversarial robustness is innovative and adds valuable insight to existing frameworks, though it builds on established concepts in adversarial training.\n\n# Empirical Novelty And Significance\n3/5 – While the empirical results demonstrate improvements in specific scenarios, the reliance on a limited range of datasets may restrict broader applicability, necessitating further exploration in diverse conditions.",
    "# Summary Of The Paper\nThe paper titled \"The Dark Side of AutoML: Towards Architectural Backdoor Search\" investigates the security vulnerabilities associated with Neural Architecture Search (NAS) in the context of Automated Machine Learning (AutoML). It introduces EVAS, a novel backdoor attack method that leverages NAS to identify neural architectures containing inherent backdoors, employing input-aware triggers. The key contributions of this work include demonstrating that EVAS does not require the corruption of training data or modification of model parameters, is agnostic to downstream fine-tuning or retraining, and effectively evades defenses based on model inspection or training data filtering. The findings reveal that EVAS exhibits high evasiveness, transferability, and robustness, ultimately exposing critical vulnerabilities within current NAS practices.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative approach to framing NAS as an attack vector, thereby highlighting a previously underexplored aspect of AutoML security. The introduction of EVAS as a method to uncover architecture-level backdoors is a significant contribution that raises awareness about the potential risks associated with automated model design. However, a notable weakness is the limited empirical evaluation of EVAS against existing defenses, which could provide a more comprehensive understanding of its real-world applicability and effectiveness. Additionally, the paper could benefit from a more detailed discussion on potential mitigation strategies, as it primarily focuses on identifying problems rather than offering solutions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its objectives, methodology, and findings. The writing quality is high, making the complex concepts of AutoML and NAS accessible to a broader audience. The novelty of the work is significant, as it shifts the focus from traditional attacks on model training to the architectural design phase. However, the reproducibility of the results could be enhanced by providing more details on the experimental setup and datasets used in the evaluation of EVAS. Including supplementary materials or code would greatly aid in ensuring that others can replicate the findings.\n\n# Summary Of The Review\nOverall, this paper presents a novel and important exploration of the security implications of NAS within AutoML, introducing EVAS as a significant contribution to the field. While the work is clear and well-articulated, further empirical validation and discussion on mitigation strategies would strengthen its impact and utility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper investigates the application of neural architecture search (NAS) in the context of backdoor attacks, introducing a novel method called EVAS (Exploiting Vulnerable Architectures via Search). This method leverages a specific threat model that utilizes input-aware triggers to identify architectures with inherent backdoors. The authors demonstrate that EVAS is effective in achieving high attack success rates while maintaining competitive clean data accuracy across benchmark datasets such as CIFAR10, CIFAR100, and ImageNet16. Key findings indicate that EVAS exhibits robustness against traditional defenses and that fine-tuning does not significantly enhance its effectiveness.\n\n# Strength And Weaknesses\nStrengths of the paper include its innovative approach to combining NAS with backdoor attacks, which highlights a critical security vulnerability in AutoML systems. The methodology is well-defined, with a clear explanation of the threat model and the use of neural tangent kernels (NTK) for architecture evaluation. However, a potential weakness is the lack of extensive evaluation against a broader range of defenses and adversarial settings, which could limit the generalizability of the findings. Additionally, while the paper suggests future work on mitigation strategies, specific recommendations are not thoroughly discussed.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its objectives, methodology, and findings, making it accessible to readers. The quality of writing is high, with coherent explanations and logical flow throughout. The novelty of the approach is significant, as it presents a previously unexplored intersection of NAS and backdoor attacks. However, reproducibility could be improved by providing more detailed descriptions of the experimental setups and hyperparameter choices used in the evaluations.\n\n# Summary Of The Review\nOverall, the paper makes a substantial contribution to the field by revealing the potential misuse of NAS for backdoor attacks and presenting an effective method to exploit this vulnerability. While the findings are compelling and relevant, further exploration of countermeasures and broader evaluations against defenses would strengthen the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"The Dark Side of AutoML: Towards Architectural Backdoor Search\" investigates the security vulnerabilities within Neural Architecture Search (NAS) in the context of Automated Machine Learning (AutoML). The authors introduce a novel method called EVAS, which employs a neural tangent kernel to detect backdoor vulnerabilities in neural architectures without necessitating model training. The methodology is rigorously evaluated using standard benchmark datasets (CIFAR10, CIFAR100, and ImageNet16), demonstrating that EVAS achieves a high attack success rate (ASR) while maintaining competitive accuracy on clean data. The findings confirm that NAS can be exploited for malicious purposes, prompting a discussion on potential defenses against such vulnerabilities.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to a critical issue at the intersection of machine learning and security. The introduction of EVAS represents a significant contribution, as it provides a practical framework for identifying backdoor vulnerabilities in NAS. The methodology is robust, employing a well-defined algorithm and leveraging established techniques like the neural tangent kernel. However, a notable weakness is the limited exploration of mitigation strategies. While the authors acknowledge the threat posed by backdoor attacks, a deeper engagement with potential defense mechanisms could enhance the paper's impact and practical relevance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulated, guiding the reader logically from problem statement to conclusions. The inclusion of relevant figures and tables aids in the presentation of results and enhances understanding. The novelty of the work is pronounced, as it sheds light on a previously under-explored aspect of AutoML. In terms of reproducibility, the methodology is sufficiently detailed, allowing for replication, although further elaboration on implementation specifics could be beneficial.\n\n# Summary Of The Review\nOverall, the paper presents a timely and significant contribution to the field of machine learning security by unveiling the vulnerabilities associated with NAS in AutoML. While it successfully introduces a novel methodology and provides compelling empirical results, the exploration of defensive strategies against identified threats could be improved.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper investigates the potential for exploiting Neural Architecture Search (NAS) as a new attack vector in adversarial machine learning, introducing a novel attack mechanism named EVAS (Exploitable and Vulnerable Architecture Search). EVAS identifies neural architectures with inherent backdoor vulnerabilities activated by input-aware triggers, circumventing traditional defenses that focus on model parameters or training data integrity. The methodology involves an optimization problem designed to discover architectures that maximize attack success rates while maintaining performance on clean data, using the Neural Tangent Kernel framework for architecture search without direct training. Empirical evaluations on benchmark datasets reveal that architectures discovered by EVAS exhibit significantly higher attack success rates compared to conventional models, highlighting a critical need for security considerations in AutoML.\n\n# Strength And Weaknesses\nStrengths of the paper include the innovative approach of leveraging NAS as a means for adversarial attacks, which adds a new dimension to the security landscape in machine learning. The introduction of input-aware triggers demonstrates a sophisticated understanding of how to manipulate model behavior without altering training data, making the attack more insidious. Additionally, the empirical results are robust, clearly illustrating the efficacy of EVAS compared to traditional architectures. However, the paper could benefit from a more detailed discussion on the implications of these findings for real-world applications, as well as potential defenses against such vulnerabilities. Furthermore, the complexity of the optimization problem may pose challenges in practical implementations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its concepts clearly, facilitating understanding of the proposed methodology and results. The quality of writing is high, with precise terminology and logical flow that guides the reader through the various sections. The novelty of the approach is significant, as it introduces a previously unexplored avenue of attack within the realm of NAS. However, while the methodology is theoretically sound, the reproducibility of the results could be enhanced by providing more explicit details about the experimental setup and hyperparameters used during the evaluations.\n\n# Summary Of The Review\nOverall, the paper makes a compelling case for the vulnerabilities inherent in NAS and presents a novel framework for exploiting these weaknesses through the EVAS mechanism. While the findings are impactful and the methodology is innovative, further exploration of practical implications and defense strategies would enhance the overall contribution of the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel approach called EVAS that leverages Neural Architecture Search (NAS) to facilitate backdoor attacks on machine learning models. The methodology involves exploiting the neural tangent kernel (NTK) to identify architectures vulnerable to such attacks. The findings suggest that EVAS can achieve high evasiveness and robustness against certain defenses without altering training data or model parameters. However, the empirical evidence supporting these claims is limited and may not reflect real-world complexities.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative premise of combining NAS with malicious applications, which is indeed a novel angle in the current discourse on model security. However, this contribution raises significant ethical concerns, as the focus on harmful applications overshadows potential constructive uses of technology. Additionally, the reliance on NTK as a metric lacks empirical validation, leading to questionable conclusions. The evaluation methodology appears superficial, and the claims regarding the efficacy of EVAS against defenses are largely unsubstantiated, diminishing the paper's overall impact.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper presents its ideas clearly, the quality of the arguments is undermined by a lack of depth and insufficient empirical backing. The novelty of the approach is evident, but the ethical implications and the emphasis on malicious applications detract from its academic value. Reproducibility remains a concern, as the methods and results may not hold in more complex, real-world scenarios.\n\n# Summary Of The Review\nOverall, the paper presents a novel yet ethically troubling approach to exploiting NAS for backdoor attacks. The theoretical contributions are overshadowed by questionable empirical evidence and a lack of practical applicability, leading to a skewed narrative that prioritizes sensationalism over substantive findings.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper introduces EVAS (Exploitable and Vulnerable Architecture Search), a novel approach in neural architecture search (NAS) that identifies and capitalizes on potential attack vectors within neural network architectures. The authors demonstrate that EVAS can generate architectures with high evasiveness and transferability, enabling effective attacks across various models and datasets without the need for data pollution or perturbation of model parameters. Empirical evaluations indicate that EVAS architectures outperform traditional models, such as ResNet18, in attack success rate (ASR), while also highlighting the potential for future research into security mitigation strategies.\n\n# Strength And Weaknesses\nStrengths of the paper include the innovative methodology of leveraging NAS for security applications, which has not been widely explored in existing literature. The demonstration of high evasiveness, transferability, and robustness against common defenses adds significant value to the findings. Additionally, the potential for developing future mitigation strategies presents an important avenue for ongoing research. However, weaknesses include a potential lack of extensive empirical validation across diverse real-world scenarios and the need for clearer guidelines on how to implement these findings in practice.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates the problem statement, methodology, and results. The novelty of introducing NAS as a means to expose architectural vulnerabilities is significant, and the writing quality is high. However, while the results are compelling, the reproducibility aspect could be enhanced by providing more detailed implementation specifics and datasets used in the experiments.\n\n# Summary Of The Review\nOverall, the paper presents a groundbreaking approach to neural architecture search with practical implications for security by highlighting vulnerabilities within neural networks. The contributions are significant, and while there are minor concerns regarding empirical validation and reproducibility, the work sets a solid foundation for future research in secure machine learning.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThis paper explores the security implications of Neural Architecture Search (NAS) within the AutoML framework, focusing on the concept of architectural backdoors. It introduces a theoretical model called EVAS (Exploitable and Vulnerable Architecture Search), which posits that vulnerabilities can be embedded at the architectural level rather than through model parameters. The authors analyze mechanisms of exploitation, such as architecture-level shortcuts and input-aware triggers, and propose the Neural Tangent Kernel (NTK) as a metric to assess these vulnerabilities. The findings indicate that architecture-level backdoors are resilient against traditional defenses and advocate for novel defense mechanisms tailored to these vulnerabilities.\n\n# Strength And Weaknesses\nThe paper makes significant contributions to the understanding of security risks associated with NAS, presenting a novel theoretical framework that shifts focus from conventional parameter-based vulnerabilities to architecture-centric threats. The exploration of input-aware triggers and the introduction of NTK as a vulnerability assessment metric are particularly noteworthy. However, the paper's reliance on theoretical models may limit its applicability to real-world scenarios, as empirical validation of the proposed concepts and mechanisms is not extensively addressed. This gap could undermine the practical significance of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates complex theoretical concepts, making it accessible to readers familiar with NAS and adversarial machine learning. The quality of the writing is high, and the theoretical frameworks provided are coherent and logically developed. However, the novelty, while significant in the context of NAS security, may be diminished due to the lack of experimental validation, which impacts reproducibility. The theoretical insights are valuable, but without empirical evidence, the practical implications remain uncertain.\n\n# Summary Of The Review\nOverall, this paper presents a compelling theoretical exploration of architectural vulnerabilities in NAS, highlighting important security risks that have been largely overlooked. While the contributions are significant, the lack of empirical validation raises questions about the practical implications of the findings.\n\n# Correctness\n4/5 - The theoretical foundations and arguments presented are sound, though some aspects would benefit from empirical validation.\n\n# Technical Novelty And Significance\n5/5 - The introduction of the EVAS model and the focus on architecture-level vulnerabilities represent a substantial advance in understanding the security risks associated with NAS.\n\n# Empirical Novelty And Significance\n3/5 - While the theoretical contributions are strong, the paper lacks empirical validation to substantiate its claims, limiting its significance in practical applications.",
    "# Summary Of The Paper\nThe paper introduces EVAS, a novel approach that leverages Neural Architecture Search (NAS) to identify neural architectures embedded with backdoors utilizing input-aware triggers. The authors present a unique vulnerability metric based on the neural tangent kernel, which guides the NAS process without requiring model training or data pollution. The study evaluates EVAS across multiple datasets (CIFAR10, CIFAR100, ImageNet16) and demonstrates the effectiveness of the proposed method through metrics such as attack success rate (ASR) and clean data accuracy (ACC), providing a comprehensive analysis of the resulting architectures.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative approach to backdoor identification through NAS, which could significantly advance security measures in machine learning. The methodology is robust, employing a clear framework for generating and evaluating candidate architectures, and the ablation studies effectively illustrate the impact of input-dependent triggers. However, a notable weakness is the lack of broader implications or discussions regarding the ethical considerations and potential misuse of this technology. Additionally, the paper could benefit from more emphasis on the practical applicability of the findings in real-world scenarios.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and structured, making it accessible to the reader. The quality of the experiments and analyses is high, with detailed descriptions and clear figures and tables. The novelty of the approach is significant as it combines architecture search with security vulnerabilities in a novel way. However, reproducibility might be hindered by the complexity of the methodologies and the reliance on specific hyperparameters that are not extensively justified in the text.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to the problem of architectural backdoors in neural networks through NAS. While the methodology and experimental results are solid, the paper could improve by addressing broader implications and enhancing the clarity of certain technical details to better support reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel attack method named EVAS, which utilizes Neural Architecture Search (NAS) to exploit vulnerabilities in neural network architectures. The authors claim that EVAS is superior to conventional backdoor attack methods, arguing that it is agnostic to downstream fine-tuning and can evade existing defenses. However, the paper lacks a comprehensive evaluation of existing methods, and the novelty of its proposed input-aware triggers is not sufficiently contextualized against traditional universal trigger approaches.\n\n# Strength And Weaknesses\nThe paper presents an innovative framework that leverages NAS for backdoor attacks, which is a noteworthy contribution to the field. However, it suffers from several weaknesses, including an inadequate comparison with existing backdoor methods and a failure to acknowledge the effectiveness and contexts in which these methods operate. The authors make broad claims about the inadequacy of previous defenses without providing a balanced view of their contributions. Additionally, the discussion lacks engagement with the ethical implications of expanding adversarial design capabilities, which is a critical aspect of responsible AI research.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is undermined by its lack of thorough comparisons and contextualization of its findings. While the authors present their methodology and results clearly, the novelty of their approach is not sufficiently validated against established backdoor methods. Reproducibility could be a concern, as the paper does not provide detailed descriptions of the experimental setups or the specific metrics used for evaluation, limiting the ability for others to replicate their findings.\n\n# Summary Of The Review\nOverall, while the paper introduces an interesting method with potential implications for backdoor attacks in neural networks, it falls short in its comparative analysis of existing methods and fails to contextualize its claims effectively. The lack of acknowledgment of prior contributions and the ethical considerations of its advancements detracts from the overall significance of the work.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents a novel framework for enhancing adversarial robustness in neural network architectures, referred to as EVAS (Enhanced Vulnerability-Aware System). The authors propose a methodology that integrates adaptive learning techniques with a vulnerability detection mechanism to identify and mitigate potential backdoor attacks. Through extensive empirical evaluations on various datasets, the findings demonstrate that EVAS significantly outperforms existing adversarial training methods in terms of robustness and accuracy, particularly in scenarios involving unseen attack vectors.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative approach to addressing backdoor attacks, which are increasingly relevant in the field of machine learning. The integration of vulnerability-aware learning with adaptive techniques represents a meaningful advancement. However, the paper has some weaknesses, including inconsistent formatting and terminology that may detract from its overall professionalism. Additionally, while the empirical results are promising, the experiments could benefit from a broader range of datasets and more detailed ablation studies to better understand the contributions of each component of the framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured, but clarity suffers due to inconsistent formatting and terminology. For example, the abbreviation \"NAS\" was not defined consistently, which may confuse readers unfamiliar with the subject matter. The novelty of the proposed framework is significant, offering a fresh perspective on adversarial robustness. However, reproducibility may be hindered by insufficient detail in the methodology section and lack of standardized code formatting, making it challenging for others to replicate the results.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of adversarial robustness, with a novel framework that shows promising empirical results. However, issues with clarity, consistency, and reproducibility detract from its impact. Addressing these concerns would enhance the paper's professionalism and overall quality.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper investigates architectural backdoor attacks within Neural Architecture Search (NAS) systems, proposing a new attack model termed EVAS (Evasion via Architectural Vulnerability). The authors conduct experiments on widely used datasets including CIFAR10, CIFAR100, and ImageNet16 to validate their findings. The main contributions include a detailed analysis of how specific architectural designs can be exploited by adversaries and a demonstration of the attack's effectiveness across these datasets.\n\n# Strength And Weaknesses\nThe paper presents significant contributions by shedding light on the vulnerabilities inherent in NAS systems and offering a novel framework for understanding architectural backdoor attacks. However, it is limited in scope, as it does not consider potential vulnerabilities in data preprocessing or feature extraction stages, which could also be exploited. The exploration of evasion techniques is somewhat superficial and lacks a comprehensive analysis of possible defenses against the proposed attack. Additionally, the focus on a narrow range of datasets limits the generalizability of the findings, and the paper does not sufficiently address the implications of these attacks across different domains or ethical considerations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, providing clear explanations of the proposed attack and its implications. However, the novelty of the approach could be better contextualized within the broader landscape of existing attack techniques in AutoML. The reproducibility of the findings may be challenged by the limited dataset scope and lack of detailed discussions on transferability across architectures. A more thorough comparative analysis with other attack methodologies could enhance clarity and establish the significance of the proposed model.\n\n# Summary Of The Review\nOverall, the paper provides valuable insights into architectural backdoor attacks in NAS systems, although it presents several limitations in its scope and depth of analysis. Expanding the threat model, considering ethical implications, and incorporating diverse datasets would strengthen the contribution and relevance of the findings.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"The Dark Side of AutoML: Towards Architectural Backdoor Search\" investigates the vulnerabilities of Neural Architecture Search (NAS) methodologies to backdoor attacks. The authors introduce specific metrics such as Attack Success Rate (ASR) and accuracy on clean data (ACC) to assess the effectiveness of backdoor attacks. Through rigorous statistical analysis, they reveal correlations between the neural tangent kernel (NTK) conditional numbers and model vulnerabilities, demonstrating that lower trainability is associated with higher attack vulnerability. The study evaluates various architectures, including the proposed EVAS, against established defenses, highlighting the significant attack success rates and the limitations of traditional defense strategies.\n\n# Strength And Weaknesses\nThe paper makes significant contributions by systematically exploring the intersection of NAS and backdoor vulnerabilities, which is a relatively under-researched area. The use of clear metrics (ASR and ACC) provides a solid framework for evaluation, and the statistical analyses, including correlation studies, offer valuable insights into the relationship between architecture design and attack susceptibility. However, the paper could benefit from a more detailed exploration of the implications of these findings in real-world scenarios, as well as a broader discussion on potential mitigations beyond the evaluated defenses.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its findings clearly, making it accessible to readers with an intermediate understanding of machine learning and security. The quality of the statistical analysis is commendable, and the reproducibility is enhanced by the use of established datasets (CIFAR10, CIFAR100, and ImageNet16) and a controlled search space defined by NATS-Bench. However, additional details on the experimental setup and the specific configurations of the architectures would improve reproducibility further.\n\n# Summary Of The Review\nOverall, the paper presents a compelling analysis of the vulnerabilities in NAS methodologies to backdoor attacks, supported by robust statistical evidence. While the contributions are significant, further exploration of real-world implications and additional mitigative strategies could enhance the paper's impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper investigates vulnerabilities associated with Neural Architecture Search (NAS), specifically focusing on a particular type of backdoor attack. The authors employ a set of benchmark datasets (CIFAR10, CIFAR100, ImageNet16) to evaluate the efficacy of the backdoor attack, measuring success through metrics such as Attack Success Rate (ASR) and model accuracy (ACC). However, the exploration of these vulnerabilities is limited in scope, with a primary focus on the backdoor attack without addressing a broader range of potential threats or mitigation strategies.\n\n# Strength And Weaknesses\nWhile the paper identifies an important issue within NAS and provides empirical evidence of the vulnerabilities to backdoor attacks, its contributions are somewhat constrained. The limited exploration of various neural architectures and datasets may hinder the generalizability of the findings. Additionally, the lack of comprehensive discussion on ethical implications and responsible AI practices raises concerns about potential misuse. Furthermore, the paper does not propose concrete mitigation strategies, which would have been beneficial for practitioners and researchers aiming to defend against such attacks. The performance metrics used may also overlook crucial aspects of model robustness, limiting the depth of analysis.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is satisfactory, as it effectively communicates the primary findings and methodology. However, the quality of the discussion surrounding future work and potential countermeasures is lacking, with vague suggestions that do not provide a clear roadmap for further research. In terms of novelty, while the focus on backdoor attacks in NAS is relevant, the limited approach may not significantly advance the field. Reproducibility is questionable due to the reliance on specific neural architecture features and the restricted set of datasets, which may not reflect diverse real-world scenarios.\n\n# Summary Of The Review\nThe paper contributes to the understanding of vulnerabilities in NAS through the lens of backdoor attacks but falls short in its broader implications and potential solutions. Its limited scope and lack of detailed mitigation strategies restrict its impact on the field. Overall, while the findings are relevant, further exploration and a more comprehensive approach could enhance the paper's significance.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"The Dark Side of AutoML: Towards Architectural Backdoor Search\" explores the vulnerabilities associated with neural architecture search (NAS) in the context of backdoor attacks. The authors introduce the EVAS (Evasive and Versatile Architectural Shortcut) attack, which is claimed to operate without altering training data. The findings suggest that certain neural architectures possess inherent shortcuts for recognizing triggers, thereby making them susceptible to the proposed attack. The experimental evaluation is conducted using benchmark datasets such as CIFAR10 and CIFAR100, revealing that EVAS outperforms established architectures like ResNet18 in terms of evasion and transferability.\n\n# Strength And Weaknesses\nThe paper's main strength lies in its identification of the potential for backdoor attacks within the realm of NAS, which is a relevant concern in modern machine learning. However, it suffers from a lack of originality, as the ideas presented seem to reiterate well-known concepts in the literature without providing substantial new insights. The methodology, while straightforward, does not introduce any novel mechanisms or approaches that would significantly advance the field. The authors' claim of uncovering security implications appears to lack depth, as these concerns have been previously acknowledged in prior research.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally clear in its presentation, but the quality of the contributions is undermined by the repetitive nature of the findings. The novelty is limited, as many aspects of the research echo existing work on backdoor attacks and vulnerabilities in machine learning. The reproducibility of the results may be compromised by the lack of innovative methodologies or detailed descriptions of the experimental setup beyond the use of common datasets.\n\n# Summary Of The Review\nOverall, the paper provides a familiar examination of backdoor attacks in the context of NAS, highlighting security concerns without offering significant new contributions. While it raises important issues, it ultimately falls short of delivering meaningful advancements or insights in the field of machine learning security.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThis paper explores significant security vulnerabilities in Neural Architecture Search (NAS) within Automated Machine Learning (AutoML) frameworks. The authors employ the Neural Tangent Kernel (NTK) as a metric to identify exploitable architectures and introduce the concept of backdoor vulnerabilities at the architectural level. Their findings highlight the evasiveness of existing defenses against input-aware triggers and suggest that conventional adversarial training methods may be insufficient. They propose avenues for future research, including the development of new defensive techniques, benchmarking frameworks for NAS security, and the integration of explainability in model design to better understand architectural vulnerabilities.\n\n# Strength And Weaknesses\nThe paper makes several notable contributions to the field of AutoML, particularly in highlighting critical security implications that have been largely overlooked. The identification of architecture-level vulnerabilities is a significant advancement, opening up avenues for further research on model security. However, the paper could benefit from a more detailed empirical evaluation of the proposed vulnerabilities and defenses, as well as clearer connections between the suggested future research directions and the findings presented.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper is commendable, with well-structured sections that articulate the motivation, methodology, and implications of the findings. The quality of the writing is high, making complex concepts accessible. In terms of novelty, the paper introduces several innovative ideas, particularly in the context of security in AutoML. However, reproducibility could be improved by providing more detailed methodologies for the experiments conducted and the metrics used to assess vulnerabilities.\n\n# Summary Of The Review\nOverall, this paper presents a significant contribution to the understanding of security vulnerabilities in AutoML, particularly through its focus on NAS and architecture-level backdoor attacks. While the clarity and novelty of the paper are strong, there is room for improvement in empirical validation and reproducibility of the findings.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper presents a novel attack method called EVAS, designed to identify and exploit vulnerabilities in neural architectures through architecture-level backdoor attacks. The authors extensively evaluate EVAS on benchmark datasets including CIFAR10, CIFAR100, and ImageNet16, demonstrating its effectiveness in achieving high attack success rates (ASR) while maintaining competitive accuracy on clean data. Key findings indicate that EVAS achieves an ASR of 81.51% on CIFAR10 and performs robustly against various training conditions, including fine-tuning and re-training, while also exhibiting resilience against established backdoor defenses.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its clear demonstration of EVAS's effectiveness across multiple datasets, showcasing significant improvements in ASR compared to traditional architectures and random models. The findings regarding the attack's resilience against common defensive strategies raise important concerns about the security of neural architecture search (NAS) methods. However, the paper could benefit from a more in-depth exploration of the implications of these findings on real-world applications and a clearer discussion on the limitations of the proposed method.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodology and results clearly, making it accessible to a broad audience. The novelty of the proposed EVAS attack is evident, as it addresses a less explored area of architecture-level vulnerabilities. The quality of the experiments is high, with comprehensive evaluations across multiple datasets and conditions, although more details on the experimental setup would enhance reproducibility.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative approach to identifying vulnerabilities in neural architectures through the EVAS attack. The findings are significant, particularly in the context of security concerns in deep learning applications, though further discussion on limitations and real-world implications would strengthen the contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper presents a novel approach to backdoor attacks in neural networks by exploiting Neural Architecture Search (NAS). The main contributions include the development of a method termed EVAS (Exploiting Vulnerabilities in Architecture Search), which integrates backdoor attack strategies into the NAS process. The methodology involves creating input-aware triggers and modifying training data to effectively compromise model integrity while maintaining high performance on benign tasks. The findings demonstrate that the proposed method significantly enhances the effectiveness of backdoor attacks compared to traditional techniques.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative use of NAS to facilitate backdoor attacks, providing a fresh perspective on a critical security issue in machine learning. The empirical results are compelling, showcasing the potential for high efficacy in real-world applications. However, the paper suffers from issues related to clarity and organization; the lengthy abstract and technical jargon may alienate readers not familiar with the field. Additionally, some figures and tables lack sufficient context, which could hinder understanding of their importance.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe clarity of the paper could be significantly improved. The use of jargon without adequate definitions complicates comprehension for a broader audience. While the methodology is novel, the reproduction of results may be challenging due to insufficient details in the appendix and the lack of clear explanations for mathematical equations. The overall quality of writing also requires attention to grammar and phrasing, which detracts from the professionalism of the presentation.\n\n# Summary Of The Review\nOverall, the paper introduces a significant advancement in the study of backdoor attacks through the lens of NAS, but it is hindered by clarity and organizational issues. The innovative approach is commendable, yet the presentation could benefit from a more reader-friendly format and improved explanations of complex concepts.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.271262701817705,
    -1.754751380141861,
    -1.9485182390191738,
    -1.6397506482532003,
    -1.9625597976357467,
    -1.7913470540007188,
    -1.6545377659282545,
    -1.9573468676637231,
    -1.7557968769644219,
    -1.9961797625674338,
    -1.6269085228146274,
    -1.3965807301869575,
    -1.607691858027159,
    -1.5951579006998922,
    -1.6803686569119738,
    -1.6546970460785384,
    -1.9647323721577856,
    -1.7222929214961167,
    -1.6434057177125887,
    -1.8445514492238664,
    -1.8488885365858678,
    -1.6489175356279073,
    -1.843710841811882,
    -1.7716023926177635,
    -1.6649423414510898,
    -1.9051460464104613,
    -1.7137626454134374,
    -1.622924837404925,
    -1.8222196707757934
  ],
  "logp_cond": [
    [
      0.0,
      -2.033003217766699,
      -2.0438710236880517,
      -2.0563388384000607,
      -2.0758803990154555,
      -2.0553431961077866,
      -2.1512583368064804,
      -2.1003998385016676,
      -2.078128942439796,
      -2.062178477969943,
      -2.054874102336902,
      -2.1049984844316754,
      -2.0571946749379686,
      -2.0459793507224706,
      -2.0910719696726026,
      -2.06164283945462,
      -2.0531011203949077,
      -2.0995162802350147,
      -2.0784523682705855,
      -2.053517519958991,
      -2.0679925466124107,
      -2.1318154259027517,
      -2.09822574956457,
      -2.07176239176535,
      -2.1030358461767853,
      -2.100156538644978,
      -2.0774110592913617,
      -2.082746711410693,
      -2.0964485550041294
    ],
    [
      -1.3912212405409001,
      0.0,
      -1.2407255874030743,
      -1.1499459954789535,
      -1.2898947872457944,
      -1.295244385739622,
      -1.3860401509579254,
      -1.3230545890850103,
      -1.2755904720624687,
      -1.314545427360841,
      -1.3028311069396081,
      -1.514639832541368,
      -1.1969988966080278,
      -1.3003118054065022,
      -1.2850120225820072,
      -1.188689442334017,
      -1.336498470871443,
      -1.314430723609346,
      -1.3618880919810024,
      -1.2523548030093656,
      -1.3261924440749333,
      -1.43790695256352,
      -1.3633120647551362,
      -1.294371999801829,
      -1.3883903837873657,
      -1.3327319241260198,
      -1.340206056761734,
      -1.3305917997761258,
      -1.316526383594919
    ],
    [
      -1.6096670397281474,
      -1.504931262847225,
      0.0,
      -1.5133960151109815,
      -1.5026355523260462,
      -1.4932472481965808,
      -1.6640930392847242,
      -1.40202260426997,
      -1.4164614187394546,
      -1.4781785420047544,
      -1.478352924904728,
      -1.6998397080147483,
      -1.413688551014311,
      -1.4678086048560266,
      -1.4992519413454175,
      -1.5020089991835142,
      -1.5150020806722513,
      -1.5327084766837915,
      -1.517316021201037,
      -1.474173250688869,
      -1.5352914367770898,
      -1.5890111384564343,
      -1.555938572100389,
      -1.4329711938572776,
      -1.602011411156274,
      -1.4914158816062846,
      -1.5729378040264161,
      -1.536573814625352,
      -1.5073393011504121
    ],
    [
      -1.2683501308418719,
      -1.0170162006132133,
      -1.1327341602916277,
      0.0,
      -1.2074290248775097,
      -1.2329381120631564,
      -1.3602583570865532,
      -1.2580975644645946,
      -1.1645205873540874,
      -1.2439799293715872,
      -1.179377434446207,
      -1.3506503025506196,
      -1.1764987853166713,
      -1.1138148201932088,
      -1.0886389917457395,
      -1.096407391117158,
      -1.222629252244365,
      -1.145744737486154,
      -1.2298475627574341,
      -1.1135067185045653,
      -1.2172885985208552,
      -1.290818104220073,
      -1.253854223487454,
      -1.177457327999242,
      -1.2694096940295765,
      -1.248212506705201,
      -1.2042260868168508,
      -1.1851988099951087,
      -1.2283739415380839
    ],
    [
      -1.6181668196476784,
      -1.5608619872795035,
      -1.5225164776036086,
      -1.5499475098637006,
      0.0,
      -1.57765361658177,
      -1.646339703288751,
      -1.5253143647565408,
      -1.5990329578774651,
      -1.531626025058819,
      -1.505538184811184,
      -1.6707792643766661,
      -1.4962139136021184,
      -1.5497503960621881,
      -1.5985578280905202,
      -1.5342625552711835,
      -1.536269219329454,
      -1.5280864653271231,
      -1.6237584373737295,
      -1.6057216335873459,
      -1.5558954305008692,
      -1.5692711424469723,
      -1.5655310146760384,
      -1.57327706906299,
      -1.6115645308489928,
      -1.5208377934770996,
      -1.616324426578356,
      -1.5845647226064161,
      -1.5432975795519537
    ],
    [
      -1.4451096273259076,
      -1.2425669960792427,
      -1.26612221866432,
      -1.304432841171285,
      -1.34453389443593,
      0.0,
      -1.3971229913678211,
      -1.343337243940186,
      -1.3226466682483478,
      -1.3448424674148562,
      -1.296388859241007,
      -1.5063991892256583,
      -1.3133806355062592,
      -1.3042572080224242,
      -1.3842171694193983,
      -1.2330538898385175,
      -1.3133068144303268,
      -1.3696449981728214,
      -1.3723924014580393,
      -1.2962682038455506,
      -1.3205593746806594,
      -1.4318288257637062,
      -1.3610361723986164,
      -1.3250874852211971,
      -1.3775062355481766,
      -1.3692769175911759,
      -1.3984743424684822,
      -1.3458409556556166,
      -1.2760598999555206
    ],
    [
      -1.4074649692085586,
      -1.3647238248017641,
      -1.3375359263342825,
      -1.364855180991176,
      -1.3433195133772993,
      -1.3400238765959058,
      0.0,
      -1.3373503325518274,
      -1.3551393403642502,
      -1.3408364604664524,
      -1.363081349425644,
      -1.4003481387639944,
      -1.3546598407715138,
      -1.3504039342130698,
      -1.3703551788484207,
      -1.3466476422359497,
      -1.346193176704478,
      -1.359554609018154,
      -1.373040093356871,
      -1.341991143680185,
      -1.3643737136862746,
      -1.3583658179037867,
      -1.332500129818056,
      -1.3422918535621329,
      -1.335780665565172,
      -1.3573185667407728,
      -1.3642653371728006,
      -1.3657722610906438,
      -1.3610841525521988
    ],
    [
      -1.7089536156666725,
      -1.6411904943461564,
      -1.4258875696252635,
      -1.688923739335777,
      -1.5958593814513102,
      -1.636534726699371,
      -1.6627360045121065,
      0.0,
      -1.5340811256137104,
      -1.505515814475865,
      -1.6194901310460794,
      -1.7342825295690352,
      -1.4989972072949673,
      -1.6555569674342059,
      -1.5628554376870496,
      -1.6196910740258668,
      -1.6262424995663847,
      -1.6386161391174485,
      -1.5967341644101287,
      -1.6447318785871539,
      -1.5767422868321304,
      -1.6443710342198814,
      -1.5910731641155005,
      -1.519432187307925,
      -1.6183111004459934,
      -1.5027257371985874,
      -1.6764333601208807,
      -1.6262683425316735,
      -1.640348299921827
    ],
    [
      -1.476109732410405,
      -1.3742972962858135,
      -1.2685013982729263,
      -1.3823967184258732,
      -1.3977872005375274,
      -1.3895349332229046,
      -1.4590495279416231,
      -1.2776895201652185,
      0.0,
      -1.2893766342008606,
      -1.3798216851627834,
      -1.510017599673548,
      -1.3237607401467861,
      -1.389942915661439,
      -1.309255004634517,
      -1.3889049385397114,
      -1.3883388015147609,
      -1.379385361727515,
      -1.4052611629958294,
      -1.3730158967972526,
      -1.4165832327904748,
      -1.4522429958423815,
      -1.382405287606866,
      -1.2792121408345372,
      -1.4171231942603222,
      -1.2865378368744176,
      -1.4233317663922747,
      -1.40566158027686,
      -1.4113328813972819
    ],
    [
      -1.6926244647826738,
      -1.6304070654982186,
      -1.5477344907670023,
      -1.6505084427193748,
      -1.6675090155683718,
      -1.6444247906796998,
      -1.6838565740248395,
      -1.531993834622193,
      -1.557230129314391,
      0.0,
      -1.6614045096990064,
      -1.7617460893044945,
      -1.5185452004610387,
      -1.6493382991935575,
      -1.586044961978776,
      -1.6327579360438977,
      -1.6438223361332505,
      -1.658398916841833,
      -1.6522777281972398,
      -1.6541248001985045,
      -1.667501179568317,
      -1.6741988665377272,
      -1.6576455447675775,
      -1.5714600974344124,
      -1.6630253642817034,
      -1.5368696372168877,
      -1.6974528191515315,
      -1.687653604716633,
      -1.6579208495831448
    ],
    [
      -1.3204005483664116,
      -1.183031324342841,
      -1.1649937982174934,
      -1.194448382305196,
      -1.253374949888652,
      -1.2066289170570257,
      -1.3413936131676092,
      -1.2041379797852831,
      -1.2058600196130056,
      -1.2381896718106251,
      0.0,
      -1.3609472846531963,
      -1.1480256392570345,
      -1.1973259917215195,
      -1.2451365241356191,
      -1.1673701162788976,
      -1.2182598657783965,
      -1.20091520571023,
      -1.2659344302126647,
      -1.2361785177774687,
      -1.21650759761055,
      -1.268474621312382,
      -1.290370849129024,
      -1.2815463244302827,
      -1.3068783161388309,
      -1.211529949159494,
      -1.252354533595526,
      -1.3183739948405913,
      -1.2178404562782725
    ],
    [
      -1.2069077748138386,
      -1.189823030590643,
      -1.189901980937919,
      -1.175054224359172,
      -1.1665135174546062,
      -1.184543253963084,
      -1.1881755132992027,
      -1.1732912095294443,
      -1.1719922521071575,
      -1.178697523505038,
      -1.174776994720577,
      0.0,
      -1.181125305925145,
      -1.1811307748318305,
      -1.1703562982252826,
      -1.1696684164122777,
      -1.1772586584260145,
      -1.167437583033231,
      -1.190610807168217,
      -1.1860135916957086,
      -1.201435293501523,
      -1.1398046194455107,
      -1.183647532150861,
      -1.2009876910729365,
      -1.1797036596951016,
      -1.2123096161348101,
      -1.177444497927735,
      -1.1978148478433488,
      -1.1769257307757843
    ],
    [
      -1.370874776795217,
      -1.1971875173950983,
      -1.1529163836136376,
      -1.2854549984339732,
      -1.2487249165529686,
      -1.295584534271671,
      -1.3711874209653134,
      -1.135627862220969,
      -1.2202409703298724,
      -1.1969694850676313,
      -1.2230085534257056,
      -1.4278188925426722,
      0.0,
      -1.2663911812798658,
      -1.2287556195544858,
      -1.2583977427217936,
      -1.2462934284227538,
      -1.2633794954564983,
      -1.2454453740777593,
      -1.282009768317165,
      -1.232033562098643,
      -1.318518104392177,
      -1.2892039683703695,
      -1.2739800163089279,
      -1.3595149459847187,
      -1.202286011117249,
      -1.2810194005955562,
      -1.3139670504031093,
      -1.2532536803102436
    ],
    [
      -1.295315736348062,
      -1.1448227339563963,
      -1.046056781379067,
      -1.107991307135395,
      -1.2263992392095904,
      -1.2169761055333441,
      -1.2691570003275974,
      -1.2093792138704975,
      -1.1518664894539752,
      -1.2339024565991268,
      -1.168783274893054,
      -1.3661909311537805,
      -1.115349468590711,
      0.0,
      -1.1430876656507034,
      -1.0717025851551911,
      -1.1769365693519949,
      -1.2400294858343879,
      -1.1805501768103461,
      -1.145760117433301,
      -1.2152267323471906,
      -1.2715085104014516,
      -1.2312417246981247,
      -1.1634478224127212,
      -1.2348394953441686,
      -1.214512555794526,
      -1.202464500241198,
      -1.1478714735195732,
      -1.183152200350612
    ],
    [
      -1.3989925811468582,
      -1.2422307598760893,
      -1.1724526109858588,
      -1.189854129722375,
      -1.3223211046291454,
      -1.2853437557198402,
      -1.4288715887742487,
      -1.2298096083078889,
      -1.1964484090899605,
      -1.2856977995851866,
      -1.2911937788595915,
      -1.4154798715266084,
      -1.204307273727423,
      -1.2228611355817833,
      0.0,
      -1.2460278783880843,
      -1.3104379168857647,
      -1.2776111541693116,
      -1.300289585279737,
      -1.238271203915471,
      -1.339117843992103,
      -1.3537849095081471,
      -1.3013445728690132,
      -1.1931186540950862,
      -1.3554634746662875,
      -1.2827275266993325,
      -1.2642315376173276,
      -1.3042093504584569,
      -1.3192114830384847
    ],
    [
      -1.36833301022346,
      -1.1825739315669495,
      -1.2351904436473702,
      -1.2640494762377794,
      -1.3423394495717886,
      -1.284429964482085,
      -1.3928819232137637,
      -1.2931432788928086,
      -1.2726686961881934,
      -1.3064903420126235,
      -1.2703276452705772,
      -1.450219031747352,
      -1.2579739182254321,
      -1.2420985251744583,
      -1.2814378069588803,
      0.0,
      -1.3421388221351274,
      -1.3070136988289198,
      -1.2694438868718834,
      -1.2720571962362803,
      -1.3430919733134854,
      -1.372023049396447,
      -1.347082167461026,
      -1.3372297961653197,
      -1.3541895294867636,
      -1.3044456799363917,
      -1.2974702615568077,
      -1.345685323915454,
      -1.3058909809503891
    ],
    [
      -1.5763624737648454,
      -1.5030354809158362,
      -1.4826512180219704,
      -1.5626649644622588,
      -1.5069430485338242,
      -1.59490865945464,
      -1.6039762161262494,
      -1.503877362202028,
      -1.546302337307043,
      -1.5475650890812243,
      -1.5420062575744649,
      -1.7339481024806551,
      -1.5255145545917042,
      -1.5014358527584997,
      -1.5828654272976457,
      -1.5410853426256084,
      0.0,
      -1.6021929264887587,
      -1.5768367625927548,
      -1.5337163595158754,
      -1.6192222297269667,
      -1.651164227510535,
      -1.5903072189376837,
      -1.5516084660449554,
      -1.650471473341862,
      -1.5534069087796165,
      -1.6043224699858882,
      -1.5974196735529465,
      -1.572195149605037
    ],
    [
      -1.4441478553092233,
      -1.35099117029895,
      -1.3598858378595573,
      -1.3094373436001823,
      -1.3668314448778778,
      -1.4016261701976258,
      -1.4732814254690723,
      -1.3629325652715383,
      -1.3635793344723635,
      -1.4355221820501902,
      -1.338229426833047,
      -1.4462061732907385,
      -1.3503327183940734,
      -1.399661803851183,
      -1.398878632872196,
      -1.3351974552429664,
      -1.3713978230076846,
      0.0,
      -1.3274653209202072,
      -1.4070461398882343,
      -1.4348393792981033,
      -1.4577219513442825,
      -1.4473734651812127,
      -1.4222516744029292,
      -1.4492619796223922,
      -1.3838125403658956,
      -1.3466837446638147,
      -1.4331056110103244,
      -1.4404702294527556
    ],
    [
      -1.3984968258514177,
      -1.3205131436659947,
      -1.2891269952002575,
      -1.356070656391248,
      -1.3784594497158207,
      -1.3251264002388128,
      -1.3901016871496799,
      -1.3174938590667717,
      -1.3611236834005715,
      -1.3511015677598308,
      -1.3506048735436726,
      -1.4011721615094166,
      -1.324024742884149,
      -1.332814132364771,
      -1.3369941613754728,
      -1.2865384273558356,
      -1.3477751413613726,
      -1.3502718541295984,
      0.0,
      -1.3454625909472613,
      -1.3531693435346857,
      -1.4031128925638974,
      -1.3914635094089687,
      -1.3303544776600995,
      -1.4027288872249304,
      -1.3370828511695942,
      -1.2260722928119498,
      -1.3877921434890748,
      -1.3606380244388268
    ],
    [
      -1.435695805872912,
      -1.344825299030847,
      -1.3170613870373447,
      -1.3329048072810572,
      -1.4243704679132925,
      -1.3686422120487602,
      -1.5284580415776896,
      -1.4384081691866648,
      -1.3675839669192917,
      -1.4037005680721157,
      -1.4345501016087903,
      -1.631243107797908,
      -1.3776395557675074,
      -1.37918249858492,
      -1.3718084992193187,
      -1.3780027421954748,
      -1.4036367586590186,
      -1.4088657590970575,
      -1.4522451818894904,
      0.0,
      -1.4324811720889605,
      -1.4964438626790109,
      -1.450865586387701,
      -1.3688600686373655,
      -1.4829035878959143,
      -1.4591124392630184,
      -1.448678710085432,
      -1.4411080743840041,
      -1.4158252344551703
    ],
    [
      -1.5764659842045334,
      -1.4380287722763756,
      -1.4332916466366812,
      -1.4713227013265118,
      -1.470443044203464,
      -1.4489682028568793,
      -1.5625393080084202,
      -1.4180485154186426,
      -1.5175676168069265,
      -1.4654312516349477,
      -1.480725007040206,
      -1.600355642953024,
      -1.4244565270099225,
      -1.4517099046744864,
      -1.5071700189551724,
      -1.4332461700578794,
      -1.4607551821806715,
      -1.5358053109836896,
      -1.5173502292549725,
      -1.4422937884000913,
      0.0,
      -1.5102547005788345,
      -1.457405060601749,
      -1.4799671739638285,
      -1.516609056875118,
      -1.4996661406084977,
      -1.5263734854095892,
      -1.4793340706274802,
      -1.4307252708664362
    ],
    [
      -1.3049331153345833,
      -1.262315563940045,
      -1.2343796456505987,
      -1.288747456085601,
      -1.1930268962738215,
      -1.2472238253940264,
      -1.290382476134116,
      -1.2104103927514929,
      -1.244894161828605,
      -1.2033369898051867,
      -1.2354851790595813,
      -1.3196926471926937,
      -1.244510302370719,
      -1.258761594941307,
      -1.2690564754470004,
      -1.2455929805153543,
      -1.2494036569061675,
      -1.2765840464246891,
      -1.2959707317821128,
      -1.2503051740100364,
      -1.2505937634349238,
      0.0,
      -1.2081689659128318,
      -1.2538040908606822,
      -1.2868857029174487,
      -1.2508255883871149,
      -1.2876621340698022,
      -1.2495956136864732,
      -1.1578770661429936
    ],
    [
      -1.6068995172803364,
      -1.5253688116978597,
      -1.4631868757434863,
      -1.554081748675166,
      -1.5115136801145486,
      -1.571533539456744,
      -1.584922191145343,
      -1.4218319418286876,
      -1.4417693703345569,
      -1.4229548839276458,
      -1.5611986088927907,
      -1.6495196508084256,
      -1.4794073625166695,
      -1.4619129882266644,
      -1.4675155144653869,
      -1.503998972017699,
      -1.5136978470277487,
      -1.5976129525432943,
      -1.496605108815947,
      -1.5272080890204054,
      -1.5053253803575943,
      -1.553677677130404,
      0.0,
      -1.440951226709553,
      -1.425743431592305,
      -1.4705117648953914,
      -1.512636361213833,
      -1.5294074063048704,
      -1.5414523773252446
    ],
    [
      -1.4076484534212264,
      -1.3876415961367436,
      -1.1991062978134455,
      -1.3638968657245467,
      -1.420554273837532,
      -1.3864974736331073,
      -1.4728177272069123,
      -1.3478580404466332,
      -1.3076369746866585,
      -1.3208640236323774,
      -1.4445754489242013,
      -1.5301840606019648,
      -1.3754755275170047,
      -1.3335172993918827,
      -1.3087392139686977,
      -1.3890247203488424,
      -1.3689818816558155,
      -1.4436701741787963,
      -1.4314445503750148,
      -1.342214002323368,
      -1.3980792049639537,
      -1.4233785607479827,
      -1.3557750637696666,
      0.0,
      -1.4078742740082382,
      -1.3532638377509272,
      -1.4160829593582134,
      -1.3599578838246922,
      -1.3984699049779157
    ],
    [
      -1.4091412342707708,
      -1.3918755625295718,
      -1.3622279868702774,
      -1.4123297793874965,
      -1.3523898965843715,
      -1.3566569087341713,
      -1.4031395582806574,
      -1.3363369804251883,
      -1.3326649434315911,
      -1.3585990213385404,
      -1.4173059281131621,
      -1.4553389754627715,
      -1.3897675379972207,
      -1.3719525818139358,
      -1.3618536469539162,
      -1.367076021973158,
      -1.366115161756099,
      -1.4341675089461843,
      -1.4205137735929392,
      -1.3518400544023292,
      -1.3756625502736044,
      -1.3830623567307296,
      -1.3358541891520557,
      -1.312862335141793,
      0.0,
      -1.3518761563754451,
      -1.3700695594583447,
      -1.3718413499165882,
      -1.3806725431245033
    ],
    [
      -1.6163274239561212,
      -1.5528149222739756,
      -1.429795177582986,
      -1.5839092009277016,
      -1.4891572931917196,
      -1.5993748765836155,
      -1.6013173576507047,
      -1.3960266332792015,
      -1.4417747841054127,
      -1.432752719544787,
      -1.5291291000232754,
      -1.7011548041865872,
      -1.4202132563020327,
      -1.5387463576341662,
      -1.4715253664065469,
      -1.555710794559529,
      -1.5113814489236719,
      -1.571705150750676,
      -1.5593525510728996,
      -1.5347447106214676,
      -1.545157780550999,
      -1.5689499974203995,
      -1.4936725708723455,
      -1.3992950416905394,
      -1.518537560417152,
      0.0,
      -1.6016923925369222,
      -1.5118730027598453,
      -1.5567135227484807
    ],
    [
      -1.402494537476613,
      -1.3495570332151323,
      -1.316636453307823,
      -1.3393318141767008,
      -1.4086450492664153,
      -1.3370849952799393,
      -1.429924556552322,
      -1.3551979226433792,
      -1.35462132699147,
      -1.3898428994144365,
      -1.3551049418887569,
      -1.4110807653337865,
      -1.294907420741098,
      -1.366359705733602,
      -1.3412668572700277,
      -1.3450345005707454,
      -1.3471060805656563,
      -1.3575765153323576,
      -1.2044115375295568,
      -1.3621823152448953,
      -1.3665870824120026,
      -1.3984793666685733,
      -1.4131667291324832,
      -1.382989087457107,
      -1.3988692918650965,
      -1.397179581898494,
      0.0,
      -1.3962232143905953,
      -1.3608758897239945
    ],
    [
      -1.2918451491799847,
      -1.2218046927886559,
      -1.1780192912684475,
      -1.2015693985597442,
      -1.2523130226912877,
      -1.218554748703816,
      -1.3259474145618835,
      -1.214534543530158,
      -1.195741987790903,
      -1.2462092039364818,
      -1.262364968337068,
      -1.3554524954041745,
      -1.2240856653082526,
      -1.1888909389720257,
      -1.2166874542034316,
      -1.2303957833456338,
      -1.269305873009946,
      -1.2828630569139514,
      -1.3090452297508053,
      -1.2305847778261712,
      -1.2459560670522716,
      -1.296757657278793,
      -1.2158853727513916,
      -1.1602089637668362,
      -1.2411654549207747,
      -1.2175905341454867,
      -1.2851304960469467,
      0.0,
      -1.23330197972289
    ],
    [
      -1.4932223935366145,
      -1.4076367791283577,
      -1.4271158251254514,
      -1.464454256272988,
      -1.4599093430564962,
      -1.433307135845578,
      -1.49571370313777,
      -1.4417412226376434,
      -1.4295138590609706,
      -1.452103288897174,
      -1.394963431252097,
      -1.5620669197245858,
      -1.4198728653480075,
      -1.444592215096021,
      -1.4681769503434758,
      -1.4220934210205292,
      -1.4182029677478099,
      -1.4975074694175223,
      -1.500423407491813,
      -1.4113617701027303,
      -1.4002298203999277,
      -1.4132574703242768,
      -1.4633583823916807,
      -1.4427538256104,
      -1.4790790354798056,
      -1.446410345331569,
      -1.477882742306678,
      -1.4484135799392939,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.23825948405100617,
      0.22739167812965322,
      0.21492386341764425,
      0.19538230280224944,
      0.21591950570991836,
      0.12000436501122458,
      0.1708628633160374,
      0.193133759377909,
      0.20908422384776193,
      0.21638859948080302,
      0.1662642173860296,
      0.21406802687973636,
      0.22528335109523434,
      0.1801907321451024,
      0.20961986236308494,
      0.2181615814227973,
      0.17174642158269027,
      0.1928103335471194,
      0.21774518185871417,
      0.20327015520529423,
      0.1394472759149532,
      0.17303695225313476,
      0.1995003100523549,
      0.16822685564091966,
      0.17110616317272687,
      0.19385164252634324,
      0.18851599040701217,
      0.17481414681357554
    ],
    [
      0.3635301396009609,
      0.0,
      0.5140257927387868,
      0.6048053846629076,
      0.4648565928960666,
      0.45950699440223897,
      0.3687112291839356,
      0.43169679105685077,
      0.4791609080793924,
      0.44020595278102004,
      0.4519202732022529,
      0.24011154760049314,
      0.5577524835338332,
      0.4544395747353589,
      0.46973935755985385,
      0.566061937807844,
      0.41825290927041814,
      0.44032065653251506,
      0.3928632881608587,
      0.5023965771324954,
      0.42855893606692774,
      0.3168444275783411,
      0.39143931538672483,
      0.460379380340032,
      0.36636099635449537,
      0.42201945601584123,
      0.41454532338012706,
      0.4241595803657352,
      0.438224996546942
    ],
    [
      0.33885119929102636,
      0.44358697617194887,
      0.0,
      0.4351222239081922,
      0.4458826866931276,
      0.4552709908225929,
      0.2844251997344496,
      0.5464956347492038,
      0.5320568202797191,
      0.47033969701441936,
      0.47016531411444573,
      0.2486785310044255,
      0.5348296880048629,
      0.48070963416314716,
      0.44926629767375625,
      0.4465092398356596,
      0.4335161583469225,
      0.41580976233538225,
      0.4312022178181367,
      0.4743449883303048,
      0.41322680224208397,
      0.3595071005627395,
      0.39257966691878465,
      0.5155470451618962,
      0.34650682786289977,
      0.4571023574128892,
      0.3755804349927576,
      0.41194442439382173,
      0.4411789378687616
    ],
    [
      0.3714005174113284,
      0.622734447639987,
      0.5070164879615726,
      0.0,
      0.4323216233756906,
      0.40681253619004387,
      0.2794922911666471,
      0.38165308378860563,
      0.4752300608991129,
      0.3957707188816131,
      0.46037321380699336,
      0.2891003457025807,
      0.463251862936529,
      0.5259358280599915,
      0.5511116565074607,
      0.5433432571360424,
      0.41712139600883535,
      0.49400591076704625,
      0.40990308549576615,
      0.526243929748635,
      0.422462049732345,
      0.34893254403312723,
      0.38589642476574637,
      0.4622933202539583,
      0.3703409542236238,
      0.39153814154799926,
      0.43552456143634943,
      0.45455183825809153,
      0.4113767067151164
    ],
    [
      0.34439297798806834,
      0.4016978103562432,
      0.4400433200321381,
      0.41261228777204617,
      0.0,
      0.38490618105397667,
      0.3162200943469957,
      0.4372454328792059,
      0.3635268397582816,
      0.4309337725769278,
      0.4570216128245628,
      0.2917805332590806,
      0.4663458840336283,
      0.4128094015735586,
      0.36400196954522657,
      0.42829724236456324,
      0.4262905783062927,
      0.4344733323086236,
      0.33880136026201724,
      0.35683816404840085,
      0.4066643671348775,
      0.3932886551887744,
      0.39702878295970834,
      0.3892827285727567,
      0.35099526678675397,
      0.44172200415864715,
      0.34623537105739066,
      0.3779950750293306,
      0.41926221808379305
    ],
    [
      0.34623742667481117,
      0.5487800579214761,
      0.5252248353363989,
      0.4869142128294337,
      0.44681315956478884,
      0.0,
      0.39422406263289766,
      0.44800981006053275,
      0.46870038575237105,
      0.44650458658586256,
      0.4949581947597117,
      0.2849478647750605,
      0.47796641849445964,
      0.48708984597829463,
      0.4071298845813205,
      0.5582931641622013,
      0.478040239570392,
      0.42170205582789744,
      0.4189546525426795,
      0.49507885015516817,
      0.4707876793200594,
      0.3595182282370126,
      0.4303108816021024,
      0.4662595687795217,
      0.41384081845254217,
      0.42207013640954294,
      0.3928727115322366,
      0.44550609834510224,
      0.5152871540451982
    ],
    [
      0.24707279671969595,
      0.2898139411264904,
      0.317001839593972,
      0.28968258493707855,
      0.31121825255095525,
      0.3145138893323487,
      0.0,
      0.3171874333764271,
      0.2993984255640043,
      0.3137013054618021,
      0.29145641650261056,
      0.2541896271642601,
      0.2998779251567407,
      0.3041338317151847,
      0.2841825870798338,
      0.30789012369230484,
      0.3083445892237766,
      0.29498315691010046,
      0.2814976725713836,
      0.3125466222480695,
      0.29016405224197994,
      0.2961719480244678,
      0.3220376361101984,
      0.31224591236612165,
      0.31875710036308247,
      0.29721919918748174,
      0.2902724287554539,
      0.28876550483761076,
      0.2934536133760557
    ],
    [
      0.24839325199705065,
      0.31615637331756674,
      0.5314592980384596,
      0.2684231283279461,
      0.3614874862124129,
      0.32081214096435207,
      0.29461086315161666,
      0.0,
      0.42326574205001277,
      0.4518310531878582,
      0.3378567366176437,
      0.22306433809468795,
      0.4583496603687558,
      0.30178990022951724,
      0.3944914299766735,
      0.33765579363785636,
      0.33110436809733845,
      0.3187307285462746,
      0.3606127032535944,
      0.31261498907656926,
      0.38060458083159276,
      0.3129758334438417,
      0.36627370354822264,
      0.43791468035579806,
      0.33903576721772977,
      0.45462113046513575,
      0.2809135075428424,
      0.3310785251320496,
      0.31699856774189605
    ],
    [
      0.2796871445540168,
      0.38149958067860834,
      0.4872954786914956,
      0.3734001585385487,
      0.3580096764268945,
      0.3662619437415173,
      0.29674734902279876,
      0.47810735679920335,
      0.0,
      0.4664202427635613,
      0.3759751918016385,
      0.2457792772908738,
      0.43203613681763575,
      0.365853961302983,
      0.44654187232990483,
      0.36689193842471046,
      0.367458075449661,
      0.37641151523690697,
      0.3505357139685925,
      0.3827809801671693,
      0.33921364417394706,
      0.3035538811220404,
      0.3733915893575559,
      0.4765847361298847,
      0.3386736827040997,
      0.4692590400900043,
      0.3324651105721472,
      0.35013529668756194,
      0.34446399556714
    ],
    [
      0.30355529778476,
      0.3657726970692152,
      0.4484452718004315,
      0.345671319848059,
      0.32867074699906196,
      0.35175497188773397,
      0.31232318854259433,
      0.4641859279452407,
      0.4389496332530427,
      0.0,
      0.33477525286842735,
      0.2344336732629393,
      0.4776345621063951,
      0.34684146337387634,
      0.4101348005886578,
      0.36342182652353605,
      0.35235742643418333,
      0.33778084572560085,
      0.34390203437019395,
      0.3420549623689293,
      0.3286785829991168,
      0.3219808960297066,
      0.33853421779985626,
      0.4247196651330214,
      0.33315439828573035,
      0.45931012535054605,
      0.29872694341590234,
      0.30852615785080073,
      0.338258912984289
    ],
    [
      0.30650797444821576,
      0.4438771984717864,
      0.461914724597134,
      0.4324601405094315,
      0.37353357292597544,
      0.4202796057576017,
      0.2855149096470182,
      0.42277054302934425,
      0.4210485032016218,
      0.3887188510040023,
      0.0,
      0.26596123816143113,
      0.4788828835575929,
      0.42958253109310784,
      0.38177199867900824,
      0.45953840653572975,
      0.4086486570362309,
      0.4259933171043975,
      0.36097409260196267,
      0.3907300050371587,
      0.41040092520407745,
      0.3584339015022453,
      0.3365376736856034,
      0.3453621983843447,
      0.3200302066757965,
      0.4153785736551334,
      0.37455398921910144,
      0.30853452797403613,
      0.40906806653635486
    ],
    [
      0.1896729553731189,
      0.20675769959631451,
      0.2066787492490385,
      0.22152650582778555,
      0.2300672127323513,
      0.21203747622387348,
      0.20840521688775482,
      0.22328952065751317,
      0.22458847807979998,
      0.2178832066819194,
      0.22180373546638044,
      0.0,
      0.21545542426181252,
      0.215449955355127,
      0.22622443196167485,
      0.2269123137746798,
      0.21932207176094298,
      0.2291431471537264,
      0.2059699230187404,
      0.21056713849124886,
      0.1951454366854346,
      0.2567761107414468,
      0.21293319803609645,
      0.19559303911402104,
      0.2168770704918559,
      0.18427111405214736,
      0.21913623225922252,
      0.1987658823436087,
      0.21965499941117317
    ],
    [
      0.23681708123194212,
      0.41050434063206076,
      0.4547754744135215,
      0.32223685959318593,
      0.3589669414741905,
      0.3121073237554881,
      0.23650443706184565,
      0.4720639958061901,
      0.38745088769728664,
      0.41072237295952774,
      0.3846833046014535,
      0.17987296548448684,
      0.0,
      0.34130067674729325,
      0.3789362384726733,
      0.34929411530536547,
      0.36139842960440527,
      0.3443123625706608,
      0.36224648394939973,
      0.3256820897099941,
      0.3756582959285162,
      0.2891737536349821,
      0.31848788965678954,
      0.3337118417182312,
      0.2481769120424404,
      0.40540584690991,
      0.3266724574316029,
      0.29372480762404973,
      0.35443817771691544
    ],
    [
      0.2998421643518301,
      0.45033516674349583,
      0.5491011193208251,
      0.4871665935644971,
      0.3687586614903018,
      0.37818179516654804,
      0.3260009003722948,
      0.38577868682939465,
      0.443291411245917,
      0.3612554441007654,
      0.42637462580683816,
      0.22896696954611162,
      0.4798084321091811,
      0.0,
      0.45207023504918875,
      0.523455315544701,
      0.4182213313478973,
      0.3551284148655043,
      0.41460772388954603,
      0.4493977832665912,
      0.3799311683527016,
      0.32364939029844053,
      0.3639161760017675,
      0.431710078287171,
      0.36031840535572357,
      0.38064534490536617,
      0.39269340045869416,
      0.44728642718031897,
      0.4120057003492801
    ],
    [
      0.2813760757651156,
      0.43813789703588446,
      0.507916045926115,
      0.49051452718959876,
      0.35804755228282836,
      0.3950249011921336,
      0.2514970681377251,
      0.4505590486040849,
      0.48392024782201326,
      0.3946708573267872,
      0.38917487805238227,
      0.2648887853853654,
      0.4760613831845508,
      0.45750752133019046,
      0.0,
      0.4343407785238895,
      0.36993074002620907,
      0.4027575027426622,
      0.38007907163223686,
      0.4420974529965027,
      0.3412508129198708,
      0.3265837474038267,
      0.3790240840429606,
      0.4872500028168876,
      0.3249051822456863,
      0.39764113021264125,
      0.41613711929464614,
      0.3761593064535169,
      0.3611571738734891
    ],
    [
      0.2863640358550783,
      0.47212311451158895,
      0.4195066024311682,
      0.390647569840759,
      0.31235759650674977,
      0.3702670815964535,
      0.2618151228647747,
      0.36155376718572985,
      0.38202834989034495,
      0.3482067040659149,
      0.3843694008079612,
      0.2044780143311864,
      0.39672312785310626,
      0.4125985209040801,
      0.3732592391196581,
      0.0,
      0.31255822394341104,
      0.3476833472496186,
      0.38525315920665504,
      0.3826398498422581,
      0.311605072765053,
      0.2826739966820915,
      0.30761487861751236,
      0.31746724991321873,
      0.30050751659177477,
      0.3502513661421467,
      0.35722678452173073,
      0.30901172216308437,
      0.34880606512814927
    ],
    [
      0.3883698983929402,
      0.46169689124194946,
      0.4820811541358152,
      0.40206740769552685,
      0.4577893236239614,
      0.3698237127031456,
      0.3607561560315362,
      0.46085500995575757,
      0.4184300348507426,
      0.41716728307656137,
      0.42272611458332077,
      0.2307842696771305,
      0.43921781756608147,
      0.46329651939928596,
      0.38186694486013995,
      0.42364702953217726,
      0.0,
      0.36253944566902696,
      0.3878956095650308,
      0.43101601264191025,
      0.3455101424308189,
      0.3135681446472507,
      0.37442515322010195,
      0.41312390611283023,
      0.3142608988159237,
      0.4113254633781691,
      0.3604099021718974,
      0.36731269860483917,
      0.3925372225527486
    ],
    [
      0.2781450661868934,
      0.3713017511971666,
      0.3624070836365594,
      0.4128555778959344,
      0.3554614766182389,
      0.32066675129849087,
      0.24901149602704442,
      0.3593603562245784,
      0.3587135870237532,
      0.28677073944592646,
      0.38406349466306966,
      0.27608674820537815,
      0.37196020310204325,
      0.3226311176449337,
      0.32341428862392063,
      0.3870954662531503,
      0.35089509848843203,
      0.0,
      0.3948276005759095,
      0.31524678160788233,
      0.28745354219801333,
      0.2645709701518342,
      0.274919456314904,
      0.30004124709318747,
      0.27303094187372445,
      0.33848038113022105,
      0.375609176832302,
      0.28918731048579227,
      0.2818226920433611
    ],
    [
      0.24490889186117104,
      0.322892574046594,
      0.35427872251233117,
      0.2873350613213408,
      0.264946267996768,
      0.3182793174737759,
      0.25330403056290884,
      0.32591185864581695,
      0.28228203431201715,
      0.2923041499527579,
      0.29280084416891605,
      0.2422335562031721,
      0.31938097482843975,
      0.3105915853478176,
      0.3064115563371159,
      0.35686729035675313,
      0.29563057635121615,
      0.2931338635829903,
      0.0,
      0.2979431267653274,
      0.29023637417790304,
      0.24029282514869132,
      0.25194220830362,
      0.3130512400524892,
      0.2406768304876583,
      0.30632286654299445,
      0.41733342490063885,
      0.25561357422351394,
      0.28276769327376194
    ],
    [
      0.4088556433509545,
      0.49972615019301947,
      0.5274900621865217,
      0.5116466419428092,
      0.4201809813105739,
      0.47590923717510614,
      0.31609340764617677,
      0.40614328003720157,
      0.47696748230457464,
      0.44085088115175064,
      0.4100013476150761,
      0.21330834142595845,
      0.466911893456359,
      0.46536895063894645,
      0.4727429500045477,
      0.4665487070283916,
      0.4409146905648478,
      0.4356856901268089,
      0.392306267334376,
      0.0,
      0.41207027713490585,
      0.3481075865448555,
      0.39368586283616547,
      0.47569138058650084,
      0.3616478613279521,
      0.385439009960848,
      0.39587273913843446,
      0.40344337483986226,
      0.4287262147686961
    ],
    [
      0.2724225523813344,
      0.4108597643094922,
      0.41559688994918664,
      0.37756583525935605,
      0.3784454923824039,
      0.3999203337289885,
      0.2863492285774476,
      0.4308400211672252,
      0.3313209197789413,
      0.38345728495092013,
      0.3681635295456618,
      0.24853289363284392,
      0.4244320095759453,
      0.3971786319113815,
      0.3417185176306954,
      0.41564236652798847,
      0.38813335440519636,
      0.31308322560217827,
      0.3315383073308953,
      0.40659474818577657,
      0.0,
      0.33863383600703334,
      0.3914834759841188,
      0.36892136262203934,
      0.3322794797107498,
      0.34922239597737015,
      0.32251505117627866,
      0.3695544659583876,
      0.41816326571943163
    ],
    [
      0.343984420293324,
      0.38660197168786237,
      0.41453788997730867,
      0.3601700795423064,
      0.4558906393540858,
      0.4016937102338809,
      0.3585350594937913,
      0.43850714287641446,
      0.4040233737993024,
      0.44558054582272066,
      0.413432356568326,
      0.3292248884352136,
      0.4044072332571884,
      0.3901559406866004,
      0.37986106018090693,
      0.40332455511255305,
      0.3995138787217398,
      0.3723334892032182,
      0.3529468038457946,
      0.39861236161787095,
      0.39832377219298354,
      0.0,
      0.4407485697150755,
      0.3951134447672251,
      0.3620318327104586,
      0.39809194724079244,
      0.3612554015581051,
      0.3993219219414341,
      0.49104046948491376
    ],
    [
      0.23681132453154552,
      0.3183420301140223,
      0.38052396606839567,
      0.28962909313671603,
      0.3321971616973334,
      0.27217730235513793,
      0.2587886506665389,
      0.4218788999831944,
      0.40194147147732506,
      0.42075595788423614,
      0.2825122329190912,
      0.1941911910034564,
      0.36430347929521245,
      0.38179785358521756,
      0.3761953273464951,
      0.339711869794183,
      0.33001299478413326,
      0.24609788926858767,
      0.34710573299593483,
      0.31650275279147655,
      0.3383854614542876,
      0.290033164681478,
      0.0,
      0.40275961510232894,
      0.41796741021957695,
      0.37319907691649057,
      0.331074480598049,
      0.31430343550701156,
      0.3022584644866373
    ],
    [
      0.3639539391965372,
      0.3839607964810199,
      0.5724960948043181,
      0.4077055268932168,
      0.35104811878023146,
      0.38510491898465626,
      0.29878466541085125,
      0.4237443521711304,
      0.463965417931105,
      0.4507383689853861,
      0.3270269436935622,
      0.24141833201579876,
      0.3961268651007588,
      0.43808509322588085,
      0.4628631786490658,
      0.38257767226892114,
      0.40262051096194806,
      0.32793221843896725,
      0.3401578422427487,
      0.42938839029439557,
      0.3735231876538099,
      0.3482238318697808,
      0.4158273288480969,
      0.0,
      0.36372811860952536,
      0.41833855486683635,
      0.35551943325955015,
      0.41164450879307135,
      0.37313248763984785
    ],
    [
      0.255801107180319,
      0.273066778921518,
      0.3027143545808124,
      0.2526125620635933,
      0.3125524448667183,
      0.30828543271691844,
      0.2618027831704324,
      0.32860536102590143,
      0.3322773980194986,
      0.3063433201125494,
      0.24763641333792763,
      0.2096033659883183,
      0.275174803453869,
      0.292989759637154,
      0.30308869449717357,
      0.29786631947793185,
      0.29882717969499084,
      0.2307748325049055,
      0.2444285678581506,
      0.31310228704876053,
      0.28927979117748537,
      0.28187998472036013,
      0.3290881522990341,
      0.3520800063092968,
      0.0,
      0.31306618507564465,
      0.294872781992745,
      0.29310099153450153,
      0.2842697983265865
    ],
    [
      0.2888186224543401,
      0.3523311241364857,
      0.47535086882747524,
      0.32123684548275966,
      0.4159887532187416,
      0.3057711698268457,
      0.30382868875975655,
      0.5091194131312597,
      0.46337126230504855,
      0.47239332686567437,
      0.37601694638718586,
      0.2039912422238741,
      0.4849327901084286,
      0.36639968877629503,
      0.4336206800039144,
      0.34943525185093227,
      0.3937645974867894,
      0.3334408956597852,
      0.34579349533756165,
      0.3704013357889937,
      0.3599882658594622,
      0.3361960489900617,
      0.41147347553811575,
      0.5058510047199218,
      0.3866084859933092,
      0.0,
      0.30345365387353906,
      0.393273043650616,
      0.3484325236619805
    ],
    [
      0.31126810793682447,
      0.36420561219830505,
      0.3971261921056144,
      0.3744308312367366,
      0.30511759614702205,
      0.3766776501334981,
      0.2838380888611154,
      0.35856472277005813,
      0.3591413184219674,
      0.32391974599900086,
      0.3586577035246805,
      0.3026818800796509,
      0.4188552246723394,
      0.34740293967983527,
      0.37249578814340967,
      0.368728144842692,
      0.3666565648477811,
      0.3561861300810798,
      0.5093511078838806,
      0.35158033016854207,
      0.3471755630014348,
      0.31528327874486406,
      0.30059591628095417,
      0.33077355795633046,
      0.3148933535483409,
      0.31658306351494336,
      0.0,
      0.3175394310228421,
      0.35288675568944283
    ],
    [
      0.33107968822494027,
      0.4011201446162691,
      0.4449055461364775,
      0.4213554388451808,
      0.37061181471363724,
      0.404370088701109,
      0.2969774228430415,
      0.408390293874767,
      0.427182849614022,
      0.37671563346844317,
      0.3605598690678571,
      0.26747234200075054,
      0.3988391720966724,
      0.4340338984328993,
      0.4062373832014934,
      0.39252905405929117,
      0.353618964394979,
      0.3400617804909736,
      0.3138796076541197,
      0.39234005957875384,
      0.3769687703526534,
      0.3261671801261319,
      0.40703946465353336,
      0.46271587363808875,
      0.3817593824841503,
      0.4053343032594383,
      0.33779434135797826,
      0.0,
      0.3896228576820351
    ],
    [
      0.32899727723917893,
      0.41458289164743567,
      0.39510384565034196,
      0.3577654145028053,
      0.36231032771929716,
      0.3889125349302154,
      0.3265059676380233,
      0.38047844813815,
      0.3927058117148228,
      0.3701163818786193,
      0.4272562395236963,
      0.2601527510512076,
      0.4023468054277859,
      0.3776274556797723,
      0.35404272043231755,
      0.40012624975526423,
      0.40401670302798354,
      0.32471220135827106,
      0.32179626328398037,
      0.41085790067306305,
      0.42198985037586567,
      0.40896220045151654,
      0.3588612883841127,
      0.3794658451653934,
      0.3431406352959878,
      0.3758093254442243,
      0.34433692846911534,
      0.3738060908364995,
      0.0
    ]
  ],
  "row_avgs": [
    0.19317892305039397,
    0.43867467153475886,
    0.43036560206101276,
    0.4369906712303871,
    0.3939540451522096,
    0.44828653517603845,
    0.2981350148639104,
    0.35046879576518913,
    0.37590837751468215,
    0.35909127866435175,
    0.38703604343698006,
    0.21467529448888603,
    0.34197594156194316,
    0.4032106737786033,
    0.39566467480070716,
    0.3460570528761164,
    0.39480357739773647,
    0.3273582286729516,
    0.29498833284780357,
    0.42329774687972216,
    0.3647346157139024,
    0.39640231286862126,
    0.33148065323800335,
    0.38962988207396493,
    0.28875683777118205,
    0.37897441074711263,
    0.35009344998189956,
    0.37963154377034597,
    0.37167094127481953
  ],
  "col_avgs": [
    0.3034684849384758,
    0.39252590236124335,
    0.432943192458281,
    0.376874417020907,
    0.3617469451200949,
    0.36040176778780675,
    0.28896685512332987,
    0.40156639486017925,
    0.39743119337514105,
    0.38333437888693894,
    0.37029109951115985,
    0.24436427608542025,
    0.4141404704014266,
    0.3838887654393915,
    0.3815575650421853,
    0.3966294747318714,
    0.36661899605641973,
    0.3481058621230857,
    0.3540085972213309,
    0.37704805898717725,
    0.3549474128504822,
    0.31433681223149634,
    0.35139762225430704,
    0.3912646514823162,
    0.3288833282990183,
    0.37538477510700474,
    0.34455197620447076,
    0.3465272147301465,
    0.3622896385031276
  ],
  "combined_avgs": [
    0.24832370399443487,
    0.4156002869480011,
    0.4316543972596469,
    0.40693254412564706,
    0.37785049513615226,
    0.4043441514819226,
    0.29355093499362017,
    0.3760175953126842,
    0.3866697854449116,
    0.3712128287756453,
    0.3786635714740699,
    0.22951978528715314,
    0.3780582059816849,
    0.39354971960899743,
    0.38861111992144626,
    0.37134326380399385,
    0.3807112867270781,
    0.33773204539801865,
    0.32449846503456725,
    0.4001729029334497,
    0.3598410142821923,
    0.3553695625500588,
    0.3414391377461552,
    0.39044726677814057,
    0.30882008303510017,
    0.3771795929270587,
    0.3473227130931852,
    0.36307937925024625,
    0.3669802898889736
  ],
  "gppm": [
    638.0796385171891,
    617.0186411649139,
    592.9967863183989,
    625.4839116257992,
    627.3876546439961,
    630.6756200498924,
    661.853997568847,
    610.0799909800493,
    612.2627908245425,
    616.1093375360132,
    627.7924629025545,
    676.7014373359101,
    606.4275161147426,
    622.6264089610796,
    621.1722582256403,
    613.732811146696,
    627.459237530902,
    637.29948596776,
    631.7781636138752,
    622.6085154809792,
    633.3061270979231,
    653.3892354122262,
    634.9076195018182,
    616.5442159121321,
    645.0128509954994,
    622.1663488283959,
    638.6731937555666,
    640.4924825596376,
    631.0522385105265
  ],
  "gppm_normalized": [
    1.4769504716109394,
    1.3849958967608713,
    1.3266359462659452,
    1.4006526929361804,
    1.4049236326327847,
    1.4092324281677837,
    1.4833438972049067,
    1.3646610086483268,
    1.3668526058417125,
    1.3787349750243223,
    1.4048506256164528,
    1.5164509991134427,
    1.3605692657858899,
    1.3963997943539628,
    1.387701123125249,
    1.37739282254555,
    1.404160421535609,
    1.425442833973135,
    1.4149674222036148,
    1.3864282538589634,
    1.4124234137182248,
    1.4563063345021205,
    1.4196455738775402,
    1.370117146518958,
    1.4398282942326264,
    1.3950904554119283,
    1.4277413916441648,
    1.4388129077942389,
    1.4049281500266235
  ],
  "token_counts": [
    890,
    478,
    448,
    442,
    445,
    418,
    452,
    445,
    419,
    443,
    428,
    434,
    473,
    470,
    422,
    478,
    439,
    426,
    441,
    384,
    396,
    387,
    433,
    369,
    405,
    468,
    417,
    502,
    384,
    474,
    506,
    445,
    440,
    760,
    432,
    447,
    385,
    403,
    395,
    512,
    407,
    451,
    431,
    460,
    432,
    397,
    381,
    423,
    424,
    400,
    412,
    382,
    404,
    423,
    393,
    416,
    480,
    350,
    915,
    391,
    409,
    451,
    406,
    405,
    455,
    370,
    378,
    427,
    403,
    522,
    462,
    448,
    413,
    439,
    408,
    375,
    424,
    413,
    457,
    403,
    419,
    429,
    472,
    383,
    374,
    454,
    405,
    2538,
    455,
    400,
    445,
    409,
    417,
    434,
    451,
    466,
    401,
    419,
    388,
    402,
    463,
    411,
    449,
    464,
    375,
    398,
    458,
    399,
    499,
    348,
    466,
    428,
    383,
    352,
    501,
    355,
    957,
    556,
    414,
    421,
    711,
    446,
    549,
    400,
    474,
    425,
    417,
    545,
    467,
    418,
    439,
    416,
    407,
    483,
    419,
    485,
    407,
    447,
    409,
    389,
    441,
    349,
    389,
    441,
    400,
    582,
    504,
    431,
    471,
    477,
    481,
    474,
    472,
    456,
    402,
    422,
    361,
    467,
    465,
    480,
    475,
    423,
    417,
    438,
    472,
    382,
    345,
    403,
    454,
    464,
    449,
    395,
    435,
    487,
    735,
    467,
    433,
    388,
    384,
    430,
    381,
    444,
    427,
    420,
    429,
    395,
    434,
    422,
    442,
    435,
    437,
    405,
    391,
    423,
    370,
    402,
    416,
    425,
    405,
    359,
    400,
    416,
    394,
    657,
    523,
    436,
    419,
    474,
    390,
    480,
    426,
    428,
    404,
    410,
    529,
    440,
    402,
    391,
    498,
    406,
    448,
    479,
    502,
    416,
    388,
    440,
    448,
    427,
    397,
    451,
    445,
    376,
    414,
    412,
    416,
    442,
    410,
    414,
    440,
    404,
    432,
    343,
    419,
    544,
    416,
    447,
    415,
    396,
    390,
    354,
    411,
    419,
    383,
    374,
    379,
    418,
    348,
    421,
    448,
    422,
    374,
    695,
    444,
    457,
    470,
    451,
    421,
    487,
    408,
    443,
    385,
    446,
    534,
    403,
    397,
    389,
    359,
    422,
    369,
    489,
    402,
    372,
    387,
    401,
    466,
    437,
    374,
    409,
    411,
    327,
    755,
    383,
    457,
    399,
    413,
    459,
    551,
    467,
    449,
    422,
    434,
    467,
    444,
    444,
    376,
    444,
    417,
    432,
    477,
    391,
    419,
    369,
    378,
    450,
    409,
    480,
    439,
    393,
    384,
    583,
    456,
    425,
    387,
    417,
    449,
    425,
    437,
    393,
    420,
    374,
    404,
    454,
    426,
    423,
    398,
    409,
    381,
    520,
    456,
    379,
    385,
    394,
    407,
    396,
    372,
    374,
    470,
    402,
    563,
    419,
    486,
    424,
    424,
    414,
    471,
    416,
    473,
    441,
    439,
    666,
    500,
    434,
    456,
    490,
    381,
    408,
    499,
    418,
    402,
    406,
    404,
    441,
    453,
    425,
    410,
    399,
    391
  ],
  "response_lengths": [
    2705,
    2393,
    2714,
    2288,
    2511,
    2374,
    2774,
    2305,
    2687,
    2521,
    2545,
    3730,
    2782,
    2393,
    2553,
    2925,
    2115,
    2334,
    2977,
    2357,
    2297,
    2331,
    2350,
    2478,
    2547,
    2350,
    2357,
    2254,
    2241
  ]
}