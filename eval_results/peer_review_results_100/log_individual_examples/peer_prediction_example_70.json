{
  "example_idx": 70,
  "reference": "Published as a conference paper at ICLR 2023\n\nHIERARCHICAL RELATIONAL LEARNING FOR FEWSHOT KNOWLEDGE GRAPH COMPLETION\n\nHan Wu1, Jie Yin1, Bala Rajaratnam1,2 & Jianyuan Guo1 1The University of Sydney, 2University of California, Davis {han.wu,jie.yin,bala.rajaratnam,jguo5172}@sydney.edu.au\n\nABSTRACT\n\nKnowledge graphs (KGs) are powerful in terms of their inference abilities, but are also notorious for their incompleteness and long-tail distribution of relations. To address these challenges and expand the coverage of KGs, few-shot KG completion aims to make predictions for triplets involving novel relations when only a few training triplets are provided as reference. Previous methods have focused on designing local neighbor aggregators to learn entity-level information and/or imposing a potentially invalid sequential dependency assumption at the triplet level to learn meta relation information. However, pairwise triplet-level interactions and context-level relational information have been largely overlooked for learning meta representations of few-shot relations. In this paper, we propose a hierarchical relational learning method (HiRe) for few-shot KG completion. By jointly capturing three levels of relational information (entity-level, triplet-level and contextlevel), HiRe can effectively learn and refine meta representations of few-shot relations, and thus generalize well to new unseen relations. Extensive experiments on benchmark datasets validate the superiority of HiRe over state-of-the-art methods. The code can be found in https://github.com/alexhw15/HiRe.git.\n\n1\n\nINTRODUCTION\n\nKnowledge graphs (KGs) comprise a collection of factual triplets, (h, r, t), where each triplet expresses the relationship r between a head entity h and a tail entity t. Large-scale KGs (Vrandeˇci ́c & Kr ̈otzsch, 2014; Mitchell et al., 2018; Suchanek et al., 2007; Bollacker et al., 2008) can provide powerful inference capabilities for many intelligent applications, including question answering (Yao & Van Durme, 2014), web search (Eder, 2012) and recommendation systems (Wang et al., 2019).\n\nAs KGs are often built semi-automatically from unstructured data, real-world KGs are far from complete and suffer from the notorious long-tail problem — a considerable proportion of relations are associated with only very few triplets. As a result, the performance of current KG completion methods significantly degrades when predicting relations with a limited number (few-shot) of training triplets. To tackle this challenge, few-shot KG completion methods have been proposed including GMatching (Xiong et al., 2018), MetaR(Chen et al., 2019), FSRL(Zhang et al., 2020), FAAN (Sheng et al., 2020) and GANA (Niu et al., 2021). These methods focus on predicting the missing tail entity t for query triplets by learning from only K reference triplets about a target relation r.\n\nGiven a target relation r and K reference triplets, K-shot KG completion aims to correctly predict the tail entity t for each query triplet (h, r, ?) using the generalizable knowledge learned from reference triplets. Thus, the crucial aspect of few-shot KG completion is to learn the meta representation of each few-shot relation from a limited amount of reference triplets that can generalize to novel relations. To facilitate the learning of meta relation representations, we identify three levels of relational information (see Figure 1). (1) At the context level, each reference triplet is closely related to its wider contexts, providing crucial evidence for enriching entity and relation embeddings. (2) At the triplet level, capturing the commonality among limited reference triplets is essential for learning meta relation representations. (3) At the entity level, the learned meta relation representations should well generalize to unseen query triplets.\n\nCurrent few-shot KG methods have, however, focused on designing local neighbor aggregators to learn entity-level information, and/or imposing a sequential assumption at the triplet level to learn meta relation information (See Table 1). The potential of leveraging pairwise triplet-level interactions and context-level relational information has been largely unexplored.\n\n1\n\nPublished as a conference paper at ICLR 2023\n\nMethods\n\nGMatching MetaR FSRL FAAN GANA\n\nHiRe (ours)\n\nEntity-level Triplet-level Context-level\n\nSeq. Pair.\n\n✓ ✓\n✓ ✓\n✓\n\n✓\n\n✗ ✗\n✓ ✓\n✓\n\n✗\n\n✗ ✗\n✗ ✗\n✗\n\n✓\n\n✗ ✗\n✗ ✗\n✗\n\n✓\n\nTable 1: Summary of few-shot KG completion methods based on different levels of relational information used.\n\nFigure 1: Three levels of relational information: (a) Context-level, (b) Triplet-level, (c) Entity-level.\n\nIn this paper, we propose a Hierarchical Relational learning framework (HiRe) for few-shot KG completion. HiRe jointly models three levels of relational information (entity-level, triplet-level, and context-level) within each few-shot task as mutually reinforcing sources of information to generalize to few-shot relations. Here, ”hierarchical” references relational learning performed at three different levels of granularity. Specifically, we make the following contributions: • We propose a contrastive learning based context-level relational learning method to learn expressive entity/relation embeddings by modeling correlations between the target triplet and its true/false contexts. We argue that a triplet itself has a close relationship with its true context. Thus, we take a contrastive approach — a given triplet should be pulled close to its true context, but pushed apart from its false contexts — to learn better entity embeddings.\n\n• We propose a transformer based meta relation learner (MRL) to learn generalizable meta relation representations. Our proposed MRL is capable of capturing pairwise interactions among reference triplets, while preserving the permutation-invariance property and being insensitive to the size of the reference set.\n\n• We devise a meta representation based embedding learner named MTransD that constrains the learned meta relation representations to hold between unseen query triplets, enabling better generalization to novel relations.\n\nLastly, we adopt a model agnostic meta learning (MAML) based training strategy (Finn et al., 2017) to optimize HiRe on each meta task within a unified framework. By performing relational learning at three granular levels, HiRe offers significant advantages for extracting expressive meta relation representations and improving model generalizability for few-shot KG completion. Extensive experiments on two benchmark datasets validate the superiority of HiRe over state-of-the-art methods.\n\n2 RELATED WORK\n\n2.1 RELATIONAL LEARNING IN KNOWLEDGE GRAPHS\n\nKG completion methods utilize relational information available in KGs to learn a unified lowdimensional embedding space for the input triplets. TransE (Bordes et al., 2013) is the first to use relation r as a translation for learning an embedding space, i.e., h + r ≈ t for triplet (h, r, t). A scoring function is then used to measure the quality of the translation and to learn a unified embedding space. TransH (Wang et al., 2014) and TransR (Lin et al., 2015) further model relation-specific information for learning an embedding space. ComplEx (Trouillon et al., 2016), RotatE (Sun et al., 2019b), and ComplEx-N3 (Lacroix et al., 2018) improve the modeling of relation patterns in a vector/complex space. ConvE (Dettmers et al., 2018) and ConvKB (Nguyen et al., 2018) employ convolution operators to enhance entity/relation embedding learning. However, these methods require a large number of triplets for each relation to learn a unified embedding space. Their performance significantly degrades at few-shot settings, where only very few triplets are available for each relation.\n\n2.2 FEW-SHOT KG COMPLETION\n\nExisting few-shot KG completion methods can be grouped into two main categories: (1) Metric learning based methods: GMatching (Xiong et al., 2018) is the first work to formulate few-shot (one-shot) KG completion. GMatching consists of two parts: a neighbor encoder that aggregates one-hop neighbors of any given entity, and a matching processor that compares similarity between query and reference entity pairs. FSRL (Zhang et al., 2020) relaxes the setting to more shots and explores how to integrate the information learned from multiple reference triplets. FAAN (Sheng et al., 2020) proposes a dynamic attention mechanism for designing one-hop neighbor aggregators.\n\n2\n\nhtt...(a)(b)(c)h1tt1httcontextContext-levelrelationalinformationtripleth1tt1h2tt2hkkttkTriplet-levelrelational informationh1tt1h2tt2Entity-levelrelational information...(a)(b)(c)httcontextContext-levelrelationalinformationtripleth1tt1h2tt2hkkttkTriplet-levelrelational informationh1tt1h2tt2Entity-levelrelational informationPublished as a conference paper at ICLR 2023\n\n(2) Meta learning based methods: MetaR (Chen et al., 2019) learns to transfer relation-specific meta information, but it simply generates meta relation representations by averaging the representations of all reference triplets. GANA (Niu et al., 2021) puts more emphasis on neighboring information and accordingly proposes a gated and attentive neighbor aggregator.\n\nDespite excellent empirical performance, the aforementioned methods suffer from two major limitations. First, they focus on designing local neighbor aggregators to learn entity-level information. Second, they impose a potentially invalid sequential dependency assumption and utilize recurrent processors (i.e., LSTMs (Hochreiter & Schmidhuber, 1996)) to learn meta relation representations. Thus, current methods fail to capture pairwise triplet-level interactions and context-level relational information. Our work is proposed to fill this important research gap in the literature.\n\n2.3 CONTRASTIVE LEARNING ON GRAPHS\n\nAs a self-supervised learning scheme, contrastive learning follows the instance discrimination principle that pairs instances according to whether they are derived from the same instance (i.e., positive pairs) or not (i.e., negative pairs) (Hadsell et al., 2006; Dosovitskiy et al., 2014).\n\nContrastive methods have been recently proposed to learn expressive node embeddings on graphs. In general, these methods train a graph encoder that produces node embeddings and a discriminator that distinguishes similar node embedding pairs from those dissimilar ones. DGI (Velickovic et al., 2019) trains a node encoder to maximize mutual information between patch representations and high-level graph summaries. InfoGraph (Sun et al., 2019a) contrasts a global graph representation with substructure representations. (Hassani & Khasahmadi, 2020) propose to contrast encodings from one-hop neighbors and a graph diffusion. GCC (Qiu et al., 2020) is a pre-training framework that leverages contrastive learning to capture structural properties across multiple networks.\n\nIn KGs, we note that positive and negative pairs naturally exist in the few-shot KG completion problem. However, the potential of contrastive learning in this task is under-explored. In our work, we adopt the idea of contrastive learning at the context level to capture correlations between a target triplet and its wider context. This enables enriching the expressiveness of entity embeddings and improving model generalization for few-shot KG completion. To the best of our knowledge, we are the first to integrate contrastive learning with KG embedding learning for few-shot KG completion.\n\n3 PROBLEM FORMULATION\n\nIn this section, we formally define the few-shot KG completion task and problem setting. The notations used in the paper can be found in Appendix A.\n\nDefinition 1 Knowledge Graph G. A knowledge graph (KG) can be denoted as G = {E, R, T P}. E and R are the entity set and the relation set, respectively. T P = {(h, r, t) ∈ E × R × E} denotes the set of all triplets in the knowledge graph.\n\nDefinition 2 Few-shot KG Completion. Given (i) a KG G = {E, R, T P}, (ii) a reference set Sr = {(hi, ti) ∈ E × E|∃r, s.t. (hi, r, ti) ∈ T P} that corresponds to a given relation r ∈ R, where |Sr| = K, and (iii) a query set Qr = {( ̃hj, r, ?)} that also corresponds to relation r, the K-shot KG completion task aims to predict the true tail entity for each triplet from Qr based on the knowledge learned from G and Sr. For each query triplet ( ̃hj, r, ?) ∈ Qr, given a set of candidates C ̃hj ,r for the missing tail entity, the goal is to rank the true tail entity highest among C ̃hj ,r.\n\nAs the definition states, few-shot KG completion is a relation-specific task. The goal of a few-shot KG completion model is to correctly make predictions for new triplets involving relation r when only a few triplets associated with r are available. Therefore, the training process is based on the unit of tasks, where each task is to predict for new triplets associated with a given relation r, denoted as Tr. Each meta training task Tr corresponds to a given relation r and is composed of a reference set Sr and a query set Qr, i.e. Tr = {Sr, Qr}:\n\nSr = {(h1, t1), (h2, t2), ..., (hK, tK)}, Qr = {( ̃h1, C ̃h1,r), ( ̃h2, C ̃h2,r), ..., ( ̃hM, C ̃hM,r)}, where M is the size of query set Qr. Mathematically, the training set can be denoted as Ttrain = {Ti}I j=1 can be similarly denoted. Note that all triplets corresponding to the relations in test set are unseen during training, i.e., Ttrain ∩ Ttest = ∅.\n\ni=1. The test set Ttest = {Tj}J\n\n(1)\n\n(2)\n\n3\n\nPublished as a conference paper at ICLR 2023\n\nFigure 2: Entity neighborhoods v.s. Triplet context. Our method jointly considers the context of the target triplet to enable the identification of crucial information, as highlighted in the right figure.\n\n4 THE PROPOSED METHOD\n\nIn this section, we present our proposed learning framework in details. As discussed earlier, we identify the research gap in K-shot KG completion, where learning only entity-level relational information and capturing sequential dependencies between reference triplets prevent the model from capturing a more stereoscopic and generalizable representation for the target relation. To fill this gap, we propose to perform three hierarchical levels of relational learning within each meta task (context-level, triplet-level and entity-level) for few-shot KG completion. An overview of our proposed hierarchical relational learning (HiRe) framework can be found in Appendix C.\n\n4.1 CONTRASTIVE LEARNING BASED CONTEXT-LEVEL RELATIONAL LEARNING\n\nGiven a reference set Sr with K training triplets, existing works (e.g., (Xiong et al., 2018; Niu et al., 2021)) seek to learn better head/tail entity embeddings by aggregating information from its respective local neighbors, and then concatenate them as triplet representation. Although treating the neighborhoods of head/tail entity separately is a common practice in homogeneous graphs, we argue that this approach is sub-optimal for few-shot KG completion due to the loss of critical information.\n\nTaking Figure 2 as an example, jointly considering the wider context shared by head/tail entity would reveal crucial information – both “Lionel Messi” and “Sergio Ag ̈uero” playFor “Argentina’s National Team” – for determining whether the relation workWith holds between the given entity pair (“Lionel Messi”, “Sergio Ag ̈uero”). Notably, our statistical analysis further affirms that the triplets on KGs indeed share a significant amount of context information (see Appendix B).\n\nMotivated by this important observation, we propose the idea of jointly considering the neighborhoods of head/tail entity as the context of a given triplet to exploit more meticulous relational information. To imbue the embedding of the target triplet with such contextual information, a contrastive loss is employed by contrasting the triplet with its true context against false ones.\n\nFormally, given a target triplet (h, r, t), we denote its wider context as C(h,r,t) = Nh ∪ Nt, where Nh = {(ri, ti)|(h, ri, ti) ∈ T P} and Nt = {(rj, tj)|(t, rj, tj) ∈ T P}. Our goal is to capture context-level relational information — the correlation between the given triplet (h, r, t) and its true context C(h,r,t). We further propose a multi-head self-attention (MSA) based context encoder, which models the interactions among the given context C(h,r,t) and assigns larger weights to more important relation-entity tuples within the context shared by head entity h and tail entity t.\n\nSpecifically, given a target triplet (h, r, t) and its context C(h,r,t), each relation-entity tuple (ri, ti) ∈ C(h,r,t) is first encoded as rei = ri ⊕ ti, where ri ∈ Rd and ti ∈ Rd are the relation and entity embedding, respectively, and ri ⊕ ti indicates the concatenation of two vectors ri and ti. An MSA block is then employed to uncover the underlying relationships within the context and generate context embedding c:\n\nc0 = [re1; re2; ..., ; reK],\n\nK = |C(h,r,t)|,\n\nc =\n\n(cid:88)K\n\ni=0\n\nα · rei,\n\nα = MSA(c0),\n\n(3)\n\n(4)\n\nwhere c0 is the concatenation of the embeddings of all relation-entity tuples and |x| is the size of set x. The self-attention scores among all relation-entity tuples from C(h,r,t) can be computed by Eq. 4. Tuples with higher correlations would be given larger weights and contribute more towards the embedding of C(h,r,t). The detailed implementation of MSA is given in Appendix D.1.\n\nAdditionally, we synthesize a group of false contexts { ̃C(h,r,t)i} by randomly corrupting the relation or entity of each relation-entity tuple (ri, ti) ∈ C(h,r,t). The embedding of each false context ̃C(h,r,t)i\n\n4\n\nLionel MessiSergio AgüeroworkWith?Paris Saint-GermainFCLuis SuárezfriendWithliveInParisFC BacelonaplayForplayForliveInBacelonaEl RubiusfriendWithArgentina’s National TeamplayForplayForaParis Saint-GermainFCLuis SuárezfriendWithliveInFC BacelonaplayForplayForliveInEl RubiusArgentina’s National TeamplayForplayForaaaaworkWith? ✔Sergio AgüeroLionel MessifriendWithaParis Saint-GermainFCLuis SuárezfriendWithliveInParisFC BacelonaplayForplayForliveInBacelonaEl RubiusArgentina’s National TeamplayForplayForaaaaworkWith? ✔Sergio AgüeroLionel MessifriendWithPublished as a conference paper at ICLR 2023\n\ncan be learned via the context encoder as ̃ci. Then, we use a contrastive loss to pull close the embedding of the target triplet with its true context and to push away from its false contexts. The contrastive loss function is defined as follows:\n\nLc = − log\n\nexp(sim(h ⊕ t, c)/τ ) i=0 exp(sim(h ⊕ t, ̃ci)/τ )\n\n(cid:80)N\n\n,\n\n(5)\n\nwhere N is the number of false contexts for (h, r, t), τ denotes the temperature parameter, h⊕t indicates the triplet embedding represented as the concatenation of its head and tail entity embeddings, sim(x, y) measures the cosine similarity between x and y. As such, we can inject context-level knowledge into entity embeddings attending to key elements within the context of the given triplet.\n\n4.2 TRANSFORMER BASED TRIPLET-LEVEL RELATIONAL LEARNING\n\nAfter obtaining the embeddings of all reference triplets, the next focus is to learn meta representation for the target relation r. State-of-the-art models (e.g., FSRL (Zhang et al., 2020) and GANA (Niu et al., 2021)) utilize LSTMs for this purpose, which inevitably imposes an unrealistic sequential dependency assumption on reference triplets since LSTMs are designed to model sequence data. However, reference triplets associated with the same relation are not sequentially dependent on each other; the occurrence of one reference triplet does not necessarily lead to other triplets in the reference set. Consequently, these LSTM based models violate two important properties. First, the model should be insensitive to the size of reference set (i.e., few-shot size K). Second, the triplets in the reference set should be permutation-invariant. To address these issues, we resort to modeling complex interactions among reference triplets for learning generalizable meta relational knowledge.\n\nTo this end, we propose a transformer based meta relation learner (MRL) that effectively models pairwise interactions among reference triplets to learn meta relation representations that generalize well to new unseen relations. There are two main considerations in our model design. (1) Reference triplets are permutation-invariant; (2) Reference triplets that are more representative should be given larger weights when learning meta relation representation. Inspired by Set Transformer (Lee et al., 2019), we design our MRL based on the idea of set attention block (SAB), which takes a set of objects as input and performs self-attention mechanism between the elements. Therefore, our proposed MRL can model pairwise triplet-triplet interactions within Sr so as to cultivate the ability to learn generalizable meta representation of the target relation.\n\nMathematically, given a meta training task Tr targeting at relation r, our proposed MRL takes the head/tail entity pairs from its reference set as input, i.e., {(hi, ti) ∈ Sr}. Each reference triplet is encoded as xi = hi ⊕ ti, where hi ∈ Rd and ti ∈ Rd are the embeddings of entity hi and tail entity ti with dimension d. Note that the same entity embeddings hi and ti are used here as in Eq. 5.\n\nFor all reference triplets associated with the same relation r, our proposed MRL aims to capture the commonality among these reference triplets and obtain the meta representation for relation r. To comprehensively incorporate triplet-level relational information in the reference set, we leverage an SAB on the embeddings of all reference triplets from Sr (see the details of SAB in Appendix D.2):\n\nX = [x0; x1; ...; xK],\n\nxi ∈ R2d,\n\n0 ≤ i ≤ K,\n\n(6)\n\nX ′ = SAB(X) ∈ RK×2d, where xi denotes the i-th reference triplet. The output of SAB has the same size of the input X, but contains pairwise triplet-triplet interactions among X. The transformed embeddings of reference triplets, X ′, are then fed into a two-layer MLP to obtain the meta representation RTr , given by\n\n(7)\n\nRTr =\n\n1 K\n\n(cid:88)K\n\ni=1\n\nMLP(X ′),\n\n(8)\n\nwhere the meta representation RTr is generated by averaging the transformed embeddings of all reference triplets. This ensures that RTr contains the fused pairwise triplet-triplet interactions among the reference set in a permutation-invariant manner.\n\n4.3 META REPRESENTATION BASED ENTITY-LEVEL RELATIONAL LEARNING\n\nA crucial aspect of few-shot KG completion is to warrant the generalizability of the learned meta representation. The learned meta representation RTr should hold between (hi, ti) if hi and ti are\n\n5\n\nPublished as a conference paper at ICLR 2023\n\nassociated with r. This motivates us to refine RTr under the constraints of true/false entity pairs. Translational models provide an intuitive solution by using the relation as a translation, enabling to explicitly model and constrain the learning of generalizable meta knowledge at the entity level. Following KG translational models (Bordes et al., 2013; Ji et al., 2015), we design a score function that accounts for the diversity of entities and relations to satisfy such constraints. Our method is referred to as MTransD that effectively captures meta translational relationships at the entity level.\n\nGiven a target relation r and its corresponding reference set Sr, after obtaining its meta representation RTr , we can now calculate a score for each entity pair (hi, ti) ∈ Sr by projecting the embeddings of head/tail entity into a latent space determined by its corresponding entities and relation simultaneously. Mathematically, the projection process and the score function can be formulated as:\n\n⊺\n\nhpi = rpih ⊺\n\ntpi = rpit\n\npihi + Im×nhi, piti + Im×nti,\n\nscore(hi, ti) = ||hpi + RTr − tpi||2,\n\n(9)\n\n(10)\n\n(11)\n\nwhere ||x||2 represents the l2 norm of vector x, hi/ti are the head/tail entity embeddings, hpi/tpi are their corresponding projection vectors. rpi is the projection vector of RTr , and Im×n is an identity matrix (Ji et al., 2015). In this way, the projection matrices of each head/tail entity are determined by both the entity itself and its associated relation. As a result, the projected tail entity embedding should be closest to the projected head entity embedding after being translated by RTr . That is to say, for these triplets associated with relation r, the corresponding meta representation RTr should hold between hpi and tpi at the entity level in the projection space. Considering the entire reference set, we can further define a loss function as follows:\n\nL(Sr) =\n\n(cid:88)\n\n(hi,ti)∈Sr\n\nmax{0, score(hi, ti) + γ − score(hi, t′\n\ni)},\n\n(12)\n\nwhere γ is a hyper-parameter that determines the margin to separate positive pairs from negative pairs. score(hi, t′ i) which results from negative sampling of the positive pair (hi, ti) ∈ Sr, i.e.(hi, r, t′ i) /∈ G. Till now, we have obtained meta relation representation RTr for each few-shot relation r, along with a loss function on the reference set.\n\ni) calculates the score of a negative pair (hi, t′\n\n4.4 MAML BASED TRAINING STRATEGY\n\nNoting that L(Sr) in Eq. 12 is task-specific and should be minimized on the target task Tr, we adopt a MAML based training strategy (Finn et al., 2017) to optimize the parameters on each task Tr. The obtained loss on reference set L(Sr) is not used to train the whole model but to update intermediate parameters. Please refer to Appendix E for the detailed training scheme of MAML. Specifically, the learned meta representation RTr can be further refined based on the gradient of L(Sr):\n\nR′\n\nTr\n\n= RTr − lr∇RTr\n\nL(Sr),\n\n(13)\n\nwhere lr indicates the learning rate. Furthermore, for each target relation Tr, the projection vectors hpi, rpi and tpi can also be optimized in the same manner of MAML so that the model can generalize and adapt to a new target relation. Following MAML, the projection vectors are updated as follows:\n\nh′ pi = hpi − lr∇hpiL(Sr), r′ pi = rpi − lr∇rpi L(Sr), t′ pi = tpi − lr∇tpi L(Sr).\n\n(14)\n\n(15)\n\n(16)\n\nWith the updated parameters, we can project and score each entity pair (hj, tj) from the query set Qr following the same scheme as reference set and obtain the entity-level loss function L(Qr):\n\n⊺\n\npj\n\npjh′ pjt′\n\nhpj = r′ tpj = r′ score(hj, tj) =∥ hpj + R′ (cid:88)\n\nhj + Im×nhj, tj + Im×ntj, − tpj ∥2, max{0, score(hj, tj) + γ − score(hj, t′\n\nTr\n\npj\n\n⊺\n\nj)},\n\nL(Qr) =\n\n(hj ,tj )∈Qr\n\n(17)\n\n(18)\n\n(19)\n\n(20)\n\nwhere (hj, t′ objective for training the whole model is to minimize L(Qr) and Lc together, given by:\n\nj) is also a negative triplet generated in the same way as (hi, t′\n\ni). The optimization\n\nwhere λ is a trade-off hyper-parameter that balances the contributions of L(Qr) and Lc.\n\n6\n\nL = L(Qr) + λLc,\n\n(21)\n\nPublished as a conference paper at ICLR 2023\n\n5 EXPERIMENTS\n\n5.1 DATASETS AND EVALUATION METRICS\n\nWe conduct experiments on two widely used few-shot KG completion datasets, Nell-One and Wiki-One, which are constructed by (Xiong et al., 2018). For fair comparison, we follow the experimental setup of GMatching (Xiong et al., 2018), where relations associated with more than 50 but less than 500 triplets are chosen for few-shot completion tasks. For each target relation, the candidate entity set provided by GMatching is used. The statistics of both datasets are provided in Table 2. We use 51/5/11 and 133/16/34 tasks for training/validation/testing on Nell-One and Wiki-One, following the common setting in the literature. We report both MRR (mean reciprocal rank) and Hits@n (n = 1, 5, 10) on both datasets for the evaluation of performance. MRR is the mean reciprocal rank of the correct entities, and Hits@n is the ratio of correct entities that rank in top n. We compare the proposed method against other baseline methods in 1-shot and 5-shot settings, which are the most common settings in the literature.\n\n181,109 4,838,244 5,859,240\n\nTable 2: Statistics of datasets.\n\nNell-One Wiki-One\n\nrespectively,\n\n# Relations\n\n# Triplets\n\n# Entities\n\n67 183\n\n358 822\n\nDataset\n\n# Tasks\n\n68,545\n\n5.2 BASELINES\n\nFor evaluation, we compare our proposed method against two groups of state-of-the-art baselines:\n\nConventional KG completion methods: TransE (Bordes et al., 2013), TransH (Wang et al., 2014), DistMult (Yang et al., 2015), ComplEx (Trouillon et al., 2016) and ComplEx-N3 (Lacroix et al., 2018). We use OpenKE (Han et al., 2018) to reproduce the results of these models with hyperparameters reported in the original papers. The models are trained using all triplets from background relations (Xiong et al., 2018) and training relations, as well as relations from all reference sets.\n\nState-of-the-art few-shot KG completion methods: GMatching (Xiong et al., 2018), MetaR (Chen et al., 2019), FAAN (Sheng et al., 2020) and FSRL (Zhang et al., 2020). For MetaR (both InTrain and Pre-Train) and FAAN, we directly report results obtained from the original papers. For GMatching, we report the results provided by (Chen et al., 2019) for both 1-shot and 5-shot. As FSRL was initially reported in different settings, where the candidate set is much smaller, we report the results re-implemented by (Sheng et al., 2020) under the same setting with other methods. Due to the fact that the reproduced results of GANA (Niu et al., 2021) is less competitive, we leave GANA out in our comparison. All reported results are produced based on the same experimental setting.\n\n5.3 EXPERIMENTAL SETUP\n\nFor fair comparison, we use the entity and relation embeddings pretrained by TransE (Bordes et al., 2013) on both datasets, released by GMatching (Xiong et al., 2018), for the initialization of our proposed HiRe. Following the literature, the embedding dimension is set to 100 and 50 for NellOne and Wiki-One, respectively. On both datasets, we set the number of SAB to 1 and each SAB contains one self-attention head. We apply drop path to avoid overfitting with a drop rate of 0.2. The maximum number of neighbors for a given entity is set to 50, the same as in prior works. For all experiments except for the sensitivity test on the trade-off parameter λ in Eq. 21, λ is set to 0.05 and the number of false contexts for each reference triplet is set to 1. The margin γ in Eq. 12 is set to 1. We apply mini-batch gradient descent to train the model with a batch size of 1, 024 for both datasets. Adam optimizer is used with a learning rate of 0.001. We evaluate HiRe on validation set every 1, 000 steps and choose the best model within 30, 000 steps based on MRR. All models are implemented by PyTorch and trained on 1 Tesla P100 GPU.\n\n5.4 COMPARISON WITH STATE-OF-THE-ART METHODS\n\nTable 3 compares HiRe against baselines on Nell-One and Wiki-One under 1-shot and 5-shot settings. In general, conventional KG completion methods are inferior to few-shot KG completion methods, especially udner 1-shot setting. This is expected because conventional KG completion methods are designed for scenarios with sufficient training data. Overall, our HiRe method outperforms all baseline methods under two settings on both datasets, which validates its efficacy for few-shot KG completion. Especially, as the number of reference triplets increases, HiRe achieves\n\n7\n\nPublished as a conference paper at ICLR 2023\n\nTable 3: Comparison against state-of-the-art methods on Nell-One and Wiki-One. MetaR-I and MetaR-P indicate the In-train and Pre-train of MetaR (Chen et al., 2019), respectively. OOM indicates out of memory.\n\nNell-One\n\nWiki-One\n\nMRR\n\nHits@10\n\nHits@5\n\nHits@1\n\nMRR\n\nHits@10\n\nHits@5\n\nHits@1\n\n1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot 1-shot 5-shot\n\n0.105 0.168 0.165 0.179 0.206\n\n0.185 0.250 0.164 -\n-\n\n0.168 0.279 0.214 0.239 0.305\n\n0.201 0.261 0.209 0.184 0.279\n\n0.226 0.233 0.285 0.299 0.335\n\n0.313 0.401 0.331 -\n-\n\n0.345 0.434 0.319 0.364 0.475\n\n0.311 0.437 0.355 0.272 0.428\n\n0.111 0.160 0.174 0.212 0.271\n\n0.260 0.336 0.238 -\n-\n\n0.186 0.317 0.246 0.253 0.399\n\n0.264 0.350 0.280 0.234 0.364\n\n0.041 0.127 0.106 0.112 0.140\n\n0.119 0.170 0.093 -\n-\n\n0.036 0.068 0.046 0.055\n\n0.042 0.090 0.082 0.047 0.177 0.162 0.035 0.134 0.140 0.176 0.030 0.124 0.205 OOM OOM OOM OOM OOM OOM OOM OOM\n\n0.059 0.133 0.087 0.100\n\n0.011 0.027 0.014 0.021\n\n0.052 0.095 0.077 0.070\n\n0.024 0.060 0.034 0.044\n\n0.057 0.092 0.078 0.063\n\n0.143 0.168 0.141 0.136 0.200\n\n0.200 0.193 0.314 -\n-\n\n- 0.221 0.323 0.158 0.341\n\n0.336 0.280 0.404 -\n-\n\n- 0.302 0.418 0.287 0.436\n\n0.272 0.233 0.375 -\n-\n\n- 0.264 0.385 0.206 0.395\n\n0.120 0.152 0.266 -\n-\n\n- 0.178 0.270 0.097 0.281\n\nMethods\n\nTransE TransH DistMult ComplEx ComplEx-N3\n\nGMatching MetaR-I MetaR-P FSRL FAAN\n\nHiRe\n\n0.288\n\n0.306\n\n0.472\n\n0.520\n\n0.403\n\n0.439\n\n0.184\n\n0.207\n\n0.322\n\n0.371\n\n0.433\n\n0.469\n\n0.383\n\n0.419\n\n0.271\n\n0.319\n\nTable 4: Ablation study of our proposed HiRe under 3-shot and 5-shot settings on Wiki-One.\n\nAblation on ↓\n\nHiRe\n\nw/o MTransD-MTransE w/o MTransD-MTransH w/o MAML w/o MRL-AVG w/o MRL-LSTM w/o Context\n\nComponents\n\n3-shot\n\n5-shot\n\nMTransD MRL Context MRR Hits@10 Hits@5 Hits@1 MRR Hits@10 Hits@5 Hits@1\n\n✓\n\n✗ ✗\n✗ ✓\n✓ ✓\n\n✓\n\n✓ ✓\n✓ ✗\n✗ ✓\n\n✓\n\n✓ ✓\n✓ ✓\n✓ ✗\n\n0.355\n\n0.467\n\n0.412\n\n0.298\n\n0.371\n\n0.469\n\n0.419\n\n0.319\n\n0.340 0.342 0.255 0.315 0.314 0.334\n\n0.433 0.456 0.375 0.430 0.409 0.449\n\n0.391 0.415 0.331 0.365 0.354 0.402\n\n0.288 0.272 0.190 0.255 0.266 0.263\n\n0.342 0.347 0.286 0.317 0.320 0.335\n\n0.454 0.457 0.388 0.433 0.436 0.470\n\n0.408 0.411 0.334 0.371 0.385 0.409\n\n0.289 0.281 0.238 0.258 0.261 0.279\n\nlarger performance gains because our transformer based MRL can capture more complex tripletlevel interactions. This further reinforces HiRe’s multi-level relational learning process in return.\n\nAs for performance gains in terms of MRR, Hits@10, Hits@5, and Hits@1, HiRe surpasses the second best performer by +3.8%, +7.1%, +6.7%, and +1.4% in 1-shot setting, and by +2.7%, +8.3%, +7.5%, and +0.7% in 5-shot setting on Nell-One. For performance gains on Wiki-One, HiRe outperforms the second best method by +0.8%, +2.9%, +0.8%, and +0.5% in 1-shot setting, and by +3.0%, +3.3%, +2.4%, and +3.8% in 5-shot setting. HiRe achieves large performance improvements in terms of all metrics, proving that leveraging hierarchical relational information enhances the model’s generalizability and leads to an overall improvement in performance.\n\n5.5 ABLATION STUDY\n\nOur proposed HiRe framework is composed of three key components. To investigate the contributions of each component to the overall performance, we conduct a thorough ablation study on both datasets under 3-shot and 5-shot settings. The detailed results on Wiki-One are reported in Table 4.\n\nw/o MTransD-MTransE and w/o MTransD-MTransH: To study the effectiveness of MTransD, we substitute MTransD with TransE and TransH respectively, retaining the MAML based training strategy. Substituting MTransD leads to performance drops at a significant level under both settings, indicating the necessity of constraining entity and relation embeddings while simultaneously considering the diversity of entities and relations.\n\nw/o MAML: To demonstrate the efficacy of MAML based training strategy, we remove MAML based training strategy from MTransD and replace it with TransD. In this ablated variant, TransD is applied on the query set after the meta relation representation is learned from the reference set. The significant performance drop suggests that MAML based training strategy is essential for the model to learn generalizable meta knowledge for predicting unseen relations in few-shot settings. This conclusion has also been affirmed by the ablation study in MetaR (Chen et al., 2019).\n\nw/o MRL-AVG: To study the impact of transformer based MRL, we replace MRL by simply averaging the embeddings of all reference triplets to generate meta relation representations. This has a profoundly negative effect, resulting in a performance drop of 4% in terms of MRR under 3-shot setting and 5.4% under 5-shot setting. The performance under 3-shot and 5-shot settings are similar, indicating that simplistic averaging fails to take advantage of more training triplets. This validates the importance of MRL to capture triplet-level interactions in learning meta relation representations.\n\nw/o MRL-LSTM: To further validate the advantages of leveraging pairwise relational information over sequential information, we replace transformer based MRL with an LSTM to generate meta\n\n8\n\nPublished as a conference paper at ICLR 2023\n\nFigure 3: Hyper-parameter sensitivity study with respect to the number of false contexts N on Wiki-One.\n\nFigure 4: The impact of different λ values in Eq. 21 on Wiki-One. λ = 0 means that we remove the contrastive learning based context-level relational learning.\n\nrelation representations. The resultant performance drop is significant; the MRR drops by 4.3% and 5.1% respectively under 3-shot and 5-shot settings. Although the use of LSTM brings some improvements over simplistic averaging through capturing triplet-level relational information, the imposed unrealistic sequential dependency assumption results in limited performance gains. This demonstrates the necessity and superiority of our proposed transformer based MRL in capturing pairwise triplet-level relational information to learn meta representations of few-shot relations. w/o Context: By ablating Lc from Eq. 21, we remove contrastive learning based context-level relational learning but retain triplet-level and entity-level relational information. As compared to jointly considering the context of the target triplet, the resultant performance drop verifies our assumption that the semantic contextual information plays a crucial role in few-shot KG completion.\n\nSimilar conclusions can also be drawn from the ablation results on Nell-One (See Appendix F).\n\n5.6 HYPER-PARAMETER SENTITIVITY\n\nWe conduct two sensitivity tests for the number of false contexts N and the trade-off parameter λ in Eq. 21 on both datasets under 1/3/5-shot settings. See Appendix G for detailed results on Nell-One.\n\nFor hyper-parameter N , we set N as 1, 2, 4, and 6. As Figure 3 shows, HiRe performs the best when N = 1 on all settings, and its performance slightly drops when N = 2. As N continues to increase, the performance of HiRe drops accordingly. One main reason is that, too many false contexts would dominate model training, causing the model to quickly converge to a sub-optimal state.\n\nFor hyper-parameter λ, since the value of contrastive loss is significantly larger than that of the margin loss, λ should be small to ensure effective supervision from the margin loss. Thus, we study the impact of different values of λ between 0 and 0.5. As Figure 4 shows, HiRe achieves the best performance when λ = 0.05. With the contrastive loss (i.e., λ > 0), HiRe consistently yields better performance, proving the efficacy of our contrastive learning based context-level relational learning.\n\n6 CONCLUSION\n\nThis paper presents a hierarchical relational learning framework (HiRe) for few-shot KG completion. We investigate the limitations of current few-shot KG completion methods and identify that jointly capturing three levels of relational information is crucial for enriching entity and relation embeddings, which ultimately leads to better meta representation learning for the target relation and model generalizability. Experimental results on two commonly used benchmark datasets show that HiRe consistently outperforms current state-of-the-art methods, demonstrating its superiority and efficacy for few-shot KG completion. The ablation analysis and hyper-parameter sensitivity study verify the significance of the key components of HiRe.\n\n9\n\n1-shot3-shot5-shot3132333435363738Impact of N on MRR (Wiki-One)N=1N=2N=4N=61-shot3-shot5-shot4142434445464748Impact of N on Hit@10 (Wiki-One)N=1N=2N=4N=61-shot3-shot5-shot3637383940414243Impact of N on Hit@5 (Wiki-One)N=1N=2N=4N=61-shot3-shot5-shot252627282930313233Impact of N on Hit@1 (Wiki-One)N=1N=2N=4N=600.010.050.10.5293031323334353637Impact of on MRR (Wiki-One)1-shot3-shot5-shot00.010.050.10.540414243444546474849Impact of on Hit@10 (Wiki-One)1-shot3-shot5-shot00.010.050.10.53536373839404142Impact of on Hit@5 (Wiki-One)1-shot3-shot5-shot00.010.050.10.5242526272829303132Impact of on Hit@1 (Wiki-One)1-shot3-shot5-shotPublished as a conference paper at ICLR 2023\n\nREFERENCES\n\nJimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\n\narXiv:1607.06450, 2016. 14\n\nKurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, pp. 1247–1250, 2008. 1\n\nAntoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In NIPS, pp. 2787–2795, 2013. 2, 6, 7\n\nMingyang Chen, Wen Zhang, Wei Zhang, Qiang Chen, and Huajun Chen. Meta relational learning for few-shot link prediction in knowledge graphs. In EMNLP-IJCNLP, pp. 4217–4226, 2019. 1, 3, 7, 8\n\nTim Dettmers, Pasquale Minervini, Pontus Stenetorp, and Sebastian Riedel. Convolutional 2d\n\nknowledge graph embeddings. In AAAI, volume 32, pp. 1811–1818, 2018. 2\n\nAlexey Dosovitskiy, Jost Tobias Springenberg, Martin Riedmiller, and Thomas Brox. Discriminative unsupervised feature learning with convolutional neural networks. In NIPS, volume 27, pp. 766– 774, 2014. 3\n\nJeffrey Scott Eder. Knowledge graph based search system, June 21 2012. US Patent App.\n\n13/404,109. 1\n\nChelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation\n\nof deep networks. In ICML, pp. 1126–1135, 2017. 2, 6\n\nRaia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant\n\nmapping. In CVPR, volume 2, pp. 1735–1742, 2006. 3\n\nXu Han, Shulin Cao, Xin Lv, Yankai Lin, Zhiyuan Liu, Maosong Sun, and Juanzi Li. Openke: An\n\nopen toolkit for knowledge embedding. In EMNLP, pp. 139–144, 2018. 7\n\nKaveh Hassani and Amir Hosein Khasahmadi. Contrastive multi-view representation learning on\n\ngraphs. In ICML, pp. 4116–4126, 2020. 3\n\nSepp Hochreiter and J ̈urgen Schmidhuber. LSTM can solve hard long time lag problems. In NIPS,\n\nvolume 9, pp. 473–479, 1996. 3\n\nGuoliang Ji, Shizhu He, Liheng Xu, Kang Liu, and Jun Zhao. Knowledge graph embedding via\n\ndynamic mapping matrix. In ACL, pp. 687–696, 2015. 6\n\nTimoth ́ee Lacroix, Nicolas Usunier, and Guillaume Obozinski. Canonical tensor decomposition for\n\nknowledge base completion. In ICML, pp. 2863–2872, 2018. 2, 7\n\nJuho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee Whye Teh. Set transformer: A framework for attention-based permutation-invariant neural networks. In ICML, pp. 3744–3753, 2019. 5, 14\n\nYankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation\n\nembeddings for knowledge graph completion. In AAAI, volume 29, pp. 2181–2187, 2015. 2\n\nT. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, B. Yang, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. Never-ending learning. Communications of the ACM, 61(5):103–115, Apr 2018. ISSN 0001-0782. 1\n\nTu Dinh Nguyen, Dat Quoc Nguyen, Dinh Phung, et al. A novel embedding model for knowledge base completion based on convolutional neural network. In NAACL-HLT, pp. 327–333, 2018. 2\n\n10\n\nPublished as a conference paper at ICLR 2023\n\nGuanglin Niu, Yang Li, Chengguang Tang, Ruiying Geng, Jian Dai, Qiao Liu, Hao Wang, Jian Sun, Fei Huang, and Luo Si. Relational learning with gated and attentive neighbor aggregator for few-shot knowledge graph completion. In SIGIR, pp. 213–222, 2021. 1, 3, 4, 5, 7\n\nJiezhong Qiu, Qibin Chen, Yuxiao Dong, Jing Zhang, Hongxia Yang, Ming Ding, Kuansan Wang, and Jie Tang. Gcc: Graph contrastive coding for graph neural network pre-training. In SIGKDD, pp. 1150–1160, 2020. 3\n\nJiawei Sheng, Shu Guo, Zhenyu Chen, Juwei Yue, Lihong Wang, Tingwen Liu, and Hongbo Xu. Adaptive attentional network for few-shot knowledge graph completion. In EMNLP, pp. 1681– 1691, 2020. 1, 2, 7\n\nFabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. Yago: a core of semantic knowledge.\n\nIn WWW, pp. 697–706, 2007. 1\n\nFan-Yun Sun, Jordan Hoffman, Vikas Verma, and Jian Tang. Infograph: Unsupervised and semisupervised graph-level representation learning via mutual information maximization. In ICLR, 2019a. 3\n\nZhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. Rotate: Knowledge graph embedding\n\nby relational rotation in complex space. In ICLR, 2019b. 2\n\nTh ́eo Trouillon, Johannes Welbl, Sebastian Riedel, ́Eric Gaussier, and Guillaume Bouchard. Com-\n\nplex embeddings for simple link prediction. In ICML, pp. 2071–2080, 2016. 2, 7\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\n\nŁukasz Kaiser, and Illia Polosukhin. Attention is all you need. NeurIPS, 30, 2017. 13, 14\n\nPetar Velickovic, William Fedus, William L Hamilton, Pietro Li`o, Yoshua Bengio, and R Devon\n\nHjelm. Deep graph infomax. volume 2, pp. 4, 2019. 3\n\nDenny Vrandeˇci ́c and Markus Kr ̈otzsch. Wikidata: a free collaborative knowledgebase. Communi-\n\ncations of the ACM, 57(10):78–85, 2014. 1\n\nHongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec, Miao Zhao, Wenjie Li, and Zhongyuan Wang. Knowledge-aware graph neural networks with label smoothness regularization for recommender systems. In SIGKDD, pp. 968–977, 2019. 1\n\nZhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. Knowledge graph embedding by trans-\n\nlating on hyperplanes. In AAAI, volume 28, pp. 1112–1119, 2014. 2, 7\n\nWenhan Xiong, Mo Yu, Shiyu Chang, Xiaoxiao Guo, and William Yang Wang. One-shot relational\n\nlearning for knowledge graphs. In EMNLP, pp. 1980–1990, 2018. 1, 2, 4, 7\n\nBishan Yang, Scott Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and\n\nrelations for learning and inference in knowledge bases. In ICLR, 2015. 7\n\nXuchen Yao and Benjamin Van Durme. Information extraction over structured data: Question an-\n\nswering with freebase. In ACL, pp. 956–966, 2014. 1\n\nChuxu Zhang, Huaxiu Yao, Chao Huang, Meng Jiang, Zhenhui Li, and Nitesh V Chawla. Few-shot\n\nknowledge graph completion. In AAAI, volume 34, pp. 3041–3048, 2020. 1, 2, 5, 7\n\n11\n\nPublished as a conference paper at ICLR 2023\n\nAPPENDIX\n\nA NOTATIONS\n\nThe notations and symbols used in this paper are summarized in Table 5.\n\nTable 5: Notations and Symbols.\n\nSymbol G\n\nDescription knowledge graph\n\nE, R, T P entity, relation and triplet sets of a knowledge graph\n\nh, t r\n(h, r, t) h, r, t Tr Sr Qr\n\nC\n\n( ̃hj ,r) Ne C(h,r,t)\n\nhead entity, tail entity relation factual triplet embeddings of h, r and t few-shot task corresponding to relation r reference set corresponding to relation r query set corresponding to relation r candidate set for the potential tail entity of ( ̃hj, r, ?) set of neighboring relation-entity tuples of entity e context of triplet (h, r, t)\n\nB MOTIVATION: SHARED CONTEXT STATISTICS\n\nOne of our key motivations is that jointly considering the wider context shared by head/tail entity would reveal crucial information for learning expressive entity embeddings. To justify our motivation, we perform a statistical analysis on Nell-One and Wiki-One dataset and the results are summarized in Table 6.\n\nOverall, out of the 189,635 triplets in Nell-One dataset, up to 39,234 triplets share entities in their contexts. That means, there exists at least one entity that is connected to both the head entity and the tail entity of the given triplet. These 39,234 triplets share 117,386 entities in all, making each triplet have almost three shared entities by average. Triplets that share entities in their contexts constitute more than 20.68% and 9.2% of the total triplets, respectively. More strictly, the triplets that share relation-entity tuples in their contexts (i.e., meaning that the head and tail entity are connected to the same entity by the same relation in the context) constitute 13.77% on Nell-One and 4.6% on Wiki-One, respectively.\n\nOur analysis affirms that the triplets on KGs indeed share a significant amount of context information. Our method is thus designed to leverage such crucial information for learning more expressive entity embeddings.\n\n# Tr.\n\n# Tr. w/ shared Ent. # shared Ent.\n\nNell-One 189,635 WiKi-One 61,498\n\n39,234 5,665\n\n117,368 7,753\n\n# Tr.\n\n# Tr. w/ shared Tup. # shared Tup.\n\nNell-One 189,635 WiKi-One 61,498\n\n26,129 2,843\n\n105,113 3,817\n\n(a) Left: triplets that share relation-entity tuple (r1, e1).\n\ntriplets that share entity e1; Right:\n\n(b) Top: triplets (Tr.) that share entities (Ent.) in their contexts; Bottom: triplets (Tr.) that share (relation, entity) tuples (Tup.).\n\nTable 6: Statistical results on Nell-One and WiKi-One. We show the number of triplets that share entities or relation-entity tuples in their contexts. “Shared tuples” means that the head entity and tail entity are connected to the same entity by the same relation in the context, and “shared entities” means that the head entity and tail entity are connected to the same entity by any relation, as illustrated in the left figure. All Numbers are calculated on the training set.\n\n12\n\nh1t1e1w/ shared entity (e1)w/ shared tuple (r1, e1)r1r2h1t1e1r1r1Published as a conference paper at ICLR 2023\n\nC OVERVIEW OF THE PROPOSED HIRE FRAMEWORK\n\nFigure 5 shows an overview of our proposed hierarchical relational learning (HiRe) framework.\n\nFigure 5: An overview of HiRe framework composed of three key components. (1) Contrastive learning based context-level relational learning; (2) Transformer based triplet-level relational learning; (3) Meta representation based entity-level relational learning. Given a target relation r and its corresponding reference set Sr and query set Qr, we employ a contrastive loss Lc between the true/false contexts and the anchor triplet (take (h1, r, t1) as an example) via our proposed contrastive learning based context-level relational learning method. The meta representation of the target relation RTr is learned by our Transformer based meta relation learner (MRL), capturing pairwise triplet-level relational information. Lastly, MTransD refines the learned meta relation representation at the entity level constrained by L(Sr). The whole learning framework is optimized by a MAML based training strategy.\n\nD DETAILS: MULTI-HEAD SELF-ATTENTION AND SET ATTENTION BLOCK\n\nD.1 DETAILS OF MULTI-HEAT SELF ATTENTION\n\nFor context-level relational learning, we employ a Multi-Head Self-Attention (MSA) block (Vaswani et al., 2017) to uncover the underlying relationships within the context C(h,r,t) of a given triplet (h, r, t) and generate the context embedding c.\n\nSpecifically, take a context that contains k relation-entity tuples as an example, the context embedding is initialized as c ∈ Rk×dc (dc = 100 and dc = 200 for WiKi-One and Nell-One, respectively). This input is first transformed into three different matrices: the query matrix Q ∈ Rk×dv , the key matrix K ∈ Rk×dk and the value matrix V ∈ Rk×dv with dimension dq=dk=dv=dc. Subsequently, the attention function is calculated as follows:\n\n• Step 1: Compute the scores between different input matrices as S = Q · K⊤;\n\n• Step 2: Normalize the scores for the stability of gradient as Sn = S/\n\ndk;\n\n√\n\n• Step 3: Translate the scores into probabilities with softmax function A = softmax(Sn);\n\n• Step 4: Obtain the weighted value matrix C = A · V\n\nThe above process can be unified into a single function:\n\nAttention(Q, K, V) = softmax(\n\nQ · K⊤ dk\n\n√\n\n) · V.\n\n(22)\n\nThe logic behind Eq. 22 is straightforward. Step 1 computes a score between each pair of different relation-entity tuples from the context. Step 2 normalizes the scores to enhance gradient stability for improved training, and Step 3 translates the scores into probabilities. Finally, each relation-entity\n\n13\n\nContext-level relational learningSSrrRTTrrLLccMTransDLSSrrAvg...rrh1tt1Transformer-based MRLrrh2tt2rrhkkttkkSSrrLSSrrRTTrr∇∇RTTrrLSSrrR′TTrr=QQrrLLQQrrMTransDTransformer-basedMRLgradientMAML-based Training StrategyRTTrr-∇∇RTTrrLSSrrMTransD’ (updated)entityrelationentity within contextcorrupted entitycorrupted relationfeature embeddingPublished as a conference paper at ICLR 2023\n\ntuple is updated by the weighted sum based on the probabilities. Overall, Eq. 3 and Eq. 4 in the main paper can be re-formulated as:\n\nc = Attention(c0) = Attention(Q, K, V) = A · V = softmax(\n\nQ · K⊤ dk\n\n√\n\n) · V,\n\n(23)\n\nwhere A = [α1; α2; ..., ; αk]. Instead of performing a single attention function with dc-dimensional queries, keys and values, it would be beneficial to linearly project the queries, keys and values h times with different linear projections (called “multi-head”) (Vaswani et al., 2017). On each of these projected versions of queries, keys and values, the attention function is executed in parallel.\n\nMultiHead(Q, K, V) = Concat(head1, ..., headh)WO,\n\nwhere headi = Attention(QWQ\n\ni , KWK\n\ni , VWV\n\ni ),\n\n(24)\n\n(25)\n\nwhere the projections are parameter matrices WQ i ∈ Rd×dk , WK WO ∈ Rhdv×d. In each paralleled attention layer, dk = dv = d/h.\n\ni ∈ Rd×dk , WV\n\ni ∈ Rd×dk and\n\nD.2 DETAILS OF SET ATTENTION BLOCK\n\nTo comprehensively incorporate triplet-level relational information in the reference set Sr, we design a transformer based MRL using a set attention block (SAB) (Lee et al., 2019) to model interactions among all reference triplets in Sr.\n\nSAB is built upon multi-head attention, defined as:\n\nSAB(X) := LayerNorm(H + rFF(H))\n\n(26)\n\nwhere H = LayerNorm(X + MultiHead(X, X, X)), rFF is any row-wise feedforward layer and LayerNorm is layer normalization (Ba et al., 2016).\n\nE MAML BASED TRAINING STRATEGY\n\nThe detailed MAML based training framework can be described as follows:\n\nAlgorithm 1: MAML based training framework of HiRe. Input: Ttrain: Training tasks Gb: Background graph\n\n1 while not converged do\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\nSample a task Tr = {Sr, Qr} from Ttrain; Construct context C(h,r,t) for each reference triplet (h, r, t) in Sr based on Gb; Encode C(h,r,t) and produce context embedding c by Eq. 3-Eq. 4; Learn context-level relational information based on contrastive learning by Eq. 5; Learn triplet-level meta representation for relation r via transformer based MRL by\n\nEq. 6-Eq. 8;\n\nLearn entity-level relational information via MTransD by Eq. 9-Eq. 11; Calculate the loss on reference set L(Sr) by Eq. 12; Update the parameters based on L(Sr) by Eq. 13-Eq. 16; Calculate the loss on query set L(Qr) by Eq. 17-Eq. 20; Update the model parameters based on the overall loss function Eq. 21\n\nF ABLATION STUDY ON NELL-ONE\n\nAs discussed in Section 5.5, each component in our proposed HiRe framework plays an important role in few-shot KG completion. Here, we provide further ablation results on Nell-One in Table 7. These results support our findings reported in the main paper and confirm that the removal of any component leads to performance drops in terms of all evaluation metrics.\n\n14\n\nPublished as a conference paper at ICLR 2023\n\nTable 7: Ablation study of HiRe under 3-shot and 5-shot settings on Nell-One.\n\nAblation on ↓\n\nHiRe\n\nw/o MTransD-MTransE w/o MTransD-MTransH w/o MAML w/o MRL-AVG w/o MRL-LSTM w/o Context\n\nComponents\n\n3-shot\n\n5-shot\n\nMTransD MRL Context MRR Hits@10 Hits@5 Hits@1 MRR Hits@10 Hits@5 Hits@1\n\n✓\n\n✗ ✗\n✗ ✓\n✓ ✓\n\n✓\n\n✓ ✓\n✓ ✗\n✗ ✓\n\n✓\n\n✓ ✓\n✓ ✓\n✓ ✗\n\n0.300\n\n0.499\n\n0.425\n\n0.199\n\n0.306\n\n0.520\n\n0.439\n\n0.207\n\n0.295 0.293 0.177 0.282 0.280 0.290\n\n0.491 0.494 0.305 0.467 0.490 0.482\n\n0.420 0.418 0.251 0.382 0.410 0.401\n\n0.193 0.191 0.105 0.185 0.168 0.186\n\n0.302 0.303 0.198 0.286 0.285 0.295\n\n0.515 0.513 0.334 0.466 0.459 0.489\n\n0.428 0.430 0.271 0.394 0.390 0.418\n\n0.202 0.203 0.123 0.188 0.185 0.197\n\nG HYPER-PARAMETER SENSITIVITY STUDY ON NELL-ONE\n\nFigure 6 and Figure 7 report further sensitivity test results on Nell-One for the number of false contexts N and the trade-off parameter λ. As shown in Figure 6, as the number of false contexts increases, the performance of HiRe drops slightly because its model training would converge to a sub-optimal state. Moreover, the best λ value is also 0.05 on Nell-One, as shown in Figure 7. The overall findings are consistent with those we draw from the results on Wiki-One in Section 5.6.\n\nFigure 6: Hyper-parameter sensitivity study with respect to the number of false contexts on Nell-One.\n\nFigure 7: The impact of different λ values in Eq. 21 on Nell-One. λ = 0 means that we remove the contrastive learning based context-level relational learning.\n\nH COMPLEXITY ANALYSIS\n\nTable 8: Complexity analysis of three hierarchical relational learning modules with respect to the number of parameters and the number of multiplication operations in each epoch.\n\nTable 8 lists the complexity of all the hierarchical relational learning modules, where d denotes the dimension of entity embeddings, k denotes the number of relation-entity tuples in the context, and n denotes the number of reference triplets in each task. As can be seen, our proposed HiRe quadratically scales with the number of reference triplets in each task. Nevertheless, given the number of reference triplets is often very small (i.e., 1, 3, 5) , our proposed HiRe framework scales reasonably well.\n\nO(nkd2 + nk2d) O(nd2 + n2d) O(d)\n\nO(nkd + nk2 + n2) O(nkd2 + nk2d + n2d)\n\nO(nkd + nk2) O(nd + n2) O(d)\n\nContext level Triplet level Entity level\n\n# Parameters\n\n# Operations\n\nTotal\n\n15\n\n1-shot3-shot5-shot262728293031Impact of N on MRR (Nell-One)N=1N=2N=4N=61-shot3-shot5-shot424446485052Impact of N on Hit@10 (Nell-One)N=1N=2N=4N=61-shot3-shot5-shot36373839404142434445Impact of N on Hit@5 (Nell-One)N=1N=2N=4N=61-shot3-shot5-shot161718192021Impact of N on Hit@1 (Nell-One)N=1N=2N=4N=600.010.050.10.5262728293031Impact of on MRR (Nell-One)1-shot3-shot5-shot00.010.050.10.54546474849505152Impact of on Hit@10 (Nell-One)1-shot3-shot5-shot00.010.050.10.53738394041424344Impact of on Hit@5 (Nell-One)1-shot3-shot5-shot00.010.050.10.5161718192021Impact of on Hit@1 (Nell-One)1-shot3-shot5-shot",
  "translations": [
    "# Summary Of The Paper\n\nThe paper proposes novel methods for few-shot KG completion. They identify two issues with existing methods for this task -- (a) They learn entity-level information from local nbr aggregators. (the paper jointly takes into account the nbr of head and tail entity for triple context) (b) They learn relation-level information using a sequential model (while the sequentiality assumption is invalid -- the paper use transformers instead). The authors proposed HiRe, which takes into account triplet-level interactions, context-level interactions, and entity-level information for query (h,r,?). MAML based training strategy used to train the model. The model shows improved performance on 2 benchmark datasets - Nell-One and Wiki-One. The ablation study demonstrates the importance of the key components of the model, where transformer-based MRL outshined.\n\n# Strength And Weaknesses\n\nThe paper address an important problem in KBC. It identifies valid issues in existing methods. However:\n1. Paper writing can be improved. Certain sections are hard to understand (especially sections 4.2/4.3/4.4). Since these sections form the core of the paper it is imperative to write them very clearly. \nAdding details of MAML training startegy, MSA and SAB in appendix should be helpful.\n2. \\bigoplus used before definition\n3. Some comments on the scalability of the model will be insightful.\n4. Why did the authors not look at (?, r, t_j) queries along with (h_j, r, ?) and report the mean (the standard way of evaluation in KBC).\n5. Definition 2: Consider adding an \\exist r.\n6. Some understanding of how the models perform on conventional KG completion datasets (where relations are associated with many more triples) is also important.\n7. Authors should use a more competitive version of ComplEx (ComplEx-N3) for comparison. (See Lacroix, Timothée, Nicolas Usunier, and Guillaume Obozinski. \"Canonical tensor decomposition for knowledge base completion.\" International Conference on Machine Learning. PMLR, 2018.)\nAlso why did the authors choose a translation model (sec 4.3) in place of more competitive KBC models like ComplEx?\n\n# Clarity, Quality, Novelty And Reproducibility\n\n1. It is imperative to share the code of the model, to be able to reproduce the results.\n2. The paper identifies valid gaps/issues in previous techniques and provides sensical first steps to address them.\n3. Further see answer to Q2\n\n# Summary Of The Review\n\nI feel the paper has interesting contribution but I believe the quality of paper writing needs to be improved.\n\n# Correctness\n\n3: Some of the paper’s claims have minor issues. A few statements are not well-supported, or require small changes to be made correct.\n\n# Technical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.\n\n# Empirical Novelty And Significance\n\n3: The contributions are significant and somewhat new. Aspects of the contributions exist in prior work.",
    "# Summary Of The Paper\nThe paper proposes a novel method called Hierarchical Relational Learning (HiRe) for few-shot knowledge graph (KG) completion, addressing the challenges of incompleteness and long-tail distributions of relations. HiRe captures relational information across three levels: context-level, triplet-level, and entity-level, allowing it to learn robust meta representations from limited training data. The methodology incorporates contrastive learning, a transformer-based meta relation learner, and a model-agnostic meta-learning training strategy to enhance performance. Experimental results demonstrate that HiRe significantly outperforms existing state-of-the-art methods on benchmark datasets, showcasing the importance of context in improving few-shot learning outcomes.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its comprehensive approach to leveraging multiple levels of relational information, which is a significant advancement over existing methods that primarily focus on local neighbor aggregators or sequential dependencies. The experimental results are robust, with consistent performance improvements across different datasets and settings. However, the paper could benefit from a more thorough discussion of the limitations and potential biases in the datasets used, as well as a clearer articulation of how the proposed method compares with other recent advancements in the field, particularly in relation to contrastive learning.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodology. The quality of writing is high, with a logical flow that aids comprehension. The novelty is substantial, particularly in the hierarchical approach to relational learning. However, reproducibility could be enhanced by providing more detailed information on hyperparameter settings and experimental configurations, as well as making the code available for public use.\n\n# Summary Of The Review\nOverall, this paper presents a significant contribution to the field of few-shot knowledge graph completion through the innovative HiRe method. Its strong empirical results and clear methodology underscore its potential impact, though some aspects related to reproducibility and limitations need further attention.\n\n# Correctness\nRating: 5\n\n# Technical Novelty And Significance\nRating: 4\n\n# Empirical Novelty And Significance\nRating: 5",
    "# Summary Of The Paper\nThe paper presents HiRe, a hierarchical relational learning framework aimed at enhancing few-shot knowledge graph (KG) completion. It addresses the challenges of incompleteness and long-tail distribution of relations in KGs by capturing three levels of relational information: entity-level, triplet-level, and context-level. The methodology includes context-level relational learning using contrastive learning, triplet-level interactions through a transformer-based Meta Relation Learner (MRL), and entity-level constraints with a score function, all optimized via a Model-Agnostic Meta-Learning (MAML) approach. The findings demonstrate that HiRe significantly outperforms baseline methods across benchmark datasets (Nell-One and Wiki-One), highlighting its effectiveness in 1-shot and 5-shot settings.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its comprehensive approach to integrating multiple levels of relational learning, which is well-supported by strong empirical results that demonstrate HiRe's superiority over conventional and state-of-the-art methods. The inclusion of ablation studies and hyper-parameter sensitivity analyses further bolsters the rigor of the findings. However, the model's complexity poses scalability challenges, particularly as the number of reference triplets increases. Additionally, the reliance on the quality of underlying KG data may limit the generalizability of the model to diverse real-world scenarios, and the paper does not explore its performance on more complex KGs.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodologies, making it accessible to the reader. The quality of the experimental design is high, with thorough comparisons to baseline methods and careful consideration of performance metrics. The novelty of the hierarchical approach to relational learning is evident, and the reproducibility is supported by the detailed descriptions of datasets, evaluation metrics, and experimental setups. However, the limitations regarding scalability and generalizability should be addressed in future work to enhance the overall robustness of the findings.\n\n# Summary Of The Review\nHiRe offers a promising advancement in few-shot knowledge graph completion through a novel framework that captures hierarchical relational information. While the empirical results are impressive, the model's scalability and adaptability to more complex KGs warrant further investigation. Overall, the paper makes a significant contribution to the field.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach, Hierarchical Relational Learning (HiRe), for few-shot knowledge graph (KG) completion. It addresses the limitations of existing methods that primarily focus on local neighbor aggregators and sequential dependencies by incorporating three levels of relational information: entity-level, triplet-level, and context-level. The proposed methodology employs a contrastive learning framework for context-level learning, a transformer-based meta relation learner for triplet-level interactions, and a MAML-based training strategy. The experimental results demonstrate that HiRe significantly outperforms conventional KG completion methods and state-of-the-art few-shot approaches across multiple metrics, highlighting its generalization capabilities to new relations.\n\n# Strength And Weaknesses\nThe strengths of this paper lie in its comprehensive approach to integrating hierarchical relational information, which is a notable advancement in few-shot KG completion. The methodology is well-structured, with clear definitions and a robust training strategy that leverages MAML for optimization. Additionally, the extensive experiments conducted on multiple datasets provide strong empirical support for the claims made. However, the paper could benefit from a more detailed discussion on the computational complexity and scalability of the proposed method, as well as potential limitations in real-world applications where data might be highly noisy or incomplete.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written, with a logical flow that guides the reader through the motivation, methodology, and results. The quality of the writing is high, with well-defined sections and appropriate use of mathematical formulations. The novelty of the approach is significant, as it introduces a hierarchical framework that captures relational information at multiple levels, which has not been adequately addressed in prior works. Reproducibility is supported by detailed descriptions of the experimental setup and baselines, although providing access to code and datasets would further enhance this aspect.\n\n# Summary Of The Review\nOverall, the paper presents a compelling contribution to the field of few-shot knowledge graph completion through the introduction of the HiRe framework. Its innovative approach and strong empirical results make it a valuable addition to the literature, though further exploration of its practical applicability is warranted.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel hierarchical relational learning method (HiRe) that captures relational information at three levels: entity-level, triplet-level, and context-level. The methodology employs contrastive learning to enhance context-level learning and utilizes a transformer-based meta relation learner (MRL) to improve generalization through pairwise interactions among reference triplets. Extensive experiments on benchmark datasets demonstrate the superiority of HiRe over existing state-of-the-art methods in few-shot knowledge graph completion tasks, with significant improvements in performance metrics such as Mean Reciprocal Rank (MRR) and Hits@N.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to relational learning and the comprehensive experimental validation performed, which underscores the effectiveness of HiRe compared to traditional methods. The use of ablation studies adds clarity to the contributions of individual components, reinforcing the paper's claims. However, the complexity of integrating multiple levels of relational information may lead to increased computational costs. Additionally, the reliance on contrastive learning introduces challenges in hyperparameter tuning, and the transformer architecture could limit real-time applicability. While the results are promising, the paper would benefit from more diverse datasets to validate the robustness of the proposed method.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and articulates its contributions clearly, providing a solid foundation for understanding the proposed methodology. The quality of the experimental validation is high, with extensive testing on benchmark datasets. However, some limitations in reproducibility arise from the lack of detailed computational resource specifications, which could impact the replicability of results across different setups. Overall, the novelty of HiRe is significant, and the open-source availability of the code further encourages reproducibility and future research.\n\n# Summary Of The Review\nThe paper presents a substantial advancement in relational learning through the HiRe framework, showcasing its effectiveness in few-shot knowledge graph completion tasks. While it demonstrates clear contributions and innovative methodologies, certain limitations regarding computational efficiency and reproducibility warrant consideration. Overall, the paper makes a valuable contribution to the field.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to few-shot knowledge graph (KG) completion through a framework termed Hierarchical Relational Learning (HiRe). The authors tackle the challenge of predicting triplets with novel relations using minimal training examples by emphasizing joint learning across multiple granularities of relational information. The HiRe framework incorporates context-level learning via contrastive methods, triplet-level interaction modeling with a transformer-based module, and entity-level representation refinement through meta-learning strategies. Experimental results on benchmark datasets, Nell-One and Wiki-One, demonstrate that HiRe outperforms existing state-of-the-art methods in both 1-shot and 5-shot settings, confirming its effectiveness.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its innovative hierarchical approach that effectively integrates different levels of relational information, which enhances the model's ability to generalize from few examples. The contrastive learning method at the context level is a significant advancement that improves the expressiveness of entity embeddings. Additionally, the comprehensive experimental validation reinforces the framework's robustness. However, a notable weakness is the scalability concern when increasing the number of reference triplets, which may limit practical applications. Furthermore, while the authors acknowledge hyperparameter sensitivity, the exploration of this aspect could be more detailed.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written and well-structured, making it accessible for readers with a background in knowledge graphs and machine learning. The quality of the methodology is high, with a thorough explanation of each component within the HiRe framework. The novelty is significant, introducing a fresh perspective on few-shot learning in KGs. The reproducibility of the results could be improved by providing more detailed descriptions of experimental setups, datasets, and hyperparameter settings.\n\n# Summary Of The Review\nOverall, the paper presents a compelling advancement in few-shot knowledge graph completion through the HiRe framework. It effectively integrates hierarchical relational learning with contrastive methods and transformer-based interaction, demonstrating strong empirical results. However, some scalability and hyperparameter exploration issues remain to be addressed.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to adversarial training in deep learning, introducing a Hierarchical Adversarial Learning framework (HiAd) aimed at improving the robustness of neural networks against adversarial attacks. The methodology involves three levels of adversarial learning: input-level, model-level, and context-level, each designed to capture different aspects of adversarial information. Additionally, the authors propose a contrastive learning strategy to better differentiate between true and false adversarial contexts, and employ a transformer-based architecture to model complex interactions among adversarial examples. Extensive experiments on benchmark datasets demonstrate that HiAd outperforms existing state-of-the-art adversarial training methods, particularly in robustness against unseen attacks.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its comprehensive approach to adversarial training through the introduction of multi-level adversarial learning, which effectively addresses previously overlooked interactions in adversarial scenarios. The inclusion of a contrastive loss function enhances the model's ability to generalize, which is a critical aspect of robustness. However, the paper could have benefitted from a more detailed discussion on the computational overhead introduced by the hierarchical approach and the transformer-based architecture, which may impact practical implementations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulated, with a logical flow that guides the reader through the proposed framework and its components. The quality of the writing is high, making complex concepts accessible. The novelty of the hierarchical approach and the integration of contrastive learning are significant contributions to the field. However, the reproducibility of the results could be enhanced by providing more details on hyperparameter settings and implementation specifics, as well as making the code publicly available.\n\n# Summary Of The Review\nOverall, the paper makes a substantial contribution to the field of adversarial training through its innovative hierarchical framework and rigorous empirical validation. The findings suggest a promising direction for enhancing model robustness, though further attention to implementation details would strengthen the work.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces HiRe, a novel framework for few-shot knowledge graph (KG) completion that claims to achieve exceptional accuracy and generalization. Its main contributions include a contrastive learning-based approach for context-level relational learning, a transformer-based meta relation learner for capturing complex interactions, and a meta representation-based entity-level relational learning methodology. Additionally, it proposes a novel MAML-based training strategy aimed at enhancing generalization to unseen relations. The results indicate that HiRe significantly outperforms state-of-the-art methods across various metrics, and ablation studies emphasize the critical role of each component within the framework.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its ambitious approach to few-shot knowledge graph completion, with innovative methodologies that leverage contrastive learning and transformer architectures. The empirical results, which demonstrate substantial performance gains over existing methods, further bolster the paper's claims. However, the paper also has notable weaknesses, particularly in its potential exaggeration of its contributions. The assertion that previous methods are fundamentally flawed without HiRe's innovations may not be fully substantiated, and the framework's high sensitivity to hyper-parameter tuning raises questions regarding its practical applicability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and articulates its contributions clearly, but some claims regarding the obsolescence of prior methods lack rigorous comparative analysis. The novelty of the proposed methods is significant, particularly in the context of few-shot learning, though the extent of their impact on the broader field is not entirely clear. While the authors present thorough empirical validation, the sensitivity to hyper-parameter tuning could pose challenges for reproducibility in diverse settings, as adaptability may not be straightforward.\n\n# Summary Of The Review\nOverall, the paper presents HiRe as a transformative advancement in few-shot knowledge graph completion, with promising methodologies and substantial empirical results. However, the claims made about the framework's superiority over existing approaches and the implications of its sensitivity to hyper-parameters warrant cautious interpretation.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper titled \"Hierarchical Relational Learning for Few-shot Knowledge Graph Completion\" by Han Wu et al. tackles the problem of knowledge graph incompleteness, especially in scenarios involving long-tail distributions of relations. The authors introduce a novel framework called Hierarchical Relational Learning (HiRe), which effectively integrates entity-level, triplet-level, and context-level relational information to enhance predictions for unseen relations. Key contributions include a contrastive learning-based method for context-level learning, a transformer-based meta relation learner (MRL), and a meta representation-based entity-level learning approach using MTransD. The experimental results demonstrate that HiRe significantly outperforms state-of-the-art methods on benchmark datasets Nell-One and Wiki-One, showcasing improvements in various metrics.\n\n# Strength And Weaknesses\nThe paper's strengths lie in its innovative approach to integrating multiple levels of relational learning, which enhances the model's ability to generalize to unseen relations. The experimental validation is robust, with significant performance improvements reported across multiple metrics, supported by a thorough ablation study that underscores the importance of individual components such as MTransD and MAML. However, the paper could benefit from a more detailed discussion on the scalability of the proposed method and its performance on more diverse datasets beyond the ones tested. Additionally, the hyper-parameter sensitivity analysis, while informative, could be expanded to examine a broader range of configurations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly articulates its contributions and methodology. The quality of the writing is high, with a logical flow that guides the reader through complex concepts. The novelty of the proposed approach is evident, particularly in the integration of hierarchical relational learning components. The reproducibility of the results appears strong, with comprehensive descriptions of the methods and metrics used, although the inclusion of code and datasets would further enhance this aspect.\n\n# Summary Of The Review\nOverall, this paper presents a significant advancement in the field of few-shot knowledge graph completion through its innovative HiRe framework. The empirical results validate the effectiveness of the proposed method, although further exploration into scalability and a broader dataset evaluation would be beneficial.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper introduces a novel approach to few-shot knowledge graph (KG) completion through a hierarchical relational learning framework, which aims to capture context-level, triplet-level, and entity-level information. The methodology employs contrastive learning to enhance entity embeddings by leveraging true and false contexts, combined with a meta-learning strategy using Model-Agnostic Meta-Learning (MAML). The findings suggest that the proposed method outperforms existing techniques on benchmark datasets, demonstrating improved generalization to unseen relations.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative integration of hierarchical relational information and the use of contrastive learning, which are promising avenues for enhancing KG completion. However, several weaknesses are noted: the necessity of the hierarchical structure is questionable, as simpler methods could potentially yield similar results. The effectiveness of the contrastive learning approach remains inadequately validated, particularly concerning the utility of negative samples. Additionally, the reliance on pre-trained embeddings raises concerns about the initial quality impacting model performance. The assumption that contextual information is universally shared across triplets requires empirical validation, and the sensitivity of hyper-parameters may limit the model's adaptability.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-organized and presents its contributions clearly, although some assumptions require more thorough justification and empirical support. The novelty is evident in the proposed hierarchical framework and the use of MAML; however, the exploration of alternative learning strategies is limited. Reproducibility may be a concern due to the reliance on pre-trained embeddings and the specificity of hyper-parameter choices that may vary across datasets.\n\n# Summary Of The Review\nWhile the paper presents a compelling framework for few-shot KG completion, it is hampered by unaddressed assumptions and a lack of empirical validation for some of its core claims. The findings are interesting, yet there is room for improvement in the robustness and generalizability of the proposed methodology.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel approach for few-shot knowledge graph (KG) completion known as Hierarchical Relational Learning (HiRe). The proposed methodology effectively leverages multi-level relational information by incorporating context-level, triplet-level, and entity-level learning strategies, optimized through a model-agnostic meta-learning (MAML) framework. Extensive empirical evaluation on benchmark datasets, Nell-One and Wiki-One, demonstrates that HiRe outperforms existing state-of-the-art methods, particularly in 1-shot and 5-shot completion tasks.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its comprehensive approach to capturing relational information at multiple levels, addressing a significant gap in existing few-shot KG completion methods. The use of a transformer-based meta relation learner and contrastive learning is innovative, contributing to the method's effectiveness. However, the paper could benefit from a clearer explanation of the implementation details of each component, as well as a more extensive discussion on the limitations of the proposed approach and potential avenues for future work.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a logical structure and clear explanations of the methodology and results. However, some sections could be enhanced for clarity, particularly the descriptions of the individual components within HiRe. The novelty of the approach is significant, as it combines previously underexplored aspects of relational learning. The reproducibility of the results could be improved by providing more detailed information on the experimental setup and hyperparameter tuning.\n\n# Summary Of The Review\nOverall, the paper presents a compelling and innovative method for few-shot KG completion, demonstrating clear empirical advantages over existing techniques. While the contributions are noteworthy, the clarity of some methodological details and discussions on limitations could be improved to enhance the overall quality of the paper.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper introduces a novel framework for enhancing the robustness of deep learning models against adversarial attacks. The authors propose a multi-step training approach that combines data augmentation with an adversarial training strategy, providing a comprehensive methodology that aims to improve model resilience. The experimental results demonstrate significant performance gains over baseline models on standard datasets, showcasing the effectiveness of the proposed method in mitigating the effects of adversarial perturbations.\n\n# Strength And Weaknesses\n**Strengths:**\n- **Innovative Approach:** The combination of data augmentation and adversarial training represents a novel methodology that stands out from traditional techniques.\n- **Strong Motivation:** The authors articulate a clear rationale for addressing adversarial robustness, highlighting its relevance to real-world applications and the growing concerns surrounding model vulnerability.\n- **Extensive Evaluation:** The paper includes a robust set of experiments, comparing the proposed method against several state-of-the-art benchmarks, which lends credibility to the findings.\n\n**Weaknesses:**\n- **Methodological Clarity:** Some aspects of the training process could be elaborated upon, particularly the selection criteria for data augmentation techniques and the specific adversarial examples used.\n- **Limited Comparative Discussion:** While comparisons with baseline models are made, the paper does not sufficiently contextualize these results against the latest advancements in adversarial robustness.\n- **Generalizability Concerns:** The results are primarily based on specific datasets, and further discussion on how the method performs across diverse datasets would strengthen the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written, with a logical structure that facilitates understanding. However, certain sections would benefit from more detailed explanations, particularly regarding the implementation and theoretical foundations of the proposed approach. The novelty of the method is commendable, yet clearer articulation of its distinct features compared to existing methods would enhance its impact. While the experimental results are reproducible, additional details on the training setup and hyperparameter tuning would provide further assurance.\n\n# Summary Of The Review\nOverall, the paper presents a promising approach to improving adversarial robustness in deep learning models, with significant contributions to the field. While the methodology is innovative and well-evaluated, enhancements in clarity and comparative analysis would strengthen the paper’s impact and applicability.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents HiRe, a novel hierarchical relational learning framework designed to enhance few-shot knowledge graph (KG) completion. HiRe captures three levels of relational information—entity-level, triplet-level, and context-level—to improve meta representation learning for predicting novel triplets with limited training data. The experimental results demonstrate that HiRe outperforms state-of-the-art methods on benchmark datasets, showcasing its effectiveness in enriching embeddings and enhancing generalization capabilities in few-shot scenarios.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its comprehensive approach to capturing multiple levels of relational information, which addresses significant gaps in existing methods that primarily focus on local neighbor aggregators or triplet-level dependencies. The integration of context-level information is particularly noteworthy, as it provides a broader understanding of relations. However, the paper could benefit from a more thorough discussion of the limitations of the proposed approach and potential areas for future work, such as its scalability in larger KGs or variations in relation distributions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and clearly presents its methodology and findings. The writing quality is high, with clear definitions and explanations of the proposed framework. The novelty of the hierarchical approach to relational learning is significant, as it provides a new perspective on few-shot KG completion. The reproducibility of the results is supported by the benchmarks used, although additional details on hyperparameter tuning and implementation specifics would enhance clarity for practitioners.\n\n# Summary Of The Review\nOverall, HiRe provides a valuable contribution to the field of few-shot knowledge graph completion through its innovative hierarchical approach to relational learning. The results indicate significant improvements over existing methods, although further exploration of the framework's scalability and limitations would strengthen the paper.\n\n# Correctness\nRating: 5\n\n# Technical Novelty And Significance\nRating: 5\n\n# Empirical Novelty And Significance\nRating: 4",
    "# Summary Of The Paper\nThe paper titled \"Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion\" by Han Wu et al. addresses the challenge of knowledge graph (KG) incompleteness, particularly in the context of few-shot learning. The authors propose the Hierarchical Relational Learning (HiRe) framework, which integrates context-level, triplet-level, and entity-level relational learning to enhance meta representation learning from limited reference triplets. The methodology employs contrastive learning for context-level enhancements, a transformer-based approach for triplet interactions, and an innovative MTransD model for entity-level representation. Experimental results on the Nell-One and Wiki-One datasets demonstrate that HiRe surpasses existing state-of-the-art methods in few-shot KG completion, validating its effectiveness.\n\n# Strength And Weaknesses\nThe paper presents several strengths, including a well-structured framework that captures multi-level relational information, which addresses the identified gaps in existing literature. The incorporation of contrastive learning and transformer-based methods is a notable advancement, providing a robust approach to few-shot learning in KGs. The experimental validation is comprehensive, with a rigorous ablation study supporting the significance of each component of the HiRe framework. However, the paper could benefit from a more detailed discussion on the computational complexity of the proposed methods and their scalability to larger datasets or real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is clearly written, with a logical flow that guides the reader through the motivation, methodology, and experimental results. The quality of the figures and tables is high, effectively illustrating the results and comparisons with baseline methods. The novelty lies in the hierarchical approach to relational learning, which combines multiple levels of interaction that have not been sufficiently addressed in previous works. The reproducibility is supported by the inclusion of sufficient methodological details, although the authors could enhance this aspect by providing code or supplementary material.\n\n# Summary Of The Review\nOverall, the paper presents a significant contribution to the field of few-shot knowledge graph completion through the innovative HiRe framework. It effectively addresses key challenges in relational learning and demonstrates substantial empirical improvements over existing methods. Minor improvements in discussing computational aspects and providing reproducibility resources could enhance the paper's impact.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper \"Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion\" introduces a novel approach called HiRe to address the challenge of completing knowledge graphs (KGs) with limited data on novel relations. The authors present a hierarchical framework that integrates three levels of relational learning: context-level, triplet-level, and entity-level. The methodology incorporates a model-agnostic meta-learning strategy (MAML) to optimize performance across these levels. Experimental results on the Nell-One and Wiki-One datasets demonstrate that HiRe outperforms existing state-of-the-art methods, highlighting its effectiveness in few-shot KG completion.\n\n# Strength And Weaknesses\nStrengths of the paper include its comprehensive approach that effectively captures different dimensions of relational information, which is a notable advancement in the field. The extensive experiments, including ablation studies and hyper-parameter sensitivity analyses, lend strong support to the claims made regarding the effectiveness of the proposed method. However, a notable weakness is the potential overemphasis on the specific components of the HiRe framework, which may limit the exploration of alternative methods or additional strategies that could be beneficial. Additionally, the paper does not sufficiently address the practical implications of the proposed method in real-world applications.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-written and presents a clear structure that facilitates understanding of the proposed methodology and findings. The quality of the writing, along with the logical flow from motivation to results, enhances its clarity. The novelty of the hierarchical approach to relational learning is significant, as it builds on existing frameworks while introducing new methodologies for few-shot learning. The reproducibility of the findings is supported by the comprehensive description of the methodology and the availability of a GitHub repository, which allows for further exploration and validation of the results.\n\n# Summary Of The Review\nThe paper provides a substantial contribution to the field of few-shot knowledge graph completion through its innovative hierarchical relational learning approach. The extensive experimental validation strengthens the claims made, although some limitations in considering broader strategies and real-world applicability are noted. Overall, the work is well-structured and presents meaningful advancements.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper presents a novel approach to few-shot knowledge graph completion through the Hierarchical Relational Learning (HiRe) framework. HiRe captures relational information across three levels—context-level, triplet-level, and entity-level—enhancing the meta representation learning for novel relations. The methodology involves a contrastive learning mechanism at the context level, a Meta Relation Learner to model pairwise interactions among triplets, and a meta representation-based embedding learning strategy. Experimental results on the Nell-One and Wiki-One datasets demonstrate that HiRe significantly outperforms existing methods, confirming its effectiveness in few-shot settings.\n\n# Strength And Weaknesses\nThe main strengths of the paper lie in its innovative multi-level approach to relational learning, which addresses limitations in previous methodologies that primarily focused on localized neighbor aggregators. The use of contrastive learning and attention mechanisms allows for a richer representation of relational contexts and interactions. However, one weakness is the computational complexity, which scales quadratically with the number of reference triplets, potentially limiting scalability in very large graphs or datasets. Additionally, while empirical results are promising, the paper could benefit from more extensive comparisons with a broader range of existing methods to further validate the robustness of HiRe.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and clearly presents the proposed methodology, making it accessible to readers familiar with the domain. The quality of the writing is high, and the mathematical formulations are detailed enough to facilitate understanding. The novelty of the hierarchical approach is significant, as it integrates multiple levels of relational learning that have not been thoroughly explored in previous work. However, the reproducibility of results may be hindered by the lack of detailed information regarding implementation specifics and hyperparameter settings.\n\n# Summary Of The Review\nOverall, the HiRe framework presents a significant advancement in few-shot knowledge graph completion by utilizing a hierarchical approach to relational learning. While the methodology is innovative and the empirical results are strong, concerns regarding scalability and reproducibility should be addressed to enhance the paper's impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n5/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper presents a novel method called HiRe, which aims to improve relational information processing in knowledge graphs through a multi-level framework that considers entity, triplet, and context information. The authors claim that their approach leverages contrastive learning and Model-Agnostic Meta-Learning (MAML) to enhance model performance. However, the findings suggest that while HiRe achieves marginal improvements on limited datasets, the contributions may not be as significant as asserted.\n\n# Strength And Weaknesses\nThe strengths of the paper include its attempt to integrate various levels of relational information, which showcases a thoughtful approach to knowledge graph representation. However, the weaknesses are pronounced: the method's complexity may lead to overfitting, and the reliance on established concepts raises concerns about its originality. Additionally, the experimental design is flawed due to limited dataset selection, insufficient baseline comparisons, and a lack of rigorous statistical analysis, undermining the robustness of the findings.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper addresses a relevant topic, the clarity suffers due to redundancy, poor organization, and formatting issues that hinder reader comprehension. The novelty of the approach appears limited, as it builds extensively on existing methodologies without introducing groundbreaking concepts. Reproducibility is questionable, given the sensitivity to hyperparameter changes and the lack of comprehensive evaluation metrics.\n\n# Summary Of The Review\nOverall, the paper presents a method that, while interesting, lacks significant novelty and robustness. The findings are derived from limited experiments and are not convincingly demonstrated, which raises questions about the method's practical applicability. Improvements in clarity, experimental rigor, and a more balanced presentation of results would enhance the paper's contribution to the field.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper presents the HiRe framework, which introduces a novel hierarchical relational learning methodology aimed at improving few-shot knowledge graph completion. HiRe operates on three levels of relational information—entity-level, triplet-level, and context-level—to enhance predictive capabilities in few-shot settings. The framework employs a transformer-based meta relation learner (MRL) and integrates a contrastive learning approach, leading to significant performance improvements across several benchmark datasets, where HiRe outperforms existing state-of-the-art methods.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to hierarchical relational learning, which captures complex relational dynamics effectively. The extensive empirical validation demonstrates the framework's robustness, with impressive performance metrics indicating its efficacy. However, potential weaknesses could include the complexity of the model, which may limit its applicability in more constrained environments or with limited computational resources. Furthermore, while the experiments are comprehensive, additional exploration of edge cases or specific scenarios could provide a deeper understanding of the model's limitations.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its methodology clearly, allowing readers to understand the innovative aspects of HiRe easily. The quality of the experiments and results is high, contributing to the framework's credibility. The novelty of the approach is significant, as it combines hierarchical learning with contrastive techniques, setting a new standard in the field. The availability of the code on GitHub enhances reproducibility, allowing the research community to build upon the findings presented.\n\n# Summary Of The Review\nOverall, HiRe represents a significant advancement in few-shot knowledge graph completion, showcasing innovative methodologies and robust empirical results. Its hierarchical relational learning paradigm and effective integration of contrastive learning make it a promising tool for future research in knowledge representation and inference.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n5\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper introduces a novel framework, HiRe (Hierarchical Relational Learning), aimed at addressing the challenges of few-shot knowledge graph (KG) completion. It emphasizes a multi-level approach to relational learning, focusing on context-level, triplet-level, and entity-level information to enhance model generalization from limited data. The methodology incorporates model-agnostic meta-learning (MAML) to optimize for rapid adaptation to new tasks, positioning HiRe as an effective solution for improving the performance of KGs with sparse data.\n\n# Strength And Weaknesses\nStrengths of this paper include its comprehensive theoretical framework that integrates different levels of relational information, which is particularly important for few-shot scenarios in KGs. The use of contrastive learning at the context-level and the choice of transformer-based architectures for triplet-level learning are innovative and theoretically sound approaches. However, the paper may lack empirical validation; while the theoretical contributions are robust, the actual performance metrics and comparisons against baseline models are not clearly detailed, potentially limiting the practical applicability of the proposed framework.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and presents its ideas clearly, effectively conveying the theoretical underpinnings of the proposed methods. The novelty lies in the hierarchical approach to relational learning, which is a significant departure from existing methodologies. However, the reproducibility of the results could be enhanced by providing more details on the experimental setup and datasets used, as well as by including code or implementation guidelines.\n\n# Summary Of The Review\nOverall, the paper presents a strong theoretical contribution to the field of knowledge graph completion through its hierarchical relational learning framework. While the proposed methodology is innovative and well-articulated, further empirical validation is needed to substantiate its claims and improve reproducibility.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper titled \"Hierarchical Relational Learning for Few-shot Knowledge Graph Completion\" presents a novel framework, HiRe, designed to enhance few-shot knowledge graph (KG) completion. The methodology integrates three hierarchical levels of relational information: context-level, triplet-level, and entity-level, utilizing techniques such as Multi-Head Self-Attention (MSA) and a Transformer-based Meta Relation Learner (MRL) to capture complex relationships among reference triplets. The experimental results, evaluated on datasets like Nell-One and Wiki-One, demonstrate significant improvements in performance metrics such as Mean Reciprocal Rank (MRR) and Hits@k, affirming the effectiveness of the proposed approach.\n\n# Strength And Weaknesses\nOne of the key strengths of the paper is its structured approach to tackling the challenge of few-shot KG completion by leveraging hierarchical learning, which allows for a more granular understanding of relationships within the data. The use of advanced techniques like MSA and MRL enhances the model's ability to generalize across unseen relations. However, the paper falls short in discussing the broader implications of its findings and could benefit from a more detailed exploration of the model's practical applications. Additionally, some aspects of the complexity analysis could be expanded for clarity.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-organized, with a clear presentation of methodologies and findings. The quality of the implementation is high, as evidenced by the use of PyTorch and detailed experimental setups. However, the novelty, while present in the hierarchical approach, is somewhat constrained by the reliance on established methods like MAML for optimization. Reproducibility is supported by the availability of code on GitHub, although further clarification on hyperparameter tuning and computational resources could enhance this aspect.\n\n# Summary Of The Review\nOverall, the paper presents a robust framework for few-shot KG completion, effectively utilizing hierarchical learning strategies. While it demonstrates strong empirical results, it could further enhance its impact by addressing broader implications and providing more detailed insights into practical applications.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4",
    "# Summary Of The Paper\nThe paper addresses the challenge of few-shot knowledge graph completion, proposing a hierarchical relational learning approach referred to as HiRe. The methodology incorporates contrastive learning at the context level and introduces a transformer-based meta relation learner (MRL) to enhance relational information processing. The findings suggest that HiRe shows improvement in specific scenarios, but the performance gains relative to existing methods appear marginal.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its structured approach to integrating hierarchical relational learning with contrastive learning techniques. However, the contributions seem to lack originality, as many of the proposed methodologies, including the hierarchical framework and the meta-learning strategy, are reminiscent of existing works such as FSRL and GMatching. The ablation study, while informative, does not convincingly establish HiRe as a superior alternative to these prior models. Furthermore, the paper fails to provide a comprehensive comparative analysis against state-of-the-art methods, limiting the assessment of its claimed generalization capabilities.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and communicates its ideas clearly. However, the novelty of the proposed methods is questionable, as they appear to be derivative of established techniques rather than groundbreaking innovations. Reproducibility may be an issue, given the limited comparisons with a broader range of existing methods, which could affect the community's ability to validate the findings independently.\n\n# Summary Of The Review\nWhile the paper presents an interesting perspective on few-shot knowledge graph completion through its HiRe framework, it largely consolidates existing ideas rather than offering substantial advancements. The methodological contributions, although structured, reflect a lack of originality, and the empirical results do not convincingly demonstrate significant improvements over prior work.\n\n# Correctness\n3\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n2",
    "# Summary Of The Paper\nThe paper titled \"Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion\" addresses the challenge of completing knowledge graphs (KGs) with limited training data. It proposes a novel hierarchical relational learning framework that leverages meta relation representations to generalize from a few training triplets to unseen query triplets. The methodology involves a self-supervised learning scheme that integrates context-level relational learning and pairwise triplet-level interactions. The experimental results demonstrate the effectiveness of the proposed method, with improvements in performance metrics compared to baseline approaches.\n\n# Strength And Weaknesses\nThe main strength of the paper lies in its innovative approach to few-shot knowledge graph completion, which combines hierarchical learning and self-supervised strategies effectively. The results indicate substantial improvements in performance, showcasing the potential of the proposed model. However, the paper suffers from several clarity and formatting issues, such as inconsistent notation, awkward phrasing, and a lack of definitions for abbreviations upon first use. These issues can detract from the reader's understanding and may hinder reproducibility.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the contributions of the paper are conceptually strong, clarity suffers due to numerous grammatical errors, inconsistent terminology, and a lack of uniform formatting. The novelty of the approach is significant, as it proposes a unique framework for few-shot learning in KGs, but the presentation could benefit from a thorough proofreading to enhance readability. Reproducibility may also be challenged by the inconsistencies in equations and notation, which could confuse potential implementers of the proposed method.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the field of knowledge graph completion through its hierarchical relational learning framework. However, clarity and presentation issues need to be addressed to improve understanding and reproducibility. If these issues are resolved, the paper has the potential to make a significant impact.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n4/5",
    "# Summary Of The Paper\nThe paper presents a novel approach to few-shot knowledge graph completion through a hierarchical relational learning framework. The authors propose a model-agnostic meta-learning strategy, specifically utilizing MAML (Model-Agnostic Meta-Learning), to address the challenges associated with limited training data in knowledge graphs. The findings indicate that the proposed method achieves competitive performance on benchmark datasets such as Nell-One and Wiki-One, suggesting its potential efficacy in knowledge graph completion tasks.\n\n# Strength And Weaknesses\nThe primary strength of this paper lies in its innovative application of hierarchical relational learning and meta-learning techniques to few-shot scenarios. However, the paper has several weaknesses. It does not explore other applications of hierarchical relational learning, such as in dynamic knowledge graphs, nor does it consider the impact of temporal relationships. Additionally, the scalability of the proposed method to larger knowledge graphs remains unaddressed, which could limit its real-world applicability. The authors also overlook the implications of contextual biases in training data and fail to provide a comparative analysis with a broader range of state-of-the-art techniques. Furthermore, the discussion on the integration of the proposed framework with existing systems and the ethical implications of knowledge graph completion is notably absent.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and clear, presenting its methodology and findings in a logical manner. However, the novelty of the approach could be further emphasized through comparative studies with existing techniques. The reproducibility of the results may be challenged by the lack of extensive dataset validation and the absence of discussions surrounding hyper-parameter sensitivities. Overall, while the contributions are relevant, they could benefit from a more thorough exploration of their implications and limitations.\n\n# Summary Of The Review\nThis paper introduces an interesting approach to few-shot knowledge graph completion using hierarchical relational learning and meta-learning. However, it has significant limitations regarding scalability, comparative analysis, and consideration of ethical implications, which hinder its overall impact.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n3\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper presents a novel framework, Hierarchical Relational Learning (HiRe), aimed at addressing the challenge of few-shot knowledge graph (KG) completion. The methodology encompasses a multi-level approach that captures relational information at the entity, triplet, and context levels. Key contributions include the introduction of a contrastive loss function for context-level learning, a transformer-based meta relation learning mechanism that ensures permutation invariance, and a meta representation for entity-level scoring. Empirical results demonstrate significant improvements over baseline models on the Nell-One and Wiki-One datasets, although the authors do not fully address the need for statistical validations of their findings.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to few-shot learning in knowledge graphs and the thorough experimental design that includes ablation studies and evaluation using established metrics like mean reciprocal rank (MRR) and Hits@n. However, the paper exhibits weaknesses in its statistical rigor, as it lacks detailed significance testing for the reported improvements, which is essential for substantiating the performance claims. Additionally, the absence of confidence intervals and effect size measures limits the understanding of the practical implications of the results.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents its ideas clearly, making it accessible to readers with a background in machine learning and knowledge graphs. The methodology is sound, although the lack of rigorous statistical analysis weakens the reproducibility of the findings. The novelty of the approach is commendable, as it integrates several advanced techniques to tackle a complex problem, yet the empirical validation could be strengthened to enhance its credibility.\n\n# Summary Of The Review\nOverall, this paper proposes a promising framework for few-shot knowledge graph completion and demonstrates notable empirical results. However, the lack of sufficient statistical validation undermines the strength of its claims, suggesting that further statistical rigor is needed to support the findings.\n\n# Correctness\n4/5\n\n# Technical Novelty And Significance\n4/5\n\n# Empirical Novelty And Significance\n3/5",
    "# Summary Of The Paper\nThe paper presents a novel framework for few-shot knowledge graph (KG) completion that emphasizes the integration of triplet-level, entity-level, and context-level relational information. The methodology employs hierarchical relational learning, leveraging embeddings pre-trained by TransE to enhance performance in few-shot scenarios. The findings suggest that the proposed approach improves upon several state-of-the-art techniques in terms of mean reciprocal rank (MRR) and Hits@n metrics, although its effectiveness is constrained by several factors, including dependency on pre-trained embeddings and scalability issues.\n\n# Strength And Weaknesses\nThe strengths of the paper lie in its innovative approach to few-shot KG completion and the empirical results demonstrating improved performance over existing models. However, there are notable weaknesses, including a limited exploration of other contextual factors that could enhance the model, concerns regarding the scalability of the hierarchical relational learning method, and a lack of consideration for noisy data, which is prevalent in real-world applications. Additionally, the paper does not adequately address the potential generalization of its approach to zero-shot or one-shot learning scenarios, nor does it provide a comprehensive comparison with a wider array of baseline models.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-structured and presents its methodology clearly, although some sections could benefit from greater detail, particularly regarding hyper-parameter selection and the implications of model architecture choices. The novelty of the proposed approach is significant within the context of few-shot learning for KGs; however, the reproducibility is hampered by the reliance on pre-trained embeddings without sufficient discussion on their domain-specific applicability. Overall, while the quality of the work is high, there are areas where clarity could be improved, especially in articulating future research directions.\n\n# Summary Of The Review\nThis paper contributes a promising framework for few-shot KG completion, yet it is limited by several factors, including its reliance on pre-trained embeddings and scalability challenges. While the methodology is innovative and shows empirical improvements, the exploration of more contextual and relational dimensions is needed to fully realize its potential.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces *HiRe*, a new approach for Few-Shot Knowledge Graph Completion that aims to address the long-standing issue of incomplete knowledge graphs. It proposes a hierarchical relational learning framework that captures relational information at three levels: context-level, triplet-level, and entity-level. The methodology employs contrastive learning to improve embedding quality and utilizes a transformer for meta relation learning, specifically implementing Model-Agnostic Meta-Learning (MAML) to enhance performance. Experimental results demonstrate that *HiRe* outperforms existing methods on benchmark datasets, with ablation studies verifying the significance of its components.\n\n# Strength And Weaknesses\nThe primary strength of the paper lies in its systematic approach to integrating multiple levels of relational information, which does show improvements in performance metrics. The extensive experimentation on benchmark datasets lends credibility to the findings, and the ablation studies provide valuable insight into the contribution of each component. However, the paper does not present significant novelty, as many concepts, including contrastive learning and MAML, are well-established techniques. Additionally, the claims of innovation feel overstated, as the proposed methods appear to be repackaged versions of existing strategies rather than groundbreaking advancements.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-organized and clearly articulates the methodology and findings. However, the novelty is questionable, as it builds on concepts widely covered in the literature. The quality of the experiments is robust, but the lack of truly innovative ideas may hinder the paper's impact. Reproducibility appears feasible due to the detailed descriptions of the methodologies and experiments.\n\n# Summary Of The Review\nOverall, while the paper presents a coherent methodology and demonstrates improvements in performance for Few-Shot Knowledge Graph Completion, it suffers from a lack of true novelty and innovation. The contributions, while methodologically sound, do not significantly advance the field, making the paper feel more like a reiteration of established concepts rather than a groundbreaking contribution.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n2\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces a hierarchical relational learning framework (HiRe) aimed at enhancing few-shot knowledge graph (KG) completion. The methodology incorporates a multi-level representation that captures entity-level, triplet-level, and context-level relational information, employing a transformer-based meta relation learner (MRL) and contrastive learning for context-level relations. Key findings highlight the framework's effectiveness in improving performance on knowledge graph tasks, while also addressing limitations associated with traditional sequence models like LSTMs.\n\n# Strength And Weaknesses\nThe paper's primary strength lies in its innovative hierarchical approach, which aligns well with current trends in multi-level representation learning. The use of contrastive learning for context-level relations is a promising technique, although the exploration of alternative loss functions could enhance the model's robustness. A notable weakness is the reliance on LSTMs for triplet-level learning, which may impose unnecessary sequential constraints. Additionally, while the experiments validate the effectiveness of HiRe, the scope could be broadened by including diverse datasets and a systematic study of hyperparameter optimization, which would provide deeper insights.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is generally well-written and presents a clear methodology, but some sections could benefit from further elaboration, particularly regarding the motivation for certain design choices. The novelty of the approach is commendable, given the integration of multiple levels of relational information. However, reproducibility could be improved by providing more detailed descriptions of experimental setups and hyperparameter configurations. Including additional datasets and performance metrics would further strengthen the reproducibility of the findings.\n\n# Summary Of The Review\nOverall, the paper presents a novel hierarchical framework for few-shot knowledge graph completion that is well-grounded in recent advances in relational learning. While it offers promising insights and methodologies, there are areas for improvement, particularly in terms of dataset diversity and the exploration of alternative learning approaches.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n3",
    "# Summary Of The Paper\nThe paper introduces HiRe, a novel method for few-shot knowledge graph completion that significantly enhances performance over existing state-of-the-art approaches. HiRe achieves notable improvements in both 1-shot and 5-shot settings across two benchmark datasets, Nell-One and Wiki-One. The method's effectiveness is supported by quantitative metrics, with HiRe outperforming competitors such as MetaR-I and MetaR-P in various evaluation metrics like MRR and Hits@k. An ablation study further confirms the robustness of HiRe, illustrating the importance of its components, particularly the contrastive learning aspect, in achieving high performance.\n\n# Strength And Weaknesses\nHiRe's primary strengths lie in its empirical results that demonstrate clear advancements in few-shot knowledge graph completion tasks and its methodological innovation that integrates contrastive learning effectively. The comprehensive evaluation across multiple datasets adds to the robustness of the findings. However, the paper could benefit from a more detailed discussion of related work and a clearer rationale for the chosen methods, which could enhance understanding and contextualization of the contributions.\n\n# Clarity, Quality, Novelty And Reproducibility\nThe paper is well-structured and articulately presents its contributions, methodology, and findings. The clarity of the results and the systematic approach to benchmarking are commendable, aiding reproducibility. However, additional details on experimental setups and hyperparameter tuning would further bolster the reproducibility aspect. Overall, the quality is high, and the novelty of the approach, particularly in the context of few-shot learning, is clear.\n\n# Summary Of The Review\nHiRe presents a significant advancement in few-shot knowledge graph completion, achieving superior performance across multiple benchmarks. While the paper is strong in empirical contributions and clarity, it could enhance its discussion on related work and reproducibility practices.\n\n# Correctness\n5\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n5",
    "# Summary Of The Paper\nThe paper titled \"HIERARCHICAL RELATIONAL LEARNING FOR FEWSHOT KNOWLEDGE GRAPH COMPLETION\" presents a novel approach to knowledge graph (KG) completion in few-shot learning scenarios. The authors propose a hierarchical relational learning framework that effectively leverages limited data to improve the performance of KG completion tasks. The methodology involves detailed ablation studies, sensitivity analyses, and comparisons with existing few-shot learning methods, demonstrating a significant performance improvement. The findings suggest that the proposed approach can effectively mitigate the notorious long-tail problem inherent in knowledge graphs.\n\n# Strength And Weaknesses\nThe main strengths of the paper include its innovative approach to few-shot KG completion, which addresses a well-known challenge in the field. The comprehensive evaluation through ablation studies provides valuable insights into the importance of different components of the proposed method. However, the paper suffers from some clarity issues, particularly in the presentation of results and terminology, which may hinder accessibility for readers not deeply familiar with the subject matter. Additionally, the organization of the methods section could overwhelm readers with its technical detail without sufficient guiding summaries.\n\n# Clarity, Quality, Novelty And Reproducibility\nWhile the paper contributes significant technical advancements, its clarity could be improved. The abstract and introduction are dense and could benefit from reorganization to enhance readability. The use of technical jargon without definitions may alienate some readers, reducing overall engagement. Furthermore, the reproducibility of the results may be hampered by inconsistencies in references and minor typographical errors throughout the paper. Clearer figures and a more structured presentation of results, especially in the ablation studies, would enhance the overall quality.\n\n# Summary Of The Review\nOverall, the paper presents a valuable contribution to the area of few-shot knowledge graph completion with a novel hierarchical approach. While it demonstrates significant technical and empirical advancements, issues related to clarity and presentation need to be addressed for broader accessibility and understanding.\n\n# Correctness\n4\n\n# Technical Novelty And Significance\n4\n\n# Empirical Novelty And Significance\n4"
  ],
  "condition_keys": [
    "Reference",
    "Faithful",
    "Objective Analysis",
    "Thorough Evaluation",
    "Balanced Critique",
    "Method Shift",
    "Question Shift",
    "Contribution Misrepresent",
    "Result Manipulation",
    "Assumption Attack",
    "Low Effort",
    "Generic",
    "Surface Skim",
    "Template Fill",
    "Checklist Review",
    "Overly Technical",
    "Harsh Critique",
    "Overly Positive",
    "Theory Focus",
    "Implementation Obsessed",
    "Comparison Fixated",
    "Pedantic Details",
    "Scope Creep",
    "Statistical Nitpick",
    "Future Work Focus",
    "Dismissive Expert",
    "Agenda Push",
    "Benchmark Obsessed",
    "Writing Critique"
  ],
  "logp_base": [
    -2.54553906050714,
    -1.6378494686001663,
    -1.7744839881752508,
    -1.5358366607808773,
    -1.7594254819173976,
    -1.7270924701523362,
    -1.4817243011586774,
    -1.9756158487527158,
    -1.717330511625576,
    -1.8466715914218281,
    -1.575599589170942,
    -1.4646393783886322,
    -1.6611637458370845,
    -1.582863546873049,
    -1.622757956471823,
    -1.6872244803046563,
    -1.8577824375374166,
    -1.6988754950805258,
    -1.7236007850529347,
    -1.641948330020091,
    -1.8875443029460248,
    -1.6570364712864019,
    -1.6884947277145903,
    -1.8893822616727947,
    -1.7835630112355985,
    -1.7591632730189646,
    -1.7692972162967566,
    -1.7395709736316929,
    -1.7602687132442725
  ],
  "logp_cond": [
    [
      0.0,
      -2.2623440162142905,
      -2.2776010438265506,
      -2.2567105585519296,
      -2.3026146567002774,
      -2.3121531490457956,
      -2.390479424536008,
      -2.3040611650211504,
      -2.2798492992328447,
      -2.334320215680974,
      -2.2858607528649095,
      -2.3793540794263732,
      -2.304881429764499,
      -2.3147437541581724,
      -2.306641361598656,
      -2.278768859535635,
      -2.3604026013156862,
      -2.3120449477811866,
      -2.318144934821035,
      -2.2788632154138546,
      -2.3313855781996757,
      -2.352301685637833,
      -2.3615858872768567,
      -2.295369410459822,
      -2.351926469445627,
      -2.317808518814567,
      -2.3002521405906093,
      -2.3376416942575866,
      -2.380598507238436
    ],
    [
      -1.164986046077311,
      0.0,
      -1.0911103320441489,
      -1.013250635005196,
      -1.122742934028722,
      -1.1717521703485205,
      -1.3262736385436622,
      -1.1432852100764448,
      -1.1080965836482404,
      -1.1962336539349527,
      -1.1194704357942074,
      -1.349565924900391,
      -1.102527578007092,
      -1.121948847108587,
      -1.2065263182433632,
      -1.0943844625377586,
      -1.2448714161004815,
      -1.1635538267831413,
      -1.1882119654274637,
      -1.1444691689368627,
      -1.211019744092545,
      -1.2416536938328622,
      -1.3065606111709456,
      -1.13558440846266,
      -1.22545189972645,
      -1.1123539811710343,
      -1.142393537686263,
      -1.2403169888087475,
      -1.2745104718668552
    ],
    [
      -1.3594683171969641,
      -1.2990620488059594,
      0.0,
      -1.2788588776201313,
      -1.2557515344910992,
      -1.289068948889048,
      -1.51466700882587,
      -1.336971876041245,
      -1.2345432217583359,
      -1.3344272227866076,
      -1.3174291820137525,
      -1.5159402546248548,
      -1.3390891792783222,
      -1.2897266767699498,
      -1.2973292381587849,
      -1.2867935945517286,
      -1.4403352236794507,
      -1.3676367964725598,
      -1.3606647890964607,
      -1.2543201056219313,
      -1.373046363365194,
      -1.4123926808458347,
      -1.3771044375289005,
      -1.3222504412380462,
      -1.3805697838041888,
      -1.3110122028579076,
      -1.3010569519272253,
      -1.3864718639306666,
      -1.4498791160861428
    ],
    [
      -1.1084364292103717,
      -0.9691049578373062,
      -0.9656832381101197,
      0.0,
      -1.0148018283521196,
      -1.0534345903742635,
      -1.2158493377896675,
      -1.0121529067754889,
      -0.991300718148875,
      -1.0934365600352238,
      -1.0271881621656411,
      -1.2714115536776447,
      -1.0593160104214452,
      -1.0315878986190001,
      -1.0565762397579568,
      -1.0186813671918196,
      -1.147686877854544,
      -1.0934552902241335,
      -1.056460143046939,
      -1.0181856735837969,
      -1.064103015508999,
      -1.170748984932402,
      -1.1842992966977113,
      -1.0345374288031852,
      -1.146643512836773,
      -1.0500549316295826,
      -1.0390777044947486,
      -1.1761953436866088,
      -1.1814053136670775
    ],
    [
      -1.3649140034960898,
      -1.2942458316014174,
      -1.1999636333616437,
      -1.2825774660438267,
      0.0,
      -1.328949764331711,
      -1.4018748485978827,
      -1.298653841465967,
      -1.2475980077392739,
      -1.3640973277193975,
      -1.3091769359106795,
      -1.4432829016124944,
      -1.3599661662249058,
      -1.304193916473726,
      -1.3224489634262528,
      -1.2903229643780607,
      -1.3966516970959975,
      -1.27554569450929,
      -1.3507624376509566,
      -1.2896189621674436,
      -1.29928409481039,
      -1.3888823018596759,
      -1.4272640377383163,
      -1.300556719982117,
      -1.3939531948779886,
      -1.2618488079796304,
      -1.2729617802216606,
      -1.4092347810678614,
      -1.4173578484034826
    ],
    [
      -1.3408190036384386,
      -1.2680575923709347,
      -1.1570210672714933,
      -1.243532637578435,
      -1.2245308169154372,
      0.0,
      -1.424619076767964,
      -1.3106056929506975,
      -1.2490693952906404,
      -1.2776309728788542,
      -1.2290420632906471,
      -1.471100312645327,
      -1.3136651802416845,
      -1.2145713602477501,
      -1.2526976223494617,
      -1.1816866060337905,
      -1.3788117238085682,
      -1.3273448292373746,
      -1.2496408868590068,
      -1.2331318673291984,
      -1.3143626386568252,
      -1.3759955009920697,
      -1.3764587607991365,
      -1.247022390094918,
      -1.3297816494184933,
      -1.2716408493159939,
      -1.3063409300787079,
      -1.311241468903034,
      -1.3680460950428222
    ],
    [
      -1.202631246305691,
      -1.108167623488462,
      -1.084006704248264,
      -1.047290765530246,
      -1.0772871009550833,
      -1.079501529108864,
      0.0,
      -1.082993153620083,
      -1.0677372340234408,
      -1.1270144547574366,
      -1.08155682477775,
      -1.1911369726138876,
      -1.1261731813893336,
      -1.087275084162564,
      -1.1199164907148957,
      -1.0882109655256949,
      -1.1634820376295547,
      -1.1229216386787166,
      -1.061000131414,
      -1.1214603112896653,
      -1.1097494580632579,
      -1.183210221833509,
      -1.1961929232473394,
      -1.086028161473803,
      -1.1798275224565506,
      -1.1233542229427445,
      -1.100723518341925,
      -1.156105622344336,
      -1.136264469192896
    ],
    [
      -1.5959562639363696,
      -1.5419041395680448,
      -1.4561808604683377,
      -1.47990716490768,
      -1.5097557728960709,
      -1.5362636945728956,
      -1.6700651916758962,
      0.0,
      -1.4388250817738175,
      -1.547458052347482,
      -1.5483094550591876,
      -1.6925818258385597,
      -1.603185211614855,
      -1.5660941424798749,
      -1.5576519989318633,
      -1.55095322625292,
      -1.6573851768903411,
      -1.539968939071158,
      -1.5369725394606435,
      -1.543745898585889,
      -1.5207941870955337,
      -1.6023897984904354,
      -1.6284943538060186,
      -1.4955432772913648,
      -1.5834665383469002,
      -1.498687863663528,
      -1.498649238824901,
      -1.6002881423009245,
      -1.6413345582193652
    ],
    [
      -1.363226460977454,
      -1.2724896257891074,
      -1.19943106222544,
      -1.281574646758134,
      -1.2537133518074952,
      -1.284392244047006,
      -1.418457952074557,
      -1.2371246340413236,
      0.0,
      -1.3416507780483165,
      -1.2783327093288213,
      -1.450673572906554,
      -1.343467957735387,
      -1.1922761305927652,
      -1.2888139651840462,
      -1.2657303778454498,
      -1.3885285444231388,
      -1.3147675233495804,
      -1.3346235078607547,
      -1.2532355094139087,
      -1.2999331699407046,
      -1.4014136932649806,
      -1.3980773878838932,
      -1.2198419801677451,
      -1.3562474707480499,
      -1.3120733421909614,
      -1.293486812673472,
      -1.3655799721618058,
      -1.4061401383152656
    ],
    [
      -1.4447334834892493,
      -1.425244484353519,
      -1.3604197849028703,
      -1.4002721773473914,
      -1.4289103826965253,
      -1.4080088674617686,
      -1.5571523567936556,
      -1.4202049061647595,
      -1.398994714031658,
      0.0,
      -1.4207643205836065,
      -1.599585693192559,
      -1.454832186860643,
      -1.4355890301047545,
      -1.407779405498366,
      -1.443183053508374,
      -1.4492249295887276,
      -1.460705147094304,
      -1.3685901110544214,
      -1.4235627202634182,
      -1.4224431716927934,
      -1.5223245258967149,
      -1.4577256104876475,
      -1.4309271230128682,
      -1.4082882395358547,
      -1.3744436192948692,
      -1.4104798323870493,
      -1.5349939311461813,
      -1.5185871412931706
    ],
    [
      -1.056402226217814,
      -0.9925868016217938,
      -0.9438955391394479,
      -0.9701661382675794,
      -1.028945879183676,
      -1.0127167701387516,
      -1.2227174434640018,
      -1.0512495121845984,
      -0.9899032763115978,
      -1.1014894304601819,
      0.0,
      -1.3108128855277157,
      -1.0996798462027761,
      -0.9896475127026003,
      -1.0559227799019375,
      -1.0501604467250014,
      -1.183103879415008,
      -1.0823397020998151,
      -1.0869556097235924,
      -1.0099531197799916,
      -1.0610377319529727,
      -1.1867024446411267,
      -1.1937150832811458,
      -1.0308675134708876,
      -1.1671783881636695,
      -1.0247560435898775,
      -1.0354297226193365,
      -1.0963830339397156,
      -1.1903882426085586
    ],
    [
      -1.191674423459633,
      -1.1907099487134059,
      -1.2159888313371012,
      -1.1927499011002711,
      -1.2084669954688936,
      -1.2045789937044153,
      -1.1995154935199213,
      -1.1941917237538358,
      -1.195987171372622,
      -1.1809706829158348,
      -1.17265228125756,
      0.0,
      -1.2050802739830806,
      -1.1971973117215902,
      -1.197891990559768,
      -1.2337194645866547,
      -1.1813308520716619,
      -1.2344786716325455,
      -1.1765119684977818,
      -1.2027689370814743,
      -1.1757538632541937,
      -1.1883626260013824,
      -1.1673067162974762,
      -1.1969935812407437,
      -1.2033506509104663,
      -1.1879969634412317,
      -1.1871333551446999,
      -1.1845975911003326,
      -1.1533636270986256
    ],
    [
      -1.260054459828844,
      -1.0377658546295045,
      -1.145833793207057,
      -1.1318423323821085,
      -1.2046180088893668,
      -1.2363438784117233,
      -1.2720225788141808,
      -1.2526412081024254,
      -1.2316576476333736,
      -1.2128769787901499,
      -1.1647187811128383,
      -1.343638952254891,
      0.0,
      -1.1940253247756598,
      -1.2356982023439531,
      -1.1212788886057943,
      -1.3047434591739662,
      -1.2049449190560764,
      -1.1925368855892897,
      -1.1896127092399313,
      -1.253006009023547,
      -1.2423469753558944,
      -1.312120766190545,
      -1.203827040491532,
      -1.2493109173546455,
      -1.231490120209252,
      -1.1500587350667555,
      -1.284909251384475,
      -1.3169530449191407
    ],
    [
      -1.2314272792353942,
      -1.1377952977891215,
      -1.1163082294515616,
      -1.1620066163956468,
      -1.1532859049920405,
      -1.1310235723071091,
      -1.3022651920012362,
      -1.219201495693115,
      -1.0354525157416323,
      -1.2500390137845125,
      -1.1545962459101036,
      -1.3336128973584855,
      -1.2246213078799841,
      0.0,
      -1.147985404969322,
      -1.1250858023140184,
      -1.2559121193413163,
      -1.235781911206232,
      -1.1853162319274015,
      -1.1350773648592805,
      -1.201890071419639,
      -1.2242871492837102,
      -1.2923213265358084,
      -1.1366888662301902,
      -1.2932948600120504,
      -1.161758655317967,
      -1.193471770490682,
      -1.2566152209559718,
      -1.2940049116156906
    ],
    [
      -1.2376274719005365,
      -1.191282944013682,
      -1.0876691144401651,
      -1.1837177204541447,
      -1.2002220137818738,
      -1.1905439606993922,
      -1.3220534260401968,
      -1.2305553765513662,
      -1.14696868930987,
      -1.1994282103943905,
      -1.1651670966329175,
      -1.3309913330987055,
      -1.245794467902427,
      -1.1217587433569876,
      0.0,
      -1.1865972613073201,
      -1.2538732800317074,
      -1.249443407526254,
      -1.17155054261167,
      -1.1666031496093707,
      -1.2162295128831713,
      -1.2707379156079865,
      -1.2406746771791906,
      -1.1610736907241535,
      -1.229075056909414,
      -1.1710282564574455,
      -1.2099206674840046,
      -1.2661545152211384,
      -1.2762316181281592
    ],
    [
      -1.2719796737911075,
      -1.192572701381374,
      -1.1316227680496895,
      -1.1882389173833703,
      -1.1814594582825513,
      -1.1477206390479329,
      -1.3972130086711734,
      -1.2453392813037756,
      -1.2157842394492957,
      -1.2766687142212152,
      -1.2174956795510632,
      -1.4740974969524392,
      -1.1901494065845992,
      -1.1518800562309495,
      -1.232850380996421,
      0.0,
      -1.3642286206256833,
      -1.2903676420215255,
      -1.2550122134026815,
      -1.1761033799502376,
      -1.2668084890469573,
      -1.2519566907710515,
      -1.353534225007083,
      -1.1786097904336061,
      -1.3346036886288306,
      -1.2253189180715984,
      -1.2584051067242834,
      -1.3411334555118957,
      -1.3626201426676963
    ],
    [
      -1.4491753735793624,
      -1.4295807275833903,
      -1.3313289877070258,
      -1.397831777521324,
      -1.365591596054802,
      -1.4069523475058405,
      -1.4824671887227887,
      -1.3965429255479456,
      -1.384801850239121,
      -1.3196652430661535,
      -1.3951754918723658,
      -1.519815426861034,
      -1.4391080192687256,
      -1.4173794956364363,
      -1.3764486100891293,
      -1.44352861941601,
      0.0,
      -1.3845153033943394,
      -1.3914502781066547,
      -1.408480471569327,
      -1.3704899234147392,
      -1.4744937202179809,
      -1.4691509139730845,
      -1.4555236739631423,
      -1.4225091945093296,
      -1.3176271441151823,
      -1.3798719867203937,
      -1.4595963758811146,
      -1.4822849213895086
    ],
    [
      -1.278436368836831,
      -1.1973176080433159,
      -1.1386628945718154,
      -1.1964984073579812,
      -1.1022146640695132,
      -1.2431481274564014,
      -1.3523007846463346,
      -1.2018980213635095,
      -1.19776806643129,
      -1.267896128034066,
      -1.171798924158995,
      -1.3885535324745604,
      -1.2240206645088472,
      -1.267080903125713,
      -1.2427659589049358,
      -1.2244466235399052,
      -1.3089608522163285,
      0.0,
      -1.2563653466830695,
      -1.1298198316524664,
      -1.211841980364716,
      -1.323131530121292,
      -1.379563150444317,
      -1.2033694340751833,
      -1.3240001771458427,
      -1.1676037650847693,
      -1.138703657190207,
      -1.2957296664941709,
      -1.3555327749044086
    ],
    [
      -1.3370715205379349,
      -1.23352630642681,
      -1.1679716607777013,
      -1.224939330366873,
      -1.2578450678884967,
      -1.2172856101255034,
      -1.3432791001969595,
      -1.2177064111239588,
      -1.2569678288788262,
      -1.2532446846859058,
      -1.246932789506799,
      -1.4198250400246657,
      -1.290840895472863,
      -1.2067641269824565,
      -1.2524542645265557,
      -1.3093381777600126,
      -1.3169898914154279,
      -1.3087248848895245,
      0.0,
      -1.2651983414010615,
      -1.2841372467485814,
      -1.319007699354281,
      -1.314203355184255,
      -1.2395609184014147,
      -1.29641458625794,
      -1.2236938440113976,
      -1.2378589993897986,
      -1.349829375729306,
      -1.322480955970906
    ],
    [
      -1.2204424940627554,
      -1.2129618641947848,
      -1.0710045595085351,
      -1.147893764971961,
      -1.1509525094591935,
      -1.1834157352743615,
      -1.2946370979122288,
      -1.236195283375887,
      -1.120409651082085,
      -1.1973088959773686,
      -1.123115409968713,
      -1.364139212869055,
      -1.2534608576720292,
      -1.1704432121043615,
      -1.1477242057679327,
      -1.1435199025035678,
      -1.2426304673041648,
      -1.209802372097609,
      -1.1824499551933343,
      0.0,
      -1.215224125698736,
      -1.2811015815632896,
      -1.2743965560164416,
      -1.165157431545444,
      -1.262643129059449,
      -1.158918062103806,
      -1.1851061841227428,
      -1.2529380894711108,
      -1.2795747183577568
    ],
    [
      -1.4808176000481317,
      -1.4598648982541695,
      -1.3497208606178939,
      -1.3920027580802248,
      -1.352027168754239,
      -1.4382359289807747,
      -1.6094895758213676,
      -1.3464981233339137,
      -1.382167953992107,
      -1.4291905514981007,
      -1.460782493683884,
      -1.6295899450563327,
      -1.5088833245617959,
      -1.4420048702255963,
      -1.441037262742647,
      -1.472181494825296,
      -1.5146886246101556,
      -1.4131352582554613,
      -1.4586435491018381,
      -1.4197881972589619,
      0.0,
      -1.504684213325623,
      -1.4860811766268849,
      -1.451275906484263,
      -1.495646358475273,
      -1.3760088450240553,
      -1.423939763363094,
      -1.522853985071908,
      -1.5046180362085897
    ],
    [
      -1.3420472441787754,
      -1.3076028664492017,
      -1.2800285986697073,
      -1.2836509475384055,
      -1.2902643467832131,
      -1.312569701155555,
      -1.3974107173933363,
      -1.332835485306507,
      -1.29624912633276,
      -1.3170693821998338,
      -1.2978616154366343,
      -1.3942385206439223,
      -1.32269869268665,
      -1.2683972876325842,
      -1.3048047437388193,
      -1.2625031480857039,
      -1.3643144176165065,
      -1.316817784865246,
      -1.3170700448017068,
      -1.2852747701823177,
      -1.3054204225823385,
      0.0,
      -1.3564370175571745,
      -1.2453447829169637,
      -1.3243563469019035,
      -1.2872053167999764,
      -1.3099630996439164,
      -1.3605015992373843,
      -1.297995959659688
    ],
    [
      -1.2907965336341978,
      -1.3398321426129045,
      -1.23709304007476,
      -1.3092655777744049,
      -1.3065954156927337,
      -1.2793664568806562,
      -1.3925701611197632,
      -1.2908760140361053,
      -1.2546853368977555,
      -1.2240738665798323,
      -1.2933000688801648,
      -1.4340506666085202,
      -1.352631376033404,
      -1.2941673774260005,
      -1.2186753093550011,
      -1.3148602475984432,
      -1.3292678787455967,
      -1.339869421197398,
      -1.2967759640131111,
      -1.284141458755677,
      -1.2758956531386632,
      -1.3587777998127635,
      0.0,
      -1.2982870815529566,
      -1.2915916074853409,
      -1.2911752735857422,
      -1.334931738569693,
      -1.314926633488377,
      -1.3249740368772092
    ],
    [
      -1.4768602049734851,
      -1.469935722524803,
      -1.3820827038940922,
      -1.4534653375157731,
      -1.4523014756338763,
      -1.433624694217737,
      -1.599828249725628,
      -1.4180298932264501,
      -1.3925856041961595,
      -1.519565896846882,
      -1.4532143168175655,
      -1.6605783102476916,
      -1.4912740658534143,
      -1.4438399934026742,
      -1.4880625878345466,
      -1.4064219504157625,
      -1.5384843863811999,
      -1.4730783342944362,
      -1.4394559046100206,
      -1.4297039881928246,
      -1.438112056718435,
      -1.4961370485436012,
      -1.545144018951884,
      0.0,
      -1.5082211248078494,
      -1.4443002726798677,
      -1.4384785176515518,
      -1.548439630377796,
      -1.5754306165295302
    ],
    [
      -1.4496545100304772,
      -1.450732099475602,
      -1.3651338710326064,
      -1.423663722285109,
      -1.3949081031551522,
      -1.4213138742809732,
      -1.5099876859770187,
      -1.3902814944640314,
      -1.4188177622985059,
      -1.307234150456186,
      -1.4376296299248106,
      -1.5290413041441522,
      -1.4433799006020749,
      -1.4503003868033209,
      -1.3705414520013863,
      -1.462533790311986,
      -1.45535590136388,
      -1.4502209091834823,
      -1.396660418629486,
      -1.3823476157548762,
      -1.3945669781621923,
      -1.4432480926304443,
      -1.3423121676760306,
      -1.388509699569114,
      0.0,
      -1.3947883109822732,
      -1.3881453748353068,
      -1.4308108258825933,
      -1.460733647514734
    ],
    [
      -1.365172348634209,
      -1.2366414432058186,
      -1.2036625980070736,
      -1.261165337867759,
      -1.24354944966616,
      -1.3044466821515455,
      -1.446881566062617,
      -1.2692629880945798,
      -1.226383611571338,
      -1.2946185200698979,
      -1.2595156603243158,
      -1.436268156729948,
      -1.3446328989428715,
      -1.2698856923129314,
      -1.2688165541327705,
      -1.3111493559018994,
      -1.346390940035141,
      -1.298771269376015,
      -1.2773167029850514,
      -1.2869359402506877,
      -1.2591636529444452,
      -1.342681271045558,
      -1.3980060034992545,
      -1.31605826248994,
      -1.3665590100614142,
      0.0,
      -1.275107584655565,
      -1.3641068095590692,
      -1.395494308396027
    ],
    [
      -1.3657940355280234,
      -1.2806643773976403,
      -1.1900940470393013,
      -1.2404489590575607,
      -1.2015015017693582,
      -1.2934483817149227,
      -1.4505713454104385,
      -1.2677950261861932,
      -1.223738216243313,
      -1.2850005832964464,
      -1.2915037409669357,
      -1.4937722178640196,
      -1.3136574759527095,
      -1.3173242597631138,
      -1.3429758736712005,
      -1.321962167754602,
      -1.3500138156304635,
      -1.2679864229856659,
      -1.2768376446483172,
      -1.2419071203137535,
      -1.2452341702842151,
      -1.3808670598075528,
      -1.3791530339783746,
      -1.2184823567397847,
      -1.332300852958477,
      -1.2841386429391697,
      0.0,
      -1.4262792398610902,
      -1.4047590912725099
    ],
    [
      -1.354321035109494,
      -1.358374247630778,
      -1.2946834847227098,
      -1.4168749087447303,
      -1.3453049582208518,
      -1.3037069774426828,
      -1.4151137550490855,
      -1.3264031267411498,
      -1.3495224659309666,
      -1.3574505013690263,
      -1.3410783506940815,
      -1.4380679258946076,
      -1.4122197080809231,
      -1.3528419161551082,
      -1.352189846591869,
      -1.3450396840977215,
      -1.404165000641796,
      -1.3711784752773235,
      -1.3556539774450205,
      -1.309844182073127,
      -1.3182149282078108,
      -1.3622242020868935,
      -1.3363200614212383,
      -1.2956101056850593,
      -1.369852996531517,
      -1.3123939484464855,
      -1.3342863309820578,
      0.0,
      -1.3583361084195005
    ],
    [
      -1.4002299734681267,
      -1.3797361149129634,
      -1.3646606746209695,
      -1.3852419687810325,
      -1.3820677600891487,
      -1.3753588760106514,
      -1.40992983173486,
      -1.3886254872661417,
      -1.371162668221336,
      -1.397504336208828,
      -1.3760356568012164,
      -1.4429499529675285,
      -1.4144580627689052,
      -1.3526817848157677,
      -1.3635810287840482,
      -1.384534338147323,
      -1.4438785196131603,
      -1.3958349826225565,
      -1.368479691412665,
      -1.3627991264155115,
      -1.383204879003887,
      -1.3020784859694816,
      -1.3880403028673527,
      -1.39307123407405,
      -1.3771198773848736,
      -1.3907960337004897,
      -1.3875933526461355,
      -1.3814532135361466,
      0.0
    ]
  ],
  "difference_matrix": [
    [
      0.0,
      0.2831950442928495,
      0.26793801668058936,
      0.28882850195521037,
      0.24292440380686253,
      0.23338591146134435,
      0.15505963597113182,
      0.24147789548598952,
      0.2656897612742952,
      0.21121884482616604,
      0.25967830764223043,
      0.16618498108076674,
      0.2406576307426409,
      0.2307953063489676,
      0.2388976989084841,
      0.26677020097150494,
      0.18513645919145372,
      0.23349411272595333,
      0.22739412568610495,
      0.26667584509328535,
      0.21415348230746423,
      0.19323737486930703,
      0.18395317323028326,
      0.25016965004731784,
      0.19361259106151296,
      0.22773054169257279,
      0.24528691991653062,
      0.20789736624955335,
      0.16494055326870383
    ],
    [
      0.4728634225228554,
      0.0,
      0.5467391365560175,
      0.6245988335949704,
      0.5151065345714443,
      0.4660972982516458,
      0.31157583005650413,
      0.49456425852372154,
      0.529752884951926,
      0.4416158146652136,
      0.518379032805959,
      0.28828354369977527,
      0.5353218905930743,
      0.5159006214915793,
      0.43132315035680313,
      0.5434650060624078,
      0.39297805249968487,
      0.474295641817025,
      0.4496375031727027,
      0.49338029966330366,
      0.42682972450762136,
      0.39619577476730417,
      0.33128885742922076,
      0.5022650601375063,
      0.41239756887371626,
      0.525495487429132,
      0.4954559309139033,
      0.3975324797914188,
      0.36333899673331116
    ],
    [
      0.4150156709782866,
      0.47542193936929134,
      0.0,
      0.4956251105551195,
      0.5187324536841516,
      0.48541503928620267,
      0.25981697934938075,
      0.43751211213400576,
      0.5399407664169149,
      0.44005676538864313,
      0.4570548061614983,
      0.25854373355039595,
      0.4353948088969286,
      0.484757311405301,
      0.4771547500164659,
      0.4876903936235222,
      0.3341487644958001,
      0.406847191702691,
      0.41381919907879006,
      0.5201638825533195,
      0.40143762481005685,
      0.3620913073294161,
      0.3973795506463502,
      0.4522335469372045,
      0.39391420437106195,
      0.4634717853173431,
      0.4734270362480255,
      0.3880121242445842,
      0.32460487208910793
    ],
    [
      0.42740023157050566,
      0.5667317029435711,
      0.5701534226707576,
      0.0,
      0.5210348324287577,
      0.48240207040661387,
      0.3199873229912098,
      0.5236837540053885,
      0.5445359426320023,
      0.4424001007456535,
      0.5086484986152362,
      0.26442510710323264,
      0.47652065035943214,
      0.5042487621618772,
      0.47926042102292055,
      0.5171552935890578,
      0.3881497829263334,
      0.44238137055674387,
      0.4793765177339384,
      0.5176509871970805,
      0.47173364527187833,
      0.36508767584847535,
      0.35153736408316605,
      0.5012992319776921,
      0.3891931479441044,
      0.4857817291512947,
      0.49675895628612876,
      0.3596413170942685,
      0.35443134711379987
    ],
    [
      0.39451147842130774,
      0.4651796503159802,
      0.5594618485557539,
      0.47684801587357084,
      0.0,
      0.4304757175856866,
      0.35755063331951487,
      0.4607716404514306,
      0.5118274741781237,
      0.39532815419800005,
      0.45024854600671804,
      0.31614258030490316,
      0.3994593156924917,
      0.4552315654436716,
      0.4369765184911447,
      0.46910251753933685,
      0.3627737848214001,
      0.48387978740810755,
      0.40866304426644096,
      0.4698065197499539,
      0.46014138710700747,
      0.3705431800577217,
      0.3321614441790812,
      0.4588687619352805,
      0.3654722870394089,
      0.49757667393776717,
      0.48646370169573694,
      0.3501907008495362,
      0.342067633513915
    ],
    [
      0.3862734665138976,
      0.4590348777814015,
      0.5700714028808429,
      0.4835598325739012,
      0.502561653236899,
      0.0,
      0.3024733933843722,
      0.41648677720163874,
      0.4780230748616958,
      0.44946149727348206,
      0.4980504068616891,
      0.2559921575070092,
      0.4134272899106517,
      0.5125211099045861,
      0.47439484780287455,
      0.5454058641185457,
      0.34828074634376804,
      0.3997476409149616,
      0.4774515832933295,
      0.4939606028231378,
      0.412729831495511,
      0.35109696916026656,
      0.3506337093531997,
      0.48007008005741825,
      0.39731082073384294,
      0.4554516208363424,
      0.42075154007362836,
      0.4158510012493022,
      0.3590463751095141
    ],
    [
      0.2790930548529864,
      0.3735566776702153,
      0.3977175969104134,
      0.43443353562843146,
      0.4044372002035941,
      0.40222277204981327,
      0.0,
      0.3987311475385944,
      0.4139870671352366,
      0.3547098464012408,
      0.4001674763809273,
      0.29058732854478975,
      0.3555511197693437,
      0.39444921699611335,
      0.36180781044378163,
      0.3935133356329825,
      0.31824226352912266,
      0.35880266247996073,
      0.4207241697446773,
      0.3602639898690121,
      0.3719748430954195,
      0.2985140793251684,
      0.285531377911338,
      0.3956961396848744,
      0.3018967787021267,
      0.3583700782159329,
      0.3810007828167523,
      0.32561867881434137,
      0.34545983196578134
    ],
    [
      0.3796595848163462,
      0.43371170918467095,
      0.5194349882843781,
      0.49570868384503575,
      0.4658600758566449,
      0.4393521541798202,
      0.3055506570768196,
      0.0,
      0.5367907669788983,
      0.4281577964052339,
      0.4273063936935282,
      0.28303402291415614,
      0.37243063713786073,
      0.4095217062728409,
      0.41796384982085244,
      0.4246626224997958,
      0.31823067186237464,
      0.43564690968155784,
      0.4386433092920723,
      0.43186995016682683,
      0.4548216616571821,
      0.3732260502622804,
      0.3471214949466972,
      0.48007257146135096,
      0.3921493104058156,
      0.4769279850891879,
      0.4769666099278147,
      0.37532770645179125,
      0.33428129053335054
    ],
    [
      0.3541040506481219,
      0.4448408858364685,
      0.5178994494001359,
      0.435755864867442,
      0.4636171598180807,
      0.43293826757857,
      0.2988725595510189,
      0.48020587758425237,
      0.0,
      0.3756797335772595,
      0.43899780229675467,
      0.26665693871902185,
      0.37386255389018896,
      0.5250543810328108,
      0.4285165464415297,
      0.4516001337801261,
      0.32880196720243715,
      0.40256298827599557,
      0.38270700376482125,
      0.4640950022116672,
      0.4173973416848713,
      0.3159168183605954,
      0.3192531237416827,
      0.4974885314578308,
      0.3610830408775261,
      0.40525716943461454,
      0.42384369895210394,
      0.3517505394637701,
      0.3111903733103103
    ],
    [
      0.4019381079325788,
      0.4214271070683091,
      0.48625180651895783,
      0.44639941407443673,
      0.41776120872530287,
      0.43866272396005956,
      0.28951923462817253,
      0.42646668525706866,
      0.44767687739017004,
      0.0,
      0.42590727083822166,
      0.24708589822926919,
      0.39183940456118505,
      0.41108256131707366,
      0.438892185923462,
      0.40348853791345407,
      0.3974466618331005,
      0.38596644432752414,
      0.4780814803674067,
      0.4231088711584099,
      0.4242284197290347,
      0.3243470655251133,
      0.38894598093418065,
      0.41574446840895996,
      0.43838335188597344,
      0.4722279721269589,
      0.4361917590347788,
      0.3116776602756468,
      0.3280844501286575
    ],
    [
      0.5191973629531279,
      0.5830127875491482,
      0.6317040500314941,
      0.6054334509033626,
      0.5466537099872659,
      0.5628828190321904,
      0.3528821457069402,
      0.5243500769863436,
      0.5856963128593442,
      0.4741101587107601,
      0.0,
      0.2647867036432263,
      0.47591974296816586,
      0.5859520764683417,
      0.5196768092690045,
      0.5254391424459406,
      0.39249570975593406,
      0.4932598870711269,
      0.4886439794473496,
      0.5656464693909504,
      0.5145618572179693,
      0.3888971445298153,
      0.38188450588979617,
      0.5447320757000544,
      0.4084212010072725,
      0.5508435455810645,
      0.5401698665516055,
      0.4792165552312264,
      0.3852113465623834
    ],
    [
      0.2729649549289992,
      0.2739294296752264,
      0.248650547051531,
      0.2718894772883611,
      0.25617238291973865,
      0.2600603846842169,
      0.26512388486871097,
      0.2704476546347965,
      0.2686522070160102,
      0.2836686954727974,
      0.2919870971310723,
      0.0,
      0.25955910440555163,
      0.26744206666704207,
      0.2667473878288642,
      0.23091991380197752,
      0.28330852631697034,
      0.23016070675608669,
      0.2881274098908504,
      0.261870441307158,
      0.2888855151344385,
      0.2762767523872498,
      0.29733266209115605,
      0.2676457971478885,
      0.2612887274781659,
      0.2766424149474005,
      0.27750602324393236,
      0.28004178728829965,
      0.3112757512900066
    ],
    [
      0.4011092860082406,
      0.6233978912075799,
      0.5153299526300275,
      0.529321413454976,
      0.4565457369477177,
      0.42481986742536115,
      0.3891411670229037,
      0.4085225377346591,
      0.4295060982037109,
      0.4482867670469346,
      0.49644496472424615,
      0.31752479358219343,
      0.0,
      0.46713842106142467,
      0.42546554349313137,
      0.5398848572312902,
      0.3564202866631183,
      0.4562188267810081,
      0.46862686024779476,
      0.47155103659715314,
      0.4081577368135374,
      0.41881677048119004,
      0.3490429796465395,
      0.4573367053455524,
      0.411852828482439,
      0.4296736256278324,
      0.511105010770329,
      0.3762544944526094,
      0.3442107009179438
    ],
    [
      0.3514362676376548,
      0.4450682490839275,
      0.46655531742148737,
      0.42085693047740214,
      0.42957764188100844,
      0.45183997456593983,
      0.2805983548718127,
      0.363662051179934,
      0.5474110311314166,
      0.33282453308853643,
      0.4282673009629454,
      0.24925064951456344,
      0.35824223899306484,
      0.0,
      0.43487814190372687,
      0.45777774455903053,
      0.3269514275317327,
      0.34708163566681693,
      0.39754731494564743,
      0.4477861820137685,
      0.38097347545341,
      0.3585763975893388,
      0.29054222033724053,
      0.4461746806428588,
      0.28956868686099857,
      0.4211048915550819,
      0.3893917763823669,
      0.3262483259170772,
      0.28885863525735833
    ],
    [
      0.3851304845712866,
      0.431475012458141,
      0.535088842031658,
      0.4390402360176784,
      0.4225359426899493,
      0.4322139957724309,
      0.30070453043162626,
      0.39220257992045693,
      0.475789267161953,
      0.42332974607743257,
      0.4575908598389056,
      0.29176662337311754,
      0.376963488569396,
      0.5009992131148355,
      0.0,
      0.43616069516450295,
      0.3688846764401157,
      0.37331454894556915,
      0.4512074138601532,
      0.45615480686245236,
      0.4065284435886518,
      0.35202004086383654,
      0.3820832792926325,
      0.46168426574766963,
      0.3936828995624091,
      0.4517297000143776,
      0.41283728898781846,
      0.35660344125068466,
      0.34652633834366386
    ],
    [
      0.4152448065135488,
      0.49465177892328227,
      0.5556017122549668,
      0.49898556292128604,
      0.505765022022105,
      0.5395038412567235,
      0.29001147163348295,
      0.44188519900088075,
      0.4714402408553606,
      0.41055576608344113,
      0.46972880075359313,
      0.21312698335221714,
      0.4970750737200571,
      0.5353444240737069,
      0.45437409930823525,
      0.0,
      0.32299585967897304,
      0.3968568382831308,
      0.4322122669019748,
      0.5111211003544187,
      0.420415991257699,
      0.4352677895336048,
      0.33369025529757335,
      0.5086146898710502,
      0.3526207916758257,
      0.4619055622330579,
      0.4288193735803729,
      0.34609102479276066,
      0.32460433763696006
    ],
    [
      0.40860706395805413,
      0.4282017099540263,
      0.5264534498303908,
      0.4599506600160925,
      0.4921908414826146,
      0.45083009003157604,
      0.37531524881462786,
      0.461239511989471,
      0.4729805872982955,
      0.538117194471263,
      0.4626069456650508,
      0.3379670106763826,
      0.418674418268691,
      0.4404029419009803,
      0.48133382744828723,
      0.4142538181214066,
      0.0,
      0.4732671341430772,
      0.4663321594307619,
      0.44930196596808947,
      0.4872925141226774,
      0.3832887173194357,
      0.38863152356433206,
      0.40225876357427426,
      0.435273243028087,
      0.5401552934222342,
      0.4779104508170229,
      0.398186061656302,
      0.37549751614790794
    ],
    [
      0.42043912624369484,
      0.5015578870372099,
      0.5602126005087105,
      0.5023770877225446,
      0.5966608310110126,
      0.45572736762412447,
      0.3465747104341912,
      0.4969774737170163,
      0.5011074286492359,
      0.4309793670464599,
      0.5270765709215308,
      0.31032196260596545,
      0.47485483057167865,
      0.43179459195481273,
      0.45610953617559,
      0.47442887154062063,
      0.3899146428641973,
      0.0,
      0.4425101483974563,
      0.5690556634280595,
      0.4870335147158098,
      0.3757439649592338,
      0.3193123446362087,
      0.49550606100534256,
      0.3748753179346831,
      0.5312717299957566,
      0.5601718378903189,
      0.40314582858635495,
      0.3433427201761172
    ],
    [
      0.3865292645149998,
      0.49007447862612463,
      0.5556291242752334,
      0.4986614546860617,
      0.465755717164438,
      0.5063151749274313,
      0.3803216848559752,
      0.5058943739289758,
      0.4666329561741085,
      0.4703561003670289,
      0.4766679955461357,
      0.303775745028269,
      0.4327598895800717,
      0.5168366580704782,
      0.47114652052637895,
      0.4142626072929221,
      0.4066108936375068,
      0.41487590016341014,
      0.0,
      0.4584024436518732,
      0.43946353830435325,
      0.4045930856986537,
      0.4093974298686798,
      0.48403986665152,
      0.42718619879499475,
      0.4999069410415371,
      0.4857417856631361,
      0.3737714093236286,
      0.4011198290820286
    ],
    [
      0.4215058359573356,
      0.4289864658253062,
      0.5709437705115559,
      0.49405456504813006,
      0.4909958205608975,
      0.4585325947457295,
      0.3473112321078622,
      0.4057530466442041,
      0.5215386789380061,
      0.44463943404272244,
      0.5188329200513779,
      0.27780911715103596,
      0.3884874723480618,
      0.47150511791572947,
      0.49422412425215834,
      0.49842842751652316,
      0.3993178627159262,
      0.432145957922482,
      0.4594983748267567,
      0.0,
      0.42672420432135505,
      0.3608467484568014,
      0.36755177400364936,
      0.47679089847464695,
      0.3793052009606419,
      0.483030267916285,
      0.4568421458973482,
      0.38901024054898015,
      0.36237361166233417
    ],
    [
      0.40672670289789314,
      0.4276794046918553,
      0.537823442328131,
      0.49554154486580004,
      0.5355171341917859,
      0.44930837396525014,
      0.2780547271246572,
      0.5410461796121111,
      0.5053763489539178,
      0.4583537514479241,
      0.4267618092621408,
      0.2579543578896921,
      0.37866097838422896,
      0.4455394327204285,
      0.4465070402033777,
      0.4153628081207288,
      0.3728556783358692,
      0.47440904469056355,
      0.4289007538441867,
      0.46775610568706294,
      0.0,
      0.38286008962040174,
      0.40146312631913994,
      0.43626839646176174,
      0.39189794447075177,
      0.5115354579219695,
      0.4636045395829309,
      0.36469031787411677,
      0.38292626673743513
    ],
    [
      0.31498922710762645,
      0.3494336048372002,
      0.37700787261669455,
      0.3733855237479964,
      0.36677212450318875,
      0.3444667701308468,
      0.2596257538930655,
      0.3242009859798949,
      0.36078734495364184,
      0.33996708908656803,
      0.3591748558497676,
      0.26279795064247957,
      0.3343377785997519,
      0.38863918365381767,
      0.3522317275475826,
      0.394533323200698,
      0.29272205366989534,
      0.3402186864211558,
      0.3399664264846951,
      0.37176170110408413,
      0.3516160487040634,
      0.0,
      0.30059945372922736,
      0.41169168836943815,
      0.33268012438449834,
      0.36983115448642545,
      0.3470733716424854,
      0.2965348720490175,
      0.3590405116267139
    ],
    [
      0.39769819408039253,
      0.3486625851016858,
      0.45140168763983035,
      0.3792291499401854,
      0.38189931202185656,
      0.4091282708339341,
      0.29592456659482713,
      0.397618713678485,
      0.4338093908168348,
      0.464420861134758,
      0.3951946588344255,
      0.2544440611060701,
      0.3358633516811862,
      0.3943273502885898,
      0.4698194183595892,
      0.3736344801161471,
      0.3592268489689936,
      0.34862530651719226,
      0.3917187637014792,
      0.4043532689589133,
      0.41259907457592715,
      0.32971692790182683,
      0.0,
      0.3902076461616337,
      0.39690312022924945,
      0.39731945412884806,
      0.35356298914489726,
      0.3735680942262134,
      0.36352069083738114
    ],
    [
      0.4125220566993095,
      0.41944653914799157,
      0.5072995577787025,
      0.43591692415702155,
      0.4370807860389183,
      0.4557575674550576,
      0.2895540119471667,
      0.47135236844634454,
      0.49679665747663515,
      0.36981636482591274,
      0.43616794485522914,
      0.228803951425103,
      0.3981081958193804,
      0.44554226827012045,
      0.40131967383824807,
      0.4829603112570322,
      0.3508978752915948,
      0.4163039273783584,
      0.44992635706277406,
      0.45967827347997003,
      0.45127020495435977,
      0.39324521312919347,
      0.34423824272091075,
      0.0,
      0.38116113686494524,
      0.44508198899292695,
      0.4509037440212429,
      0.3409426312949986,
      0.31395164514326446
    ],
    [
      0.3339085012051213,
      0.33283091175999635,
      0.41842914020299204,
      0.3598992889504895,
      0.3886549080804462,
      0.36224913695462524,
      0.27357532525857975,
      0.3932815167715671,
      0.3647452489370926,
      0.4763288607794125,
      0.3459333813107879,
      0.2545217070914463,
      0.3401831106335236,
      0.3332626244322776,
      0.41302155923421213,
      0.3210292209236125,
      0.3282071098717185,
      0.3333421020521161,
      0.3869025926061125,
      0.40121539548072227,
      0.38899603307340613,
      0.34031491860515417,
      0.4412508435595679,
      0.3950533116664845,
      0.0,
      0.3887747002533253,
      0.3954176364002917,
      0.3527521853530051,
      0.32282936372086457
    ],
    [
      0.39399092438475547,
      0.522521829813146,
      0.5555006750118909,
      0.4979979351512056,
      0.5156138233528045,
      0.4547165908674191,
      0.3122817069563475,
      0.48990028492438475,
      0.5327796614476266,
      0.4645447529490667,
      0.49964761269464875,
      0.32289511628901657,
      0.41453037407609306,
      0.4892775807060332,
      0.4903467188861941,
      0.4480139171170652,
      0.41277233298382354,
      0.46039200364294963,
      0.4818465700339132,
      0.4722273327682769,
      0.49999962007451937,
      0.41648200197340657,
      0.36115726951971006,
      0.4431050105290246,
      0.39260426295755035,
      0.0,
      0.4840556883633995,
      0.3950564634598954,
      0.36366896462293763
    ],
    [
      0.40350318076873326,
      0.48863283889911635,
      0.5792031692574553,
      0.5288482572391959,
      0.5677957145273984,
      0.4758488345818339,
      0.3187258708863181,
      0.5015021901105634,
      0.5455590000534436,
      0.48429663300031023,
      0.47779347532982097,
      0.27552499843273703,
      0.4556397403440471,
      0.4519729565336428,
      0.4263213426255561,
      0.44733504854215456,
      0.4192834006662931,
      0.5013107933110907,
      0.49245957164843945,
      0.5273900959830031,
      0.5240630460125415,
      0.38843015648920387,
      0.390144182318382,
      0.550814859556972,
      0.4369963633382796,
      0.48515857335758694,
      0.0,
      0.34301797643566645,
      0.36453812502424676
    ],
    [
      0.3852499385221988,
      0.3811967260009148,
      0.4448874889089831,
      0.32269606488696256,
      0.39426601541084105,
      0.43586399618901006,
      0.32445721858260734,
      0.4131678468905431,
      0.3900485077007263,
      0.38212047226266654,
      0.39849262293761134,
      0.30150304773708525,
      0.32735126555076977,
      0.3867290574765847,
      0.38738112703982397,
      0.39453128953397143,
      0.33540597298989683,
      0.3683924983543694,
      0.3839169961866724,
      0.42972679155856586,
      0.42135604542388205,
      0.37734677154479934,
      0.4032509122104546,
      0.4439608679466336,
      0.36971797710017595,
      0.4271770251852074,
      0.40528464264963504,
      0.0,
      0.3812348652121924
    ],
    [
      0.36003873977614576,
      0.38053259833130904,
      0.39560803862330296,
      0.37502674446324,
      0.3782009531551238,
      0.38490983723362104,
      0.3503388815094124,
      0.3716432259781308,
      0.38910604502293644,
      0.3627643770354445,
      0.38423305644305605,
      0.317318760276744,
      0.3458106504753673,
      0.40758692842850475,
      0.3966876844602243,
      0.3757343750969495,
      0.3163901936311122,
      0.364433730621716,
      0.3917890218316076,
      0.397469586828761,
      0.3770638342403856,
      0.45819022727479086,
      0.3722284103769198,
      0.3671974791702224,
      0.38314883585939885,
      0.3694726795437828,
      0.372675360598137,
      0.3788154997081259,
      0.0
    ]
  ],
  "row_avgs": [
    0.22808515488532416,
    0.46059566558713394,
    0.4285601332371379,
    0.455414685229683,
    0.4274187343906783,
    0.4325042919020611,
    0.36346645936832045,
    0.416943970382328,
    0.40249820727714314,
    0.40424405750262377,
    0.49613148190897166,
    0.271020632273375,
    0.4404181128786231,
    0.38318043133664814,
    0.4112231664626216,
    0.43101823799179606,
    0.444518595111479,
    0.45639585779835495,
    0.4480974666944984,
    0.43667806826156585,
    0.4316207770787897,
    0.3434316860365186,
    0.38229993705647686,
    0.41021594356331115,
    0.3638182369703196,
    0.4495688223413251,
    0.45900394268835826,
    0.38631121614263514,
    0.37587199128551685
  ],
  "col_avgs": [
    0.389344678106643,
    0.4383711544066409,
    0.495321360977603,
    0.45253107374664675,
    0.4528817835814589,
    0.4330688372513242,
    0.3082474549939014,
    0.43051957022538767,
    0.4652852724810557,
    0.4142181956575119,
    0.4370371933719682,
    0.27425106540966654,
    0.3931245359479602,
    0.44299483700400616,
    0.4275992879153037,
    0.4338408841897609,
    0.35031608952568377,
    0.40172265280759784,
    0.4220939613481753,
    0.44869445042533146,
    0.41937316641625116,
    0.3639703576379852,
    0.3507716961370472,
    0.44346396807601657,
    0.3737356415316234,
    0.44317521605128024,
    0.43390073100188126,
    0.3591945279976133,
    0.34150631942029264
  ],
  "combined_avgs": [
    0.3087149164959836,
    0.4494834099968874,
    0.46194074710737043,
    0.4539728794881649,
    0.44015025898606863,
    0.4327865645766926,
    0.3358569571811109,
    0.42373177030385784,
    0.43389173987909946,
    0.4092311265800678,
    0.4665843376404699,
    0.27263584884152076,
    0.4167713244132917,
    0.4130876341703271,
    0.4194112271889626,
    0.43242956109077846,
    0.3974173423185814,
    0.4290592553029764,
    0.43509571402133684,
    0.44268625934344863,
    0.42549697174752044,
    0.3537010218372519,
    0.36653581659676204,
    0.42683995581966383,
    0.36877693925097155,
    0.44637201919630265,
    0.44645233684511976,
    0.3727528720701242,
    0.35868915535290474
  ],
  "gppm": [
    565.5279095165725,
    576.2901452838283,
    547.3411963610305,
    570.8390367610016,
    567.6826563786891,
    576.761241600956,
    635.4242704082214,
    574.767916741432,
    561.7006022056933,
    584.705727882739,
    579.187632503915,
    647.4716739274435,
    597.1531525432977,
    573.3023986487406,
    580.2543181363052,
    576.375892216899,
    614.1934234829969,
    593.5086446891704,
    584.2399346709309,
    571.3379730898104,
    583.8536816670618,
    609.3506295374574,
    614.1220295748125,
    570.8779796182263,
    602.0327323766713,
    573.178779843647,
    577.6355059415044,
    610.784870464049,
    617.4981597534527
  ],
  "gppm_normalized": [
    1.260290042032189,
    1.3629697072663478,
    1.306336288624981,
    1.348272030707756,
    1.3433058544496994,
    1.3615190425507915,
    1.4986192608643756,
    1.3487231727536648,
    1.3256824768029087,
    1.3781322772182623,
    1.3616185595329393,
    1.5215707404897234,
    1.4093636892438277,
    1.3516266488987365,
    1.3670737511117357,
    1.3560576556032289,
    1.4439286125500679,
    1.3989813230759682,
    1.3748784815982433,
    1.3514262337992817,
    1.3714032627665058,
    1.4270718464778434,
    1.4391448005307066,
    1.3433303738801943,
    1.4166386171217862,
    1.3476312361424991,
    1.3608665768548218,
    1.4361861427450298,
    1.445024172492643
  ],
  "token_counts": [
    277,
    515,
    611,
    479,
    483,
    468,
    529,
    403,
    449,
    451,
    404,
    473,
    494,
    442,
    447,
    417,
    443,
    473,
    430,
    500,
    413,
    401,
    405,
    424,
    448,
    408,
    436,
    450,
    391,
    303,
    497,
    433,
    459,
    752,
    459,
    495,
    438,
    433,
    410,
    431,
    387,
    410,
    444,
    431,
    438,
    393,
    372,
    470,
    373,
    439,
    420,
    389,
    490,
    384,
    410,
    374,
    372,
    394,
    324,
    414,
    458,
    484,
    436,
    428,
    501,
    399,
    399,
    381,
    466,
    408,
    398,
    376,
    425,
    390,
    398,
    422,
    389,
    407,
    452,
    424,
    401,
    424,
    397,
    379,
    413,
    401,
    344,
    781,
    392,
    394,
    392,
    352,
    525,
    360,
    385,
    392,
    397,
    413,
    380,
    455,
    358,
    381,
    399,
    424,
    396,
    397,
    404,
    410,
    394,
    346,
    390,
    420,
    367,
    398,
    386,
    349,
    693,
    449,
    447,
    450,
    437,
    450,
    518,
    423,
    431,
    416,
    460,
    437,
    476,
    460,
    444,
    463,
    451,
    458,
    421,
    440,
    470,
    414,
    457,
    429,
    431,
    416,
    443,
    439,
    406,
    1366,
    431,
    451,
    431,
    382,
    435,
    379,
    402,
    392,
    554,
    420,
    469,
    441,
    450,
    466,
    420,
    414,
    410,
    438,
    442,
    378,
    440,
    388,
    437,
    397,
    387,
    391,
    431,
    399,
    1428,
    431,
    434,
    454,
    409,
    434,
    388,
    406,
    484,
    448,
    357,
    618,
    424,
    397,
    365,
    453,
    437,
    439,
    452,
    382,
    412,
    347,
    390,
    420,
    459,
    322,
    408,
    451,
    409,
    557,
    395,
    451,
    431,
    438,
    437,
    417,
    383,
    398,
    374,
    428,
    387,
    416,
    435,
    406,
    409,
    457,
    395,
    425,
    379,
    415,
    441,
    340,
    408,
    417,
    426,
    414,
    438,
    335,
    468,
    442,
    473,
    474,
    383,
    401,
    465,
    446,
    413,
    388,
    399,
    481,
    480,
    453,
    411,
    415,
    389,
    446,
    406,
    459,
    411,
    398,
    367,
    435,
    415,
    350,
    346,
    429,
    364,
    533,
    424,
    479,
    491,
    712,
    431,
    444,
    521,
    415,
    476,
    408,
    564,
    485,
    428,
    449,
    470,
    420,
    441,
    430,
    446,
    447,
    421,
    459,
    433,
    414,
    473,
    353,
    452,
    397,
    650,
    429,
    489,
    455,
    450,
    445,
    432,
    435,
    464,
    421,
    395,
    489,
    392,
    476,
    454,
    450,
    376,
    391,
    389,
    441,
    381,
    413,
    421,
    418,
    441,
    428,
    410,
    396,
    417
  ],
  "response_lengths": [
    3003,
    2443,
    2705,
    2626,
    2630,
    2580,
    2510,
    2545,
    2658,
    2392,
    2189,
    2842,
    2268,
    2760,
    2639,
    2574,
    2108,
    2308,
    2205,
    2407,
    2186,
    2323,
    2471,
    2356,
    2547,
    2406,
    2396,
    2139,
    2421
  ]
}